{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Homepage","text":"<p>Powertools for AWS Lambda (Python) is a developer toolkit to implement Serverless best practices and increase developer velocity.</p> Tip <p>Powertools for AWS Lambda (Python) is also available for Java, TypeScript, and .NET</p> Support this project by becoming a reference customer, sharing your work, or using Layers/SAR  <p>You can choose to support us in three ways:</p> <p>1) Become a reference customer. This gives us permission to list your company in our documentation.</p> <p>2) Share your work. Blog posts, video, sample projects you used Powertools!</p> <p>3) Use Lambda Layers or SAR, if possible. This helps us understand who uses Powertools for AWS Lambda (Python) in a non-intrusive way, and helps us gain future investments for other Powertools for AWS Lambda languages.</p> <p>When using Layers, you can add Powertools for AWS Lambda (Python) as a dev dependency (or as part of your virtual env) to not impact the development process.</p>"},{"location":"#install","title":"Install","text":"<p>You can install Powertools for AWS Lambda (Python) using one of the following options:</p> <ul> <li>Lambda Layer (x86_64): arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37</li> <li>Lambda Layer (arm64): arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37</li> <li>Pip: <code>pip install \"aws-lambda-powertools\"</code></li> </ul> Using Pip? You might need to install additional dependencies. <p>Tracer, Validation and Parser require additional dependencies. If you prefer to install all of them, use <code>pip install \"aws-lambda-powertools[all]\"</code>.</p> <p>For example:</p> <ul> <li>Tracer: <code>pip install \"aws-lambda-powertools[tracer]\"</code></li> <li>Validation: <code>pip install \"aws-lambda-powertools[validation]\"</code></li> <li>Parser: <code>pip install \"aws-lambda-powertools[parser]\"</code></li> <li>Tracer and Parser: <code>pip install \"aws-lambda-powertools[tracer,parser]\"</code></li> </ul>"},{"location":"#local-development","title":"Local development","text":"<p>Using Powertools for AWS Lambda (Python) via Lambda Layer? Simply add <code>\"aws-lambda-powertools[all]\"</code> as a development dependency.</p> <p>Powertools for AWS Lambda (Python) relies on the AWS SDK bundled in the Lambda runtime. This helps us achieve an optimal package size and initialization. However, when developing locally, you need to install AWS SDK as a development dependency (not as a production dependency):</p> <ul> <li>Pip: <code>pip install \"aws-lambda-powertools[aws-sdk]\"</code></li> <li>Poetry: <code>poetry add \"aws-lambda-powertools[aws-sdk]\" --group dev</code></li> <li>Pipenv: <code>pipenv install --dev \"aws-lambda-powertools[aws-sdk]\"</code></li> </ul> Why is that necessary? <p>Powertools for AWS Lambda (Python) relies on the AWS SDK being available to use in the target runtime (AWS Lambda).</p> <p>As a result, it affects your favorite IDE in terms of code auto-completion, or running your tests suite locally with no Lambda emulation such as AWS SAM CLI.</p> <p>A word about dependency resolution</p> <p>In this context, <code>[aws-sdk]</code> is an alias to the <code>boto3</code> package. Due to dependency resolution, it'll either install:</p> <ul> <li>(A) the SDK version available in Lambda runtime</li> <li>(B) a more up-to-date version if another package you use also depends on <code>boto3</code>, for example Powertools for AWS Lambda (Python) Tracer</li> </ul>"},{"location":"#lambda-layer","title":"Lambda Layer","text":"As of now, Container Image deployment (OCI) or inline Lambda functions do not support Lambda Layers. <p>Lambda Layer is a .zip file archive that can contain additional code, pre-packaged dependencies, data,  or configuration files. Layers promote code sharing and separation of responsibilities so that you can iterate faster on writing business logic.</p> <p>For our Layers, we compile and optimize all dependencies, and remove duplicate dependencies already available in the Lambda runtime to achieve the most optimal size.</p> <p>You can include Powertools for AWS Lambda (Python) Lambda Layer using AWS Lambda Console, or your preferred deployment framework.</p> Note: Click to expand and copy any regional Lambda Layer ARN x86_64arm64 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37 Note: Click to expand and copy code snippets for popular frameworks x86_64arm64 SAMServerless frameworkCDKTerraformPulumiAmplify <pre><code>MyLambdaFunction:\nType: AWS::Serverless::Function\nProperties:\nLayers:\n- !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\n</code></pre> <pre><code>functions:\nhello:\nhandler: lambda_function.lambda_handler\nlayers:\n- arn:aws:lambda:${aws:region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\n</code></pre> <pre><code>from aws_cdk import core, aws_lambda\n\nclass SampleApp(core.Construct):\n\n    def __init__(self, scope: core.Construct, id_: str, env: core.Environment) -&gt; None:\n        super().__init__(scope, id_)\n\n        powertools_layer = aws_lambda.LayerVersion.from_layer_version_arn(\n            self,\n            id=\"lambda-powertools\",\nlayer_version_arn=f\"arn:aws:lambda:{env.region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\"\n)\n        aws_lambda.Function(self,\n            'sample-app-lambda',\n            runtime=aws_lambda.Runtime.PYTHON_3_9,\nlayers=[powertools_layer]\n# other props...\n        )\n</code></pre> <pre><code>terraform {\nrequired_version = \"~&gt; 1.0.5\"\nrequired_providers {\naws = \"~&gt; 3.50.0\"\n}\n}\n\nprovider \"aws\" {\nregion  = \"{region}\"\n}\n\nresource \"aws_iam_role\" \"iam_for_lambda\" {\nname = \"iam_for_lambda\"\n\nassume_role_policy = &lt;&lt;EOF\n    {\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Action\": \"sts:AssumeRole\",\n          \"Principal\": {\n            \"Service\": \"lambda.amazonaws.com\"\n          },\n          \"Effect\": \"Allow\"\n        }\n      ]\n    }\n    EOF\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\nfilename      = \"lambda_function_payload.zip\"\nfunction_name = \"lambda_function_name\"\nrole          = aws_iam_role.iam_for_lambda.arn\nhandler       = \"index.test\"\nruntime       = \"python3.9\"\nlayers        = [\"arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\"]\nsource_code_hash = filebase64sha256(\"lambda_function_payload.zip\")\n}\n</code></pre> <pre><code>import json\nimport pulumi\nimport pulumi_aws as aws\n\nrole = aws.iam.Role(\"role\",\n    assume_role_policy=json.dumps({\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n        \"Action\": \"sts:AssumeRole\",\n        \"Principal\": {\n            \"Service\": \"lambda.amazonaws.com\"\n        },\n        \"Effect\": \"Allow\"\n        }\n    ]\n    }),\n    managed_policy_arns=[aws.iam.ManagedPolicy.AWS_LAMBDA_BASIC_EXECUTION_ROLE]\n)\n\nlambda_function = aws.lambda_.Function(\"function\",\n    layers=[pulumi.Output.concat(\"arn:aws:lambda:\",aws.get_region_output().name,\":017000801446:layer:AWSLambdaPowertoolsPythonV2:11\")],\n    tracing_config={\n        \"mode\": \"Active\"\n    },\n    runtime=aws.lambda_.Runtime.PYTHON3D9,\n    handler=\"index.handler\",\n    role=role.arn,\n    architectures=[\"x86_64\"],\n    code=pulumi.FileArchive(\"lambda_function_payload.zip\")\n)\n</code></pre> <pre><code># Create a new one with the layer\n\u276f amplify add function\n? Select which capability you want to add: Lambda function (serverless function)\n? Provide an AWS Lambda function name: &lt;NAME-OF-FUNCTION&gt;\n? Choose the runtime that you want to use: Python\n? Do you want to configure advanced settings? Yes\n...\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\n\u276f amplify push -y\n\n\n# Updating an existing function and add the layer\n\u276f amplify update function\n? Select the Lambda function you want to update test2\nGeneral information\n- Name: &lt;NAME-OF-FUNCTION&gt;\n? Which setting do you want to update? Lambda layers configuration\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\n? Do you want to edit the local lambda function now? No\n</code></pre> SAMServerless frameworkCDKTerraformPulumiAmplify <pre><code>MyLambdaFunction:\nType: AWS::Serverless::Function\nProperties:\nArchitectures: [arm64]\nLayers:\n- !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37\n</code></pre> <pre><code>functions:\nhello:\nhandler: lambda_function.lambda_handler\narchitecture: arm64\nlayers:\n- arn:aws:lambda:${aws:region}:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37\n</code></pre> <pre><code>from aws_cdk import core, aws_lambda\n\nclass SampleApp(core.Construct):\n\n    def __init__(self, scope: core.Construct, id_: str, env: core.Environment) -&gt; None:\n        super().__init__(scope, id_)\n\n        powertools_layer = aws_lambda.LayerVersion.from_layer_version_arn(\n            self,\n            id=\"lambda-powertools\",\nlayer_version_arn=f\"arn:aws:lambda:{env.region}:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37\"\n)\n        aws_lambda.Function(self,\n            'sample-app-lambda',\n            runtime=aws_lambda.Runtime.PYTHON_3_9,\n            architecture=aws_lambda.Architecture.ARM_64,\nlayers=[powertools_layer]\n# other props...\n        )\n</code></pre> <pre><code>terraform {\nrequired_version = \"~&gt; 1.0.5\"\nrequired_providers {\naws = \"~&gt; 3.50.0\"\n}\n}\n\nprovider \"aws\" {\nregion  = \"{region}\"\n}\n\nresource \"aws_iam_role\" \"iam_for_lambda\" {\nname = \"iam_for_lambda\"\n\nassume_role_policy = &lt;&lt;EOF\n    {\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Action\": \"sts:AssumeRole\",\n          \"Principal\": {\n            \"Service\": \"lambda.amazonaws.com\"\n          },\n          \"Effect\": \"Allow\"\n        }\n      ]\n    }\n    EOF\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\nfilename      = \"lambda_function_payload.zip\"\nfunction_name = \"lambda_function_name\"\nrole          = aws_iam_role.iam_for_lambda.arn\nhandler       = \"index.test\"\nruntime       = \"python3.9\"\nlayers        = [\"arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37\"]\narchitectures = [\"arm64\"]\n\nsource_code_hash = filebase64sha256(\"lambda_function_payload.zip\")\n}\n</code></pre> <pre><code>import json\nimport pulumi\nimport pulumi_aws as aws\n\nrole = aws.iam.Role(\"role\",\n    assume_role_policy=json.dumps({\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n        \"Action\": \"sts:AssumeRole\",\n        \"Principal\": {\n            \"Service\": \"lambda.amazonaws.com\"\n        },\n        \"Effect\": \"Allow\"\n        }\n    ]\n    }),\n    managed_policy_arns=[aws.iam.ManagedPolicy.AWS_LAMBDA_BASIC_EXECUTION_ROLE]\n)\n\nlambda_function = aws.lambda_.Function(\"function\",\n    layers=[pulumi.Output.concat(\"arn:aws:lambda:\",aws.get_region_output().name,\":017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:11\")],\n    tracing_config={\n        \"mode\": \"Active\"\n    },\n    runtime=aws.lambda_.Runtime.PYTHON3D9,\n    handler=\"index.handler\",\n    role=role.arn,\n    architectures=[\"arm64\"],\n    code=pulumi.FileArchive(\"lambda_function_payload.zip\")\n)\n</code></pre> <pre><code># Create a new one with the layer\n\u276f amplify add function\n? Select which capability you want to add: Lambda function (serverless function)\n? Provide an AWS Lambda function name: &lt;NAME-OF-FUNCTION&gt;\n? Choose the runtime that you want to use: Python\n? Do you want to configure advanced settings? Yes\n...\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37\n\u276f amplify push -y\n\n\n# Updating an existing function and add the layer\n\u276f amplify update function\n? Select the Lambda function you want to update test2\nGeneral information\n- Name: &lt;NAME-OF-FUNCTION&gt;\n? Which setting do you want to update? Lambda layers configuration\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV2-Arm64:37\n? Do you want to edit the local lambda function now? No\n</code></pre> Want to inspect the contents of the Layer? <p>Change {region} to your AWS region, e.g. <code>eu-west-1</code></p> AWS CLI<pre><code>aws lambda get-layer-version-by-arn --arn arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37 --region {region}\n</code></pre> <p>The pre-signed URL to download this Lambda Layer will be within <code>Location</code> key.</p>"},{"location":"#sar","title":"SAR","text":"<p>Serverless Application Repository (SAR) App deploys a CloudFormation stack with a copy of our Lambda Layer in your AWS account and region.</p> <p>Compared with the public Layer ARN option, SAR allows you to choose a semantic version and deploys a Layer in your target account.</p> App ARN Description aws-lambda-powertools-python-layer arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer Contains all extra dependencies (e.g: pydantic). aws-lambda-powertools-python-layer-arm64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-arm64 Contains all extra dependencies (e.g: pydantic). For arm64 functions. Click to expand and copy SAR code snippets for popular frameworks <p>You can create a shared Lambda Layers stack and make this along with other account level layers stack.</p> SAMServerless frameworkCDKTerraform <pre><code>AwsLambdaPowertoolsPythonLayer:\nType: AWS::Serverless::Application\nProperties:\nLocation:\nApplicationId: arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer\nSemanticVersion: 2.0.0 # change to latest semantic version available in SAR\nMyLambdaFunction:\nType: AWS::Serverless::Function\nProperties:\nLayers:\n# fetch Layer ARN from SAR App stack output\n- !GetAtt AwsLambdaPowertoolsPythonLayer.Outputs.LayerVersionArn\n</code></pre> <pre><code>functions:\nmain:\nhandler: lambda_function.lambda_handler\nlayers:\n- !GetAtt AwsLambdaPowertoolsPythonLayer.Outputs.LayerVersionArn\nresources:\nTransform: AWS::Serverless-2016-10-31\nResources:****\nAwsLambdaPowertoolsPythonLayer:\nType: AWS::Serverless::Application\nProperties:\nLocation:\nApplicationId: arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer\n# Find latest from github.com/aws-powertools/powertools-lambda-python/releases\nSemanticVersion: 2.0.0\n</code></pre> <pre><code>from aws_cdk import core, aws_sam as sam, aws_lambda\n\nPOWERTOOLS_BASE_NAME = 'AWSLambdaPowertools'\n# Find latest from github.com/aws-powertools/powertools-lambda-python/releases\nPOWERTOOLS_VER = '2.0.0'\nPOWERTOOLS_ARN = 'arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer'\n\nclass SampleApp(core.Construct):\n\n    def __init__(self, scope: core.Construct, id_: str) -&gt; None:\n        super().__init__(scope, id_)\n\n        # Launches SAR App as CloudFormation nested stack and return Lambda Layer\npowertools_app = sam.CfnApplication(self,\nf'{POWERTOOLS_BASE_NAME}Application',\n            location={\n                'applicationId': POWERTOOLS_ARN,\n                'semanticVersion': POWERTOOLS_VER\n            },\n        )\n\npowertools_layer_arn = powertools_app.get_att(\"Outputs.LayerVersionArn\").to_string()\npowertools_layer_version = aws_lambda.LayerVersion.from_layer_version_arn(self, f'{POWERTOOLS_BASE_NAME}', powertools_layer_arn)\naws_lambda.Function(self,\n            'sample-app-lambda',\n            runtime=aws_lambda.Runtime.PYTHON_3_8,\n            function_name='sample-lambda',\n            code=aws_lambda.Code.asset('./src'),\n            handler='app.handler',\nlayers: [powertools_layer_version]\n)\n</code></pre> <p>Credits to Dani Comnea for providing the Terraform equivalent.</p> <pre><code>terraform {\nrequired_version = \"~&gt; 0.13\"\nrequired_providers {\naws = \"~&gt; 3.50.0\"\n}\n}\n\nprovider \"aws\" {\nregion  = \"us-east-1\"\n}\n\nresource \"aws_serverlessapplicationrepository_cloudformation_stack\" \"deploy_sar_stack\" {\nname = \"aws-lambda-powertools-python-layer\"\napplication_id   = data.aws_serverlessapplicationrepository_application.sar_app.application_id\nsemantic_version = data.aws_serverlessapplicationrepository_application.sar_app.semantic_version\ncapabilities = [\n\"CAPABILITY_IAM\",\n\"CAPABILITY_NAMED_IAM\"\n]\n}\n\ndata \"aws_serverlessapplicationrepository_application\" \"sar_app\" {\napplication_id   = \"arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer\"\nsemantic_version = var.aws_powertools_version\n}\n\nvariable \"aws_powertools_version\" {\ntype        = string\ndefault     = \"2.0.0\"\ndescription = \"The Powertools for AWS Lambda (Python) release version\"\n}\n\noutput \"deployed_powertools_sar_version\" {\nvalue = data.aws_serverlessapplicationrepository_application.sar_app.semantic_version\n}\n\n# Fetch Powertools for AWS Lambda (Python) Layer ARN from deployed SAR App\noutput \"aws_lambda_powertools_layer_arn\" {\nvalue = aws_serverlessapplicationrepository_cloudformation_stack.deploy_sar_stack.outputs.LayerVersionArn\n}\n</code></pre> Example: Least-privileged IAM permissions to deploy Layer <p>Credits to mwarkentin for providing the scoped down IAM permissions.</p> <p>The region and the account id for <code>CloudFormationTransform</code> and <code>GetCfnTemplate</code> are fixed.</p> template.yml <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nResources:\nPowertoolsLayerIamRole:\nType: \"AWS::IAM::Role\"\nProperties:\nAssumeRolePolicyDocument:\nVersion: \"2012-10-17\"\nStatement:\n- Effect: \"Allow\"\nPrincipal:\nService:\n- \"cloudformation.amazonaws.com\"\nAction:\n- \"sts:AssumeRole\"\nPath: \"/\"\nPowertoolsLayerIamPolicy:\nType: \"AWS::IAM::Policy\"\nProperties:\nPolicyName: PowertoolsLambdaLayerPolicy\nPolicyDocument:\nVersion: \"2012-10-17\"\nStatement:\n- Sid: CloudFormationTransform\nEffect: Allow\nAction: cloudformation:CreateChangeSet\nResource:\n- arn:aws:cloudformation:us-east-1:aws:transform/Serverless-2016-10-31\n- Sid: GetCfnTemplate\nEffect: Allow\nAction:\n- serverlessrepo:CreateCloudFormationTemplate\n- serverlessrepo:GetCloudFormationTemplate\nResource:\n# this is arn of the Powertools for AWS Lambda (Python) SAR app\n- arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer\n- Sid: S3AccessLayer\nEffect: Allow\nAction:\n- s3:GetObject\nResource:\n# AWS publishes to an external S3 bucket locked down to your account ID\n# The below example is us publishing Powertools for AWS Lambda (Python)\n# Bucket: awsserverlessrepo-changesets-plntc6bfnfj\n# Key: *****/arn:aws:serverlessrepo:eu-west-1:057560766410:applications-aws-lambda-powertools-python-layer-versions-1.10.2/aeeccf50-****-****-****-*********\n- arn:aws:s3:::awsserverlessrepo-changesets-*/*\n- Sid: GetLayerVersion\nEffect: Allow\nAction:\n- lambda:PublishLayerVersion\n- lambda:GetLayerVersion\nResource:\n- !Sub arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:layer:aws-lambda-powertools-python-layer*\nRoles:\n- Ref: \"PowertoolsLayerIamRole\"\n</code></pre> Click to expand and copy an AWS CLI command to list all versions available in SAR <p>You can fetch available versions via SAR ListApplicationVersions API:</p> AWS CLI example<pre><code>aws serverlessrepo list-application-versions \\\n--application-id arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer\n</code></pre>"},{"location":"#quick-getting-started","title":"Quick getting started","text":"Hello world example using SAM CLI<pre><code>sam init --app-template hello-world-powertools-python --name sam-app --package-type Zip --runtime python3.10 --no-tracing\n</code></pre>"},{"location":"#features","title":"Features","text":"<p>Core utilities such as Tracing, Logging, Metrics, and Event Handler will be available across all Powertools for AWS Lambda languages. Additional utilities are subjective to each language ecosystem and customer demand.</p> Utility Description Tracing Decorators and utilities to trace Lambda function handlers, and both synchronous and asynchronous functions Logger Structured logging made easier, and decorator to enrich structured logging with key Lambda context details Metrics Custom Metrics created asynchronously via CloudWatch Embedded Metric Format (EMF) Event handler: AppSync AppSync event handler for Lambda Direct Resolver and Amplify GraphQL Transformer function Event handler: API Gateway, ALB and Lambda Function URL Amazon API Gateway REST/HTTP API and ALB event handler for Lambda functions invoked using Proxy integration, and Lambda Function URL Middleware factory Decorator factory to create your own middleware to run logic before, and after each Lambda invocation Parameters Retrieve parameter values from AWS Systems Manager Parameter Store, AWS Secrets Manager, or Amazon DynamoDB, and cache them for a specific amount of time Batch processing Handle partial failures for AWS SQS batch processing Typing Static typing classes to speedup development in your IDE Validation JSON Schema validator for inbound events and responses Event source data classes Data classes describing the schema of common Lambda event triggers Parser Data parsing and deep validation using Pydantic Idempotency Idempotent Lambda handler Feature Flags A simple rule engine to evaluate when one or multiple features should be enabled depending on the input Streaming Streams datasets larger than the available memory as streaming data."},{"location":"#environment-variables","title":"Environment variables","text":"Info <p>Explicit parameters take precedence over environment variables</p> Environment variable Description Utility Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All <code>\"service_undefined\"</code> POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics <code>None</code> POWERTOOLS_TRACE_DISABLED Explicitly disables tracing Tracing <code>false</code> POWERTOOLS_TRACER_CAPTURE_RESPONSE Captures Lambda or method return as metadata. Tracing <code>true</code> POWERTOOLS_TRACER_CAPTURE_ERROR Captures Lambda or method exception as metadata. Tracing <code>true</code> POWERTOOLS_TRACE_MIDDLEWARES Creates sub-segment for each custom middleware Middleware factory <code>false</code> POWERTOOLS_LOGGER_LOG_EVENT Logs incoming event Logging <code>false</code> POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging <code>0</code> POWERTOOLS_LOG_DEDUPLICATION_DISABLED Disables log deduplication filter protection to use Pytest Live Log feature Logging <code>false</code> POWERTOOLS_PARAMETERS_MAX_AGE Adjust how long values are kept in cache (in seconds) Parameters <code>5</code> POWERTOOLS_PARAMETERS_SSM_DECRYPT Sets whether to decrypt or not values retrieved from AWS SSM Parameters Store Parameters <code>false</code> POWERTOOLS_DEV Increases verbosity across utilities Multiple; see POWERTOOLS_DEV effect below <code>false</code> LOG_LEVEL Sets logging level Logging <code>INFO</code>"},{"location":"#optimizing-for-non-production-environments","title":"Optimizing for non-production environments","text":"<p>Whether you're prototyping locally or against a non-production environment, you can use <code>POWERTOOLS_DEV</code> to increase verbosity across multiple utilities.</p> Info <p>We will emit a warning when <code>POWERTOOLS_DEV</code> is enabled to help you detect misuse in production environments.</p> <p>When <code>POWERTOOLS_DEV</code> is set to a truthy value (<code>1</code>, <code>true</code>), it'll have the following effects:</p> Utility Effect Logger Increase JSON indentation to 4. This will ease local debugging when running functions locally under emulators or direct calls while not affecting unit tests Event Handler Enable full traceback errors in the response, indent request/responses, and CORS in dev mode (<code>*</code>). Tracer Future-proof safety to disables tracing operations in non-Lambda environments. This already happens automatically in the Tracer utility."},{"location":"#debug-mode","title":"Debug mode","text":"<p>As a best practice for libraries, Powertools module logging statements are suppressed.</p> <p>When necessary, you can use <code>POWERTOOLS_DEBUG</code> environment variable to enable debugging. This will provide additional information on every internal operation.</p>"},{"location":"#how-to-support-powertools-for-aws-lambda-python","title":"How to support Powertools for AWS Lambda (Python)?","text":""},{"location":"#becoming-a-reference-customer","title":"Becoming a reference customer","text":"<p>Knowing which companies are using this library is important to help prioritize the project internally. If your company is using Powertools for AWS Lambda (Python), you can request to have your name and logo added to the README file by raising a Support Powertools for AWS Lambda (Python) (become a reference) issue.</p> <p>The following companies, among others, use Powertools:</p> <ul> <li>Capital One</li> <li>CPQi (Exadel Financial Services)</li> <li>CloudZero</li> <li>CyberArk</li> <li>globaldatanet</li> <li>IMS</li> <li>Propellor.ai</li> <li>TopSport</li> <li>Trek10</li> </ul>"},{"location":"#sharing-your-work","title":"Sharing your work","text":"<p>Share what you did with Powertools for AWS Lambda (Python) \ud83d\udc9e\ud83d\udc9e. Blog post, workshops, presentation, sample apps and others. Check out what the community has already shared about Powertools for AWS Lambda (Python) here.</p>"},{"location":"#using-lambda-layer-or-sar","title":"Using Lambda Layer or SAR","text":"<p>This helps us understand who uses Powertools for AWS Lambda (Python) in a non-intrusive way, and helps us gain future investments for other Powertools for AWS Lambda languages. When using Layers, you can add Powertools for AWS Lambda (Python) as a dev dependency (or as part of your virtual env) to not impact the development process.</p>"},{"location":"#tenets","title":"Tenets","text":"<p>These are our core principles to guide our decision making.</p> <ul> <li>AWS Lambda only. We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported.</li> <li>Eases the adoption of best practices. The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional.</li> <li>Keep it lean. Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time.</li> <li>We strive for backwards compatibility. New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined.</li> <li>We work backwards from the community. We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs)</li> <li>Progressive. Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community\u2019s common practices.</li> </ul>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>docs: ensure alias is applied to versioned releases (#2644)</li> <li>docs: ensure version alias is in an array to prevent \"you're not viewing the latest version\" incorrect message (#2629)</li> </ul>"},{"location":"changelog/#code-refactoring","title":"Code Refactoring","text":"<ul> <li>parser: convert functional tests to unit tests (#2656)</li> </ul>"},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>contributing: add code integration journey graph (#2685)</li> <li>maintainers: add cicd pipeline diagram (#2692)</li> </ul>"},{"location":"changelog/#maintenance","title":"Maintenance","text":"<ul> <li>ci: add gitleaks in pre-commit hooks as an extra safety measure (#2677)</li> <li>ci: use deps sha for docs and gitpod images based on ossf findings (#2662)</li> <li>ci: prevent merging PRs that do not meet minimum requirements (#2639)</li> <li>ci: enforce top-level permission to minimum fail-safe permission as per openssf (#2638)</li> <li>ci: propagate checkout permission to nested workflows (#2642)</li> <li>ci: improves dependabot based on ossf scorecard recommendations (#2647)</li> <li>ci: address ossf scorecard findings on npm, pip, and top-level permission leftover (#2694)</li> <li>ci: use sast on every commit on any supported language (#2646)</li> <li>ci: enforce pip --require-hashes to maybe satistify scorecard (#2679)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/service/lambda from 1.24.6 to 1.37.0 in /layer/scripts/layer-balancer (#2653)</li> <li>deps: bump pydantic from 1.10.10 to 1.10.11 (#2671)</li> <li>deps: bump actions/dependency-review-action from 2.5.1 to 3.0.6 (#2650)</li> <li>deps: bump squidfunk/mkdocs-material from <code>3837c0f</code> to <code>a28ed81</code> in /docs (#2669)</li> <li>deps: bump golang.org/x/sync from 0.1.0 to 0.3.0 in /layer/scripts/layer-balancer (#2649)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2 from 1.16.16 to 1.18.1 in /layer/scripts/layer-balancer (#2654)</li> <li>deps: migrate from retry to retry2 to address CVE-2022-42969 (#2665)</li> <li>deps: bump actions/setup-node from 3.6.0 to 3.7.0 (#2689)</li> <li>deps: bump pydantic from 1.10.9 to 1.10.10 (#2624)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.17.8 to 1.18.27 in /layer/scripts/layer-balancer (#2651)</li> <li>deps-dev: bump sentry-sdk from 1.26.0 to 1.27.0 (#2652)</li> <li>deps-dev: bump ruff from 0.0.275 to 0.0.276 (#2655)</li> <li>deps-dev: bump typed-ast from 1.5.4 to 1.5.5 (#2670)</li> <li>deps-dev: bump ruff from 0.0.276 to 0.0.277 (#2682)</li> <li>deps-dev: bump sentry-sdk from 1.27.0 to 1.27.1 (#2701)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.27.0 to 1.28.0 (#2700)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.27.0 to 1.28.0 (#2699)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.27.0 to 1.28.0 (#2698)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.26.70 to 1.27.0 (#2636)</li> <li>deps-dev: bump aws-cdk from 2.86.0 to 2.87.0 (#2696)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.158 to 1.26.164 (#2622)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.27.0 to 1.28.0 (#2697)</li> <li>user-agent: support patching botocore session (#2614)</li> </ul>"},{"location":"changelog/#v2190-2023-06-30","title":"v2.19.0 - 2023-06-30","text":""},{"location":"changelog/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>e2e: fix idempotency tests (#2576)</li> </ul>"},{"location":"changelog/#code-refactoring_1","title":"Code Refactoring","text":"<ul> <li>event_source: convert functional tests to unit tests (#2506)</li> </ul>"},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>i-made-this: added new article on idempotency (#2582)</li> <li>i-made-this: article on idempotency w/ CDK and Powertools (#2569)</li> <li>idempotency: split snippets, improve wording and lint examples (#2492)</li> </ul>"},{"location":"changelog/#features","title":"Features","text":"<ul> <li>event_handler: add VPCLatticeResolver (#2601)</li> <li>event_source: decode nested messages on SQS events (#2349)</li> <li>parser: add support to VpcLatticeModel (#2584)</li> </ul>"},{"location":"changelog/#maintenance_1","title":"Maintenance","text":"<ul> <li>version bump</li> <li>analytics: update docs base origin url (#2560)</li> <li>ci: replace flake8 with Ruff as a linter (#2495)</li> <li>ci: enable Ruff rule E501 and fix errors (#2587)</li> <li>ci: enable Ruff rule COM812 and fix the errors (#2595)</li> <li>ci: enable Ruff rules PLW, PLR, PLC and PLE and fix the errors (#2593)</li> <li>ci: enable Ruff autofix rules (#2599)</li> <li>ci: enable Ruff rules ISC, I001, B018 and fix the errors (#2597)</li> <li>ci: enable Ruff rule ERA001 and fix errors (#2591)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.6 to 1.8.7 (#2573)</li> <li>deps: bump docker/setup-buildx-action from 2.7.0 to 2.8.0 (#2604)</li> <li>deps: bump ossf/scorecard-action from 2.1.3 to 2.2.0 (#2563)</li> <li>deps: bump release-drafter/release-drafter from 5.23.0 to 5.24.0 (#2603)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.155 to 1.26.163 (#2608)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.157 to 1.26.163 (#2607)</li> <li>deps-dev: bump mkdocs-material from 9.1.16 to 9.1.17 (#2564)</li> <li>deps-dev: bump ruff from 0.0.272 to 0.0.275 (#2586)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.97 to 1.26.162 (#2606)</li> <li>deps-dev: bump pytest from 7.3.2 to 7.4.0 (#2557)</li> <li>deps-dev: bump aws-cdk from 2.85.0 to 2.86.0 (#2613)</li> <li>deps-dev: bump mypy from 1.4.0 to 1.4.1 (#2574)</li> </ul>"},{"location":"changelog/#v2180-2023-06-23","title":"v2.18.0 - 2023-06-23","text":""},{"location":"changelog/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>docs: ensure versions.json is updated (#2505)</li> <li>event_source: centralizing helper functions for query, header and base64 (#2496)</li> </ul>"},{"location":"changelog/#documentation_2","title":"Documentation","text":"<ul> <li>homepage: fix .NET repository link (#2549)</li> <li>homepage: add Open Source Security Foundation badge; update links to new url (#2545)</li> <li>navigation: make Key Feature the first section (#2517)</li> </ul>"},{"location":"changelog/#features_1","title":"Features","text":"<ul> <li>event_handler: support to enable or disable compression in custom responses (#2544)</li> <li>feature_flags: add modulo range condition for segmented experimentation support (#2331)</li> </ul>"},{"location":"changelog/#maintenance_2","title":"Maintenance","text":"<ul> <li>version bump</li> <li>ci: fix changelog build permissions (#2519)</li> <li>ci: remove GH pages action (#2501)</li> <li>ci: updates runner names in workflows (#2510)</li> <li>ci: introduces OSSF Scorecard (#2512)</li> <li>ci: fix codeowners team name (#2516)</li> <li>deps: bump actions/upload-artifact from 3.1.0 to 3.1.2 (#2522)</li> <li>deps: bump actions/checkout from 3.1.0 to 3.5.3 (#2523)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.153 to 1.26.155 (#2498)</li> <li>deps-dev: bump aws-cdk from 2.84.0 to 2.85.0 (#2524)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.147 to 1.26.157 (#2507)</li> <li>deps-dev: bump cfn-lint from 0.77.9 to 0.77.10 (#2508)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.149 to 1.26.156 (#2503)</li> <li>deps-dev: bump sentry-sdk from 1.25.1 to 1.26.0 (#2527)</li> <li>deps-dev: bump hvac from 1.1.0 to 1.1.1 (#2497)</li> <li>deps-dev: bump flake8-variables-names from 0.0.5 to 0.0.6 (#2525)</li> <li>deps-dev: bump ijson from 3.2.1 to 3.2.2 (#2526)</li> <li>deps-dev: bump pytest-mock from 3.10.0 to 3.11.1 (#2485)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.152 to 1.26.158 (#2528)</li> <li>deps-dev: bump mypy from 1.3.0 to 1.4.0 (#2509)</li> <li>documentation: updating repository URL and name to the new location (#2499)</li> </ul>"},{"location":"changelog/#v2170-2023-06-16","title":"v2.17.0 - 2023-06-16","text":""},{"location":"changelog/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>event_handler: prioritize static over dynamic route to prevent order of route registration mismatch (#2458)</li> <li>idempotency: treat missing idempotency key as non-idempotent transaction (no-op) when raise_on_no_idempotency_key is False (#2477)</li> </ul>"},{"location":"changelog/#documentation_3","title":"Documentation","text":"<ul> <li>event_handler: improve compress example using Response class (#2426)</li> <li>event_sources: fix DynamoDB stream event docstring (#2468)</li> <li>idempotency: new sequence flow when idempotency key is optional (#2480)</li> <li>idempotency: add CDK example (#2434)</li> <li>maintainers: visual representation of release process (#2399)</li> <li>navigation: standardize link targets to enhance customer experience (#2420)</li> <li>we-made-this: new article about idempotency design (#2425)</li> </ul>"},{"location":"changelog/#features_2","title":"Features","text":"<ul> <li>event_sources: add AWS Config Rule event data class (#2175)</li> <li>event_sources: add support for VPC Lattice events (#2358)</li> <li>logger: type log record in LambdaPowertoolsFormatter with TypedDict (#2419)</li> <li>parser: support for CloudFormation Custom Resources (#2335)</li> </ul>"},{"location":"changelog/#maintenance_3","title":"Maintenance","text":"<ul> <li>version bump</li> <li>ci: document all github action workflows and enforce least-privilege (#2395)</li> <li>ci: fix PR labeling permission scope (#2396)</li> <li>deps: bump aws-actions/configure-aws-credentials from 2.1.0 to 2.2.0 (#2469)</li> <li>deps: bump docker/setup-buildx-action from 2.5.0 to 2.6.0 (#2403)</li> <li>deps: bump docker/setup-qemu-action from 2.1.0 to 2.2.0 (#2404)</li> <li>deps: bump docker/setup-buildx-action from 2.6.0 to 2.7.0 (#2450)</li> <li>deps: bump pydantic from 1.10.8 to 1.10.9 (#2405)</li> <li>deps: bump actions/checkout from 3.5.2 to 3.5.3 (#2431)</li> <li>deps-dev: bump ijson from 3.2.0.post0 to 3.2.1 (#2441)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.115 to 1.26.152 (#2444)</li> <li>deps-dev: bump filelock from 3.12.0 to 3.12.2 (#2446)</li> <li>deps-dev: bump aws-cdk from 2.83.0 to 2.83.1 (#2432)</li> <li>deps-dev: bump cfn-lint from 0.77.6 to 0.77.7 (#2414)</li> <li>deps-dev: bump pytest from 7.3.1 to 7.3.2 (#2443)</li> <li>deps-dev: bump sentry-sdk from 1.25.0 to 1.25.1 (#2408)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.147 to 1.26.149 (#2410)</li> <li>deps-dev: bump aws-cdk from 2.82.0 to 2.83.0 (#2406)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.53 to 1.26.149 (#2409)</li> <li>deps-dev: bump cfn-lint from 0.77.7 to 0.77.8 (#2451)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.127 to 1.26.153 (#2452)</li> <li>deps-dev: bump cfn-lint from 0.77.8 to 0.77.9 (#2472)</li> <li>deps-dev: bump flake8-comprehensions from 3.12.0 to 3.13.0 (#2471)</li> <li>deps-dev: bump mkdocs-material from 9.1.15 to 9.1.16 (#2470)</li> <li>deps-dev: bump aws-cdk from 2.83.1 to 2.84.0 (#2460)</li> </ul>"},{"location":"changelog/#v2162-2023-06-06","title":"v2.16.2 - 2023-06-06","text":""},{"location":"changelog/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>parameters: AppConfigProvider when retrieving multiple unique configuration names (#2378)</li> <li>shared: move to static version bumping to prevent issues with customers custom builds (#2386)</li> </ul>"},{"location":"changelog/#maintenance_4","title":"Maintenance","text":"<ul> <li>version bump</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.108 to 1.26.147 (#2383)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.122 to 1.26.147 (#2382)</li> <li>deps-dev: bump sentry-sdk from 1.24.0 to 1.25.0 (#2374)</li> <li>deps-dev: bump aws-cdk from 2.81.0 to 2.82.0 (#2373)</li> <li>typing: add setLevel and addHandler to Logger for mypy/pyright (#2388)</li> </ul>"},{"location":"changelog/#v2161-2023-06-02","title":"v2.16.1 - 2023-06-02","text":""},{"location":"changelog/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>shared: skip user agent on much older botocore versions (#2366)</li> </ul>"},{"location":"changelog/#maintenance_5","title":"Maintenance","text":"<ul> <li>version bump</li> </ul>"},{"location":"changelog/#v2160-2023-06-02","title":"v2.16.0 - 2023-06-02","text":""},{"location":"changelog/#bug-fixes_6","title":"Bug Fixes","text":"<ul> <li>docs: use concrete secrets from settings (#2322)</li> <li>event_source: change the import location of boto3 in CodePipelineJobEvent data class (#2353)</li> <li>logger: add setLevel function to set level programmatically (#2320)</li> </ul>"},{"location":"changelog/#code-refactoring_2","title":"Code Refactoring","text":"<ul> <li>logger: remove subclassing and move unnecessary APIs (#2334)</li> </ul>"},{"location":"changelog/#documentation_4","title":"Documentation","text":"<ul> <li>batch: add encryption at rest for SQS (#2290)</li> <li>batch_processing: snippets split, improved, and lint (#2231)</li> <li>feature_flags: snippets split, improved, and lint (#2222)</li> <li>project: rename project to Powertools for AWS Lambda (Python) (#2313)</li> </ul>"},{"location":"changelog/#features_3","title":"Features","text":"<ul> <li>docs: Move docs to S3 (#2277)</li> <li>event_source: allow multiple CORS origins (#2279)</li> <li>parser: add support for parsing SQS events wrapped in Kinesis Firehose (#2294)</li> <li>user-agent: add custom header User-Agent to AWS SDK requests (#2267)</li> </ul>"},{"location":"changelog/#maintenance_6","title":"Maintenance","text":"<ul> <li>version bump</li> <li>ci: remove auto-merge workflow (#2214)</li> <li>ci: schedule changelog to rebuild daily at 8am, and on release only (#2216)</li> <li>ci: create pull request on changelog update (#2224)</li> <li>ci: skip analytics on forks (#2225)</li> <li>ci: enforce zero trust for third party workflows (#2215)</li> <li>ci: convert create-pr steps into composite action (#2238)</li> <li>ci: bump package version after release via pull request (#2239)</li> <li>ci: update layer ARN docs and create PR during release (#2240)</li> <li>ci: fail create-pr when branch cannot be created or behind tip</li> <li>ci: filter out bot commits from CHANGELOG</li> <li>ci: add more permissions to analytics</li> <li>ci: source code tampering protection for release (#2301)</li> <li>deps: bump fastjsonschema from 2.16.3 to 2.17.1 (#2307)</li> <li>deps: bump aws-actions/configure-aws-credentials from 2.0.0 to 2.1.0 (#2350)</li> <li>deps: bump typing-extensions from 4.5.0 to 4.6.2 (#2345)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.2 to 2.1.3 (#2227)</li> <li>deps: bump actions/setup-python from 4.6.0 to 4.6.1 (#2325)</li> <li>deps: update mkdocs configuration to support pymdown-extensions 10.0 (#2271)</li> <li>deps: bump pymdown-extensions from 9.11 to 10.0 (#2262)</li> <li>deps: bump pydantic from 1.10.7 to 1.10.8 (#2316)</li> <li>deps: bump codecov/codecov-action from 3.1.3 to 3.1.4 (#2263)</li> <li>deps: bump requests from 2.28.2 to 2.31.0 (#2308)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.116 to 1.26.135 (#2282)</li> <li>deps-dev: bump pytest-xdist from 3.2.1 to 3.3.0 (#2251)</li> <li>deps-dev: bump aws-cdk from 2.79.0 to 2.79.1 (#2252)</li> <li>deps-dev: bump mkdocs-material from 9.1.11 to 9.1.12 (#2253)</li> <li>deps-dev: bump aws-cdk from 2.79.1 to 2.80.0 (#2305)</li> <li>deps-dev: bump mkdocs-material from 9.1.13 to 9.1.14 (#2304)</li> <li>deps-dev: bump mkdocs-material from 9.1.12 to 9.1.13 (#2280)</li> <li>deps-dev: bump aws-cdk from 2.80.0 to 2.81.0 (#2332)</li> <li>deps-dev: bump sentry-sdk from 1.22.2 to 1.23.0 (#2264)</li> <li>deps-dev: bump sentry-sdk from 1.23.1 to 1.24.0 (#2314)</li> <li>deps-dev: bump types-requests from 2.30.0.0 to 2.31.0.0 (#2315)</li> <li>deps-dev: bump httpx from 0.24.0 to 0.24.1 (#2298)</li> <li>deps-dev: bump aws-cdk from 2.78.0 to 2.79.0 (#2235)</li> <li>deps-dev: bump mypy from 1.2.0 to 1.3.0 (#2233)</li> <li>deps-dev: bump pytest-cov from 4.0.0 to 4.1.0 (#2327)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.12 to 2.8.19.13 (#2234)</li> <li>deps-dev: bump coverage from 7.2.5 to 7.2.6 (#2326)</li> <li>deps-dev: bump mkdocs-material from 9.1.14 to 9.1.15 (#2337)</li> <li>deps-dev: bump mkdocs-material from 9.1.9 to 9.1.11 (#2229)</li> <li>deps-dev: bump cfn-lint from 0.77.4 to 0.77.5 (#2228)</li> <li>deps-dev: bump cfn-lint from 0.77.5 to 0.77.6 (#2360)</li> <li>deps-dev: bump coverage from 7.2.6 to 7.2.7 (#2338)</li> <li>deps-dev: bump types-requests from 2.31.0.0 to 2.31.0.1 (#2339)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.99 to 1.26.127 (#2219)</li> <li>deps-dev: bump types-requests from 2.29.0.0 to 2.30.0.0 (#2220)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.116 to 1.26.127 (#2218)</li> <li>deps-dev: bump pytest-xdist from 3.3.0 to 3.3.1 (#2297)</li> <li>deps-dev: bump sentry-sdk from 1.23.0 to 1.23.1 (#2283)</li> <li>deps-dev: bump aws-cdk from 2.77.0 to 2.78.0 (#2202)</li> <li>governance: Fix python version in issue templates (#2275)</li> </ul>"},{"location":"changelog/#v2150-2023-05-04","title":"v2.15.0 - 2023-05-04","text":""},{"location":"changelog/#bug-fixes_7","title":"Bug Fixes","text":"<ul> <li>typo</li> <li>ci: pypi publishing was targetting test endpoint</li> </ul>"},{"location":"changelog/#documentation_5","title":"Documentation","text":"<ul> <li>batch: fixed typo in DynamoDB Streams section (#2189)</li> <li>examples: standardize lambda handler function name (#2192)</li> <li>homepage: add customer references section (#2159)</li> <li>jmespath: fix MD037/no-space-in-emphasis</li> <li>tutorial: use newer sam cli template; update to py3.10 (#2167)</li> <li>we-made-this: add serverless transactional message app (#2182)</li> </ul>"},{"location":"changelog/#features_4","title":"Features","text":"<ul> <li>ci: dispatch GitHub analytics action (#2161)</li> <li>event_source: support custom json_deserializer; add json_body in SQSEvent (#2200)</li> <li>event_source: add support for dynamic partitions in the Api Gateway Authorizer event (#2176)</li> <li>event_sources: Add str to Data Classes base DictWrapper (#2129)</li> <li>jmespath: new built-in envelopes to unwrap S3 events (#2169)</li> <li>logger: add DatadogLogFormatter and observability provider (#2183)</li> <li>metrics: add flush_metrics() method to allow manual flushing of metrics (#2171)</li> <li>parser: add support for SQS-wrapped S3 event notifications (#2108)</li> </ul>"},{"location":"changelog/#maintenance_7","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>add dummy reusable dispatch analytics job</li> <li>ci: remove build step from release env; no more secrets need</li> <li>ci: use new pypi trusted publisher for increase security (#2198)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.5 to 1.8.6 (#2201)</li> <li>deps-dev: bump cfn-lint from 0.77.3 to 0.77.4 (#2178)</li> <li>deps-dev: bump types-requests from 2.28.11.17 to 2.29.0.0 (#2187)</li> <li>deps-dev: bump coverage from 7.2.4 to 7.2.5 (#2186)</li> <li>deps-dev: bump mkdocs-material from 9.1.8 to 9.1.9 (#2190)</li> <li>deps-dev: bump importlib-metadata from 6.5.0 to 6.6.0 (#2163)</li> <li>deps-dev: bump mypy-boto3-xray from 1.26.11.post1 to 1.26.122 (#2173)</li> <li>deps-dev: bump aws-cdk from 2.76.0 to 2.77.0 (#2174)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.115 to 1.26.122 (#2172)</li> <li>deps-dev: bump cfn-lint from 0.77.2 to 0.77.3 (#2165)</li> <li>deps-dev: bump mkdocs-material from 9.1.6 to 9.1.8 (#2162)</li> <li>deps-dev: bump coverage from 7.2.3 to 7.2.4 (#2179)</li> <li>governance: add Lambda Powertools for .NET in issue templates (#2196)</li> </ul>"},{"location":"changelog/#v2141-2023-04-21","title":"v2.14.1 - 2023-04-21","text":""},{"location":"changelog/#bug-fixes_8","title":"Bug Fixes","text":"<ul> <li>batch: resolve use of ValidationError in batch (#2157)</li> <li>e2e: fix test brittleness (#2152)</li> </ul>"},{"location":"changelog/#documentation_6","title":"Documentation","text":"<ul> <li>readme: update python version badge to 3.10</li> </ul>"},{"location":"changelog/#features_5","title":"Features","text":"<ul> <li>event_sources: add queue_url field in SQS EventSource DataClass (#2146)</li> </ul>"},{"location":"changelog/#maintenance_8","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>add Python 3.10 PyPi language classifier (#2144)</li> <li>update v2 layer ARN on documentation</li> <li>batch: safeguard custom use of BatchProcessingError exception (#2155)</li> <li>deps: bump codecov/codecov-action from 3.1.2 to 3.1.3 (#2153)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.6 to 1.4.0 (#2140)</li> <li>deps-dev: bump aws-cdk from 2.75.0 to 2.75.1 (#2150)</li> <li>deps-dev: bump aws-cdk from 2.75.1 to 2.76.0 (#2154)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.89 to 1.26.116 (#2147)</li> <li>deps-dev: bump importlib-metadata from 6.4.1 to 6.5.0 (#2141)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.104 to 1.26.116 (#2149)</li> <li>deps-dev: bump filelock from 3.11.0 to 3.12.0 (#2142)</li> <li>deps-dev: bump cfn-lint from 0.77.1 to 0.77.2 (#2148)</li> </ul>"},{"location":"changelog/#v2140-2023-04-18","title":"v2.14.0 - 2023-04-18","text":""},{"location":"changelog/#bug-fixes_9","title":"Bug Fixes","text":"<ul> <li>enable python 3.10 on SAR template</li> <li>ci: fix layer version in tracer, logger and metrics</li> <li>ci: typo</li> <li>docs: add Layer ARN for new 5 regions</li> <li>layers: add debug to update layer arn script</li> </ul>"},{"location":"changelog/#features_6","title":"Features","text":"<ul> <li>runtime: add support for python 3.10 (#2137)</li> </ul>"},{"location":"changelog/#maintenance_9","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>ci: add support for x86-64 regions only (#2122)</li> <li>deps-dev: bump importlib-metadata from 6.3.0 to 6.4.1 (#2134)</li> <li>deps-dev: bump cfn-lint from 0.77.0 to 0.77.1 (#2133)</li> <li>deps-dev: bump pytest from 7.3.0 to 7.3.1 (#2127)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.109 to 1.26.114 (#2126)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.114 to 1.26.115 (#2135)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.97.post1 to 1.26.115 (#2132)</li> <li>github: new tech debt issue form (#2131)</li> <li>layer: change layer-balance script to support new regions</li> </ul>"},{"location":"changelog/#reverts","title":"Reverts","text":"<ul> <li>chore: update v2 layer ARN on documentation</li> </ul>"},{"location":"changelog/#v2130-2023-04-14","title":"v2.13.0 - 2023-04-14","text":""},{"location":"changelog/#bug-fixes_10","title":"Bug Fixes","text":"<ul> <li>ci: replace the correct files for Layer ARN</li> <li>ci: fix working directory</li> <li>ci: add debug log to NPM install</li> <li>ci: use project's CDK version when building layers</li> <li>ci: add the rest of the changed docs</li> <li>ci: update layer version on logger, tracer and metrics docs (#2120)</li> <li>event_sources: Update CodePipeline event source to include optional encryption_key field and make user_parameters field optional (#2113)</li> </ul>"},{"location":"changelog/#features_7","title":"Features","text":"<ul> <li>parameters: Configure max_age and decrypt parameters via environment variables (#2088)</li> </ul>"},{"location":"changelog/#maintenance_10","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>ci: bump the cdk-aws-lambda-powertools-layer version (#2121)</li> <li>deps: bump codecov/codecov-action from 3.1.1 to 3.1.2 (#2110)</li> <li>deps-dev: bump httpx from 0.23.3 to 0.24.0 (#2111)</li> <li>deps-dev: bump aws-cdk-lib from 2.73.0 to 2.74.0 (#2123)</li> <li>deps-dev: bump mkdocs-material from 9.1.5 to 9.1.6 (#2104)</li> <li>deps-dev: bump aws-cdk from 2.73.0 to 2.74.0 (#2125)</li> <li>deps-dev: bump flake8-comprehensions from 3.11.1 to 3.12.0 (#2124)</li> <li>deps-dev: bump mypy from 1.1.1 to 1.2.0 (#2096)</li> <li>deps-dev: bump cfn-lint from 0.76.2 to 0.77.0 (#2107)</li> <li>deps-dev: bump pytest from 7.2.2 to 7.3.0 (#2106)</li> <li>deps-dev: bump importlib-metadata from 6.1.0 to 6.3.0 (#2105)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.80 to 1.26.109 (#2103)</li> <li>maintenance: validate acknowledgement section is present (#2112)</li> </ul>"},{"location":"changelog/#v2120-2023-04-07","title":"v2.12.0 - 2023-04-07","text":""},{"location":"changelog/#bug-fixes_11","title":"Bug Fixes","text":"<ul> <li>batch: handle early validation errors for pydantic models (poison pill) #2091 (#2099)</li> </ul>"},{"location":"changelog/#documentation_7","title":"Documentation","text":"<ul> <li>batch: use newly supported Json model (#2100)</li> <li>homepage: remove banner for end-of-support v1 (#2098)</li> <li>idempotency: fixes to testing your code section (#2073)</li> <li>idempotency: new sequence diagrams, fix idempotency record vs DynamoDB TTL confusion (#2074)</li> <li>parser: fix highlighted line (#2064)</li> </ul>"},{"location":"changelog/#features_8","title":"Features","text":"<ul> <li>batch: reduce boilerplate with process_partial_response (#2090)</li> <li>idempotency: allow custom sdk clients in DynamoDBPersistenceLayer (#2087)</li> </ul>"},{"location":"changelog/#maintenance_11","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump peaceiris/actions-gh-pages from 3.9.2 to 3.9.3 (#2069)</li> <li>deps: bump aws-xray-sdk from 2.11.0 to 2.12.0 (#2080)</li> <li>deps-dev: bump coverage from 7.2.2 to 7.2.3 (#2092)</li> <li>deps-dev: bump aws-cdk from 2.72.1 to 2.73.0 (#2093)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.60 to 1.26.108 (#2095)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.11 to 2.8.19.12 (#2085)</li> <li>deps-dev: bump cfn-lint from 0.76.1 to 0.76.2 (#2084)</li> <li>deps-dev: bump aws-cdk from 2.72.0 to 2.72.1 (#2081)</li> <li>deps-dev: bump filelock from 3.10.7 to 3.11.0 (#2094)</li> <li>deps-dev: bump mkdocs-material from 9.1.4 to 9.1.5 (#2077)</li> <li>deps-dev: bump aws-cdk-lib from 2.72.0 to 2.72.1 (#2076)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.99 to 1.26.104 (#2075)</li> <li>deps-dev: bump aws-cdk from 2.71.0 to 2.72.0 (#2071)</li> <li>deps-dev: bump aws-cdk-lib from 2.72.1 to 2.73.0 (#2097)</li> <li>deps-dev: bump aws-cdk-lib from 2.71.0 to 2.72.0 (#2070)</li> <li>deps-dev: bump black from 23.1.0 to 23.3.0 (#2066)</li> <li>deps-dev: bump aws-cdk from 2.70.0 to 2.71.0 (#2067)</li> <li>deps-dev: bump aws-cdk-lib from 2.70.0 to 2.71.0 (#2065)</li> </ul>"},{"location":"changelog/#v2110-2023-03-29","title":"v2.11.0 - 2023-03-29","text":""},{"location":"changelog/#bug-fixes_12","title":"Bug Fixes","text":"<ul> <li>feature_flags: make test conditions deterministic (#2059)</li> <li>feature_flags: handle expected falsy values in conditions (#2052)</li> </ul>"},{"location":"changelog/#documentation_8","title":"Documentation","text":"<ul> <li>logger: warn append_keys on not being thread-safe (#2046)</li> </ul>"},{"location":"changelog/#features_9","title":"Features","text":"<ul> <li>event_sources: support for S3 Event Notifications through EventBridge (#2024)</li> </ul>"},{"location":"changelog/#maintenance_12","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump pydantic from 1.10.6 to 1.10.7 (#2034)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.97 to 1.26.97.post2 (#2043)</li> <li>deps-dev: bump cfn-lint from 0.75.1 to 0.76.1 (#2056)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.10 to 2.8.19.11 (#2057)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.97.post2 to 1.26.99 (#2054)</li> <li>deps-dev: bump mkdocs-material from 9.1.3 to 9.1.4 (#2050)</li> <li>deps-dev: bump filelock from 3.10.2 to 3.10.4 (#2048)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.52 to 1.26.99 (#2049)</li> <li>deps-dev: bump filelock from 3.10.1 to 3.10.2 (#2045)</li> <li>deps-dev: bump types-requests from 2.28.11.15 to 2.28.11.16 (#2044)</li> <li>deps-dev: bump filelock from 3.10.4 to 3.10.7 (#2055)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.97 to 1.26.97.post1 (#2042)</li> <li>deps-dev: bump filelock from 3.10.0 to 3.10.1 (#2036)</li> <li>deps-dev: bump aws-cdk from 2.69.0 to 2.70.0 (#2039)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.87 to 1.26.97 (#2035)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.62 to 1.26.97 (#2037)</li> <li>deps-dev: bump aws-cdk-lib from 2.69.0 to 2.70.0 (#2038)</li> <li>deps-dev: bump types-requests from 2.28.11.16 to 2.28.11.17 (#2061)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.77 to 1.26.97 (#2033)</li> <li>deps-dev: bump flake8-comprehensions from 3.11.0 to 3.11.1 (#2029)</li> <li>deps-dev: bump cfn-lint from 0.75.0 to 0.75.1 (#2027)</li> <li>deps-dev: bump pytest-asyncio from 0.20.3 to 0.21.0 (#2026)</li> </ul>"},{"location":"changelog/#v2100-2023-03-17","title":"v2.10.0 - 2023-03-17","text":""},{"location":"changelog/#bug-fixes_13","title":"Bug Fixes","text":"<ul> <li>only allow one e2e test at a time</li> <li>build: auto-generate setup.py for legacy build tools (#2013)</li> <li>ci: bump CDK version</li> <li>typing: swap NoReturn with None for methods with no return value (#2004)</li> </ul>"},{"location":"changelog/#documentation_9","title":"Documentation","text":"<ul> <li>homepage: revamp install UX &amp; share how we build Lambda Layer (#1978)</li> <li>metrics: fix high-resolution metrics announcement link (#2017)</li> </ul>"},{"location":"changelog/#features_10","title":"Features","text":"<ul> <li>event_sources: support for custom properties in ActiveMQEvent (#1999)</li> <li>parser: support for S3 Event Notifications via EventBridge (#1982)</li> </ul>"},{"location":"changelog/#maintenance_13","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>ci: allow dependabot to upgrade CDK for JS</li> <li>deps: bump docker/setup-buildx-action from 2.4.1 to 2.5.0 (#1995)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.1 to 2.1.2 (#1979)</li> <li>deps: bump aws-actions/configure-aws-credentials from 1 to 2 (#1987)</li> <li>deps: bump pydantic from 1.10.5 to 1.10.6 (#1991)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.49 to 1.26.89 (#1996)</li> <li>deps-dev: bump cfn-lint from 0.74.2 to 0.74.3 (#2008)</li> <li>deps-dev: bump filelock from 3.9.0 to 3.9.1 (#2006)</li> <li>deps-dev: bump aws-cdk-lib from 2.68.0 to 2.69.0 (#2007)</li> <li>deps-dev: bump cfn-lint from 0.74.1 to 0.74.2 (#2005)</li> <li>deps-dev: bump mypy from 0.982 to 1.1.1 (#1985)</li> <li>deps-dev: bump pytest-xdist from 3.2.0 to 3.2.1 (#2000)</li> <li>deps-dev: bump flake8-bugbear from 23.2.13 to 23.3.12 (#2001)</li> <li>deps-dev: bump bandit from 1.7.4 to 1.7.5 (#1997)</li> <li>deps-dev: bump mkdocs-material from 9.1.2 to 9.1.3 (#2009)</li> <li>deps-dev: bump aws-cdk from 2.67.0 to 2.69.0 (#2010)</li> <li>deps-dev: bump mkdocs-material from 9.1.1 to 9.1.2 (#1994)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.84 to 1.26.87 (#1993)</li> <li>deps-dev: bump filelock from 3.9.1 to 3.10.0 (#2019)</li> <li>deps-dev: bump aws-cdk-lib from 2.67.0 to 2.68.0 (#1992)</li> <li>deps-dev: bump cfn-lint from 0.74.0 to 0.74.1 (#1988)</li> <li>deps-dev: bump coverage from 7.2.1 to 7.2.2 (#2021)</li> <li>deps-dev: bump pytest from 7.2.1 to 7.2.2 (#1980)</li> <li>deps-dev: bump cfn-lint from 0.74.3 to 0.75.0 (#2020)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.9 to 2.8.19.10 (#1973)</li> <li>deps-dev: bump hvac from 1.0.2 to 1.1.0 (#1983)</li> <li>deps-dev: bump mkdocs-material from 9.1.0 to 9.1.1 (#1984)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.24 to 1.26.84 (#1981)</li> <li>deps-dev: bump mkdocs-material from 9.0.15 to 9.1.0 (#1976)</li> <li>deps-dev: bump cfn-lint from 0.67.0 to 0.74.0 (#1974)</li> <li>deps-dev: bump aws-cdk-lib from 2.66.1 to 2.67.0 (#1977)</li> </ul>"},{"location":"changelog/#v291-2023-03-01","title":"v2.9.1 - 2023-03-01","text":""},{"location":"changelog/#bug-fixes_14","title":"Bug Fixes","text":"<ul> <li>idempotency: revert dict mutation that impacted static_pk_value feature (#1970)</li> </ul>"},{"location":"changelog/#documentation_10","title":"Documentation","text":"<ul> <li>appsync: add mutation example and infrastructure fix (#1964)</li> <li>parameters: fix typos and inconsistencies (#1966)</li> </ul>"},{"location":"changelog/#maintenance_14","title":"Maintenance","text":"<ul> <li>update project description</li> <li>update v2 layer ARN on documentation</li> <li>ci: disable pypi test due to maintenance mode</li> <li>ci: replace deprecated set-output commands (#1957)</li> <li>deps: bump fastjsonschema from 2.16.2 to 2.16.3 (#1961)</li> <li>deps: bump release-drafter/release-drafter from 5.22.0 to 5.23.0 (#1947)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.0 to 2.1.1 (#1958)</li> <li>deps-dev: bump coverage from 7.2.0 to 7.2.1 (#1963)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.8 to 2.8.19.9 (#1960)</li> <li>deps-dev: bump mkdocs-material from 9.0.14 to 9.0.15 (#1959)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.55 to 1.26.80 (#1967)</li> <li>deps-dev: bump types-requests from 2.28.11.14 to 2.28.11.15 (#1962)</li> <li>deps-dev: bump aws-cdk-lib from 2.66.0 to 2.66.1 (#1954)</li> <li>deps-dev: bump coverage from 7.1.0 to 7.2.0 (#1951)</li> <li>deps-dev: bump mkdocs-material from 9.0.13 to 9.0.14 (#1952)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.43 to 1.26.77 (#1949)</li> <li>deps-dev: bump types-requests from 2.28.11.13 to 2.28.11.14 (#1946)</li> <li>deps-dev: bump aws-cdk-lib from 2.65.0 to 2.66.0 (#1948)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.7 to 2.8.19.8 (#1945)</li> <li>parser: add workaround to make API GW test button work (#1971)</li> </ul>"},{"location":"changelog/#v290-2023-02-21","title":"v2.9.0 - 2023-02-21","text":""},{"location":"changelog/#bug-fixes_15","title":"Bug Fixes","text":"<ul> <li>ci: upgraded cdk to match the version used on e2e tests</li> <li>feature-flags: revert RuleAction Enum inheritance on str (#1910)</li> <li>logger: support exception and exception_name fields at any log level (#1930)</li> <li>metrics: clarify no-metrics user warning (#1935)</li> </ul>"},{"location":"changelog/#documentation_11","title":"Documentation","text":"<ul> <li>event_handlers: Fix REST API - HTTP Methods documentation (#1936)</li> <li>home: update powertools definition</li> <li>we-made-this: add CI/CD using Feature Flags video   (#1940)</li> <li>we-made-this: add Feature Flags post (#1939)</li> </ul>"},{"location":"changelog/#features_11","title":"Features","text":"<ul> <li>batch: add support to SQS FIFO queues (SqsFifoPartialProcessor) (#1934)</li> </ul>"},{"location":"changelog/#maintenance_15","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.5 to 2.1.0 (#1943)</li> <li>deps: bump pydantic from 1.10.4 to 1.10.5 (#1931)</li> <li>deps-dev: bump mkdocs-material from 9.0.12 to 9.0.13 (#1944)</li> <li>deps-dev: bump aws-cdk-lib from 2.64.0 to 2.65.0 (#1938)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.6 to 2.8.19.7 (#1932)</li> <li>deps-dev: bump types-requests from 2.28.11.12 to 2.28.11.13 (#1933)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.26.63 to 1.26.71 (#1928)</li> <li>deps-dev: bump flake8-bugbear from 23.1.20 to 23.2.13 (#1924)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.26.0.post1 to 1.26.70 (#1925)</li> </ul>"},{"location":"changelog/#v280-2023-02-10","title":"v2.8.0 - 2023-02-10","text":""},{"location":"changelog/#bug-fixes_16","title":"Bug Fixes","text":"<ul> <li>idempotency: make idempotent_function decorator thread safe (#1899)</li> </ul>"},{"location":"changelog/#documentation_12","title":"Documentation","text":"<ul> <li>engine: re-enable clipboard button for code snippets</li> <li>homepage: Replace poetry command to add group parameter (#1917)</li> <li>homepage: set url for end-of-support in announce block (#1893)</li> <li>idempotency: add IAM permissions section (#1902)</li> <li>metrics: remove reduntant wording before release</li> <li>metrics: fix syntax highlighting for new default_dimensions</li> </ul>"},{"location":"changelog/#features_12","title":"Features","text":"<ul> <li>batch: add async_batch_processor for concurrent processing (#1724)</li> <li>metrics: add default_dimensions to single_metric (#1880)</li> </ul>"},{"location":"changelog/#maintenance_16","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump docker/setup-buildx-action from 2.4.0 to 2.4.1 (#1903)</li> <li>deps-dev: bump aws-cdk-lib from 2.63.0 to 2.63.2 (#1904)</li> <li>deps-dev: bump black from 22.12.0 to 23.1.0 (#1886)</li> <li>deps-dev: bump types-requests from 2.28.11.8 to 2.28.11.12 (#1906)</li> <li>deps-dev: bump pytest-xdist from 3.1.0 to 3.2.0 (#1905)</li> <li>deps-dev: bump aws-cdk-lib from 2.63.2 to 2.64.0 (#1918)</li> <li>deps-dev: bump mkdocs-material from 9.0.11 to 9.0.12 (#1919)</li> <li>deps-dev: bump mkdocs-material from 9.0.10 to 9.0.11 (#1896)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.26.0.post1 to 1.26.63 (#1895)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.58 to 1.26.62 (#1889)</li> <li>deps-dev: bump mkdocs-material from 9.0.9 to 9.0.10 (#1888)</li> <li>deps-dev: bump aws-cdk-lib from 2.62.2 to 2.63.0 (#1887)</li> <li>maintainers: fix release workflow rename</li> <li>pypi: add new links to Pypi package homepage (#1912)</li> </ul>"},{"location":"changelog/#v271-2023-02-01","title":"v2.7.1 - 2023-02-01","text":""},{"location":"changelog/#bug-fixes_17","title":"Bug Fixes","text":"<ul> <li>parallel_run should fail when e2e tests fail</li> <li>bump aws-cdk version</li> <li>ci: scope e2e tests by python version</li> <li>ci: add auth to API HTTP Gateway and Lambda Function Url (#1882)</li> <li>license: correction to MIT + MIT-0 (no proprietary anymore) (#1883)</li> <li>license: add MIT-0 license header (#1871)</li> <li>tests: make logs fetching more robust (#1878)</li> <li>tests: remove custom workers</li> <li>tests: make sure multiple e2e tests run concurrently (#1861)</li> </ul>"},{"location":"changelog/#documentation_13","title":"Documentation","text":"<ul> <li>event-source:  fix incorrect method in example CloudWatch Logs (#1857)</li> <li>homepage: add banner for end-of-support v1 (#1879)</li> <li>parameters: snippets split, improved, and lint (#1564)</li> </ul>"},{"location":"changelog/#maintenance_17","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump docker/setup-buildx-action from 2.0.0 to 2.4.0 (#1873)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.5 to 1.3.6 (#1855)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.0.post1 to 1.26.58 (#1868)</li> <li>deps-dev: bump isort from 5.11.4 to 5.11.5 (#1875)</li> <li>deps-dev: bump aws-cdk-lib from 2.62.1 to 2.62.2 (#1869)</li> <li>deps-dev: bump mkdocs-material from 9.0.6 to 9.0.8 (#1874)</li> <li>deps-dev: bump aws-cdk-lib from 2.62.0 to 2.62.1 (#1866)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.35.post1 to 1.26.57 (#1865)</li> <li>deps-dev: bump coverage from 7.0.5 to 7.1.0 (#1862)</li> <li>deps-dev: bump aws-cdk-lib from 2.61.1 to 2.62.0 (#1863)</li> <li>deps-dev: bump flake8-bugbear from 22.12.6 to 23.1.20 (#1854)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.49 to 1.26.55 (#1856)</li> </ul>"},{"location":"changelog/#reverts_1","title":"Reverts","text":"<ul> <li>fix(tests): remove custom workers</li> </ul>"},{"location":"changelog/#v270-2023-01-24","title":"v2.7.0 - 2023-01-24","text":""},{"location":"changelog/#bug-fixes_18","title":"Bug Fixes","text":"<ul> <li>git-chlg docker image is broken</li> </ul>"},{"location":"changelog/#features_13","title":"Features","text":"<ul> <li>feature_flags: Add Time based feature flags actions (#1846)</li> </ul>"},{"location":"changelog/#maintenance_18","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump peaceiris/actions-gh-pages from 3.9.1 to 3.9.2 (#1841)</li> <li>deps: bump future from 0.18.2 to 0.18.3 (#1836)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.4 to 2.0.5 (#1837)</li> <li>deps-dev: bump mkdocs-material from 9.0.4 to 9.0.5 (#1840)</li> <li>deps-dev: bump types-requests from 2.28.11.7 to 2.28.11.8 (#1843)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.30 to 1.26.52 (#1847)</li> <li>deps-dev: bump pytest from 7.2.0 to 7.2.1 (#1838)</li> <li>deps-dev: bump aws-cdk-lib from 2.60.0 to 2.61.1 (#1849)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.49 to 1.26.53 (#1850)</li> <li>deps-dev: bump mkdocs-material from 9.0.5 to 9.0.6 (#1851)</li> <li>deps-dev: bump mkdocs-material from 9.0.3 to 9.0.4 (#1833)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.43 to 1.26.49 (#1834)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.40 to 1.26.49 (#1835)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.18 to 1.26.49 (#1832)</li> <li>deps-dev: bump aws-cdk-lib from 2.59.0 to 2.60.0 (#1831)</li> </ul>"},{"location":"changelog/#v260-2023-01-12","title":"v2.6.0 - 2023-01-12","text":""},{"location":"changelog/#bug-fixes_19","title":"Bug Fixes","text":"<ul> <li>api_gateway: fixed custom metrics issue when using debug mode (#1827)</li> </ul>"},{"location":"changelog/#documentation_14","title":"Documentation","text":"<ul> <li>logger: fix incorrect field names in example structured logs (#1830)</li> <li>logger: Add warning of uncaught exceptions (#1826)</li> </ul>"},{"location":"changelog/#maintenance_19","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump pydantic from 1.10.2 to 1.10.4 (#1817)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.1 to 2.0.3 (#1801)</li> <li>deps: bump release-drafter/release-drafter from 5.21.1 to 5.22.0 (#1802)</li> <li>deps: bump gitpython from 3.1.29 to 3.1.30 (#1812)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.3 to 2.0.4 (#1821)</li> <li>deps: bump peaceiris/actions-gh-pages from 3.9.0 to 3.9.1 (#1814)</li> <li>deps-dev: bump mkdocs-material from 8.5.11 to 9.0.2 (#1808)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.11.post1 to 1.26.43 (#1819)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.27 to 1.26.43 (#1820)</li> <li>deps-dev: bump filelock from 3.8.2 to 3.9.0 (#1816)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.11.post1 to 1.26.35.post1 (#1818)</li> <li>deps-dev: bump ijson from 3.1.4 to 3.2.0.post0 (#1815)</li> <li>deps-dev: bump coverage from 6.5.0 to 7.0.3 (#1806)</li> <li>deps-dev: bump flake8-builtins from 2.0.1 to 2.1.0 (#1799)</li> <li>deps-dev: bump coverage from 7.0.3 to 7.0.4 (#1822)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.12 to 1.26.40 (#1811)</li> <li>deps-dev: bump isort from 5.11.3 to 5.11.4 (#1809)</li> <li>deps-dev: bump aws-cdk-lib from 2.55.1 to 2.59.0 (#1810)</li> <li>deps-dev: bump importlib-metadata from 5.1.0 to 6.0.0 (#1804)</li> <li>deps-dev: bump mkdocs-material from 9.0.2 to 9.0.3 (#1823)</li> <li>deps-dev: bump black from 22.10.0 to 22.12.0 (#1770)</li> <li>deps-dev: bump flake8-black from 0.3.5 to 0.3.6 (#1792)</li> <li>deps-dev: bump coverage from 7.0.4 to 7.0.5 (#1829)</li> <li>deps-dev: bump types-requests from 2.28.11.5 to 2.28.11.7 (#1795)</li> </ul>"},{"location":"changelog/#v250-2022-12-21","title":"v2.5.0 - 2022-12-21","text":""},{"location":"changelog/#bug-fixes_20","title":"Bug Fixes","text":"<ul> <li>event_handlers: omit explicit None HTTP header values (#1793)</li> </ul>"},{"location":"changelog/#documentation_15","title":"Documentation","text":"<ul> <li>idempotency: fix, improve, and increase visibility for batch integration (#1776)</li> <li>validation: fix broken link; enrich built-in jmespath links (#1777)</li> </ul>"},{"location":"changelog/#features_14","title":"Features","text":"<ul> <li>logger: unwrap event from common models if asked to log (#1778)</li> </ul>"},{"location":"changelog/#maintenance_20","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>common: reusable function to extract event from models</li> <li>deps: bump certifi from 2022.9.24 to 2022.12.7 (#1768)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 1.4.0 to 2.0.1 (#1752)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 1.3.0 to 1.4.0 (#1749)</li> <li>deps-dev: bump pytest-asyncio from 0.20.2 to 0.20.3 (#1767)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.0.post1 to 1.26.17 (#1753)</li> <li>deps-dev: bump isort from 5.10.1 to 5.11.2 (#1782)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.17 to 1.26.30 (#1785)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.13.post16 to 1.26.24 (#1765)</li> <li>deps-dev: bump aws-cdk-lib from 2.54.0 to 2.55.1 (#1787)</li> <li>deps-dev: bump aws-cdk-lib from 2.53.0 to 2.54.0 (#1764)</li> <li>deps-dev: bump flake8-bugbear from 22.10.27 to 22.12.6 (#1760)</li> <li>deps-dev: bump filelock from 3.8.0 to 3.8.2 (#1759)</li> <li>deps-dev: bump pytest-xdist from 3.0.2 to 3.1.0 (#1758)</li> <li>deps-dev: bump mkdocs-material from 8.5.10 to 8.5.11 (#1756)</li> <li>deps-dev: bump importlib-metadata from 4.13.0 to 5.1.0 (#1750)</li> <li>deps-dev: bump isort from 5.11.2 to 5.11.3 (#1788)</li> <li>deps-dev: bump flake8-black from 0.3.3 to 0.3.5 (#1738)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.17 to 1.26.27 (#1775)</li> <li>tests: move shared_functions to unit tests</li> </ul>"},{"location":"changelog/#v240-2022-11-24","title":"v2.4.0 - 2022-11-24","text":""},{"location":"changelog/#bug-fixes_21","title":"Bug Fixes","text":"<ul> <li>ci: use gh-pages env as official docs are wrong</li> <li>ci: api docs path</li> </ul>"},{"location":"changelog/#documentation_16","title":"Documentation","text":"<ul> <li>idempotency: fix register_lambda_context order (#1747)</li> <li>streaming: fix leftover newline</li> </ul>"},{"location":"changelog/#features_15","title":"Features","text":"<ul> <li>streaming: add new s3 streaming utility (#1719)</li> </ul>"},{"location":"changelog/#maintenance_21","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>ci: re-create versioned API docs for new pages deployment</li> <li>ci: re-create versioned API docs for new pages deployment</li> <li>ci: increase permission in parent job for docs publishing</li> <li>ci: attempt gh-pages deployment via beta route</li> <li>deps: bump aws-xray-sdk from 2.10.0 to 2.11.0 (#1730)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.0.post1 to 1.26.12 (#1742)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.0.post1 to 1.26.11.post1 (#1746)</li> <li>deps-dev: bump aws-cdk-lib from 2.50.0 to 2.51.1 (#1741)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.0.post1 to 1.26.13.post16 (#1743)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.0.post1 to 1.26.12 (#1744)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.4 to 1.26.11.post1 (#1740)</li> <li>deps-dev: bump types-requests from 2.28.11.4 to 2.28.11.5 (#1729)</li> <li>deps-dev: bump mkdocs-material from 8.5.9 to 8.5.10 (#1731)</li> <li>governance: remove markdown rendering from docs issue template</li> </ul>"},{"location":"changelog/#regression","title":"Regression","text":"<ul> <li>ci: new gh-pages beta doesn't work either; reverting as gh-pages is disrupted</li> </ul>"},{"location":"changelog/#v231-2022-11-21","title":"v2.3.1 - 2022-11-21","text":""},{"location":"changelog/#bug-fixes_22","title":"Bug Fixes","text":"<ul> <li>apigateway: support dynamic routes with equal sign (RFC3986) (#1737)</li> </ul>"},{"location":"changelog/#maintenance_22","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>test build layer hardware to 8 core</li> <li>deps-dev: bump mypy-boto3-xray from 1.26.9 to 1.26.11.post1 (#1734)</li> </ul>"},{"location":"changelog/#v230-2022-11-17","title":"v2.3.0 - 2022-11-17","text":""},{"location":"changelog/#bug-fixes_23","title":"Bug Fixes","text":"<ul> <li>apigateway: support nested router decorators (#1709)</li> <li>ci: increase permission to allow version sync back to repo</li> <li>ci: disable pre-commit hook download from version bump</li> <li>ci: setup git client earlier to prevent dirty stash error</li> <li>parameters: get_secret correctly return SecretBinary value (#1717)</li> </ul>"},{"location":"changelog/#documentation_17","title":"Documentation","text":"<ul> <li>project name consistency</li> <li>apigateway: add all resolvers in testing your code section for accuracy (#1688)</li> <li>examples: linting unnecessary whitespace</li> <li>homepage: update default value for <code>POWERTOOLS_DEV</code> (#1695)</li> <li>idempotency: add missing Lambda Context; note on thread-safe (#1732)</li> <li>logger: update uncaught exception message value</li> </ul>"},{"location":"changelog/#features_16","title":"Features","text":"<ul> <li>apigateway: multiple exceptions in exception_handler (#1707)</li> <li>event_sources: extract CloudWatch Logs in Kinesis streams (#1710)</li> <li>logger: log uncaught exceptions via system's exception hook (#1727)</li> <li>parser: export Pydantic.errors through escape hatch (#1728)</li> <li>parser: extract CloudWatch Logs in Kinesis streams (#1726)</li> </ul>"},{"location":"changelog/#maintenance_23","title":"Maintenance","text":"<ul> <li>apigw test event wrongly set with base64</li> <li>update v2 layer ARN on documentation</li> <li>ci: revert custom hw for E2E due to lack of hw</li> <li>ci: try bigger hardware for e2e test</li> <li>ci: uncomment test pypi, fix version bump sync</li> <li>ci: limit to src only to prevent dependabot failures</li> <li>ci: use new custom hw for E2E</li> <li>ci: prevent dependabot updates to trigger E2E</li> <li>ci: bump hardware for build steps</li> <li>deps: bump dependabot/fetch-metadata from 1.3.4 to 1.3.5 (#1689)</li> <li>deps-dev: bump types-requests from 2.28.11.3 to 2.28.11.4 (#1701)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.25.0 to 1.26.0.post1 (#1716)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.25.0 to 1.26.0.post1 (#1704)</li> <li>deps-dev: bump mypy-boto3-xray from 1.25.0 to 1.26.0.post1 (#1703)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.25.0 to 1.26.0.post1 (#1714)</li> <li>deps-dev: bump flake8-bugbear from 22.10.25 to 22.10.27 (#1665)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.25.0 to 1.26.0.post1 (#1705)</li> <li>deps-dev: bump mypy-boto3-xray from 1.26.0.post1 to 1.26.9 (#1720)</li> <li>deps-dev: bump mypy-boto3-logs from 1.25.0 to 1.26.3 (#1702)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.0.post1 to 1.26.4 (#1721)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.25.0 to 1.26.0.post1 (#1722)</li> <li>deps-dev: bump pytest-asyncio from 0.20.1 to 0.20.2 (#1723)</li> <li>deps-dev: bump flake8-builtins from 2.0.0 to 2.0.1 (#1715)</li> <li>deps-dev: bump pytest-xdist from 2.5.0 to 3.0.2 (#1655)</li> <li>deps-dev: bump mkdocs-material from 8.5.7 to 8.5.9 (#1697)</li> <li>deps-dev: bump flake8-comprehensions from 3.10.0 to 3.10.1 (#1699)</li> <li>deps-dev: bump types-requests from 2.28.11.2 to 2.28.11.3 (#1698)</li> <li>deps-dev: bump pytest-benchmark from 3.4.1 to 4.0.0 (#1659)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.25.0 to 1.26.0.post1 (#1691)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.25.0 to 1.26.0.post1 (#1690)</li> <li>logger: uncaught exception to use exception value as message</li> <li>logger: overload inject_lambda_context with generics (#1583)</li> </ul>"},{"location":"changelog/#v220-2022-11-07","title":"v2.2.0 - 2022-11-07","text":""},{"location":"changelog/#documentation_18","title":"Documentation","text":"<ul> <li>homepage: remove v1 layer limitation on pydantic not being included</li> <li>tracer: add note on why X-Ray SDK over ADOT closes #1675</li> </ul>"},{"location":"changelog/#features_17","title":"Features","text":"<ul> <li>metrics: add EphemeralMetrics as a non-singleton option (#1676)</li> <li>parameters: add get_parameters_by_name for SSM params in distinct paths (#1678)</li> </ul>"},{"location":"changelog/#maintenance_24","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump package to 2.2.0</li> <li>deps-dev: bump aws-cdk-lib from 2.49.0 to 2.50.0 (#1683)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.25.0 to 1.26.0.post1 (#1682)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.25.0 to 1.26.0.post1 (#1679)</li> <li>package: correct pyproject version manually</li> </ul>"},{"location":"changelog/#v210-2022-10-31","title":"v2.1.0 - 2022-10-31","text":""},{"location":"changelog/#bug-fixes_24","title":"Bug Fixes","text":"<ul> <li>ci: linting issues after flake8-blackbear,mypy upgrades</li> <li>deps: update build system to poetry-core (#1651)</li> <li>idempotency: idempotent_function should support standalone falsy values (#1669)</li> <li>logger: fix unknown attributes being ignored by mypy (#1670)</li> </ul>"},{"location":"changelog/#documentation_19","title":"Documentation","text":"<ul> <li>community: fix social handlers for Ran (#1654)</li> <li>community: fix twitch parent domain for embedded video</li> <li>homepage: remove 3.6 and add hero image</li> <li>homepage: add Pulumi code example (#1652)</li> <li>index: fold support us banner</li> <li>index: add quotes to pip for zsh customers</li> <li>install: address early v2 feedback on installation and project support</li> <li>we-made-this: new community content section (#1650)</li> </ul>"},{"location":"changelog/#features_18","title":"Features","text":"<ul> <li>layers: add layer balancer script (#1643)</li> <li>logger: add use_rfc3339 and auto-complete formatter opts in Logger (#1662)</li> <li>logger: accept arbitrary keyword=value for ephemeral metadata (#1658)</li> </ul>"},{"location":"changelog/#maintenance_25","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>ci: fix typo on version description</li> <li>deps: bump peaceiris/actions-gh-pages from 3.8.0 to 3.9.0 (#1649)</li> <li>deps: bump docker/setup-qemu-action from 2.0.0 to 2.1.0 (#1627)</li> <li>deps-dev: bump aws-cdk-lib from 2.47.0 to 2.48.0 (#1664)</li> <li>deps-dev: bump flake8-variables-names from 0.0.4 to 0.0.5 (#1628)</li> <li>deps-dev: bump pytest-asyncio from 0.16.0 to 0.20.1 (#1635)</li> <li>deps-dev: bump aws-cdk-lib from 2.48.0 to 2.49.0 (#1671)</li> <li>docs: remove v2 banner on top of the docs</li> <li>governance: remove 'area/' from PR labels</li> </ul>"},{"location":"changelog/#v200-2022-10-24","title":"v2.0.0 - 2022-10-24","text":""},{"location":"changelog/#bug-fixes_25","title":"Bug Fixes","text":"<ul> <li>lock dependencies</li> <li>mypy errors</li> <li>lint files</li> <li>ci: temporarly remove pypi test deployment</li> <li>ci: use docker driver on buildx</li> <li>ci: new artifact path, sed gnu/linux syntax, and pypi test</li> <li>ci: secret and OIDC inheritance in nested children workflow</li> <li>ci: build without buildkit</li> <li>ci: fix arm64 layer builds</li> <li>ci: remove v2 suffix from SAR apps (#1633)</li> <li>ci: workflow should use npx for CDK CLI</li> <li>parser: S3Model Object Deleted omits size and eTag attr (#1638)</li> </ul>"},{"location":"changelog/#code-refactoring_3","title":"Code Refactoring","text":"<ul> <li>apigateway: remove POWERTOOLS_EVENT_HANDLER_DEBUG env var (#1620)</li> <li>batch: remove legacy sqs_batch_processor (#1492)</li> <li>e2e: make table name dynamic</li> <li>e2e: fix idempotency typing</li> </ul>"},{"location":"changelog/#documentation_20","title":"Documentation","text":"<ul> <li>batch: remove legacy reference to sqs processor</li> <li>homepage: note about v2 version</li> <li>homepage: auto-update Layer ARN on every release (#1610)</li> <li>roadmap: refresh roadmap post-v2 launch</li> <li>roadmap: include observability provider and lambda layer themes before v2</li> <li>upgrade_guide: add latest changes and quick summary (#1623)</li> <li>v2: document optional dependencies and local dev (#1574)</li> </ul>"},{"location":"changelog/#features_19","title":"Features","text":"<ul> <li>apigateway: ignore trailing slashes in routes (APIGatewayRestResolver) (#1609)</li> <li>ci: release docs as alpha when doing a pre-release (#1624)</li> <li>data-classes: replace AttributeValue in DynamoDBStreamEvent with deserialized Python values (#1619)</li> <li>data_classes: add KinesisFirehoseEvent (#1540)</li> <li>event_handler: improved support for headers and cookies in v2 (#1455)</li> <li>event_handler: add cookies as 1st class citizen in v2 (#1487)</li> <li>idempotency: support methods with the same name (ABCs) by including fully qualified name in v2 (#1535)</li> <li>layer: publish SAR v2 via Github actions (#1585)</li> <li>layers: add support for publishing v2 layer (#1558)</li> <li>parameters: migrate AppConfig to new APIs due to API deprecation (#1553)</li> <li>tracer: support methods with the same name (ABCs) by including fully qualified name in v2 (#1486)</li> </ul>"},{"location":"changelog/#maintenance_26","title":"Maintenance","text":"<ul> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>merge v2 branch</li> <li>bump pyproject version to 2.0</li> <li>ci: make release process manual</li> <li>ci: migrate E2E tests to CDK CLI and off Docker (#1501)</li> <li>ci: remove v1 workflows (#1617)</li> <li>core: expose modules in the Top-level package (#1517)</li> <li>dep: add cfn-lint as a dev dependency; pre-commit (#1612)</li> <li>deps: remove email-validator; use Str over EmailStr in SES model (#1608)</li> <li>deps: bump release-drafter/release-drafter from 5.21.0 to 5.21.1 (#1611)</li> <li>deps: lock importlib to 4.x</li> <li>deps-dev: bump mypy-boto3-s3 from 1.24.76 to 1.24.94 (#1622)</li> <li>deps-dev: bump aws-cdk-lib from 2.46.0 to 2.47.0 (#1629)</li> <li>layer: bump to 1.31.1 (v39)</li> </ul>"},{"location":"changelog/#v1311-2022-10-14","title":"v1.31.1 - 2022-10-14","text":""},{"location":"changelog/#bug-fixes_26","title":"Bug Fixes","text":"<ul> <li>parser: loose validation on SNS fields to support FIFO (#1606)</li> </ul>"},{"location":"changelog/#documentation_21","title":"Documentation","text":"<ul> <li>governance: allow community to suggest feature content (#1593)</li> <li>governance: new form to allow customers self-nominate as public reference (#1589)</li> <li>homepage: include .NET powertools</li> <li>idempotency: \"persisntence\" typo (#1596)</li> <li>logger: fix typo. (#1587)</li> </ul>"},{"location":"changelog/#maintenance_27","title":"Maintenance","text":"<ul> <li>add dummy v2 sar deploy job</li> <li>bump layer version to 38</li> <li>deps-dev: bump mypy-boto3-ssm from 1.24.81 to 1.24.90 (#1594)</li> <li>deps-dev: bump flake8-builtins from 1.5.3 to 2.0.0 (#1582)</li> </ul>"},{"location":"changelog/#v1310-2022-10-10","title":"v1.31.0 - 2022-10-10","text":""},{"location":"changelog/#bug-fixes_27","title":"Bug Fixes","text":"<ul> <li>metrics: ensure dimension_set is reused across instances (pointer) (#1581)</li> </ul>"},{"location":"changelog/#documentation_22","title":"Documentation","text":"<ul> <li>readme: add lambda layer latest version badge</li> </ul>"},{"location":"changelog/#features_20","title":"Features","text":"<ul> <li>parser: add KinesisFirehoseModel (#1556)</li> </ul>"},{"location":"changelog/#maintenance_28","title":"Maintenance","text":"<ul> <li>deps-dev: bump types-requests from 2.28.11.1 to 2.28.11.2 (#1576)</li> <li>deps-dev: bump typing-extensions from 4.3.0 to 4.4.0 (#1575)</li> <li>layer: remove unsused GetFunction permission for the canary</li> <li>layer: bump to latest version 37</li> </ul>"},{"location":"changelog/#v1300-2022-10-05","title":"v1.30.0 - 2022-10-05","text":""},{"location":"changelog/#bug-fixes_28","title":"Bug Fixes","text":"<ul> <li>apigateway: update Response class to require status_code only (#1560)</li> <li>ci: integrate isort 5.0 with black to resolve conflicts</li> <li>event_sources: implement Mapping protocol on DictWrapper for better interop with existing middlewares (#1516)</li> <li>typing: fix mypy error</li> <li>typing: level arg in copy_config_to_registered_loggers (#1534)</li> </ul>"},{"location":"changelog/#documentation_23","title":"Documentation","text":"<ul> <li>batch: document the new lambda context feature</li> <li>homepage: introduce POWERTOOLS_DEV env var (#1569)</li> <li>multiple: fix highlighting after new isort/black integration</li> <li>parser: add JSON string field extension example (#1526)</li> </ul>"},{"location":"changelog/#features_21","title":"Features","text":"<ul> <li>batch: inject lambda_context if record handler signature accepts it (#1561)</li> <li>event-handler: context support to share data between routers (#1567)</li> <li>logger: introduce POWERTOOLS_DEBUG for internal debugging (#1572)</li> <li>logger: include logger name attribute when copy_config_to_registered_logger is used (#1568)</li> <li>logger: pretty-print JSON when POWERTOOLS_DEV is set (#1548)</li> </ul>"},{"location":"changelog/#maintenance_29","title":"Maintenance","text":"<ul> <li>dep: bump pyproject to pypi sync</li> <li>deps: bump fastjsonschema from 2.16.1 to 2.16.2 (#1530)</li> <li>deps: bump actions/setup-python from 3 to 4 (#1528)</li> <li>deps: bump codecov/codecov-action from 3.1.0 to 3.1.1 (#1529)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.3 to 1.3.4 (#1565)</li> <li>deps: bump email-validator from 1.2.1 to 1.3.0 (#1533)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.24.54 to 1.24.83 (#1557)</li> <li>deps-dev: bump mkdocs-material from 8.5.3 to 8.5.4 (#1563)</li> <li>deps-dev: bump pytest-cov from 3.0.0 to 4.0.0 (#1551)</li> <li>deps-dev: bump flake8-bugbear from 22.9.11 to 22.9.23 (#1541)</li> <li>deps-dev: bump types-requests from 2.28.11 to 2.28.11.1 (#1571)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.24.69 to 1.24.80 (#1542)</li> <li>deps-dev: bump mako from 1.2.2 to 1.2.3 (#1537)</li> <li>deps-dev: bump types-requests from 2.28.10 to 2.28.11 (#1538)</li> <li>deps-dev: bump mkdocs-material from 8.5.1 to 8.5.3 (#1532)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.24.80 to 1.24.81 (#1544)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.24.36.post1 to 1.24.76 (#1531)</li> <li>docs: bump layer version to 36 (1.29.2)</li> <li>layers: add dummy v2 layer automation</li> <li>lint: use new isort black integration</li> <li>multiple: localize powertools_dev env logic and warning (#1570)</li> </ul>"},{"location":"changelog/#v1292-2022-09-19","title":"v1.29.2 - 2022-09-19","text":""},{"location":"changelog/#bug-fixes_29","title":"Bug Fixes","text":"<ul> <li>deps: bump dev dep mako version to address CVE-2022-40023 (#1524)</li> </ul>"},{"location":"changelog/#maintenance_30","title":"Maintenance","text":"<ul> <li>deps: bump release-drafter/release-drafter from 5.20.1 to 5.21.0 (#1520)</li> <li>deps-dev: bump mkdocs-material from 8.5.0 to 8.5.1 (#1521)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.60 to 1.24.74 (#1522)</li> </ul>"},{"location":"changelog/#v1291-2022-09-13","title":"v1.29.1 - 2022-09-13","text":""},{"location":"changelog/#v1290-2022-09-13","title":"v1.29.0 - 2022-09-13","text":""},{"location":"changelog/#bug-fixes_30","title":"Bug Fixes","text":"<ul> <li>ci: ignore v2 action for now</li> <li>ci: only run e2e tests on py 3.7</li> <li>ci: pass core fns to large pr workflow script</li> <li>ci: on_label permissioning model &amp; workflow execution</li> <li>ci: ensure PR_AUTHOR is present for large_pr_split workflow</li> <li>ci: gracefully and successful exit changelog upon no changes</li> <li>ci: event resolution for on_label_added workflow</li> <li>core: fixes leftovers from rebase</li> </ul>"},{"location":"changelog/#documentation_24","title":"Documentation","text":"<ul> <li>layer: upgrade to 1.28.0 (v33)</li> </ul>"},{"location":"changelog/#features_22","title":"Features","text":"<ul> <li>ci: add actionlint in pre-commit hook</li> <li>data-classes: add KafkaEvent and KafkaEventRecord (#1485)</li> <li>event_sources: add CloudWatch dashboard custom widget event (#1474)</li> <li>parser: add KafkaMskEventModel and KafkaSelfManagedEventModel (#1499)</li> </ul>"},{"location":"changelog/#maintenance_31","title":"Maintenance","text":"<ul> <li>ci: add workflow to suggest splitting large PRs (#1480)</li> <li>ci: remove unused and undeclared OS matrix env</li> <li>ci: disable v2 docs</li> <li>ci: limit E2E workflow run for source code change</li> <li>ci: add missing description fields</li> <li>ci: sync package version with pypi</li> <li>ci: fix invalid dependency leftover</li> <li>ci: create adhoc docs workflow for v2</li> <li>ci: create adhoc docs workflow for v2</li> <li>ci: remove dangling debug step</li> <li>ci: create docs workflow for v2</li> <li>ci: create reusable docs publishing workflow (#1482)</li> <li>ci: format comment  on comment_large_pr script</li> <li>ci: add note for state persistence on comment_large_pr</li> <li>ci: destructure assignment on comment_large_pr</li> <li>ci: record pr details upon labeling</li> <li>ci: add linter for GitHub Actions as pre-commit hook (#1479)</li> <li>ci: enable ci checks for v2</li> <li>deps-dev: bump black from 21.12b0 to 22.8.0 (#1515)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.55.post1 to 1.24.60 (#1481)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.55.post1 to 1.24.60 (#306)</li> <li>deps-dev: bump mkdocs-material from 8.4.1 to 8.4.2 (#1483)</li> <li>deps-dev: revert to v1.28.0 dependencies</li> <li>deps-dev: bump mkdocs-material from 8.4.4 to 8.5.0 (#1514)</li> <li>maintainers: update release workflow link</li> <li>maintenance: add discord link to first PR and first issue (#1493)</li> </ul>"},{"location":"changelog/#v1280-2022-08-25","title":"v1.28.0 - 2022-08-25","text":""},{"location":"changelog/#bug-fixes_31","title":"Bug Fixes","text":"<ul> <li>ci: calculate parallel jobs based on infrastructure needs (#1475)</li> <li>ci: del flake8 direct dep over py3.6 conflicts and docs failure</li> <li>ci: move from pip-tools to poetry on layers reusable workflow</li> <li>ci: move from pip-tools to poetry on layers to fix conflicts</li> <li>ci: typo and bust gh actions cache</li> <li>ci: use poetry to resolve layer deps; pip for CDK</li> <li>ci: disable poetry venv for layer workflow as cdk ignores venv</li> <li>ci: add cdk v2 dep for layers workflow</li> <li>ci: move from pip-tools to poetry on layers</li> <li>ci: temporarily disable changelog upon release</li> <li>ci: add explicit origin to fix release detached head</li> <li>jmespath_util: snappy as dev dep and typing example (#1446)</li> </ul>"},{"location":"changelog/#documentation_25","title":"Documentation","text":"<ul> <li>apigateway: removes duplicate admonition (#1426)</li> <li>home: fix discord syntax and add Discord badge</li> <li>home: add discord invitation link (#1471)</li> <li>jmespath_util: snippets split, improved, and lint (#1419)</li> <li>layer: upgrade to 1.27.0</li> <li>layer: upgrade to 1.27.0</li> <li>middleware-factory: snippets split, improved, and lint (#1451)</li> <li>parser: minor grammar fix (#1427)</li> <li>typing: snippets split, improved, and lint (#1465)</li> <li>validation: snippets split, improved, and lint (#1449)</li> </ul>"},{"location":"changelog/#features_23","title":"Features","text":"<ul> <li>parser: add support for Lambda Function URL (#1442)</li> </ul>"},{"location":"changelog/#maintenance_32","title":"Maintenance","text":"<ul> <li>batch: deprecate sqs_batch_processor (#1463)</li> <li>ci: prevent concurrent git update in critical workflows (#1478)</li> <li>ci: disable e2e py version matrix due to concurrent locking</li> <li>ci: revert e2e py version matrix</li> <li>ci: temp disable e2e matrix</li> <li>ci: update changelog with latest changes</li> <li>ci: update changelog with latest changes</li> <li>ci: reduce payload and only send prod notification</li> <li>ci: remove area/utilities conflicting label</li> <li>ci: include py version in stack and cache lock</li> <li>ci: remove conventional changelog commit to reduce noise</li> <li>ci: update changelog with latest changes</li> <li>deps: bump release-drafter/release-drafter from 5.20.0 to 5.20.1 (#1458)</li> <li>deps: bump pydantic from 1.9.1 to 1.9.2 (#1448)</li> <li>deps-dev: bump flake8-bugbear from 22.8.22 to 22.8.23 (#1473)</li> <li>deps-dev: bump types-requests from 2.28.7 to 2.28.8 (#1423)</li> <li>maintainer: add Leandro as maintainer (#1468)</li> <li>tests: build and deploy Lambda Layer stack once (#1466)</li> <li>tests: refactor E2E test mechanics to ease maintenance, writing tests and parallelization (#1444)</li> <li>tests: enable end-to-end test workflow (#1470)</li> <li>tests: refactor E2E logger to ease maintenance, writing tests and parallelization (#1460)</li> <li>tests: refactor E2E tracer to ease maintenance, writing tests and parallelization (#1457)</li> </ul>"},{"location":"changelog/#reverts_2","title":"Reverts","text":"<ul> <li>fix(ci): add explicit origin to fix release detached head</li> </ul>"},{"location":"changelog/#v1270-2022-08-05","title":"v1.27.0 - 2022-08-05","text":""},{"location":"changelog/#bug-fixes_32","title":"Bug Fixes","text":"<ul> <li>ci: changelog workflow must receive git tags too</li> <li>ci: add additional input to accurately describe intent on skip</li> <li>ci: job permissions</li> <li>event_sources: add test for Function URL AuthZ (#1421)</li> </ul>"},{"location":"changelog/#documentation_26","title":"Documentation","text":"<ul> <li>layer: upgrade to 1.26.7</li> </ul>"},{"location":"changelog/#features_24","title":"Features","text":"<ul> <li>ci: create reusable changelog generation (#1418)</li> <li>ci: include changelog generation on docs build</li> <li>ci: create reusable changelog generation</li> <li>event_handlers: Add support for Lambda Function URLs (#1408)</li> <li>metrics: update max user-defined dimensions from 9 to 29 (#1417)</li> </ul>"},{"location":"changelog/#maintenance_33","title":"Maintenance","text":"<ul> <li>ci: sync area labels to prevent dedup</li> <li>ci: update changelog with latest changes</li> <li>ci: update changelog with latest changes</li> <li>ci: add manual trigger for docs</li> <li>ci: update changelog with latest changes</li> <li>ci: temporarily disable changelog push on release</li> <li>ci: update changelog with latest changes</li> <li>ci: move changelog generation to rebuild_latest_doc workflow</li> <li>ci: update project with version</li> <li>ci: update release automated activities</li> <li>ci: readd changelog step on release</li> <li>ci: move changelog generation to rebuild_latest_doc workflow</li> <li>ci: drop 3.6 from workflows</li> <li>deps: bump constructs from 10.1.1 to 10.1.60 (#1399)</li> <li>deps: bump constructs from 10.1.1 to 10.1.66 (#1414)</li> <li>deps: bump jsii from 1.57.0 to 1.63.2 (#1400)</li> <li>deps: bump constructs from 10.1.1 to 10.1.64 (#1405)</li> <li>deps: bump attrs from 21.4.0 to 22.1.0 (#1397)</li> <li>deps: bump constructs from 10.1.1 to 10.1.63 (#1402)</li> <li>deps: bump constructs from 10.1.1 to 10.1.65 (#1407)</li> <li>deps-dev: bump types-requests from 2.28.5 to 2.28.6 (#1401)</li> <li>deps-dev: bump types-requests from 2.28.6 to 2.28.7 (#1406)</li> <li>docs: remove pause sentence from roadmap (#1409)</li> <li>docs: update site name to test ci changelog</li> <li>docs: update CHANGELOG for v1.26.7</li> <li>docs: update description to trigger changelog generation</li> <li>governance: remove devcontainer in favour of gitpod.io (#1411)</li> <li>governance: add pre-configured dev environment with GitPod.io to ease contributions (#1403)</li> <li>layers: upgrade cdk dep hashes to prevent ci fail</li> </ul>"},{"location":"changelog/#v1267-2022-07-29","title":"v1.26.7 - 2022-07-29","text":""},{"location":"changelog/#bug-fixes_33","title":"Bug Fixes","text":"<ul> <li>ci: add missing oidc token generation permission</li> <li>event_handlers: ImportError when importing Response from top-level event_handler (#1388)</li> </ul>"},{"location":"changelog/#documentation_27","title":"Documentation","text":"<ul> <li>examples: enforce and fix all mypy errors (#1393)</li> </ul>"},{"location":"changelog/#features_25","title":"Features","text":"<ul> <li>idempotency: handle lambda timeout scenarios for INPROGRESS records (#1387)</li> </ul>"},{"location":"changelog/#maintenance_34","title":"Maintenance","text":"<ul> <li>ci: increase skip_pypi logic to cover tests/changelog on re-run failures</li> <li>ci: update project with version 1.26.6</li> <li>ci: drop 3.6 from workflows (#1395)</li> <li>ci: add conditional to skip pypi release (#1366)</li> <li>ci: remove leftover logic from on_merged_pr workflow</li> <li>ci: update project with version 1.26.6</li> <li>ci: update project with version 1.26.6</li> <li>deps: bump jsii from 1.57.0 to 1.63.1 (#1390)</li> <li>deps: bump constructs from 10.1.1 to 10.1.59 (#1396)</li> <li>deps-dev: bump flake8-isort from 4.1.1 to 4.1.2.post0 (#1384)</li> <li>layers: bump to 1.26.6 using layer v26</li> <li>maintainers: add Ruben as a maintainer (#1392)</li> </ul>"},{"location":"changelog/#v1266-2022-07-25","title":"v1.26.6 - 2022-07-25","text":""},{"location":"changelog/#bug-fixes_34","title":"Bug Fixes","text":"<ul> <li>ci: remove unsupported env in workflow_call</li> <li>ci: allow inherit secrets for reusable workflow</li> <li>ci: remove unused secret</li> <li>ci: label_related_issue unresolved var from history mixup</li> <li>ci: cond doesnt support two expr w/ env</li> <li>ci: only event is resolved in cond</li> <li>ci: unexpected symbol due to double quotes...</li> <li>event_handlers: handle lack of headers when using auto-compression feature (#1325)</li> </ul>"},{"location":"changelog/#maintenance_35","title":"Maintenance","text":"<ul> <li>dummy for PR test</li> <li>print full event depth</li> <li>print full workflow event depth</li> <li>debug full event</li> <li>remove leftover from fork one more time</li> <li>ci: test env expr</li> <li>ci: test upstream job skip</li> <li>ci: lockdown workflow_run by origin (#1350)</li> <li>ci: test default env</li> <li>ci: experiment hardening origin</li> <li>ci: experiment hardening origin</li> <li>ci: introduce codeowners (#1352)</li> <li>ci: use OIDC and encrypt release secrets (#1355)</li> <li>ci: remove core group from codeowners (#1358)</li> <li>ci: confirm workflow_run event</li> <li>ci: use gh environment for beta and prod layer deploy (#1356)</li> <li>ci: update project with version 1.26.5</li> <li>deps: bump constructs from 10.1.1 to 10.1.52 (#1343)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.24.0 to 1.24.35 (#1342)</li> <li>governance: update wording tech debt to summary in maintenance template</li> <li>governance: add new maintenance issue template for tech debt (#1326)</li> <li>layers: layer canary stack should not hardcode resource name</li> <li>layers: replace layers account secret (#1329)</li> <li>layers: expand to all aws commercial regions (#1324)</li> <li>layers: bump to 1.26.5</li> </ul>"},{"location":"changelog/#pull-requests","title":"Pull Requests","text":"<ul> <li>Merge pull request #285 from heitorlessa/chore/skip-dep-workflow</li> <li>Merge pull request #284 from heitorlessa/chore/dummy</li> </ul>"},{"location":"changelog/#v1265-2022-07-20","title":"v1.26.5 - 2022-07-20","text":""},{"location":"changelog/#bug-fixes_35","title":"Bug Fixes","text":"<ul> <li>mathc the name of the cdk synth from the build phase</li> <li>typo in input for layer workflow</li> <li>no need to cache npm since we only install cdk cli and don't have .lock files</li> <li>add entire ARN role instead of account and role name</li> <li>path to artefact</li> <li>unzip the right artifact name</li> <li>download artefact into the layer dir</li> <li>sight, yes a whitespace character breaks the build</li> <li>ci: checkout project before validating related issue workflow</li> <li>ci: install poetry before calling setup/python with cache (#1315)</li> <li>ci: remove additional quotes in PR action (#1317)</li> <li>ci: lambda layer workflow release version and conditionals (#1316)</li> <li>ci: fetch all git info so we can check tags</li> <li>ci: lambda layer workflow release version and conditionals (#1316)</li> <li>ci: keep layer version permission (#1318)</li> <li>ci: regex to catch combination of related issues workflow</li> <li>deps: correct mypy types as dev dependency (#1322)</li> <li>logger: preserve std keys when using custom formatters (#1264)</li> </ul>"},{"location":"changelog/#documentation_28","title":"Documentation","text":"<ul> <li>event-handler: snippets split, improved, and lint (#1279)</li> <li>governance: typos on PR template fixes #1314</li> <li>governance: add security doc to the root</li> </ul>"},{"location":"changelog/#maintenance_36","title":"Maintenance","text":"<ul> <li>ci: limits concurrency for docs workflow</li> <li>ci: adds caching when installing python dependencies (#1311)</li> <li>ci: update project with version 1.26.4</li> <li>ci: fix reference error in related_issue</li> <li>deps: bump constructs from 10.1.1 to 10.1.51 (#1323)</li> <li>deps-dev: bump mypy from 0.961 to 0.971 (#1320)</li> <li>governance: fix typo on semantic commit link introduced in #1aef4</li> <li>layers: add release pipeline in GitHub Actions (#1278)</li> <li>layers: bump to 22 for 1.26.3</li> </ul>"},{"location":"changelog/#v1264-2022-07-18","title":"v1.26.4 - 2022-07-18","text":""},{"location":"changelog/#bug-fixes_36","title":"Bug Fixes","text":"<ul> <li>ci: checkout project before validating related issue workflow</li> <li>ci: fixes typos and small issues on github scripts (#1302)</li> <li>ci: address conditional type on_merge</li> <li>ci: address pr title semantic not found logic</li> <li>ci: address gh-actions additional quotes; remove debug</li> <li>ci: regex group name for on_merge workflow</li> <li>ci: escape outputs as certain PRs can break GH Actions expressions</li> <li>ci: move conditionals from yaml to code; leftover</li> <li>ci: move conditionals from yaml to code</li> <li>ci: accept core arg in label related issue workflow</li> <li>ci: match the name of the cdk synth from the build phase</li> <li>ci: regex to catch combination of related issues workflow</li> <li>logger: preserve std keys when using custom formatters (#1264)</li> <li>parser: raise ValidationError when SNS-&gt;SQS keys are intentionally missing (#1299)</li> </ul>"},{"location":"changelog/#documentation_29","title":"Documentation","text":"<ul> <li>event-handler: snippets split, improved, and lint (#1279)</li> <li>graphql: snippets split, improved, and lint (#1287)</li> <li>homepage: emphasize additional powertools languages (#1292)</li> <li>metrics: snippets split, improved, and lint</li> </ul>"},{"location":"changelog/#maintenance_37","title":"Maintenance","text":"<ul> <li>ci: increase release automation and limit to one manual step (#1297)</li> <li>ci: make export PR reusable</li> <li>ci: auto-merge cdk lib and lambda layer construct</li> <li>ci: convert inline gh-script to file</li> <li>ci: lockdown 3rd party workflows to pin sha (#1301)</li> <li>ci: automatically add area label based on title (#1300)</li> <li>ci: disable output debugging as pr body isnt accepted</li> <li>ci: experiment with conditional on outputs</li> <li>ci: improve error handling for non-issue numbers</li> <li>ci: add end to end testing mechanism (#1247)</li> <li>ci: limits concurrency for docs workflow</li> <li>ci: fix reference error in related_issue</li> <li>ci: move error prone env to code as constants</li> <li>ci: move all scripts under .github/scripts</li> <li>deps: bump cdk-lambda-powertools-python-layer (#1284)</li> <li>deps: bump jsii from 1.61.0 to 1.62.0 (#1294)</li> <li>deps: bump constructs from 10.1.1 to 10.1.46 (#1306)</li> <li>deps: bump actions/setup-node from 2 to 3 (#1281)</li> <li>deps: bump fastjsonschema from 2.15.3 to 2.16.1 (#1309)</li> <li>deps: bump constructs from 10.1.1 to 10.1.49 (#1308)</li> <li>deps: bump attrs from 21.2.0 to 21.4.0 (#1282)</li> <li>deps: bump aws-cdk-lib from 2.29.0 to 2.31.1 (#1290)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.12 to 1.24.27 (#1293)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.24.0 to 1.24.29 (#1295)</li> <li>governance: remove any step relying on master branch</li> <li>governance: update emeritus affiliation</li> <li>layers: add release pipeline in GitHub Actions (#1278)</li> <li>layers: bump to 22 for 1.26.3</li> </ul>"},{"location":"changelog/#v1263-2022-07-04","title":"v1.26.3 - 2022-07-04","text":""},{"location":"changelog/#bug-fixes_37","title":"Bug Fixes","text":"<ul> <li>ci: remove utf-8 body in octokit body req</li> <li>ci: improve msg visibility on closed issues</li> <li>ci: disable merged_pr workflow</li> <li>ci: merged_pr add issues write access</li> <li>ci: quote prBody GH expr on_opened_pr</li> <li>ci: reusable workflow secrets param</li> <li>logger: support additional args for handlers when injecting lambda context (#1276)</li> <li>logger: preserve std keys when using custom formatters (#1264)</li> </ul>"},{"location":"changelog/#documentation_30","title":"Documentation","text":"<ul> <li>lint: add markdownlint rules and automation (#1256)</li> <li>logger: document enriching logs with logrecord attributes (#1271)</li> <li>logger: snippets split, improved, and lint (#1262)</li> <li>metrics: snippets split, improved, and lint (#1272)</li> <li>tracer: snippets split, improved, and lint (#1261)</li> <li>tracer: split and lint code snippets (#1260)</li> </ul>"},{"location":"changelog/#maintenance_38","title":"Maintenance","text":"<ul> <li>move to approach B for multiple IaC</li> <li>add sam build gitignore</li> <li>bump to version 1.26.3</li> <li>ci: reactivate on_merged_pr workflow</li> <li>ci: improve wording on closed issues action</li> <li>ci: deactivate on_merged_pr workflow</li> <li>deps: bump aws-xray-sdk from 2.9.0 to 2.10.0 (#1270)</li> <li>deps: bump dependabot/fetch-metadata from 1.1.1 to 1.3.2 (#1269)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.2 to 1.3.3 (#1273)</li> <li>deps-dev: bump flake8-bugbear from 22.6.22 to 22.7.1 (#1274)</li> <li>deps-dev: bump flake8-bugbear from 22.4.25 to 22.6.22 (#1258)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.0 to 1.24.12 (#1255)</li> <li>deps-dev: bump mypy-boto3-secretsmanager (#1252)</li> <li>governance: fix on_merged_pr workflow syntax</li> <li>governance: warn message on closed issues</li> <li>layers: bump to 21 for 1.26.2</li> <li>test-perf: use pytest-benchmark to improve reliability (#1250)</li> </ul>"},{"location":"changelog/#v1262-2022-06-16","title":"v1.26.2 - 2022-06-16","text":""},{"location":"changelog/#bug-fixes_38","title":"Bug Fixes","text":"<ul> <li>event-handler: body to empty string in CORS preflight (ALB non-compliant) (#1249)</li> </ul>"},{"location":"changelog/#code-refactoring_4","title":"Code Refactoring","text":"<ul> <li>rename to clear_state</li> <li>rename to remove_custom_keys</li> </ul>"},{"location":"changelog/#documentation_31","title":"Documentation","text":"<ul> <li>fix anchor</li> </ul>"},{"location":"changelog/#features_26","title":"Features","text":"<ul> <li>logger: add option to clear state per invocation</li> </ul>"},{"location":"changelog/#maintenance_39","title":"Maintenance","text":"<ul> <li>bump to 1.26.2</li> <li>deps: bump actions/setup-python from 3 to 4 (#1244)</li> <li>deps-dev: bump mypy from 0.960 to 0.961 (#1241)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.23.0.post1 to 1.24.0 (#1231)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.23.8 to 1.24.0 (#1232)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.23.0.post1 to 1.24.0 (#1234)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.23.0.post1 to 1.24.0 (#1233)</li> <li>governance: auto-merge on all PR events</li> <li>governance: add release label on pr merge</li> <li>governance: enforce safe scope on pr merge labelling</li> <li>governance: limit build workflow to code changes only</li> <li>governance: auto-merge workflow_dispatch off</li> <li>governance: auto-merge to use squash</li> <li>governance: check for related issue in new PRs</li> <li>governance: auto-merge mypy-stub dependabot</li> <li>governance: address gh reusable workflow limitation</li> <li>governance: fix workflow action requirements &amp; syntax</li> <li>governance: warn message on closed issues</li> <li>metrics: revert dimensions test before splitting (#1243)</li> </ul>"},{"location":"changelog/#v1261-2022-06-07","title":"v1.26.1 - 2022-06-07","text":""},{"location":"changelog/#bug-fixes_39","title":"Bug Fixes","text":"<ul> <li>metrics: raise SchemaValidationError for &gt;8 metric dimensions (#1240)</li> </ul>"},{"location":"changelog/#documentation_32","title":"Documentation","text":"<ul> <li>governance: link roadmap and maintainers doc</li> <li>maintainers: initial maintainers playbook (#1222)</li> <li>roadmap: use pinned pause issue instead</li> </ul>"},{"location":"changelog/#maintenance_40","title":"Maintenance","text":"<ul> <li>bump version 1.26.1</li> <li>deps-dev: bump mypy from 0.950 to 0.960 (#1224)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.23.0.post1 to 1.23.8 (#1225)</li> </ul>"},{"location":"changelog/#v1260-2022-05-20","title":"v1.26.0 - 2022-05-20","text":""},{"location":"changelog/#bug-fixes_40","title":"Bug Fixes","text":"<ul> <li>batch: missing space in BatchProcessingError message (#1201)</li> <li>batch: docstring fix for success_handler() record parameter (#1202)</li> <li>docs: remove Slack link (#1210)</li> </ul>"},{"location":"changelog/#documentation_33","title":"Documentation","text":"<ul> <li>layer: upgrade to 1.25.10</li> <li>roadmap: add new roadmap section (#1204)</li> </ul>"},{"location":"changelog/#features_27","title":"Features","text":"<ul> <li>parameters: accept boto3_client to support private endpoints and ease testing (#1096)</li> </ul>"},{"location":"changelog/#maintenance_41","title":"Maintenance","text":"<ul> <li>bump to 1.26.0</li> <li>deps: bump pydantic from 1.9.0 to 1.9.1 (#1221)</li> <li>deps: bump email-validator from 1.1.3 to 1.2.1 (#1199)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.21.34 to 1.23.0.post1 (#1218)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.21.34 to 1.23.0.post1 (#1219)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.21.34 to 1.23.0.post1 (#1220)</li> </ul>"},{"location":"changelog/#v12510-2022-04-29","title":"v1.25.10 - 2022-04-29","text":""},{"location":"changelog/#bug-fixes_41","title":"Bug Fixes","text":"<ul> <li>data-classes: Add missing SES fields and (#1045)</li> <li>deps: Ignore boto3 changes until needed (#1151)</li> <li>deps-dev: remove jmespath due to dev deps conflict  (#1148)</li> <li>event_handler: exception_handler to handle ServiceError exceptions (#1160)</li> <li>event_handler: Allow for event_source support (#1159)</li> <li>parser: Add missing fields for SESEvent (#1027)</li> </ul>"},{"location":"changelog/#documentation_34","title":"Documentation","text":"<ul> <li>layer: upgrade to 1.25.9</li> </ul>"},{"location":"changelog/#features_28","title":"Features","text":"<ul> <li>parameters: add clear_cache method for providers (#1194)</li> </ul>"},{"location":"changelog/#maintenance_42","title":"Maintenance","text":"<ul> <li>include regression in changelog</li> <li>bump to 1.25.10</li> <li>ci: changelog pre-generation to fetch tags from origin</li> <li>ci: disable mergify configuration after breaking changes (#1188)</li> <li>ci: post release on tagged issues too</li> <li>deps: bump codecov/codecov-action from 3.0.0 to 3.1.0 (#1143)</li> <li>deps: bump github/codeql-action from 1 to 2 (#1154)</li> <li>deps-dev: bump flake8-eradicate from 1.2.0 to 1.2.1 (#1158)</li> <li>deps-dev: bump mypy from 0.942 to 0.950 (#1162)</li> <li>deps-dev: bump mkdocs-git-revision-date-plugin (#1146)</li> <li>deps-dev: bump flake8-bugbear from 22.1.11 to 22.4.25 (#1156)</li> <li>deps-dev: bump xenon from 0.8.0 to 0.9.0 (#1145)</li> <li>deps-dev: bump mypy from 0.931 to 0.942 (#1133)</li> </ul>"},{"location":"changelog/#regression_1","title":"Regression","text":"<ul> <li>parser: Add missing fields for SESEvent (#1027) (#1190)</li> </ul>"},{"location":"changelog/#v1259-2022-04-21","title":"v1.25.9 - 2022-04-21","text":""},{"location":"changelog/#bug-fixes_42","title":"Bug Fixes","text":"<ul> <li>deps: correct py36 marker for jmespath</li> </ul>"},{"location":"changelog/#maintenance_43","title":"Maintenance","text":"<ul> <li>bump to 1.25.9</li> </ul>"},{"location":"changelog/#v1258-2022-04-21","title":"v1.25.8 - 2022-04-21","text":""},{"location":"changelog/#bug-fixes_43","title":"Bug Fixes","text":"<ul> <li>removed ambiguous quotes from labels.</li> <li>deps: update jmespath marker to support 1.0 and py3.6 (#1139)</li> <li>governance: update label in names in issues</li> </ul>"},{"location":"changelog/#documentation_35","title":"Documentation","text":"<ul> <li>install: instructions to reduce pydantic package size (#1077)</li> <li>layer: remove link from clipboard button (#1135)</li> <li>layer: update to 1.25.7</li> </ul>"},{"location":"changelog/#maintenance_44","title":"Maintenance","text":"<ul> <li>bump to 1.25.8</li> <li>deps: bump codecov/codecov-action from 2.1.0 to 3.0.0 (#1102)</li> <li>deps: bump actions/upload-artifact from 2 to 3 (#1103)</li> <li>deps-dev: bump mkdocs-material from 8.2.4 to 8.2.7 (#1131)</li> <li>deps-dev: bump pytest from 6.2.5 to 7.0.1 (#1063)</li> </ul>"},{"location":"changelog/#v1257-2022-04-08","title":"v1.25.7 - 2022-04-08","text":""},{"location":"changelog/#bug-fixes_44","title":"Bug Fixes","text":"<ul> <li>api_gateway: allow whitespace in routes' path parameter (#1099)</li> <li>api_gateway: allow whitespace in routes' path parameter (#1099)</li> <li>idempotency: pass by value on idem key to guard inadvert mutations (#1090)</li> <li>logger: clear_state should keep custom key formats (#1095)</li> <li>middleware_factory: ret type annotation for handler dec (#1066)</li> </ul>"},{"location":"changelog/#documentation_36","title":"Documentation","text":"<ul> <li>layer: update to 1.25.6; cosmetic changes</li> </ul>"},{"location":"changelog/#maintenance_45","title":"Maintenance","text":"<ul> <li>bump to 1.25.7</li> <li>governance: refresh pull request template sections</li> <li>governance: update external non-triage effort disclaimer</li> <li>governance: update static typing to a form</li> <li>governance: update rfc to a form</li> <li>governance: update feat request to a form</li> <li>governance: bug report form typo</li> <li>governance: update docs report to a form</li> <li>governance: update bug report to a form</li> <li>governance: new ask a question</li> <li>governance: new static typing report</li> </ul>"},{"location":"changelog/#v1256-2022-04-01","title":"v1.25.6 - 2022-04-01","text":""},{"location":"changelog/#bug-fixes_45","title":"Bug Fixes","text":"<ul> <li>logger: clear_state regression on absent standard keys (#1088)</li> </ul>"},{"location":"changelog/#documentation_37","title":"Documentation","text":"<ul> <li>layer: bump to 1.25.5</li> </ul>"},{"location":"changelog/#maintenance_46","title":"Maintenance","text":"<ul> <li>bump to 1.25.6</li> </ul>"},{"location":"changelog/#v1255-2022-03-18","title":"v1.25.5 - 2022-03-18","text":""},{"location":"changelog/#bug-fixes_46","title":"Bug Fixes","text":"<ul> <li>logger-utils: regression on exclude set leading to no formatter (#1080)</li> </ul>"},{"location":"changelog/#maintenance_47","title":"Maintenance","text":"<ul> <li>bump to 1.25.5</li> </ul>"},{"location":"changelog/#v1254-2022-03-17","title":"v1.25.4 - 2022-03-17","text":""},{"location":"changelog/#bug-fixes_47","title":"Bug Fixes","text":"<ul> <li>package_logger as const over logger instance</li> <li>repurpose test to cover parent loggers case</li> <li>use addHandler over monkeypatch</li> </ul>"},{"location":"changelog/#documentation_38","title":"Documentation","text":"<ul> <li>appsync: fix typo</li> <li>contributing: operational excellence pause</li> <li>layer: update to 1.25.3</li> </ul>"},{"location":"changelog/#maintenance_48","title":"Maintenance","text":"<ul> <li>bump to 1.25.4</li> <li>remove duplicate test</li> <li>comment reason for change</li> <li>remove unnecessary test</li> <li>lint unused import</li> </ul>"},{"location":"changelog/#regression_2","title":"Regression","text":"<ul> <li>service_name fixture</li> </ul>"},{"location":"changelog/#pull-requests_1","title":"Pull Requests","text":"<ul> <li>Merge pull request #1075 from mploski/fix/existing-loggers-duplicated-logs</li> </ul>"},{"location":"changelog/#v1253-2022-03-09","title":"v1.25.3 - 2022-03-09","text":""},{"location":"changelog/#bug-fixes_48","title":"Bug Fixes","text":"<ul> <li>logger: ensure state is cleared for custom formatters (#1072)</li> </ul>"},{"location":"changelog/#documentation_39","title":"Documentation","text":"<ul> <li>plugin: add mermaid to create diagram as code (#1070)</li> </ul>"},{"location":"changelog/#maintenance_49","title":"Maintenance","text":"<ul> <li>bump to 1.25.3</li> </ul>"},{"location":"changelog/#v1252-2022-03-07","title":"v1.25.2 - 2022-03-07","text":""},{"location":"changelog/#bug-fixes_49","title":"Bug Fixes","text":"<ul> <li>event_handler: docs snippets, high-level import CorsConfig (#1019)</li> <li>lambda-authorizer: allow proxy resources path in arn (#1051)</li> <li>metrics: flush upon a single metric 100th data point (#1046)</li> </ul>"},{"location":"changelog/#documentation_40","title":"Documentation","text":"<ul> <li>layer: update to 1.25.1</li> <li>parser: APIGatewayProxyEvent to APIGatewayProxyEventModel (#1061)</li> </ul>"},{"location":"changelog/#maintenance_50","title":"Maintenance","text":"<ul> <li>bump to 1.25.2</li> <li>deps: bump actions/setup-python from 2.3.1 to 3 (#1048)</li> <li>deps: bump actions/checkout from 2 to 3 (#1052)</li> <li>deps: bump actions/github-script from 5 to 6 (#1023)</li> <li>deps: bump fastjsonschema from 2.15.2 to 2.15.3 (#949)</li> <li>deps-dev: bump mkdocs-material from 8.1.9 to 8.2.4 (#1054)</li> </ul>"},{"location":"changelog/#v1251-2022-02-14","title":"v1.25.1 - 2022-02-14","text":""},{"location":"changelog/#bug-fixes_50","title":"Bug Fixes","text":"<ul> <li>batch: bugfix to clear exceptions between executions (#1022)</li> </ul>"},{"location":"changelog/#maintenance_51","title":"Maintenance","text":"<ul> <li>bump to 1.25.1</li> <li>layers: bump to 10 for 1.25.0</li> </ul>"},{"location":"changelog/#v1250-2022-02-09","title":"v1.25.0 - 2022-02-09","text":""},{"location":"changelog/#bug-fixes_51","title":"Bug Fixes","text":"<ul> <li>apigateway: remove indentation in debug_mode (#987)</li> <li>batch: delete &gt;10 messages in legacy sqs processor (#818)</li> <li>ci: pr label regex for special chars in title</li> <li>logger: exclude source_logger in copy_config_to_registered_loggers (#1001)</li> <li>logger: test generates logfile</li> </ul>"},{"location":"changelog/#documentation_41","title":"Documentation","text":"<ul> <li>fix syntax errors and line highlights (#1004)</li> <li>add better BDD coments</li> <li>event-handler: improve testing section for graphql (#996)</li> <li>layer: update to 1.24.2</li> <li>parameters: add testing your code section (#1017)</li> <li>theme: upgrade mkdocs-material to 8.x (#1002)</li> <li>tutorial: fix broken internal links (#1000)</li> </ul>"},{"location":"changelog/#features_29","title":"Features","text":"<ul> <li>event-handler: new resolvers to fix current_event typing (#978)</li> <li>logger: log_event support event data classes (e.g. S3Event) (#984)</li> <li>mypy: complete mypy support for the entire codebase (#943)</li> </ul>"},{"location":"changelog/#maintenance_52","title":"Maintenance","text":"<ul> <li>bump to 1.25.0</li> <li>correct docs</li> <li>correct docs</li> <li>use isinstance over type</li> <li>deps-dev: bump flake8-bugbear from 21.11.29 to 22.1.11 (#955)</li> <li>metrics: fix tests when warnings are disabled (#994)</li> </ul>"},{"location":"changelog/#pull-requests_2","title":"Pull Requests","text":"<ul> <li>Merge pull request #971 from gyft/fix-logger-util-tests</li> </ul>"},{"location":"changelog/#v1242-2022-01-21","title":"v1.24.2 - 2022-01-21","text":""},{"location":"changelog/#bug-fixes_52","title":"Bug Fixes","text":"<ul> <li>data-classes: underscore support in api gateway authorizer resource name (#969)</li> </ul>"},{"location":"changelog/#documentation_42","title":"Documentation","text":"<ul> <li>layer: update to 1.24.1</li> </ul>"},{"location":"changelog/#maintenance_53","title":"Maintenance","text":"<ul> <li>bump to 1.24.2</li> </ul>"},{"location":"changelog/#v1241-2022-01-20","title":"v1.24.1 - 2022-01-20","text":""},{"location":"changelog/#bug-fixes_53","title":"Bug Fixes","text":"<ul> <li>remove unused json import</li> <li>remove apigw contract when using event-handler, apigw tracing</li> <li>use decorators, split cold start to ease reading</li> <li>incorrect log keys, indentation, snippet consistency</li> <li>remove f-strings that doesn't evaluate expr</li> <li>batch: report multiple failures (#967)</li> <li>data-classes: docstring typos and clean up (#937)</li> <li>parameters: appconfig internal _get docstrings (#934)</li> </ul>"},{"location":"changelog/#documentation_43","title":"Documentation","text":"<ul> <li>rename quickstart to tutorial in readme</li> <li>rename to tutorial given the size</li> <li>add final consideration section</li> <li>batch: snippet typo on batch processed messages iteration (#951)</li> <li>batch: fix typo in context manager keyword (#938)</li> <li>homepage: link to typescript version (#950)</li> <li>install: new lambda layer for 1.24.0 release</li> <li>metrics: keep it consistent with other sections, update metric names</li> <li>nav: make REST and GraphQL event handlers more explicit (#959)</li> <li>quickstart: expand on intro line</li> <li>quickstart: tidy requirements up</li> <li>quickstart: make section agnostic to json lib</li> <li>quickstart: same process for Logger</li> <li>quickstart: add sub-sections, fix highlight &amp; code</li> <li>quickstart: sentence fragmentation, tidy up</li> <li>tenets: make core, non-core more explicit</li> <li>tracer: warning to note on local traces</li> <li>tracer: add initial image, requirements</li> <li>tracer: add annotation, metadata, and image</li> <li>tracer: update ServiceLens image w/ API GW, copywriting</li> <li>tutorial: fix path to images (#963)</li> </ul>"},{"location":"changelog/#features_30","title":"Features","text":"<ul> <li>ci: auto-notify &amp; close issues on release</li> <li>logger: clone powertools logger config to any Python logger (#927)</li> </ul>"},{"location":"changelog/#maintenance_54","title":"Maintenance","text":"<ul> <li>bump to 1.24.1</li> <li>bump to 1.24.1</li> <li>ci: run codeql analysis on push only</li> <li>ci: fix mergify dependabot queue</li> <li>ci: add queue name in mergify</li> <li>ci: remove mergify legacy key</li> <li>ci: update mergify bot breaking change</li> <li>ci: safely label PR based on title</li> <li>deps: bump pydantic from 1.8.2 to 1.9.0 (#933)</li> <li>deps-dev: bump mypy from 0.930 to 0.931 (#941)</li> </ul>"},{"location":"changelog/#regression_3","title":"Regression","text":"<ul> <li>order to APP logger/service name due to screenshots</li> </ul>"},{"location":"changelog/#pull-requests_3","title":"Pull Requests","text":"<ul> <li>Merge pull request #769 from mploski/docs/quick-start</li> </ul>"},{"location":"changelog/#v1240-2021-12-31","title":"v1.24.0 - 2021-12-31","text":""},{"location":"changelog/#bug-fixes_54","title":"Bug Fixes","text":"<ul> <li>apigateway: support @app.not_found() syntax &amp; housekeeping (#926)</li> <li>event-sources: handle dynamodb null type as none, not bool (#929)</li> <li>warning: future distutils deprecation (#921)</li> </ul>"},{"location":"changelog/#documentation_44","title":"Documentation","text":"<ul> <li>consistency around admonitions and snippets (#919)</li> <li>Added GraphQL Sample API to Examples section of README.md (#930)</li> <li>batch: remove leftover from legacy</li> <li>layer: bump Lambda Layer to version 6</li> <li>tracer: new ignore_endpoint feature (#931)</li> </ul>"},{"location":"changelog/#features_31","title":"Features","text":"<ul> <li>event-sources: cache parsed json in data class (#909)</li> <li>feature_flags: support beyond boolean values (JSON values) (#804)</li> <li>idempotency: support dataclasses &amp; pydantic models payloads (#908)</li> <li>logger: support use_datetime_directive for timestamps (#920)</li> <li>tracer: ignore tracing for certain hostname(s) or url(s) (#910)</li> </ul>"},{"location":"changelog/#maintenance_55","title":"Maintenance","text":"<ul> <li>bump to 1.24.0</li> <li>deps-dev: bump mypy from 0.920 to 0.930 (#925)</li> </ul>"},{"location":"changelog/#v1230-2021-12-20","title":"v1.23.0 - 2021-12-20","text":""},{"location":"changelog/#bug-fixes_55","title":"Bug Fixes","text":"<ul> <li>apigateway: allow list of HTTP methods in route method (#838)</li> <li>event-sources: Pass authorizer data to APIGatewayEventAuthorizer (#897)</li> <li>event-sources: handle claimsOverrideDetails set to null (#878)</li> <li>idempotency: include decorated fn name in hash (#869)</li> <li>metrics: explicit type to single_metric ctx manager (#865)</li> <li>parameters: appconfig transform and return types (#877)</li> <li>parser: overload parse when using envelope (#885)</li> <li>parser: kinesis sequence number is str, not int (#907)</li> <li>parser: mypy support for payload type override as models (#883)</li> <li>tracer: add warm start annotation (ColdStart=False) (#851)</li> </ul>"},{"location":"changelog/#documentation_45","title":"Documentation","text":"<ul> <li>external reference to cloudformation custom resource helper (#914)</li> <li>add new public Slack invite</li> <li>disable search blur in non-prod env</li> <li>update Lambda Layers version</li> <li>apigateway: add new not_found feature (#915)</li> <li>apigateway: fix sample layout provided (#864)</li> <li>appsync: fix users.py typo to locations #830</li> <li>lambda_layer: fix CDK layer syntax</li> </ul>"},{"location":"changelog/#features_32","title":"Features","text":"<ul> <li>apigateway: add exception_handler support (#898)</li> <li>apigateway: access parent api resolver from router (#842)</li> <li>batch: new BatchProcessor for SQS, DynamoDB, Kinesis (#886)</li> <li>logger: allow handler with custom kwargs signature (#913)</li> <li>tracer: add service annotation when service is set (#861)</li> </ul>"},{"location":"changelog/#maintenance_56","title":"Maintenance","text":"<ul> <li>correct pr label order</li> <li>minor housekeeping before release (#912)</li> <li>bump to 1.23.0</li> <li>ci: split latest docs workflow</li> <li>deps: bump fastjsonschema from 2.15.1 to 2.15.2 (#891)</li> <li>deps: bump actions/setup-python from 2.2.2 to 2.3.0 (#831)</li> <li>deps: bump aws-xray-sdk from 2.8.0 to 2.9.0 (#876)</li> <li>deps: support arm64 when developing locally (#862)</li> <li>deps: bump actions/setup-python from 2.3.0 to 2.3.1 (#852)</li> <li>deps-dev: bump flake8 from 3.9.2 to 4.0.1 (#789)</li> <li>deps-dev: bump black from 21.10b0 to 21.11b1 (#839)</li> <li>deps-dev: bump black from 21.11b1 to 21.12b0 (#872)</li> <li>deps-dev: bump mypy from 0.910 to 0.920 (#903)</li> </ul>"},{"location":"changelog/#v1220-2021-11-17","title":"v1.22.0 - 2021-11-17","text":""},{"location":"changelog/#bug-fixes_56","title":"Bug Fixes","text":"<ul> <li>change supported python version from 3.6.1 to 3.6.2, bump black (#807)</li> <li>ci: comment custom publish version checker</li> <li>ci: skip sync master on docs hotfix</li> <li>parser: body/QS can be null or omitted in apigw v1/v2 (#820)</li> </ul>"},{"location":"changelog/#code-refactoring_5","title":"Code Refactoring","text":"<ul> <li>apigateway: Add BaseRouter and duplicate route check (#757)</li> </ul>"},{"location":"changelog/#documentation_46","title":"Documentation","text":"<ul> <li>updated Lambda Layers definition &amp; limitations. (#775)</li> <li>Idiomatic tenet updated to Progressive</li> <li>use higher contrast font (#822)</li> <li>use higher contrast font</li> <li>fix indentation of SAM snippets in install section (#778)</li> <li>improve public lambda layer wording, clipboard buttons (#762)</li> <li>add amplify-cli instructions for public layer (#754)</li> <li>api-gateway: add support for new router feature (#767)</li> <li>apigateway: re-add sample layout, add considerations (#826)</li> <li>appsync: add new router feature (#821)</li> <li>idempotency: add support for DynamoDB composite keys (#808)</li> <li>tenets: update Idiomatic tenet to Progressive (#823)</li> </ul>"},{"location":"changelog/#features_33","title":"Features","text":"<ul> <li>apigateway: add Router to allow large routing composition (#645)</li> <li>appsync: add Router to allow large resolver composition (#776)</li> <li>data-classes: ActiveMQ and RabbitMQ support (#770)</li> <li>logger: add ALB correlation ID support (#816)</li> </ul>"},{"location":"changelog/#maintenance_57","title":"Maintenance","text":"<ul> <li>fix var expr</li> <li>remove Lambda Layer version tag</li> <li>bump to 1.22.0</li> <li>conditional to publish docs only attempt 3</li> <li>conditional to publish docs only attempt 2</li> <li>conditional to publish docs only</li> <li>deps: bump boto3 from 1.18.58 to 1.18.59 (#760)</li> <li>deps: bump boto3 from 1.18.56 to 1.18.58 (#755)</li> <li>deps: bump urllib3 from 1.26.4 to 1.26.5 (#787)</li> <li>deps: bump boto3 from 1.19.6 to 1.20.3 (#809)</li> <li>deps: bump boto3 from 1.18.61 to 1.19.6 (#783)</li> <li>deps: bump boto3 from 1.20.3 to 1.20.5 (#817)</li> <li>deps: bump boto3 from 1.18.59 to 1.18.61 (#766)</li> <li>deps-dev: bump coverage from 6.0.1 to 6.0.2 (#764)</li> <li>deps-dev: bump pytest-asyncio from 0.15.1 to 0.16.0 (#782)</li> <li>deps-dev: bump flake8-eradicate from 1.1.0 to 1.2.0 (#784)</li> <li>deps-dev: bump flake8-isort from 4.0.0 to 4.1.1 (#785)</li> <li>deps-dev: bump mkdocs-material from 7.3.2 to 7.3.3 (#758)</li> <li>deps-dev: bump flake8-comprehensions from 3.6.1 to 3.7.0 (#759)</li> <li>deps-dev: bump mkdocs-material from 7.3.3 to 7.3.5 (#781)</li> <li>deps-dev: bump coverage from 6.0 to 6.0.1 (#751)</li> <li>deps-dev: bump mkdocs-material from 7.3.5 to 7.3.6 (#791)</li> <li>deps-dev: bump coverage from 6.0.2 to 6.1.2 (#810)</li> <li>deps-dev: bump isort from 5.9.3 to 5.10.1 (#811)</li> </ul>"},{"location":"changelog/#v1211-2021-10-07","title":"v1.21.1 - 2021-10-07","text":""},{"location":"changelog/#documentation_47","title":"Documentation","text":"<ul> <li>add new public layer ARNs (#746)</li> </ul>"},{"location":"changelog/#maintenance_58","title":"Maintenance","text":"<ul> <li>include public layers changelog</li> <li>bump to 1.21.1</li> <li>include regression in changelog</li> <li>ignore constants in test cov (#745)</li> <li>ignore constants in tests cov</li> <li>add support for publishing fallback</li> <li>deps: bump boto3 from 1.18.54 to 1.18.56 (#742)</li> <li>deps-dev: bump mkdocs-material from 7.3.1 to 7.3.2 (#741)</li> </ul>"},{"location":"changelog/#regression_4","title":"Regression","text":"<ul> <li>metrics: typing regression on log_metrics callable (#744)</li> </ul>"},{"location":"changelog/#v1210-2021-10-05","title":"v1.21.0 - 2021-10-05","text":""},{"location":"changelog/#bug-fixes_57","title":"Bug Fixes","text":"<ul> <li>data-classes: use correct asdict funciton (#666)</li> <li>feature-flags: rules should evaluate with an AND op (#724)</li> <li>idempotency: sorting keys before hashing (#722)</li> <li>idempotency: sorting keys before hashing</li> <li>logger: push extra keys to the end (#722)</li> <li>mypy: a few return types, type signatures, and untyped areas (#718)</li> </ul>"},{"location":"changelog/#code-refactoring_6","title":"Code Refactoring","text":"<ul> <li>data-classes: clean up internal logic for APIGatewayAuthorizerResponse (#643)</li> </ul>"},{"location":"changelog/#documentation_48","title":"Documentation","text":"<ul> <li>Terraform reference for SAR Lambda Layer (#716)</li> <li>add team behind it and email</li> <li>event-handler: document catch-all routes (#705)</li> <li>idempotency: fix misleading idempotent examples (#661)</li> <li>jmespath: clarify envelope terminology</li> <li>parser: fix incorrect import in root_validator example (#735)</li> </ul>"},{"location":"changelog/#features_34","title":"Features","text":"<ul> <li>expose jmespath powertools functions (#736)</li> <li>add get_raw_configuration property in store; expose store</li> <li>boto3 sessions in batch, parameters &amp; idempotency (#717)</li> <li>feature-flags: Bring your own logger for debug (#709)</li> <li>feature-flags: improve \"IN/NOT_IN\"; new rule actions (#710)</li> <li>feature-flags: get_raw_configuration property in Store (#720)</li> <li>feature_flags: Added inequality conditions (#721)</li> <li>idempotency: makes customers unit testing easier (#719)</li> <li>validator: include missing data elements from a validation error (#686)</li> </ul>"},{"location":"changelog/#maintenance_59","title":"Maintenance","text":"<ul> <li>add python 3.9 support</li> <li>bump to 1.21.0</li> <li>deps: bump boto3 from 1.18.41 to 1.18.49 (#703)</li> <li>deps: bump boto3 from 1.18.32 to 1.18.38 (#671)</li> <li>deps: bump boto3 from 1.18.38 to 1.18.41 (#677)</li> <li>deps: bump boto3 from 1.18.51 to 1.18.54 (#733)</li> <li>deps: bump boto3 from 1.18.49 to 1.18.51 (#713)</li> <li>deps: bump codecov/codecov-action from 2.0.2 to 2.1.0 (#675)</li> <li>deps-dev: bump flake8-bugbear from 21.9.1 to 21.9.2 (#712)</li> <li>deps-dev: bump mkdocs-material from 7.3.0 to 7.3.1 (#731)</li> <li>deps-dev: bump mkdocs-material from 7.2.8 to 7.3.0 (#695)</li> <li>deps-dev: bump mkdocs-material from 7.2.6 to 7.2.8 (#682)</li> <li>deps-dev: bump flake8-bugbear from 21.4.3 to 21.9.1 (#676)</li> <li>deps-dev: bump coverage from 5.5 to 6.0 (#732)</li> <li>deps-dev: bump radon from 4.5.2 to 5.1.0 (#673)</li> <li>deps-dev: bump pytest-cov from 2.12.1 to 3.0.0 (#730)</li> <li>deps-dev: bump xenon from 0.7.3 to 0.8.0 (#669)</li> </ul>"},{"location":"changelog/#v1202-2021-09-02","title":"v1.20.2 - 2021-09-02","text":""},{"location":"changelog/#bug-fixes_58","title":"Bug Fixes","text":"<ul> <li>Fix issue with strip_prefixes (#647)</li> </ul>"},{"location":"changelog/#maintenance_60","title":"Maintenance","text":"<ul> <li>bump to 1.20.2</li> <li>deps: bump boto3 from 1.18.26 to 1.18.32 (#663)</li> <li>deps-dev: bump mkdocs-material from 7.2.4 to 7.2.6 (#665)</li> <li>deps-dev: bump pytest from 6.2.4 to 6.2.5 (#662)</li> <li>license: Add THIRD-PARTY-LICENSES (#641)</li> </ul>"},{"location":"changelog/#v1201-2021-08-22","title":"v1.20.1 - 2021-08-22","text":""},{"location":"changelog/#bug-fixes_59","title":"Bug Fixes","text":"<ul> <li>idempotency: sorting keys before hashing (#639)</li> </ul>"},{"location":"changelog/#maintenance_61","title":"Maintenance","text":"<ul> <li>bump to 1.20.1</li> <li>markdown linter fixes (#636)</li> <li>setup codespaces (#637)</li> <li>license: add third party license (#635)</li> </ul>"},{"location":"changelog/#v1200-2021-08-21","title":"v1.20.0 - 2021-08-21","text":""},{"location":"changelog/#bug-fixes_60","title":"Bug Fixes","text":"<ul> <li>api-gateway: HTTP API strip stage name from request path (#622)</li> <li>docs: correct feature_flags link and json exmaples (#605)</li> </ul>"},{"location":"changelog/#code-refactoring_7","title":"Code Refactoring","text":"<ul> <li>event_handler: match to match_results; 3.10 new keyword (#616)</li> </ul>"},{"location":"changelog/#documentation_49","title":"Documentation","text":"<ul> <li>api-gateway: add new API mapping support</li> <li>data-class: fix invalid syntax in new AppSync Authorizer</li> <li>data-classes: make authorizer concise; use enum (#630)</li> </ul>"},{"location":"changelog/#features_35","title":"Features","text":"<ul> <li>data-classes: authorizer for http api and rest api (#620)</li> <li>data-classes: data_as_bytes prop KinesisStreamRecordPayload (#628)</li> <li>data-classes: AppSync Lambda authorizer event (#610)</li> <li>event-handler: prefixes to strip for custom mappings (#579)</li> <li>general: support for Python 3.9 (#626)</li> <li>idempotency: support for any synchronous function (#625)</li> </ul>"},{"location":"changelog/#maintenance_62","title":"Maintenance","text":"<ul> <li>update changelog to reflect out-of-band commits</li> <li>bump to 1.20.0</li> <li>update new changelog version tag</li> <li>actions: include new labels</li> <li>api-docs: enable allow_reuse to fix the docs (#612)</li> <li>deps: bump boto3 from 1.18.25 to 1.18.26 (#627)</li> <li>deps: bump boto3 from 1.18.24 to 1.18.25 (#623)</li> <li>deps: bump boto3 from 1.18.22 to 1.18.24 (#619)</li> <li>deps: bump boto3 from 1.18.21 to 1.18.22 (#614)</li> <li>deps: bump boto3 from 1.18.17 to 1.18.21 (#608)</li> <li>deps-dev: bump flake8-comprehensions from 3.6.0 to 3.6.1 (#615)</li> <li>deps-dev: bump flake8-comprehensions from 3.5.0 to 3.6.0 (#609)</li> <li>deps-dev: bump mkdocs-material from 7.2.3 to 7.2.4 (#607)</li> <li>docs: correct markdown based on markdown lint (#603)</li> <li>shared: fix cyclic import &amp; refactor data extraction fn (#613)</li> </ul>"},{"location":"changelog/#v1190-2021-08-11","title":"v1.19.0 - 2021-08-11","text":""},{"location":"changelog/#bug-fixes_61","title":"Bug Fixes","text":"<ul> <li>deps: bump poetry to latest (#592)</li> <li>feature-flags:  bug handling multiple conditions (#599)</li> <li>feature-toggles: correct cdk example (#601)</li> <li>parser: apigw wss validation check_message_id; housekeeping (#553)</li> </ul>"},{"location":"changelog/#code-refactoring_8","title":"Code Refactoring","text":"<ul> <li>feature-flags: add debug for all features evaluation\" (#590)</li> <li>feature_flags: optimize UX and maintenance (#563)</li> </ul>"},{"location":"changelog/#documentation_50","title":"Documentation","text":"<ul> <li>event-handler: new custom serializer option</li> <li>feature-flags: add guidance when to use vs env vars vs parameters</li> <li>feature-flags: fix sample feature name in evaluate</li> <li>feature-flags: create concrete documentation (#594)</li> <li>feature-toggles: correct docs and typing (#588)</li> <li>feature_flags: fix SAM infra, convert CDK to Python</li> <li>parameters: auto-transforming values based on suffix (#573)</li> <li>readme: add code coverage badge (#577)</li> <li>tracer: update wording that it auto-disables on non-Lambda env</li> </ul>"},{"location":"changelog/#features_36","title":"Features","text":"<ul> <li>api-gateway: add support for custom serializer (#568)</li> <li>data-classes: decode json_body if based64 encoded (#560)</li> <li>feature flags: Add not_in action and rename contains to in (#589)</li> <li>params: expose high level max_age, raise_on_transform_error (#567)</li> <li>tracer: disable tracer when for non-Lambda envs (#598)</li> </ul>"},{"location":"changelog/#maintenance_63","title":"Maintenance","text":"<ul> <li>only build docs on docs path</li> <li>update pypi description, keywords</li> <li>bump to 1.19.0</li> <li>enable autolabel based on PR title</li> <li>include feature-flags docs hotfix</li> <li>deps: bump boto3 from 1.18.15 to 1.18.17 (#597)</li> <li>deps: bump boto3 from 1.18.1 to 1.18.15 (#591)</li> <li>deps: bump codecov/codecov-action from 2.0.1 to 2.0.2 (#558)</li> <li>deps-dev: bump mkdocs-material from 7.2.1 to 7.2.2 (#582)</li> <li>deps-dev: bump mkdocs-material from 7.2.2 to 7.2.3 (#596)</li> <li>deps-dev: bump pdoc3 from 0.9.2 to 0.10.0 (#584)</li> <li>deps-dev: bump isort from 5.9.2 to 5.9.3 (#574)</li> <li>deps-dev: bump mkdocs-material from 7.2.0 to 7.2.1 (#566)</li> <li>deps-dev: bump mkdocs-material from 7.1.11 to 7.2.0 (#551)</li> <li>deps-dev: bump flake8-black from 0.2.1 to 0.2.3 (#541)</li> </ul>"},{"location":"changelog/#v1181-2021-07-23","title":"v1.18.1 - 2021-07-23","text":""},{"location":"changelog/#bug-fixes_62","title":"Bug Fixes","text":"<ul> <li>api-gateway: route regression non-word and unsafe URI chars (#556)</li> </ul>"},{"location":"changelog/#maintenance_64","title":"Maintenance","text":"<ul> <li>bump 1.18.1</li> </ul>"},{"location":"changelog/#v1180-2021-07-20","title":"v1.18.0 - 2021-07-20","text":""},{"location":"changelog/#bug-fixes_63","title":"Bug Fixes","text":"<ul> <li>api-gateway: non-greedy route pattern regex (#533)</li> <li>api-gateway: incorrect plain text mimetype #506</li> <li>data-classes: include milliseconds in scalar types (#504)</li> <li>mypy: fixes to resolve no implicit optional errors (#521)</li> <li>parser: Make ApiGateway version, authorizer fields optional (#532)</li> <li>tracer: mypy generic to preserve decorated method signature (#529)</li> </ul>"},{"location":"changelog/#code-refactoring_9","title":"Code Refactoring","text":"<ul> <li>feature-toggles: Code coverage and housekeeping (#530)</li> </ul>"},{"location":"changelog/#documentation_51","title":"Documentation","text":"<ul> <li>api-gateway: document new HTTP service error exceptions (#546)</li> <li>logger: document new get_correlation_id method (#545)</li> </ul>"},{"location":"changelog/#features_37","title":"Features","text":"<ul> <li>api-gateway: add debug mode (#507)</li> <li>api-gateway: add common service errors (#506)</li> <li>event-handler: Support AppSyncResolverEvent subclassing (#526)</li> <li>feat-toggle: New simple feature toggles rule engine (WIP) (#494)</li> <li>logger: add get_correlation_id method (#516)</li> <li>mypy: add mypy support to makefile (#508)</li> </ul>"},{"location":"changelog/#maintenance_65","title":"Maintenance","text":"<ul> <li>bump 1.18.0 (#547)</li> <li>deps: bump codecov/codecov-action from 1 to 2.0.1 (#539)</li> <li>deps: bump boto3 from 1.18.0 to 1.18.1 (#528)</li> <li>deps: bump boto3 from 1.17.110 to 1.18.0 (#527)</li> <li>deps: bump boto3 from 1.17.102 to 1.17.110 (#523)</li> <li>deps-dev: bump mkdocs-material from 7.1.10 to 7.1.11 (#542)</li> <li>deps-dev: bump mkdocs-material from 7.1.9 to 7.1.10 (#522)</li> <li>deps-dev: bump isort from 5.9.1 to 5.9.2 (#514)</li> <li>event-handler: adjusts exception docstrings to not confuse AppSync customers</li> </ul>"},{"location":"changelog/#v1171-2021-07-02","title":"v1.17.1 - 2021-07-02","text":""},{"location":"changelog/#bug-fixes_64","title":"Bug Fixes","text":"<ul> <li>validator: handle built-in custom formats correctly (#498)</li> </ul>"},{"location":"changelog/#documentation_52","title":"Documentation","text":"<ul> <li>add Layers example for Serverless framework &amp; CDK (#500)</li> <li>enable dark mode switch (#471)</li> <li>logger: add FAQ for cross-account searches (#501)</li> <li>tracer: additional scenario when to disable auto-capture (#499)</li> </ul>"},{"location":"changelog/#maintenance_66","title":"Maintenance","text":"<ul> <li>bump 1.17.1 (#502)</li> <li>deps: bump boto3 from 1.17.101 to 1.17.102 (#493)</li> <li>deps: bump boto3 from 1.17.91 to 1.17.101 (#490)</li> <li>deps: bump email-validator from 1.1.2 to 1.1.3 (#478)</li> <li>deps: bump boto3 from 1.17.89 to 1.17.91 (#473)</li> <li>deps-dev: bump flake8-eradicate from 1.0.0 to 1.1.0 (#492)</li> <li>deps-dev: bump isort from 5.8.0 to 5.9.1 (#487)</li> <li>deps-dev: bump mkdocs-material from 7.1.7 to 7.1.9 (#491)</li> </ul>"},{"location":"changelog/#v1170-2021-06-08","title":"v1.17.0 - 2021-06-08","text":""},{"location":"changelog/#documentation_53","title":"Documentation","text":"<ul> <li>include new public roadmap (#452)</li> <li>data_classes: fix missing dynamodb stream get_type/value</li> <li>idempotency: remove old todo</li> </ul>"},{"location":"changelog/#features_38","title":"Features","text":"<ul> <li>data-classes: add AttributeValueType to DynamoDBStreamEvent (#462)</li> <li>data-classes: decorator to instantiate data_classes and docs updates (#442)</li> <li>logger: add option to clear state per invocation (#467)</li> <li>parser: add support for API Gateway HTTP API #434 (#441)</li> </ul>"},{"location":"changelog/#maintenance_67","title":"Maintenance","text":"<ul> <li>bump xenon from 0.7.1 to 0.7.3 (#446)</li> <li>fix changelog file redirection</li> <li>include dependencies label under maintenance</li> <li>ignore codecov upload</li> <li>reintroduce codecov token</li> <li>fix path for PR auto-labelling</li> <li>assited changelog pre-generation, auto-label PR (#443)</li> <li>enable dependabot for dep upgrades (#444)</li> <li>enable mergify (#450)</li> <li>dependabot/mergify guardrail for major versions</li> <li>fix dependabot commit messages prefix</li> <li>fix dependabot unique set config</li> <li>bump mkdocs-material from 7.1.5 to 7.1.6 (#451)</li> <li>bump boto3 from 1.17.78 to 1.17.84 (#449)</li> <li>update mergify to require approval on dependabot (#456)</li> <li>bump actions/setup-python from 1 to 2.2.2 (#445)</li> <li>trial boring cyborg automation</li> <li>deps: bump boto3 from 1.17.87 to 1.17.88 (#463)</li> <li>deps: bump boto3 from 1.17.88 to 1.17.89 (#466)</li> <li>deps: bump boto3 from 1.17.84 to 1.17.85 (#455)</li> <li>deps: bump boto3 from 1.17.85 to 1.17.86 (#458)</li> <li>deps: bump boto3 from 1.17.86 to 1.17.87 (#459)</li> <li>deps-dev: bump mkdocs-material from 7.1.6 to 7.1.7 (#464)</li> <li>deps-dev: bump pytest-cov from 2.12.0 to 2.12.1 (#454)</li> <li>mergify: use job name to match GH Actions</li> <li>mergify: disable check for matrix jobs</li> </ul>"},{"location":"changelog/#v1161-2021-05-23","title":"v1.16.1 - 2021-05-23","text":""},{"location":"changelog/#features_39","title":"Features","text":"<ul> <li>parser: security issue in Pydantic #436 (#437)</li> </ul>"},{"location":"changelog/#maintenance_68","title":"Maintenance","text":"<ul> <li>bump to 1.16.1</li> </ul>"},{"location":"changelog/#v1160-2021-05-17","title":"v1.16.0 - 2021-05-17","text":""},{"location":"changelog/#features_40","title":"Features","text":"<ul> <li>data-classes: decode base64 encoded body (#425)</li> <li>data-classes: support for code pipeline job event (#416)</li> </ul>"},{"location":"changelog/#maintenance_69","title":"Maintenance","text":"<ul> <li>bump to 1.16.0</li> </ul>"},{"location":"changelog/#v1151-2021-05-13","title":"v1.15.1 - 2021-05-13","text":""},{"location":"changelog/#bug-fixes_65","title":"Bug Fixes","text":"<ul> <li>docs: Use updated names for ProxyEventType (#424)</li> </ul>"},{"location":"changelog/#documentation_54","title":"Documentation","text":"<ul> <li>update list of features</li> <li>event_handler: add missing note on trimmed responses</li> </ul>"},{"location":"changelog/#maintenance_70","title":"Maintenance","text":"<ul> <li>bump to 1.15.1</li> </ul>"},{"location":"changelog/#v1150-2021-05-06","title":"v1.15.0 - 2021-05-06","text":""},{"location":"changelog/#bug-fixes_66","title":"Bug Fixes","text":"<ul> <li>deps: Bump aws-xray-sdk from 2.6.0 to 2.8.0 (#413)</li> <li>docs: workflow to include api ref in latest alias (#408)</li> <li>parser: Improve types for parser.py (#419)</li> <li>validator: event type annotation as any in validate fn (#405)</li> </ul>"},{"location":"changelog/#code-refactoring_10","title":"Code Refactoring","text":"<ul> <li>simplify custom formatter for minor changes (#417)</li> <li>event-handler: api gateway handler review changes (#420)</li> <li>event-handler: Add ResponseBuilder and more docs (#412)</li> <li>logger: BYOFormatter and Handler, UTC support, and more (#404)</li> </ul>"},{"location":"changelog/#documentation_55","title":"Documentation","text":"<ul> <li>api_gateway: new event handler for API Gateway and ALB (#418)</li> <li>event_handler: fix closing brackets in CORS sample</li> <li>event_handler: remove beta flag from new HTTP utility</li> <li>idempotency: remove beta flag</li> <li>logger: improvements extensibility &amp; new features (#415)</li> <li>parser: fix table and heading syntax</li> <li>tracer: Fix line highlighting (#395)</li> </ul>"},{"location":"changelog/#features_41","title":"Features","text":"<ul> <li>add support to persist default dimensions (#410)</li> <li>event-handle: allow for cors=None setting (#421)</li> <li>event-handler: add http ProxyEvent handler (#369)</li> <li>parser: Support for API GW v1 proxy schema &amp; envelope (#403)</li> </ul>"},{"location":"changelog/#maintenance_71","title":"Maintenance","text":"<ul> <li>bump to 1.15.0 (#422)</li> </ul>"},{"location":"changelog/#v1140-2021-04-09","title":"v1.14.0 - 2021-04-09","text":""},{"location":"changelog/#bug-fixes_67","title":"Bug Fixes","text":"<ul> <li>perf tests for Logger and fail str msgs</li> <li>downgrade poetry to 1.1.4 (#385)</li> <li>lock X-Ray SDK to 2.6.0 (#384)</li> <li>data-classes: Add missing operationName (#373)</li> <li>idempotent: Correctly raise IdempotencyKeyError (#378)</li> <li>metrics: AttributeError raised by MediaManager and Typing and docs (#357)</li> <li>parser: S3Model support empty keys (#375)</li> <li>tracer: Correct type hint for MyPy (#365)</li> <li>workflow: github actions depends on for release</li> </ul>"},{"location":"changelog/#documentation_56","title":"Documentation","text":"<ul> <li>Fix doc links and line highlights (#380)</li> <li>fix extra key for versioning</li> <li>update mkdocs-material to 7.1.0</li> <li>Correct link targets and line highlights (#390)</li> <li>introduce event handlers utility section (#388)</li> <li>enable versioning feature (#374)</li> <li>idempotency: add default configuration for those not using CFN (#391)</li> <li>index: fix link to event handler</li> <li>logger: add example on how to set UTC timestamp (#392)</li> <li>validator: include more complete examples &amp; intro to JSON Schema (#389)</li> </ul>"},{"location":"changelog/#features_42","title":"Features","text":"<ul> <li>event-handler: Add AppSync handler decorator (#363)</li> <li>parameter: add dynamodb_endpoint_url for local_testing (#376)</li> <li>parser: Add S3 Object Lambda Event (#362)</li> </ul>"},{"location":"changelog/#maintenance_72","title":"Maintenance","text":"<ul> <li>bump to 1.14.0</li> <li>add approved by field in RFC template</li> <li>make RFC proposal more explicit</li> <li>update automated steps in release process</li> </ul>"},{"location":"changelog/#v1130-2021-03-23","title":"v1.13.0 - 2021-03-23","text":""},{"location":"changelog/#bug-fixes_68","title":"Bug Fixes","text":"<ul> <li>deps: Bump dependencies and fix some of the dev tooling (#354)</li> <li>lint: Move <code>tests/THIRD-PARTY-LICENSES</code> to root (#352)</li> </ul>"},{"location":"changelog/#features_43","title":"Features","text":"<ul> <li>data-classes: Add S3 Object Lambda Event (#353)</li> </ul>"},{"location":"changelog/#maintenance_73","title":"Maintenance","text":"<ul> <li>include internals in release template</li> <li>bump to 1.13.0</li> <li>correct 3rd party license</li> </ul>"},{"location":"changelog/#v1120-2021-03-17","title":"v1.12.0 - 2021-03-17","text":""},{"location":"changelog/#bug-fixes_69","title":"Bug Fixes","text":"<ul> <li>idempotency: TypeError when calling is_missing_idempotency_key with an int (#315)</li> <li>idempotency: Correctly handle save_inprogress errors (#313)</li> </ul>"},{"location":"changelog/#code-refactoring_11","title":"Code Refactoring","text":"<ul> <li>parameters: Consistently reference env (#319)</li> </ul>"},{"location":"changelog/#documentation_57","title":"Documentation","text":"<ul> <li>surface new 1.12.0 features and enhancements  (#344)</li> <li>Correct code examples (#317)</li> <li>data-classes: Add more cognito code examples (#340)</li> <li>idempotency: Correct examples and line highlights (#312)</li> <li>metrics: Corrections to the code examples (#314)</li> <li>metrics: remove minimum dimensions</li> <li>metrics: Correct code examples in markdown (#316)</li> <li>tracer: Fix Tracer typing hinting for Pycharm (#345)</li> </ul>"},{"location":"changelog/#features_44","title":"Features","text":"<ul> <li>data-classes: Add appsync scalar_types_utils (#339)</li> <li>data-classes: AppSync Resolver Event (#323)</li> <li>idempotent: Include function name in the idempotent key (#326)</li> <li>logging: Add correlation_id support (#321)</li> <li>logging: Include exception_name (#320)</li> <li>parameters: Add force_fetch option (#341)</li> </ul>"},{"location":"changelog/#maintenance_74","title":"Maintenance","text":"<ul> <li>bump to 1.12.0</li> <li>remove auto-label as restrictions prevent it from working</li> <li>increase perf SLA due to slow GitHub Actions machine</li> <li>add PR size labelling action # 2</li> <li>add PR size labelling action</li> <li>add PR auto-label action</li> <li>remove gatsby mention as migrated completed</li> </ul>"},{"location":"changelog/#v1110-2021-03-05","title":"v1.11.0 - 2021-03-05","text":""},{"location":"changelog/#bug-fixes_70","title":"Bug Fixes","text":"<ul> <li>import time latency by lazily loading high level modules (#301)</li> <li>correct behaviour to avoid caching \"INPROGRESS\" records (#295)</li> <li>idempotency: PR feedback on config and kwargs</li> </ul>"},{"location":"changelog/#code-refactoring_12","title":"Code Refactoring","text":"<ul> <li>idempotent: Change UX to use a config class for non-persistence related features (#306)</li> <li>metrics: optimize validation and serialization (#307)</li> </ul>"},{"location":"changelog/#documentation_58","title":"Documentation","text":"<ul> <li>batch: add example on how to integrate with sentry.io (#308)</li> <li>data-classes: Correct import for DynamoDBRecordEventName (#299)</li> <li>dataclasses: new Connect Contact Flow (#310)</li> <li>idempotency: tidy up doc before release (#309)</li> <li>idempotent: Fix typos and code formatting (#305)</li> </ul>"},{"location":"changelog/#features_45","title":"Features","text":"<ul> <li>Idempotency helper utility (#245)</li> <li>data-classes: Add connect contact flow event (#304)</li> <li>idempotency: Add raise_on_no_idempotency_key flag (#297)</li> <li>idempotency: Fix KeyError when local_cache is True and an error is raised in the lambda handler (#300)</li> <li>idempotent: Add support for jmespath_options (#302)</li> </ul>"},{"location":"changelog/#maintenance_75","title":"Maintenance","text":"<ul> <li>update changelog (#311)</li> <li>adjusts Metrics SLA for slow py36 interpreters</li> <li>remove unsuccessful labeler bot</li> <li>update labeler bot to sync upon PR changes</li> <li>attempt 1 to fix PR labeler</li> </ul>"},{"location":"changelog/#v1105-2021-02-17","title":"v1.10.5 - 2021-02-17","text":""},{"location":"changelog/#maintenance_76","title":"Maintenance","text":"<ul> <li>version bump to 1.10.5 (#292)</li> </ul>"},{"location":"changelog/#v1104-2021-02-17","title":"v1.10.4 - 2021-02-17","text":""},{"location":"changelog/#bug-fixes_71","title":"Bug Fixes","text":"<ul> <li>sync features in main page</li> <li>meta tags, and ext link to open in new tab</li> </ul>"},{"location":"changelog/#documentation_59","title":"Documentation","text":"<ul> <li>data-classes: Fix anchor tags to be lower case (#288)</li> </ul>"},{"location":"changelog/#maintenance_77","title":"Maintenance","text":"<ul> <li>version bump to 1.10.4 (#291)</li> <li>add default runtime key</li> <li>Correct the docs location (#289)</li> <li>enable PR labeler workflow</li> <li>add auto-label for known files</li> </ul>"},{"location":"changelog/#regression_5","title":"Regression","text":"<ul> <li>search input size</li> </ul>"},{"location":"changelog/#v1103-2021-02-12","title":"v1.10.3 - 2021-02-12","text":""},{"location":"changelog/#bug-fixes_72","title":"Bug Fixes","text":"<ul> <li>sfix typing hit for envelope parse model (#286)</li> <li>disable batching of X-Ray subsegments (#284)</li> </ul>"},{"location":"changelog/#documentation_60","title":"Documentation","text":"<ul> <li>migrate documentation from Gatsby to MkDocs material (#279)</li> </ul>"},{"location":"changelog/#maintenance_78","title":"Maintenance","text":"<ul> <li>bump to 1.10.3 (#287)</li> </ul>"},{"location":"changelog/#v1102-2021-02-04","title":"v1.10.2 - 2021-02-04","text":""},{"location":"changelog/#bug-fixes_73","title":"Bug Fixes","text":"<ul> <li>remove unnecessary typing-extensions for py3.8 (#281)</li> <li>batch processing exceptions (#276)</li> </ul>"},{"location":"changelog/#documentation_61","title":"Documentation","text":"<ul> <li>appconfig: Use correct import for docstring (#271)</li> </ul>"},{"location":"changelog/#maintenance_79","title":"Maintenance","text":"<ul> <li>bump to 1.10.2 (#282)</li> <li>fix immer and socket.io CVEs (#278)</li> <li>typo in parser docs</li> </ul>"},{"location":"changelog/#v1101-2021-01-19","title":"v1.10.1 - 2021-01-19","text":""},{"location":"changelog/#features_46","title":"Features","text":"<ul> <li>add support for SNS-&gt;SQS protocol (#272)</li> </ul>"},{"location":"changelog/#maintenance_80","title":"Maintenance","text":"<ul> <li>bump to 1.10.1 (#273)</li> </ul>"},{"location":"changelog/#v1100-2021-01-18","title":"v1.10.0 - 2021-01-18","text":""},{"location":"changelog/#documentation_62","title":"Documentation","text":"<ul> <li>fix import (#267)</li> <li>add info about extras layer (#260)</li> <li>fix note whitespace</li> <li>add missing parser models (#254)</li> </ul>"},{"location":"changelog/#features_47","title":"Features","text":"<ul> <li>toggle to disable log deduplication locally for pytest live log #262 (#268)</li> <li>Add AppConfig parameter provider (#236)</li> <li>support extra parameter in Logger messages (#257)</li> <li>support custom formats in JSON Schema validation (#247)</li> </ul>"},{"location":"changelog/#maintenance_81","title":"Maintenance","text":"<ul> <li>bump to 1.10.0 (#270)</li> <li>move env names to constant file (#264)</li> <li>update stale bot</li> <li>general simplifications and cleanup (#255)</li> <li>hardcode axios transitive resolution (#256)</li> </ul>"},{"location":"changelog/#v191-2020-12-21","title":"v1.9.1 - 2020-12-21","text":""},{"location":"changelog/#bug-fixes_74","title":"Bug Fixes","text":"<ul> <li>ensures all Loggers have unique service names</li> </ul>"},{"location":"changelog/#code-refactoring_13","title":"Code Refactoring","text":"<ul> <li>convert dict into a literal dict object and re-use it</li> </ul>"},{"location":"changelog/#documentation_63","title":"Documentation","text":"<ul> <li>add clarification to Tracer docs for how <code>capture_method</code> decorator can cause function responses to be read and serialized.</li> </ul>"},{"location":"changelog/#features_48","title":"Features","text":"<ul> <li>pep-561: Create py.typed file and include into pyproject.</li> </ul>"},{"location":"changelog/#maintenance_82","title":"Maintenance","text":"<ul> <li>bump to 1.9.1 (#252)</li> <li>add changelog</li> <li>implement phony targets correctly</li> <li>deps: bump ini from 1.3.5 to 1.3.8 in /docs</li> </ul>"},{"location":"changelog/#pull-requests_4","title":"Pull Requests","text":"<ul> <li>Merge pull request #250 from heitorlessa/fix/#249</li> <li>Merge pull request #235 from Nr18/phony</li> <li>Merge pull request #244 from awslabs/docs/capture_method_clarification</li> <li>Merge pull request #241 from awslabs/dependabot/npm_and_yarn/docs/ini-1.3.8</li> <li>Merge pull request #237 from gmcrocetti/pep-561</li> <li>Merge pull request #234 from Nr18/test-equal</li> <li>Merge pull request #233 from GroovyDan/improv/add_equality_check_to_dict_wrapper</li> <li>Merge pull request #232 from gyft/add-missing-tests</li> </ul>"},{"location":"changelog/#v190-2020-12-04","title":"v1.9.0 - 2020-12-04","text":""},{"location":"changelog/#bug-fixes_75","title":"Bug Fixes","text":"<ul> <li>s3 model import</li> <li>cloudwatch logs envelope typo</li> </ul>"},{"location":"changelog/#documentation_64","title":"Documentation","text":"<ul> <li>add Kinesis Streams as a supported model &amp; envelope</li> <li>add S3 as a supported model</li> <li>add CW Logs as a supported envelope</li> <li>add CW Logs as a supported model</li> <li>add Alb as a supported model</li> <li>shadow sidebar to remain expanded</li> <li>add source code link in nav bar</li> <li>fix broken link for github</li> </ul>"},{"location":"changelog/#features_49","title":"Features","text":"<ul> <li>Add Kinesis lambda event support to Parser utility</li> <li>Add cloudwatch lambda event support to Parser utility</li> <li>Add alb lambda event support to Parser utility #228</li> <li>Add Kinesis lambda event support to Parser utility</li> <li>Add S3 lambda event support to Parser utility #224</li> <li>Add Ses lambda event support to Parser utility #213</li> </ul>"},{"location":"changelog/#maintenance_83","title":"Maintenance","text":""},{"location":"changelog/#pull-requests_5","title":"Pull Requests","text":"<ul> <li>Merge pull request #227 from risenberg-cyberark/kinesis</li> <li>Merge pull request #225 from risenberg-cyberark/s3</li> <li>Merge pull request #231 from risenberg-cyberark/cloudwatch</li> <li>Merge pull request #229 from risenberg-cyberark/alb</li> <li>Merge pull request #223 from heitorlessa/docs/add-source-code-link</li> <li>Merge pull request #222 from awslabs/docs-fix-broken-link</li> <li>Merge pull request #219 from igorlg/docs/logger-supress-clarify</li> <li>Merge pull request #214 from risenberg-cyberark/ses</li> </ul>"},{"location":"changelog/#v180-2020-11-20","title":"v1.8.0 - 2020-11-20","text":""},{"location":"changelog/#bug-fixes_76","title":"Bug Fixes","text":"<ul> <li>replace now deprecated set-env with new GitHub Env file</li> <li>remove dummy heading to prevent htmlAst bug</li> </ul>"},{"location":"changelog/#documentation_65","title":"Documentation","text":"<ul> <li>correct example usage of SES data class</li> <li>add faq section</li> <li>add minimal permission set for using layer</li> </ul>"},{"location":"changelog/#features_50","title":"Features","text":"<ul> <li>include new replay-name field in parser and data_classes</li> <li>data_classes: API Gateway V2 IAM and Lambda</li> </ul>"},{"location":"changelog/#maintenance_84","title":"Maintenance","text":"<ul> <li>bump to 1.8.0</li> <li>bump dependencies</li> <li>docs: Add some of the missing docstrings</li> </ul>"},{"location":"changelog/#pull-requests_6","title":"Pull Requests","text":"<ul> <li>Merge pull request #212 from heitorlessa/chore/bump-1.8.0</li> <li>Merge pull request #211 from heitorlessa/feat/eventbridge-replay-support</li> <li>Merge pull request #209 from awslabs/docs/correct_ses_dataclass_example</li> <li>Merge pull request #207 from risenberg-cyberark/sns</li> <li>Merge pull request #205 from heitorlessa/chore/update-docs-dep</li> <li>Merge pull request #202 from Nr18/logger-faq</li> <li>Merge pull request #204 from am29d/docs/add-iam-permissions-for-layer</li> <li>Merge pull request #201 from gyft/feat-data-classes-event-updates</li> </ul>"},{"location":"changelog/#v170-2020-10-26","title":"v1.7.0 - 2020-10-26","text":""},{"location":"changelog/#bug-fixes_77","title":"Bug Fixes","text":"<ul> <li>_parse return type</li> <li>high and security peer dependency vulnerabilities</li> <li>change to Yarn to support manual resolutions</li> <li>generic type to match ABC bound class</li> <li>debug logging in envelopes before each parsing</li> <li>remove malformed 3.1. sentence</li> <li>ensures parser can take json strings as input</li> <li>parse high level import</li> <li>code inspect issues</li> <li>unnecessary return; better error handling</li> <li>snake_case</li> <li>comment out validators #118</li> <li>CR fixes Merge branch 'develop' of https://github.com/awslabs/aws-lambda-powertools-python into pydantic</li> <li>reduce complexity of dynamo envelope</li> <li>poetry update + pydantic, typing_extensions as optional</li> <li>add only pydantic (+1 squashed commit) Squashed commits: [804f251] fix poetry.lock, revert changes</li> <li>Correct typo</li> <li>remove only dev extras</li> <li>remove jmespath extras in Make</li> </ul>"},{"location":"changelog/#code-refactoring_14","title":"Code Refactoring","text":"<ul> <li>pydantic as optional dependancy, remove lambdaContext</li> <li>change to advanced parser</li> </ul>"},{"location":"changelog/#documentation_66","title":"Documentation","text":"<ul> <li>reorder parser's payload sample position</li> <li>add more info on conditional keys #195</li> <li>add a note that decorator will replace the event</li> <li>address Ran's feedback</li> <li>reorder data validation; improve envelopes section</li> <li>reorder extending models as parse fn wasn't introduced</li> <li>use yarn's resolution to fix incompatible dependency</li> <li>add cold start data</li> <li>add a FAQ section</li> <li>ensure examples can be copied/pasted as-is</li> <li>add extending built-in models</li> <li>add envelope section</li> <li>add data model validation section</li> <li>use non-hello world model to better exemplify parsing</li> <li>add 101 parsing events content</li> <li>initial structure for parser docs</li> <li>initial sketch of parser docs</li> <li>update examples in README</li> </ul>"},{"location":"changelog/#features_51","title":"Features","text":"<ul> <li>experiment with codeQL over LGTM</li> <li>add standalone parse function</li> <li>Advanced parser utility (pydantic)</li> <li>RFC: Validate incoming and outgoing events utility #95</li> <li>data_classes: case insensitive header lookup</li> <li>data_classes: Cognito custom auth triggers</li> </ul>"},{"location":"changelog/#maintenance_85","title":"Maintenance","text":"<ul> <li>fix repository URL</li> <li>spacing</li> <li>typo in list</li> <li>typo on code generation tool</li> <li>remove flake8 polyfill as explicit dep</li> <li>explicit DynamoDB Stream schema naming</li> <li>lint</li> <li>kwarg over arg to ease refactoring</li> <li>remove test for commented code</li> <li>fix make build syntax for internal build whl</li> <li>upgrade docs dep</li> <li>remove dev deps from example project</li> <li>remove kitchen sink example</li> <li>upgrade gatsby</li> <li>upgrade amplify, antd, and gatsby plugins</li> <li>upgrade apollo-docs theme</li> <li>remove dev deps from example project</li> <li>remove kitchen sink example</li> </ul>"},{"location":"changelog/#reverts_3","title":"Reverts","text":"<ul> <li>fix: remove jmespath extras in Make</li> <li>fix: remove jmespath extras in Make</li> </ul>"},{"location":"changelog/#pull-requests_7","title":"Pull Requests","text":"<ul> <li>Merge pull request #200 from heitorlessa/chore/bump-1.7.0</li> <li>Merge pull request #199 from heitorlessa/docs/clarify-dynamic-log-keys</li> <li>Merge pull request #198 from awslabs/improv/suppress-logger-propagation</li> <li>Merge pull request #192 from heitorlessa/docs/parser</li> <li>Merge pull request #196 from awslabs/dependabot/npm_and_yarn/docs/object-path-0.11.5</li> <li>Merge pull request #189 from heitorlessa/improv/parser#118</li> <li>Merge pull request #186 from gyft/feat-case-insensitive-dict</li> <li>Merge pull request #188 from gyft/tests-pydantic</li> <li>Merge pull request #178 from gyft/cognito-custom-auth</li> <li>Merge pull request #118 from risenberg-cyberark/pydantic</li> <li>Merge pull request #181 from awslabs/fix/docs-sec-vuln</li> <li>Merge pull request #180 from heitorlessa/chore/remove-example</li> </ul>"},{"location":"changelog/#v161-2020-09-23","title":"v1.6.1 - 2020-09-23","text":""},{"location":"changelog/#maintenance_86","title":"Maintenance","text":"<ul> <li>bump to 1.6.1 (#177)</li> </ul>"},{"location":"changelog/#v160-2020-09-22","title":"v1.6.0 - 2020-09-22","text":""},{"location":"changelog/#bug-fixes_78","title":"Bug Fixes","text":"<ul> <li>apply Tom's suggestion</li> <li>branding</li> <li>Correct description for data classes util</li> <li>duplicate features content</li> <li>navigation, branding</li> <li>remove DeleteMessageBatch call to SQS api if there are no messages to delete (#170)</li> <li>correct type hint Dict instead of dict</li> </ul>"},{"location":"changelog/#code-refactoring_15","title":"Code Refactoring","text":"<ul> <li>correct type hint</li> </ul>"},{"location":"changelog/#documentation_67","title":"Documentation","text":"<ul> <li>fixed more typos, correct index reference to new util</li> <li>fix typo in DynamoDB example</li> <li>add docs for data classes utility</li> <li>improve wording on jmespath fns</li> <li>document validator utility</li> </ul>"},{"location":"changelog/#features_52","title":"Features","text":"<ul> <li>add custom jmespath functions support</li> <li>emf multiple metric values (#167)</li> <li>add initial validator tests</li> <li>add cloudwatch_logs based on Bryan's feedback</li> <li>add powertools_base64 custom fn</li> <li>add built-in envelopes</li> <li>add jmespath as optional dependency</li> <li>add initial draft simple validator</li> <li>trigger: data class and helper functions for lambda trigger events (#159)</li> </ul>"},{"location":"changelog/#maintenance_87","title":"Maintenance","text":"<ul> <li>typo</li> <li>bump to 1.6.0</li> <li>better type hinting</li> <li>update changelog</li> <li>fix docstring; import order</li> </ul>"},{"location":"changelog/#pull-requests_8","title":"Pull Requests","text":"<ul> <li>Merge pull request #175 from heitorlessa/chore/bump-1.6.0</li> <li>Merge pull request #171 from awslabs/docs/data_classes</li> <li>Merge pull request #174 from heitorlessa/improv/docs-logger-metrics-testing</li> <li>Merge pull request #168 from gyft/tests-missing</li> <li>Merge pull request #153 from heitorlessa/feat/validator-utility</li> </ul>"},{"location":"changelog/#v150-2020-09-04","title":"v1.5.0 - 2020-09-04","text":""},{"location":"changelog/#bug-fixes_79","title":"Bug Fixes","text":"<ul> <li>throw exception by default if messages processing fails</li> <li>add sqs_batch_processor as its own method</li> <li>ensure debug log event has latest ctx</li> <li>update image with correct sample</li> <li>ensures xray_trace_id is refreshed</li> <li>typo in example</li> <li>include proposed suggestions</li> <li>base-partial: append record instead of entry</li> <li>logging: Don't include <code>json_default</code> in logs (#132)</li> </ul>"},{"location":"changelog/#code-refactoring_16","title":"Code Refactoring","text":"<ul> <li>changes partial_sqs middleware in favor of a generic interface always expecting a BatchProcessor</li> <li>replace LambdaEvent with Dict[str, Any]</li> <li>remove initial reference</li> <li>fix import issues and provide context in docblocks</li> <li>split properties and add docblocks</li> <li>split the objects into seperate files</li> <li>make requested changes</li> <li>use None instead of</li> <li>batch middleware</li> <li>remove references to BaseProcessor. Left BasePartialProcessor</li> <li>change return for failure/success handlers</li> <li>sqs: add module middlewares</li> <li>sqs: change methods to protected</li> <li>tests: update tests to new batch processor middleware</li> <li>tests: processor using default config</li> </ul>"},{"location":"changelog/#documentation_68","title":"Documentation","text":"<ul> <li>address readability feedbacks</li> <li>add detail to batch processing</li> <li>simplify documentation more SQS specific focus Update for sqs_batch_processor interface</li> <li>rephrase the wording to make it more clear</li> <li>refactor example; improve docs about creating your own processor</li> <li>add newly created Slack Channel</li> <li>describe the typing utility</li> <li>add troubleshooting section</li> <li>add xray_trace_id key</li> <li>fix suggestions made by @heitorlessa</li> <li>add description where to find the layer arn (#145)</li> <li>new section \"Migrating from other Loggers\" (#148)</li> <li>minor edit to letter case part 2</li> <li>user specific documentation</li> <li>Fix doc for log sampling (#135)</li> <li>partial-processor: add simple docstrings to success/failure handlers</li> <li>sqs: docstrings for PartialSQS</li> <li>sqs-base: docstring for base class</li> </ul>"},{"location":"changelog/#features_53","title":"Features","text":"<ul> <li>add xray_trace_id key when tracing is active #137</li> <li>initial implementation as the proposed gist is</li> <li>add sqs failure processors</li> <li>include base processors</li> <li>add batch module</li> <li>add package level import for batch utility</li> <li>logger: readable log_dict seq</li> <li>logging: suppress some log keys</li> <li>logging: allow for custom json order</li> <li>parameters: transform = \"auto\" (#133)</li> <li>sqs: add optional config parameter</li> <li>sqs: improve validation for queue_url</li> </ul>"},{"location":"changelog/#maintenance_88","title":"Maintenance","text":"<ul> <li>tiny changes for readability</li> <li>add debug logging for sqs batch processing</li> <li>remove middlewares module, moving decorator functionality to base and sqs</li> <li>add test for sqs_batch_processor interface</li> <li>add sqs_batch_processor decorator to simplify interface</li> <li>fix typos, docstrings and type hints (#154)</li> <li>doc typo</li> <li>batch: Housekeeping for recent changes (#157)</li> </ul>"},{"location":"changelog/#pull-requests_9","title":"Pull Requests","text":"<ul> <li>Merge pull request #149 from Nr18/static-types</li> <li>Merge pull request #155 from awslabs/docs/batch_processing_util</li> <li>Merge pull request #100 from gmcrocetti/partial-sqs-batch</li> <li>Merge pull request #151 from Nr18/troubleshooting</li> <li>Merge pull request #150 from heitorlessa/feat/logger-add-xray-trace-id</li> <li>Merge pull request #140 from gyft/fix-log-key-order</li> <li>Merge pull request #142 from gyft/fix-letter-case</li> </ul>"},{"location":"changelog/#v140-2020-08-25","title":"v1.4.0 - 2020-08-25","text":""},{"location":"changelog/#bug-fixes_80","title":"Bug Fixes","text":"<ul> <li>upgrade dot-prop, serialize-javascript</li> <li>remove actual response from debug logs</li> <li>naming and staticmethod consistency</li> <li>correct in_subsegment assertion</li> <li>update cold_start doc to reflect #125</li> <li>split ColdStart metric to its own EMF blob #125</li> <li>ssm: Make decrypt an explicit option and refactoring (#123)</li> </ul>"},{"location":"changelog/#documentation_69","title":"Documentation","text":"<ul> <li>add Lambda Layer SAR App url and ARN</li> <li>move tenets; remove extra space</li> <li>use table for clarity</li> <li>add blog post, and quick example</li> <li>subtle rewording for better clarity</li> <li>fix typos, log_event &amp; sampling wording</li> <li>make sensitive info more explicit with an example</li> <li>create Patching modules section; cleanup response wording</li> <li>move concurrent asynchronous under escape hatch</li> <li>grammar</li> <li>bring new feature upfront when returning sensitive info</li> </ul>"},{"location":"changelog/#features_54","title":"Features","text":"<ul> <li>capture_response as metadata option #127</li> </ul>"},{"location":"changelog/#maintenance_89","title":"Maintenance","text":"<ul> <li>bump to 1.4.0</li> <li>update internal docstrings for consistency</li> <li>update changelog to reflect new feature</li> <li>clarify changelog bugfix vs breaking change</li> <li>remove/correct unnecessary debug logs</li> <li>fix debug log adding unused obj</li> <li>grammar</li> <li>add metrics fix description</li> <li>correct typos</li> </ul>"},{"location":"changelog/#pull-requests_10","title":"Pull Requests","text":"<ul> <li>Merge pull request #129 from am29d/feat/lambda-layers</li> <li>Merge pull request #130 from heitorlessa/docs/readability-improvements</li> <li>Merge pull request #128 from heitorlessa/feat/tracer-disallow-response-metadata</li> <li>Merge pull request #126 from heitorlessa/fix/metrics-cold-start-split</li> </ul>"},{"location":"changelog/#v131-2020-08-22","title":"v1.3.1 - 2020-08-22","text":""},{"location":"changelog/#bug-fixes_81","title":"Bug Fixes","text":"<ul> <li>capture_method: should yield inside with (#124)</li> </ul>"},{"location":"changelog/#maintenance_90","title":"Maintenance","text":"<ul> <li>version bump to 1.3.1</li> <li>deps: bump prismjs from 1.20.0 to 1.21.0 in /docs</li> <li>deps: bump elliptic from 6.5.2 to 6.5.3 in /docs</li> </ul>"},{"location":"changelog/#pull-requests_11","title":"Pull Requests","text":"<ul> <li>Merge pull request #120 from awslabs/dependabot/npm_and_yarn/docs/elliptic-6.5.3</li> <li>Merge pull request #121 from awslabs/dependabot/npm_and_yarn/docs/prismjs-1.21.0</li> </ul>"},{"location":"changelog/#v130-2020-08-21","title":"v1.3.0 - 2020-08-21","text":""},{"location":"changelog/#features_55","title":"Features","text":"<ul> <li>add parameter utility (#96)</li> </ul>"},{"location":"changelog/#maintenance_91","title":"Maintenance","text":""},{"location":"changelog/#v120-2020-08-20","title":"v1.2.0 - 2020-08-20","text":""},{"location":"changelog/#features_56","title":"Features","text":"<ul> <li>add support for tracing of generators using capture_method decorator (#113)</li> </ul>"},{"location":"changelog/#maintenance_92","title":"Maintenance","text":""},{"location":"changelog/#v113-2020-08-18","title":"v1.1.3 - 2020-08-18","text":""},{"location":"changelog/#bug-fixes_82","title":"Bug Fixes","text":"<ul> <li>remove root logger handler set by Lambda #115</li> </ul>"},{"location":"changelog/#maintenance_93","title":"Maintenance","text":"<ul> <li>bump to 1.1.3</li> </ul>"},{"location":"changelog/#pull-requests_12","title":"Pull Requests","text":"<ul> <li>Merge pull request #117 from heitorlessa/chore/bump-1.1.3</li> <li>Merge pull request #116 from heitorlessa/fix/remove-root-logger-handler</li> </ul>"},{"location":"changelog/#v112-2020-08-16","title":"v1.1.2 - 2020-08-16","text":""},{"location":"changelog/#bug-fixes_83","title":"Bug Fixes","text":"<ul> <li>return subclass #107</li> </ul>"},{"location":"changelog/#documentation_70","title":"Documentation","text":"<ul> <li>clarify auto_patch as per #108</li> </ul>"},{"location":"changelog/#maintenance_94","title":"Maintenance","text":"<ul> <li>suppress LGTM alert</li> <li>add autocomplete as unreleased</li> <li>remove unused stdout fixture</li> <li>update Tracer docs as per #108</li> </ul>"},{"location":"changelog/#pull-requests_13","title":"Pull Requests","text":"<ul> <li>Merge pull request #111 from heitorlessa/chore/bump-1.1.2</li> <li>Merge pull request #110 from heitorlessa/improv/logger-auto-complete</li> <li>Merge pull request #109 from heitorlessa/docs/tracer-reuse</li> </ul>"},{"location":"changelog/#v111-2020-08-14","title":"v1.1.1 - 2020-08-14","text":""},{"location":"changelog/#bug-fixes_84","title":"Bug Fixes","text":"<ul> <li>regression 104 (#105)</li> <li>return log level int immediately</li> <li>add test covering logging constant</li> </ul>"},{"location":"changelog/#maintenance_95","title":"Maintenance","text":"<ul> <li>bump patch version</li> <li>fix unused fixture</li> <li>fix docstring on level [str,int] consistency</li> <li>fix test level typo</li> <li>trigger docs on new release (#102) (#103)</li> <li>trigger docs on new release (#102)</li> <li>trigger docs on new release</li> </ul>"},{"location":"changelog/#regression_6","title":"Regression","text":"<ul> <li>log level docstring as str</li> </ul>"},{"location":"changelog/#pull-requests_14","title":"Pull Requests","text":"<ul> <li>Merge pull request #106 from heitorlessa/fix/regression-104</li> </ul>"},{"location":"changelog/#v110-2020-08-14","title":"v1.1.0 - 2020-08-14","text":""},{"location":"changelog/#bug-fixes_85","title":"Bug Fixes","text":"<ul> <li>auto-assigner filename as per docs</li> </ul>"},{"location":"changelog/#features_57","title":"Features","text":"<ul> <li>add support for logger inheritance (#99)</li> <li>enable issue auto-assigner to core team</li> </ul>"},{"location":"changelog/#maintenance_96","title":"Maintenance","text":"<ul> <li>bump to 1.1.0 (#101)</li> <li>deps: bump lodash from 4.17.15 to 4.17.19 in /docs (#93)</li> </ul>"},{"location":"changelog/#v102-2020-07-16","title":"v1.0.2 - 2020-07-16","text":""},{"location":"changelog/#maintenance_97","title":"Maintenance","text":"<ul> <li>bump to 1.0.2 (#90)</li> <li>support aws-xray-sdk &gt;=2.5.0 till &lt;3.0.0 (#89)</li> </ul>"},{"location":"changelog/#v101-2020-07-05","title":"v1.0.1 - 2020-07-05","text":""},{"location":"changelog/#bug-fixes_86","title":"Bug Fixes","text":"<ul> <li>append structured logs when injecting lambda context  (#86)</li> </ul>"},{"location":"changelog/#documentation_71","title":"Documentation","text":"<ul> <li>add blog post in the readme</li> </ul>"},{"location":"changelog/#v100-2020-06-18","title":"v1.0.0 - 2020-06-18","text":""},{"location":"changelog/#documentation_72","title":"Documentation","text":"<ul> <li>customize contributing guide (#77)</li> </ul>"},{"location":"changelog/#features_58","title":"Features","text":"<ul> <li>docs anonymized page view (#82)</li> <li>add metrics metadata (#81)</li> </ul>"},{"location":"changelog/#maintenance_98","title":"Maintenance","text":"<ul> <li>bump to 1.0.0 GA (#83)</li> <li>add missing ':' and identation in examples</li> <li>cleanup tests (#79)</li> <li>remove deprecated code before GA (#78)</li> <li>move blockquotes as hidden comments</li> </ul>"},{"location":"changelog/#v0110-2020-06-10","title":"v0.11.0 - 2020-06-10","text":""},{"location":"changelog/#bug-fixes_87","title":"Bug Fixes","text":"<ul> <li>default dimension creation now happens when metrics are serialized instead of on metrics constructor (#74)</li> </ul>"},{"location":"changelog/#maintenance_99","title":"Maintenance","text":"<ul> <li>update CHANGELOG</li> </ul>"},{"location":"changelog/#v0101-2020-06-10","title":"v0.10.1 - 2020-06-10","text":""},{"location":"changelog/#bug-fixes_88","title":"Bug Fixes","text":"<ul> <li>default dimension creation now happens when metrics are serialized instead of on metrics constructor (#74)</li> </ul>"},{"location":"changelog/#documentation_73","title":"Documentation","text":"<ul> <li>fix contrast on highlighted code text (#73)</li> </ul>"},{"location":"changelog/#features_59","title":"Features","text":"<ul> <li>improve error handling for log_metrics decorator (#71)</li> <li>add high level imports (#70)</li> </ul>"},{"location":"changelog/#maintenance_100","title":"Maintenance","text":"<ul> <li>version bump 0.10.1</li> <li>deps: bump graphql-playground-html from 1.6.19 to 1.6.25 in /docs</li> </ul>"},{"location":"changelog/#pull-requests_15","title":"Pull Requests","text":"<ul> <li>Merge pull request #72 from awslabs/dependabot/npm_and_yarn/docs/graphql-playground-html-1.6.25</li> </ul>"},{"location":"changelog/#v0100-2020-06-08","title":"v0.10.0 - 2020-06-08","text":""},{"location":"changelog/#bug-fixes_89","title":"Bug Fixes","text":"<ul> <li>correct env var name for publish to pypi test (#69)</li> <li>release-drafter action syntax</li> <li>release-drafter label for new feature/major non-breaking changes</li> <li>cast dimension value to str to avoid issue where EMF silently fails (#52)</li> <li>ignore path that might seem a broken link #49</li> <li>open api ref in a new tab #48</li> <li>metrics not being flushed on every invocation (#45)</li> <li>#35 duplicate changelog to project root</li> <li>#24 correct example test and docs</li> <li>CI attempt 4</li> <li>CI attempt 3</li> <li>CI attempt 3</li> <li>CI attempt 2</li> <li>add missing single_metric example; test var name</li> <li>fix import of aws_lambda_logging to relative import</li> <li>Makefile: format before linting</li> <li>make: add twine as a dev dep</li> <li>setup: correct invalid license classifier</li> <li>setup: correct license to MIT-0 in meta</li> </ul>"},{"location":"changelog/#documentation_74","title":"Documentation","text":"<ul> <li>build on master only</li> <li>clarify logger debug sampling message</li> <li>clean up readme in favour of docs website</li> <li>add install in main docs website</li> <li>add pypi badge</li> </ul>"},{"location":"changelog/#features_60","title":"Features","text":"<ul> <li>add capture_cold_start_metric for log_metrics (#67)</li> <li>automate publishing to pypi (#58)</li> <li>add pre-commit hooks (#64)</li> <li>update Metrics interface to resemble tracer &amp; logger: use \"service\" as its namespace.</li> <li>add codecov service (#59)</li> <li>add security and complexity baseline #33 (#57)</li> <li>add pull request template #33</li> <li>add RFC template for proposals</li> <li>create issue templates</li> <li>readd release drafter action #33</li> <li>add release drafter (#56)</li> <li>add stale issues config #33 (#55)</li> <li>enforce semantic PR titles (#54)</li> <li>add algolia search for docs and api ref (#39)</li> <li>add documentation website (#37)</li> <li>add docs to CI</li> <li>Add Python3.8 support</li> <li>logger: add log sampling</li> <li>pypi: add bumpversion, public release pypi</li> <li>pyproject.toml: move to poetry</li> </ul>"},{"location":"changelog/#maintenance_101","title":"Maintenance","text":"<ul> <li>version bump (#68)</li> <li>public beta version</li> <li>rename Makefile target docs-dev to docs-local (#65)</li> <li>correct docstring for log_metrics</li> <li>fix typo in metrics doc</li> <li>Correct test comment</li> <li>remove unused import</li> <li>formatting</li> <li>plat wheels are not needed</li> <li>reformat changelog to follow KeepAChangelog standard (#50)</li> <li>bump to release candidate</li> <li>renamed history to changelog dependabot</li> <li>grammar issues</li> <li>bump example to use 0.8.0 features</li> <li>clean up CI workflows</li> <li>fix github badge typo</li> <li>pypi monthly download badge</li> <li>lint</li> <li>bump 0.3.1 with logging patch</li> <li>bump history</li> <li>lint</li> <li>add Python 3.8 in badge as it's supported</li> <li>CI badge</li> <li>public beta version</li> <li>deps: bump bleach from 3.1.0 to 3.1.1 in /python</li> <li>deps: bump websocket-extensions from 0.1.3 to 0.1.4 in /docs (#66)</li> </ul>"},{"location":"changelog/#pull-requests_16","title":"Pull Requests","text":"<ul> <li>Merge pull request #60 from awslabs/improv/metrics_interface</li> <li>Merge pull request #8 from awslabs/dependabot/pip/python/bleach-3.1.1</li> <li>Merge pull request #7 from danilohgds/sampling_feature</li> <li>Merge pull request #5 from jfuss/feat/python38</li> </ul>"},{"location":"roadmap/","title":"Roadmap","text":""},{"location":"roadmap/#overview","title":"Overview","text":"<p>This is our public roadmap that outlines the high level direction we are working towards, namely Themes. We update this document when our priorities change: security and stability is our top priority.</p> <p>See our latest list of activities \u00bb</p>"},{"location":"roadmap/#themes","title":"Themes","text":"<p>Operational Excellence is priority number 1.</p> <p>Themes are key activities maintainers are focusing on, besides bug reports. These are updated periodically and you can find the latest under Epics in our public board.</p>"},{"location":"roadmap/#increased-end-to-end-coverage","title":"Increased end-to-end coverage","text":"<p>We continue to work on increasing end-to-end coverage for all features. Our main challenge is testing contracts for Lambda Event Sources (Parser, Event Source Data Classes) due to the lack of an official JSON schema.</p> <p>Some Lambda Event Sources require clusters (e.g., MSK) leading to additional delays of up to 30m in the end-to-end feedback loop. We need a RFC to start discussing viable options, and whether we should publish JSON Schemas from identified contracts.</p>"},{"location":"roadmap/#observability-providers","title":"Observability providers","text":"<p>We want to extend Tracer, Metrics, and Logger to support any observability provider. We need a RFC to define a contract and to identify two most requested observability providers that we can work with as an initial step.</p>"},{"location":"roadmap/#lambda-layer-in-release-notes","title":"Lambda Layer in release notes","text":"<p>We want to publish a JSON with a map of region and Lambda Layer ARN as a GitHub Release Note asset.</p> <p>As of V2, we prioritize Lambda Layers being available before release notes are out. This is due to X86 and ARM64 compilation for smaller binaries and extra speed.</p> <p>This means we have room to include a JSON map for Lambda Layers and facilitate automation for customers wanting the latest version as soon as it's available.</p>"},{"location":"roadmap/#strict-typing","title":"Strict typing","text":"<p>We want to enable MyPy strict mode against the code base. We need a RFC to identify most critical areas to start, and do so gradually as to not impact new features and enhancements in parallel.</p> <p>This also means bringing <code>typing-extensions</code> as a runtime dependency to ensure complete coverage across all Python versions. Future wise, we might be able to experiment with MyPyC to compile less performing parts of the code base as a C-Extension.</p>"},{"location":"roadmap/#new-utilities","title":"New utilities","text":"<p>With V2 launched, we want to resume working on new utilities, specifically but not limited to the most commonly asked: (1) Sensitive Data Masking, (2) Integration/End-to-end Testing, and (3) Event Bridge.</p>"},{"location":"roadmap/#open-iteration-planning","title":"Open iteration planning","text":"<p>We want to experiment running a bi-weekly audio channel on Discord to help us prioritize backlog in real-time. Depending on attendance, we might switch to run an office hours instead.</p>"},{"location":"roadmap/#roadmap-status-definition","title":"Roadmap status definition","text":"<p> <pre><code>graph LR\n    Ideas --&gt; Backlog --&gt; Work[\"Working on it\"] --&gt; Merged[\"Coming soon\"] --&gt; Shipped</code></pre> Visual representation </p> <p>Within our public board, you'll see the following values in the <code>Status</code> column:</p> <ul> <li>Ideas. Incoming and existing feature requests that are not being actively considered yet. These will be reviewed when bandwidth permits.</li> <li>Backlog. Accepted feature requests or enhancements that we want to work on.</li> <li>Working on it. Features or enhancements we're currently either researching or implementing it.</li> <li>Coming soon. Any feature, enhancement, or bug fixes that have been merged and are coming in the next release.</li> <li>Shipped. Features or enhancements that are now available in the most recent release.</li> </ul> <p>Tasks or issues with empty <code>Status</code> will be categorized in upcoming review cycles.</p>"},{"location":"roadmap/#process","title":"Process","text":"<p> <pre><code>graph LR\n    PFR[Feature request] --&gt; Triage{Need RFC?}\n    Triage --&gt; |Complex/major change or new utility?| RFC[Ask or write RFC] --&gt; Approval{Approved?}\n    Triage --&gt; |Minor feature or enhancement?| NoRFC[No RFC required] --&gt; Approval\n    Approval --&gt; |Yes| Backlog\n    Approval --&gt; |No | Reject[\"Inform next steps\"]\n    Backlog --&gt; |Prioritized| Implementation\n    Backlog --&gt; |Defer| WelcomeContributions[\"help-wanted label\"]</code></pre> Visual representation </p> <p>Our end-to-end mechanism follows four major steps:</p> <ul> <li>Feature Request. Ideas start with a feature request to outline their use case at a high level. For complex use cases, maintainers might ask for/write a RFC.<ul> <li>Maintainers review requests based on project tenets, customers reaction (\ud83d\udc4d), and use cases.</li> </ul> </li> <li>Request-for-comments (RFC). Design proposals use our RFC issue template to describe its implementation, challenges, developer experience, dependencies, and alternative solutions.<ul> <li>This helps refine the initial idea with community feedback before a decision is made.</li> </ul> </li> <li>Decision. After carefully reviewing and discussing them, maintainers make a final decision on whether to start implementation, defer or reject it, and update everyone with the next steps.</li> <li>Implementation. For approved features, maintainers give priority to the original authors for implementation unless it is a sensitive task that is best handled by maintainers.</li> </ul> See Maintainers document to understand how we triage issues and pull requests, labels and governance."},{"location":"roadmap/#disclaimer","title":"Disclaimer","text":"<p>The Powertools for AWS Lambda (Python) team values feedback and guidance from its community of users, although final decisions on inclusion into the project will be made by AWS.</p> <p>We determine the high-level direction for our open roadmap based on customer feedback and popularity (\ud83d\udc4d\ud83c\udffd and comments), security and operational impacts, and business value. Where features don\u2019t meet our goals and longer-term strategy, we will communicate that clearly and openly as quickly as possible with an explanation of why the decision was made.</p>"},{"location":"roadmap/#faqs","title":"FAQs","text":"<p>Q: Why did you build this?</p> <p>A: We know that our customers are making decisions and plans based on what we are developing, and we want to provide our customers the insights they need to plan.</p> <p>Q: Why are there no dates on your roadmap?</p> <p>A: Because job zero is security and operational stability, we can't provide specific target dates for features. The roadmap is subject to change at any time, and roadmap issues in this repository do not guarantee a feature will be launched as proposed.</p> <p>Q: How can I provide feedback or ask for more information?</p> <p>A: For existing features, you can directly comment on issues. For anything else, please open an issue.</p>"},{"location":"upgrade/","title":"Upgrade guide","text":""},{"location":"upgrade/#end-of-support-v1","title":"End of support v1","text":"<p>On March 31st, 2023, Powertools for AWS Lambda (Python) v1 reached end of support and will no longer receive updates or releases. If you are still using v1, we strongly recommend you to read our upgrade guide and update to the latest version.</p> <p>Given our commitment to all of our customers using Powertools for AWS Lambda (Python), we will keep Pypi v1 releases and documentation 1.x versions to prevent any disruption.</p>"},{"location":"upgrade/#migrate-to-v2-from-v1","title":"Migrate to v2 from v1","text":"<p>We've made minimal breaking changes to make your transition to v2 as smooth as possible.</p>"},{"location":"upgrade/#quick-summary","title":"Quick summary","text":"Area Change Code change required IAM Permissions change required Batch Removed legacy SQS batch processor in favour of <code>BatchProcessor</code>. Yes - Environment variables Removed legacy <code>POWERTOOLS_EVENT_HANDLER_DEBUG</code> in favour of <code>POWERTOOLS_DEV</code>. - - Event Handler Updated headers response format due to multi-value headers and cookie support. Tests only - Event Source Data Classes Replaced DynamoDBStreamEvent <code>AttributeValue</code> with native Python types. Yes - Feature Flags / Parameters Updated AppConfig API calls due to <code>GetConfiguration</code> API deprecation. - Yes Idempotency Updated partition key to include fully qualified function/method names. - -"},{"location":"upgrade/#first-steps","title":"First Steps","text":"<p>All dependencies are optional now. Tracer, Validation, and Parser now require additional dependencies.</p> <p>Before you start, we suggest making a copy of your current working project or create a new branch with git.</p> <ol> <li>Upgrade Python to at least v3.7</li> <li>Ensure you have the latest version via Lambda Layer or PyPi.</li> <li>Review the following sections to confirm whether they affect your code</li> </ol>"},{"location":"upgrade/#legacy-sqs-batch-processor","title":"Legacy SQS Batch Processor","text":"<p>We removed the deprecated <code>PartialSQSProcessor</code> class and <code>sqs_batch_processor</code> decorator.</p> <p>You can migrate to <code>BatchProcessor</code> with the following changes:</p> <ol> <li>If you use <code>sqs_batch_decorator</code>, change to <code>batch_processor</code> decorator</li> <li>If you use <code>PartialSQSProcessor</code>, change to <code>BatchProcessor</code></li> <li>Enable <code>ReportBatchItemFailures</code> in your Lambda Event Source</li> <li>Change your Lambda Handler to return the new response format</li> </ol> [Before] Decorator[After] Decorator[Before] Context manager[After] Context manager <pre><code>from aws_lambda_powertools.utilities.batch import sqs_batch_processor\ndef record_handler(record):\n    return do_something_with(record[\"body\"])\n\n@sqs_batch_processor(record_handler=record_handler)\ndef lambda_handler(event, context):\n    return {\"statusCode\": 200}\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\nprocessor = BatchProcessor(event_type=EventType.SQS)\ndef record_handler(record):\n    return do_something_with(record[\"body\"])\n\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context):\nreturn processor.response()\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.batch import PartialSQSProcessor\nfrom botocore.config import Config\nconfig = Config(region_name=\"us-east-1\")\ndef record_handler(record):\n    return_value = do_something_with(record[\"body\"])\n    return return_value\n\n\ndef lambda_handler(event, context):\n    records = event[\"Records\"]\n\nprocessor = PartialSQSProcessor(config=config)\nwith processor(records, record_handler):\n        result = processor.process()\n\nreturn result\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\ndef record_handler(record):\n    return_value = do_something_with(record[\"body\"])\n    return return_value\n\ndef lambda_handler(event, context):\n    records = event[\"Records\"]\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\nwith processor(records, record_handler):\n        result = processor.process()\n\nreturn processor.response()\n</code></pre>"},{"location":"upgrade/#event-handler-headers-response-format","title":"Event Handler headers response format","text":"<p>No code changes required</p> <p>This only applies if you're using <code>APIGatewayRestResolver</code> and asserting custom header values in your tests.</p> <p>Previously, custom headers were available under <code>headers</code> key in the Event Handler response.</p> V1 response headers<pre><code>{\n\"headers\": {\n\"Content-Type\": \"application/json\"\n    }\n}\n</code></pre> <p>In V2, we add all headers under <code>multiValueHeaders</code> key. This enables seamless support for multi-value headers and cookies in fine grained responses.</p> V2 response headers<pre><code>{\n\"multiValueHeaders\": {\n\"Content-Type\": \"application/json\"\n    }\n}\n</code></pre>"},{"location":"upgrade/#dynamodbstreamevent-in-event-source-data-classes","title":"DynamoDBStreamEvent in Event Source Data Classes","text":"<p>This also applies if you're using DynamoDB BatchProcessor.</p> <p>You will now receive native Python types when accessing DynamoDB records via <code>keys</code>, <code>new_image</code>, and <code>old_image</code> attributes in <code>DynamoDBStreamEvent</code>.</p> <p>Previously, you'd receive a <code>AttributeValue</code> instance and need to deserialize each item to the type you'd want for convenience, or to the type DynamoDB stored via <code>get_value</code> method.</p> <p>With this change, you can access data deserialized as stored in DynamoDB, and no longer need to recursively deserialize nested objects (Maps) if you had them.</p> Note <p>For a lossless conversion of DynamoDB <code>Number</code> type, we follow AWS Python SDK (boto3) approach and convert to <code>Decimal</code>.</p> <pre><code>from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\n    DynamoDBStreamEvent,\n    DynamoDBRecordEventName\n)\n\ndef send_to_sqs(data: Dict):\n    body = json.dumps(data)\n    ...\n\n@event_source(data_class=DynamoDBStreamEvent)\ndef lambda_handler(event: DynamoDBStreamEvent, context):\n    for record in event.records:\n\n        # BEFORE\nnew_image: Dict[str, AttributeValue] = record.dynamodb.new_image\nevent_type: AttributeValue = new_image[\"eventType\"].get_value\nif event_type == \"PENDING\":\n# deserialize attribute value into Python native type\n# NOTE: nested objects would need additional logic\ndata = {k: v.get_value for k, v in image.items()}\nsend_to_sqs(data)\n\n        # AFTER\nnew_image: Dict[str, Any] = record.dynamodb.new_image\nif new_image.get(\"eventType\") == \"PENDING\":\nsend_to_sqs(new_image)  # Here new_image is just a Python Dict type\n</code></pre>"},{"location":"upgrade/#feature-flags-and-appconfig-parameter-utility","title":"Feature Flags and AppConfig Parameter utility","text":"<p>No code changes required</p> <p>We replaced <code>GetConfiguration</code> API (now deprecated) with <code>GetLatestConfiguration</code> and <code>StartConfigurationSession</code>.</p> <p>As such, you must update your IAM Role permissions to allow the following IAM actions:</p> <ul> <li><code>appconfig:GetLatestConfiguration</code></li> <li><code>appconfig:StartConfigurationSession</code></li> </ul>"},{"location":"upgrade/#idempotency-partition-key-format","title":"Idempotency partition key format","text":"<p>No code changes required</p> <p>We replaced the DynamoDB partition key format to include fully qualified function/method names. This means that recent non-expired idempotent transactions will be ignored.</p> <p>Previously, we used the function/method name to generate the partition key value.</p> <p>e.g. <code>HelloWorldFunction.lambda_handler#99914b932bd37a50b983c5e7c90ae93b</code></p> <p></p> <p>In V2, we now distinguish between distinct classes or modules that may have the same function/method name.</p> <p>For example, an ABC or Protocol class may have multiple implementations of <code>process_payment</code> method and may have different results.</p> <p>e.g. <code>HelloWorldFunction.app.lambda_handler#99914b932bd37a50b983c5e7c90ae93b</code></p> <p></p>"},{"location":"we_made_this/","title":"We Made This (Community)","text":"<p>This space is dedicated to highlight our awesome community content featuring Powertools for AWS Lambda (Python) \ud83d\ude4f!</p> <p>Get your content featured here!</p>"},{"location":"we_made_this/#connect","title":"Connect","text":"<p>Join us on Discord to connect with the Powertools for AWS Lambda (Python) community \ud83d\udc4b. Ask questions, learn from each other, contribute, hang out with key contributors, and more!</p>"},{"location":"we_made_this/#blog-posts","title":"Blog posts","text":""},{"location":"we_made_this/#aws-lambda-cookbook-following-best-practices-with-lambda-powertools","title":"AWS Lambda Cookbook \u2014 Following best practices with Lambda Powertools","text":"<p>Author: Ran Isenberg </p> <p>A collection of articles explaining in detail how Lambda Powertools helps with a Serverless adoption strategy and its challenges.</p> <ul> <li> <p>Part 1 - Logging</p> </li> <li> <p>Part 2 - Observability: monitoring and tracing</p> </li> <li> <p>Part 3 - Business Domain Observability</p> </li> <li> <p>Part 4 - Environment Variables</p> </li> <li> <p>Part 5 - Input Validation</p> </li> <li> <p>Part 6 - Configuration &amp; Feature Flags</p> </li> <li> <p>Serverless API Idempotency with AWS Lambda Powertools and CDK</p> </li> </ul>"},{"location":"we_made_this/#making-all-your-apis-idempotent","title":"Making all your APIs idempotent","text":"<p>Author: Michael Walmsley </p> <p>This article dives into what idempotency means for APIs, their use cases, and how to implement them.</p> <ul> <li>blog.walmsles.io/making-all-your-apis-idempotent</li> </ul>"},{"location":"we_made_this/#deep-dive-on-lambda-powertools-idempotency-feature","title":"Deep dive on Lambda Powertools Idempotency feature","text":"<p>Author: Michael Walmsley </p> <p>This article describes how to best calculate your idempotency token, implementation details, and how to handle idempotency in RESTful APIs.</p> <ul> <li>blog.walmsles.io/aws-lambda-powertools-idempotency-a-deeper-dive</li> </ul>"},{"location":"we_made_this/#developing-aws-lambda-functions-with-aws-lambda-powertools","title":"Developing AWS Lambda functions with AWS Lambda Powertools","text":"<p>Author: Stephan Huber </p> <p>This article walks through how to add Powertools to an existing project, covers Tracer, Logger, Metrics, and JSON Schema Validation.</p> <ul> <li>globaldatanet.com/tech-blog/develop-lambda-functions-with-aws-lambda-powertools</li> </ul>"},{"location":"we_made_this/#speed-up-event-driven-projects","title":"Speed-up event-driven projects","text":"<p>Author: Joris Conijn </p> <p>This article walks through a sample AWS EventBridge cookiecutter template presented at the AWS Community Day Netherlands 2022.</p> <ul> <li>binx.io/2022/10/11/speedup-event-driven-projects/</li> <li>Slides</li> </ul>"},{"location":"we_made_this/#implementing-feature-flags-with-aws-appconfig-and-aws-lambda-powertools","title":"Implementing Feature Flags with AWS AppConfig and AWS Lambda Powertools","text":"<p>Author: Ran Isenberg </p> <p>This article walks through how CyberArk uses Powertools to implement Feature Flags with AWS AppConfig</p> <ul> <li>aws.amazon.com/blogs/mt/how-cyberark-implements-feature-flags-with-aws-appconfig</li> </ul>"},{"location":"we_made_this/#designing-for-idempotency","title":"Designing for Idempotency","text":"<p>Author: Valentin Dreismann </p> <p>This article outlines the importance of idempotency, key considerations and trade-offs when implementing in your systems.</p> <ul> <li>Idempotency the right way</li> </ul>"},{"location":"we_made_this/#implementing-idempotency-in-serverless-architectures","title":"Implementing Idempotency in Serverless Architectures","text":"<p>Author: Seongwoo Choi </p> <p>This blog post focuses on the importance of idempotency in distributed services and explores streamlined idempotent request flows. It provides guidance on idempotency tests using duplicate requests.</p> <ul> <li>Implementing Idempotency in Serverless Architectures</li> </ul>"},{"location":"we_made_this/#videos","title":"Videos","text":""},{"location":"we_made_this/#building-a-resilient-input-handling-with-parser","title":"Building a resilient input handling with Parser","text":"<p>Author: Ran Isenberg </p> <p>When building applications with AWS Lambda it is critical to verify the data structure and validate the input due to the multiple different sources that can trigger them. In this session Ran Isenberg (CyberArk) will present one of the interesting features of AWS Lambda Powertools for python: the parser.</p> <p>In this session you will learn how to increase code quality, extensibility and testability, boost you productivity and ship rock solid apps to production.</p>"},{"location":"we_made_this/#talk-dev-to-me-feature-flags-with-aws-lambda-powertools","title":"Talk DEV to me | Feature Flags with AWS Lambda Powertools","text":"<p>Author: Ran Isenberg </p> <p>A deep dive in the Feature Flags feature along with tips and tricks.</p>"},{"location":"we_made_this/#level-up-your-cicd-with-smart-aws-feature-flags","title":"Level Up Your CI/CD With Smart AWS Feature Flags","text":"<p>Author: Ran Isenberg </p> <p>Feature flags can improve your CI/CD process by enabling capabilities otherwise not possible, thus making them an enabler of DevOps and a crucial part of continuous integration. Partial rollouts, A/B testing, and the ability to quickly change a configuration without redeploying code are advantages you gain by using features flags.</p> <p>In this talk, you will learn the added value of using feature flags as part of your CI/CD process and how AWS Lambda Powertools can help with that.</p>"},{"location":"we_made_this/#workshops","title":"Workshops","text":""},{"location":"we_made_this/#introduction-to-lambda-powertools","title":"Introduction to Lambda Powertools","text":"<p>Author: Michael Walmsley </p> <p>This repo contains documentation for a live coding workshop for the AWS Programming and Tools Meetup in Melbourne. The workshop will start with the SAM Cli \"Hello World\" example API project.</p> <p>Throughout the labs we will introduce each of the AWS Lambda Powertools Core utilities to showcase how simple they are to use and adopt for all your projects, and how powerful they are at bringing you closer to the Well Architected Serverless Lens.</p> <ul> <li> github.com/walmsles/lambda-powertools-coding-workshop</li> </ul> <p>Walk-through video</p>"},{"location":"we_made_this/#sample-projects","title":"Sample projects","text":""},{"location":"we_made_this/#complete-lambda-handler-cookbook","title":"Complete Lambda Handler Cookbook","text":"<p>Author: Ran Isenberg </p> <p>This repository provides a working, deployable, open source based, AWS Lambda handler and AWS CDK Python code.</p> <p>This handler embodies Serverless best practices and has all the bells and whistles for a proper production ready handler. It uses many of the AWS Lambda Powertools utilities for Python.</p> <p> github.com/ran-isenberg/aws-lambda-handler-cookbook</p>"},{"location":"we_made_this/#serverless-transactional-message-app","title":"Serverless Transactional Message App","text":"<p>Author: Santiago Garcia Arango </p> <p>This repository contains a well documented example of a Transactional Messages App that illustrates how to use Lambda PowerTools to process SQS  messages in batches (with IaC on top of CDK).</p> <p>It uses LambdaPowerTools Logger, Tracing, DataClasses and includes unit tests.</p> <p> github.com/san99tiago/aws-cdk-transactional-messages</p>"},{"location":"core/logger/","title":"Logger","text":"<p>Logger provides an opinionated logger with output structured as JSON.</p>"},{"location":"core/logger/#key-features","title":"Key features","text":"<ul> <li>Capture key fields from Lambda context, cold start and structures logging output as JSON</li> <li>Log Lambda event when instructed (disabled by default)</li> <li>Log sampling enables DEBUG log level for a percentage of requests (disabled by default)</li> <li>Append additional keys to structured log at any point in time</li> </ul>"},{"location":"core/logger/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>Logger requires two settings:</p> Setting Description Environment variable Constructor parameter Logging level Sets how verbose Logger should be (INFO, by default) <code>LOG_LEVEL</code> <code>level</code> Service Sets service key that will be present across all log statements <code>POWERTOOLS_SERVICE_NAME</code> <code>service</code> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\nFunction:\nTimeout: 5\nRuntime: python3.10\nTracing: Active\nEnvironment:\nVariables:\nPOWERTOOLS_SERVICE_NAME: payment\nLOG_LEVEL: INFO\nLayers:\n# Find the latest Layer version in the official documentation\n# https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n- !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\n\nResources:\nLoggerLambdaHandlerExample:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: ../src\nHandler: inject_lambda_context.handler\n</code></pre>"},{"location":"core/logger/#standard-structured-keys","title":"Standard structured keys","text":"<p>Your Logger will include the following keys to your structured logging:</p> Key Example Note level: <code>str</code> <code>INFO</code> Logging level location: <code>str</code> <code>collect.handler:1</code> Source code location where statement was executed message: <code>Any</code> <code>Collecting payment</code> Unserializable JSON values are casted as <code>str</code> timestamp: <code>str</code> <code>2021-05-03 10:20:19,650+0200</code> Timestamp with milliseconds, by default uses local timezone service: <code>str</code> <code>payment</code> Service name defined, by default <code>service_undefined</code> xray_trace_id: <code>str</code> <code>1-5759e988-bd862e3fe1be46a994272793</code> When tracing is enabled, it shows X-Ray Trace ID sampling_rate: <code>float</code> <code>0.1</code> When enabled, it shows sampling rate in percentage e.g. 10% exception_name: <code>str</code> <code>ValueError</code> When <code>logger.exception</code> is used and there is an exception exception: <code>str</code> <code>Traceback (most recent call last)..</code> When <code>logger.exception</code> is used and there is an exception"},{"location":"core/logger/#capturing-lambda-context-info","title":"Capturing Lambda context info","text":"<p>You can enrich your structured logs with key Lambda context information via <code>inject_lambda_context</code>.</p> inject_lambda_context.pyinject_lambda_context_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.info(\"Collecting payment\")\n\n    # You can log entire objects too\n    logger.info({\"operation\": \"collect_payment\", \"charge_id\": event[\"charge_id\"]})\n    return \"hello world\"\n</code></pre> <pre><code>[\n{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:9\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n},\n{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:12\",\n\"message\": {\n\"operation\": \"collect_payment\",\n\"charge_id\": \"ch_AZFlk2345C0\"\n},\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n]\n</code></pre> <p>When used, this will include the following keys:</p> Key Example cold_start: <code>bool</code> <code>false</code> function_name <code>str</code> <code>example-powertools-HelloWorldFunction-1P1Z6B39FLU73</code> function_memory_size: <code>int</code> <code>128</code> function_arn: <code>str</code> <code>arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73</code> function_request_id: <code>str</code> <code>899856cb-83d1-40d7-8611-9e78f15f32f4</code>"},{"location":"core/logger/#logging-incoming-event","title":"Logging incoming event","text":"<p>When debugging in non-production environments, you can instruct Logger to log the incoming event with <code>log_event</code> param or via <code>POWERTOOLS_LOGGER_LOG_EVENT</code> env var.</p> Warning <p>This is disabled by default to prevent sensitive info being logged</p> Logging incoming event<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(log_event=True)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    return \"hello world\"\n</code></pre>"},{"location":"core/logger/#setting-a-correlation-id","title":"Setting a Correlation ID","text":"<p>You can set a Correlation ID using <code>correlation_id_path</code> param by passing a JMESPath expression.</p> Tip <p>You can retrieve correlation IDs via <code>get_correlation_id</code> method</p> set_correlation_id.pyset_correlation_id_event.jsonset_correlation_id_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(correlation_id_path=\"headers.my_request_id_header\")\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.debug(f\"Correlation ID =&gt; {logger.get_correlation_id()}\")\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n\"headers\": {\n\"my_request_id_header\": \"correlation_id_value\"\n}\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:10\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"},{"location":"core/logger/#set_correlation_id-method","title":"set_correlation_id method","text":"<p>You can also use <code>set_correlation_id</code> method to inject it anywhere else in your code. Example below uses Event Source Data Classes utility to easily access events properties.</p> set_correlation_id_method.pyset_correlation_id_method.jsonset_correlation_id_method_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import APIGatewayProxyEvent\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    request = APIGatewayProxyEvent(event)\n\nlogger.set_correlation_id(request.request_context.request_id)\nlogger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n\"requestContext\": {\n\"requestId\": \"correlation_id_value\"\n}\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:13\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"},{"location":"core/logger/#known-correlation-ids","title":"Known correlation IDs","text":"<p>To ease routine tasks like extracting correlation ID from popular event sources, we provide built-in JMESPath expressions.</p> set_correlation_id_jmespath.pyset_correlation_id_jmespath.jsonset_correlation_id_jmespath_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.debug(f\"Correlation ID =&gt; {logger.get_correlation_id()}\")\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n\"requestContext\": {\n\"requestId\": \"correlation_id_value\"\n}\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:11\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"},{"location":"core/logger/#appending-additional-keys","title":"Appending additional keys","text":"Info: Custom keys are persisted across warm invocations <p>Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with <code>clear_state=True</code>.</p> <p>You can append additional keys using either mechanism:</p> <ul> <li>Persist new keys across all future log messages via <code>append_keys</code> method</li> <li>Add additional keys on a per log message basis as a keyword=value, or via <code>extra</code> parameter</li> </ul>"},{"location":"core/logger/#append_keys-method","title":"append_keys method","text":"Warning <p><code>append_keys</code> is not thread-safe, please see RFC.</p> <p>You can append your own keys to your existing Logger via <code>append_keys(**additional_key_values)</code> method.</p> append_keys.pyappend_keys_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    order_id = event.get(\"order_id\")\n\n    # this will ensure order_id key always has the latest value before logging\n    # alternative, you can use `clear_state=True` parameter in @inject_lambda_context\nlogger.append_keys(order_id=order_id)\nlogger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:11\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"order_id\": \"order_id_value\"\n}\n</code></pre> Tip: Logger will automatically reject any key with a None value <p>If you conditionally add keys depending on the payload, you can follow the example above.</p> <p>This example will add <code>order_id</code> if its value is not empty, and in subsequent invocations where <code>order_id</code> might not be present it'll remove it from the Logger.</p>"},{"location":"core/logger/#ephemeral-metadata","title":"ephemeral metadata","text":"<p>You can pass an arbitrary number of keyword arguments (kwargs) to all log level's methods, e.g. <code>logger.info, logger.warning</code>.</p> <p>Two common use cases for this feature is to enrich log statements with additional metadata, or only add certain keys conditionally.</p> <p>Any keyword argument added will not be persisted in subsequent messages.</p> append_keys_kwargs.pyappend_keys_kwargs_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\nlogger.info(\"Collecting payment\", request_id=\"1123\")\nreturn \"hello world\"\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:8\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2022-11-26 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"request_id\": \"1123\"\n}\n</code></pre>"},{"location":"core/logger/#extra-parameter","title":"extra parameter","text":"<p>Extra parameter is available for all log levels' methods, as implemented in the standard logging library - e.g. <code>logger.info, logger.warning</code>.</p> <p>It accepts any dictionary, and all keyword arguments will be added as part of the root structure of the logs for that log statement.</p> <p>Any keyword argument added using <code>extra</code> will not be persisted in subsequent messages.</p> append_keys_extra.pyappend_keys_extra_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    fields = {\"request_id\": \"1123\"}\nlogger.info(\"Collecting payment\", extra=fields)\nreturn \"hello world\"\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:9\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"request_id\": \"1123\"\n}\n</code></pre>"},{"location":"core/logger/#removing-additional-keys","title":"Removing additional keys","text":"<p>You can remove any additional key from Logger state using <code>remove_keys</code>.</p> remove_keys.pyremove_keys_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.append_keys(sample_key=\"value\")\n    logger.info(\"Collecting payment\")\n\nlogger.remove_keys([\"sample_key\"])\nlogger.info(\"Collecting payment without sample key\")\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:9\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"sample_key\": \"value\"\n},\n{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:12\",\n\"message\": \"Collecting payment without sample key\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\"\n}\n]\n</code></pre>"},{"location":"core/logger/#clearing-all-state","title":"Clearing all state","text":"<p>Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse, this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use <code>clear_state=True</code> param in <code>inject_lambda_context</code> decorator.</p> Tip: When is this useful? <p>It is useful when you add multiple custom keys conditionally, instead of setting a default <code>None</code> value if not present. Any key with <code>None</code> value is automatically removed by Logger.</p> Danger: This can have unintended side effects if you use Layers <p>Lambda Layers code is imported before the Lambda handler.</p> <p>This means that <code>clear_state=True</code> will instruct Logger to remove any keys previously added before Lambda handler execution proceeds.</p> <p>You can either avoid running any code as part of Lambda Layers global scope, or override keys with their latest value as part of handler's execution.</p> clear_state.pyclear_state_event_one.jsonclear_state_event_two.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(clear_state=True)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    if event.get(\"special_key\"):\n# Should only be available in the first request log\n# as the second request doesn't contain `special_key`\n        logger.append_keys(debugging_key=\"value\")\n\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:10\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"special_key\": \"debug_key\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:10\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": false,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"},{"location":"core/logger/#logging-exceptions","title":"Logging exceptions","text":"<p>Use <code>logger.exception</code> method to log contextual information about exceptions. Logger will include <code>exception_name</code> and <code>exception</code> keys to aid troubleshooting and error enumeration.</p> Tip <p>You can use your preferred Log Analytics tool to enumerate and visualize exceptions across all your services using <code>exception_name</code> key.</p> logging_exceptions.pylogging_exceptions_output.json <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = \"http://httpbin.org/status/500\"\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    try:\n        ret = requests.get(ENDPOINT)\n        ret.raise_for_status()\n    except requests.HTTPError as e:\nlogger.exception(\"Received a HTTP 5xx error\")\nraise RuntimeError(\"Unable to fullfil request\") from e\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n\"level\": \"ERROR\",\n\"location\": \"collect.handler:15\",\n\"message\": \"Received a HTTP 5xx error\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"exception_name\": \"RuntimeError\",\n\"exception\": \"Traceback (most recent call last):\\n  File \\\"&lt;input&gt;\\\", line 2, in &lt;module&gt; RuntimeError: Unable to fullfil request\"\n}\n</code></pre>"},{"location":"core/logger/#uncaught-exceptions","title":"Uncaught exceptions","text":"<p>CAUTION: some users reported a problem that causes this functionality not to work in the Lambda runtime. We recommend that you don't use this feature for the time being.</p> <p>Logger can optionally log uncaught exceptions by setting <code>log_uncaught_exceptions=True</code> at initialization.</p> <p>Logger will replace any exception hook previously registered via sys.excepthook.</p> What are uncaught exceptions? <p>It's any raised exception that wasn't handled by the <code>except</code> statement, leading a Python program to a non-successful exit.</p> <p>They are typically raised intentionally to signal a problem (<code>raise ValueError</code>), or a propagated exception from elsewhere in your code that you didn't handle it willingly or not (<code>KeyError</code>, <code>jsonDecoderError</code>, etc.).</p> logging_uncaught_exceptions.pylogging_uncaught_exceptions_output.json <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = \"http://httpbin.org/status/500\"\nlogger = Logger(log_uncaught_exceptions=True)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    ret = requests.get(ENDPOINT)\n    # HTTP 4xx/5xx status will lead to requests.HTTPError\n    # Logger will log this exception before this program exits non-successfully\n    ret.raise_for_status()\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n\"level\": \"ERROR\",\n\"location\": \"log_uncaught_exception_hook:756\",\n\"message\": \"500 Server Error: INTERNAL SERVER ERROR for url: http://httpbin.org/status/500\",\n\"timestamp\": \"2022-11-16 13:51:29,198+0100\",\n\"service\": \"payment\",\n\"exception\": \"Traceback (most recent call last):\\n  File \\\"&lt;input&gt;\\\", line 52, in &lt;module&gt;\\n    handler({}, {})\\n  File \\\"&lt;input&gt;\\\", line 17, in handler\\n    ret.raise_for_status()\\n  File \\\"&lt;input&gt;/lib/python3.9/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\nrequests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://httpbin.org/status/500\",\n\"exception_name\": \"HTTPError\"\n}\n</code></pre>"},{"location":"core/logger/#date-formatting","title":"Date formatting","text":"<p>Logger uses Python's standard logging date format with the addition of timezone: <code>2021-05-03 11:47:12,494+0200</code>.</p> <p>You can easily change the date format using one of the following parameters:</p> <ul> <li><code>datefmt</code>. You can pass any strftime format codes. Use <code>%F</code> if you need milliseconds.</li> <li><code>use_rfc3339</code>. This flag will use a format compliant with both RFC3339 and ISO8601: <code>2022-10-27T16:27:43.738+02:00</code></li> </ul> Prefer using datetime string formats? <p>Use <code>use_datetime_directive</code> flag along with <code>datefmt</code> to instruct Logger to use <code>datetime</code> instead of <code>time.strftime</code>.</p> date_formatting.pydate_formatting_output.json <pre><code>from aws_lambda_powertools import Logger\n\ndate_format = \"%m/%d/%Y %I:%M:%S %p\"\n\nlogger = Logger(service=\"payment\", use_rfc3339=True)\nlogger.info(\"Collecting payment\")\n\nlogger_custom_format = Logger(service=\"loyalty\", datefmt=date_format)\nlogger_custom_format.info(\"Calculating points\")\n</code></pre> <pre><code>[\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:6\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2022-10-28T14:35:03.210+02:00\",\n\"service\": \"payment\"\n},\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:9\",\n\"message\": \"Calculating points\",\n\"timestamp\": \"10/28/2022 02:35:03 PM\",\n\"service\": \"loyalty\"\n}\n]\n</code></pre>"},{"location":"core/logger/#advanced","title":"Advanced","text":""},{"location":"core/logger/#built-in-correlation-id-expressions","title":"Built-in Correlation ID expressions","text":"<p>You can use any of the following built-in JMESPath expressions as part of inject_lambda_context decorator.</p> Note: Any object key named with <code>-</code> must be escaped <p>For example, <code>request.headers.\"x-amzn-trace-id\"</code>.</p> Name Expression Description API_GATEWAY_REST <code>\"requestContext.requestId\"</code> API Gateway REST API request ID API_GATEWAY_HTTP <code>\"requestContext.requestId\"</code> API Gateway HTTP API request ID APPSYNC_RESOLVER <code>'request.headers.\"x-amzn-trace-id\"'</code> AppSync X-Ray Trace ID APPLICATION_LOAD_BALANCER <code>'headers.\"x-amzn-trace-id\"'</code> ALB X-Ray Trace ID EVENT_BRIDGE <code>\"id\"</code> EventBridge Event ID"},{"location":"core/logger/#reusing-logger-across-your-code","title":"Reusing Logger across your code","text":"<p>Similar to Tracer, a new instance that uses the same <code>service</code> name - env var or explicit parameter - will reuse a previous Logger instance. Just like <code>logging.getLogger(\"logger_name\")</code> would in the standard library if called with the same logger name.</p> <p>Notice in the CloudWatch Logs output how <code>payment_id</code> appeared as expected when logging in <code>collect.py</code>.</p> logger_reuse.pylogger_reuse_payment.pylogger_reuse_output.json <pre><code>from logger_reuse_payment import inject_payment_id\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\ninject_payment_id(context=event)\nlogger.info(\"Collecting payment\")\nreturn \"hello world\"\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger()\ndef inject_payment_id(context):\nlogger.append_keys(payment_id=context.get(\"payment_id\"))\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:12\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"payment_id\": \"968adaae-a211-47af-bda3-eed3ca2c0ed0\"\n}\n</code></pre> Note: About Child Loggers <p>Coming from standard library, you might be used to use <code>logging.getLogger(__name__)</code>. This will create a new instance of a Logger with a different name.</p> <p>In Powertools, you can have the same effect by using <code>child=True</code> parameter: <code>Logger(child=True)</code>. This creates a new Logger instance named after <code>service.&lt;module&gt;</code>. All state changes will be propagated bi-directionally between Child and Parent.</p> <p>For that reason, there could be side effects depending on the order the Child Logger is instantiated, because Child Loggers don't have a handler.</p> <p>For example, if you instantiated a Child Logger and immediately used <code>logger.append_keys/remove_keys/set_correlation_id</code> to update logging state, this might fail if the Parent Logger wasn't instantiated.</p> <p>In this scenario, you can either ensure any calls manipulating state are only called when a Parent Logger is instantiated (example above), or refrain from using <code>child=True</code> parameter altogether.</p>"},{"location":"core/logger/#sampling-debug-logs","title":"Sampling debug logs","text":"<p>Use sampling when you want to dynamically change your log level to DEBUG based on a percentage of your concurrent/cold start invocations.</p> <p>You can use values ranging from <code>0.0</code> to <code>1</code> (100%) when setting <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> env var, or <code>sample_rate</code> parameter in Logger.</p> Tip: When is this useful? <p>Let's imagine a sudden spike increase in concurrency triggered a transient issue downstream. When looking into the logs you might not have enough information, and while you can adjust log levels it might not happen again.</p> <p>This feature takes into account transient issues where additional debugging information can be useful.</p> <p>Sampling decision happens at the Logger initialization. This means sampling may happen significantly more or less than depending on your traffic patterns, for example a steady low number of invocations and thus few cold starts.</p> Note <p>Open a feature request if you want Logger to calculate sampling for every invocation</p> sampling_debug_logs.pysampling_debug_logs_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# Sample 10% of debug logs e.g. 0.1\n# NOTE: this evaluation will only occur at cold start\nlogger = Logger(service=\"payment\", sample_rate=0.1)\ndef lambda_handler(event: dict, context: LambdaContext):\nlogger.debug(\"Verifying whether order_id is present\")\nlogger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n{\n\"level\": \"DEBUG\",\n\"location\": \"collect.handler:7\",\n\"message\": \"Verifying whether order_id is present\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"sampling_rate\": 0.1\n},\n{\n\"level\": \"INFO\",\n\"location\": \"collect.handler:7\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n\"service\": \"payment\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n\"sampling_rate\": 0.1\n}\n]\n</code></pre>"},{"location":"core/logger/#lambdapowertoolsformatter","title":"LambdaPowertoolsFormatter","text":"<p>Logger propagates a few formatting configurations to the built-in <code>LambdaPowertoolsFormatter</code> logging formatter.</p> <p>If you prefer configuring it separately, or you'd want to bring this JSON Formatter to another application, these are the supported settings:</p> Parameter Description Default <code>json_serializer</code> function to serialize <code>obj</code> to a JSON formatted <code>str</code> <code>json.dumps</code> <code>json_deserializer</code> function to deserialize <code>str</code>, <code>bytes</code>, <code>bytearray</code> containing a JSON document to a Python obj <code>json.loads</code> <code>json_default</code> function to coerce unserializable values, when no custom serializer/deserializer is set <code>str</code> <code>datefmt</code> string directives (strftime) to format log timestamp <code>%Y-%m-%d %H:%M:%S,%F%z</code>, where <code>%F</code> is a custom ms directive <code>use_datetime_directive</code> format the <code>datefmt</code> timestamps using <code>datetime</code>, not <code>time</code>  (also supports the custom <code>%F</code> directive for milliseconds) <code>False</code> <code>utc</code> set logging timestamp to UTC <code>False</code> <code>log_record_order</code> set order of log keys when logging <code>[\"level\", \"location\", \"message\", \"timestamp\"]</code> <code>kwargs</code> key-value to be included in log messages <code>None</code> Info <p>When <code>POWERTOOLS_DEV</code> env var is present and set to <code>\"true\"</code>, Logger's default serializer (<code>json.dumps</code>) will pretty-print log messages for easier readability.</p> Pre-configuring Powertools for AWS Lambda (Python) Formatter<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatter import LambdaPowertoolsFormatter\n# NOTE: Check docs for all available options\n# https://docs.powertools.aws.dev/lambda/python/latest/core/logger/#lambdapowertoolsformatter\n\nformatter = LambdaPowertoolsFormatter(utc=True, log_record_order=[\"message\"])\nlogger = Logger(service=\"example\", logger_formatter=formatter)\n</code></pre>"},{"location":"core/logger/#observability-providers","title":"Observability providers","text":"<p>In this context, an observability provider is an AWS Lambda Partner offering a platform for logging, metrics, traces, etc.</p> <p>You can send logs to the observability provider of your choice via Lambda Extensions. In most cases, you shouldn't need any custom Logger configuration, and logs will be shipped async without any performance impact.</p>"},{"location":"core/logger/#built-in-formatters","title":"Built-in formatters","text":"<p>In rare circumstances where JSON logs are not parsed correctly by your provider, we offer built-in formatters to make this transition easier.</p> Provider Formatter Notes Datadog <code>DatadogLogFormatter</code> Modifies default timestamp to use RFC3339 by default <p>You can use import and use them as any other Logger formatter via <code>logger_formatter</code> parameter:</p> Using built-in Logger Formatters<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatters.datadog import DatadogLogFormatter\nlogger = Logger(service=\"payment\", logger_formatter=DatadogLogFormatter())\nlogger.info(\"hello\")\n</code></pre>"},{"location":"core/logger/#migrating-from-other-loggers","title":"Migrating from other Loggers","text":"<p>If you're migrating from other Loggers, there are few key points to be aware of: Service parameter, Inheriting Loggers, Overriding Log records, and Logging exceptions.</p>"},{"location":"core/logger/#the-service-parameter","title":"The service parameter","text":"<p>Service is what defines the Logger name, including what the Lambda function is responsible for, or part of (e.g payment service).</p> <p>For Logger, the <code>service</code> is the logging key customers can use to search log operations for one or more functions - For example, search for all errors, or messages like X, where service is payment.</p>"},{"location":"core/logger/#inheriting-loggers","title":"Inheriting Loggers","text":"Tip: Prefer Logger Reuse feature over inheritance unless strictly necessary, see caveats. <p>Python Logging hierarchy happens via the dot notation: <code>service</code>, <code>service.child</code>, <code>service.child_2</code></p> <p>For inheritance, Logger uses a <code>child=True</code> parameter along with <code>service</code> being the same value across Loggers.</p> <p>For child Loggers, we introspect the name of your module where <code>Logger(child=True, service=\"name\")</code> is called, and we name your Logger as {service}.{filename}.</p> Danger <p>A common issue when migrating from other Loggers is that <code>service</code> might be defined in the parent Logger (no child param), and not defined in the child Logger:</p> logging_inheritance_bad.pylogging_inheritance_module.py <pre><code>from logging_inheritance_module import inject_payment_id\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# NOTE: explicit service name differs from Child\n# meaning we will have two Logger instances with different state\n# and an orphan child logger who won't be able to manipulate state\nlogger = Logger(service=\"payment\")\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    inject_payment_id(context=event)\n\n    return \"hello world\"\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\nlogger = Logger(child=True)\n\n\ndef inject_payment_id(context):\n    logger.append_keys(payment_id=context.get(\"payment_id\"))\n</code></pre> <p>In this case, Logger will register a Logger named <code>payment</code>, and a Logger named <code>service_undefined</code>. The latter isn't inheriting from the parent, and will have no handler, resulting in no message being logged to standard output.</p> Tip <p>This can be fixed by either ensuring both has the <code>service</code> value as <code>payment</code>, or simply use the environment variable <code>POWERTOOLS_SERVICE_NAME</code> to ensure service value will be the same across all Loggers when not explicitly set.</p> <p>Do this instead:</p> logging_inheritance_good.pylogging_inheritance_module.py <pre><code>from logging_inheritance_module import inject_payment_id\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# NOTE: explicit service name matches any new Logger\n# because we're using POWERTOOLS_SERVICE_NAME env var\n# but we could equally use the same string as service value, e.g. \"payment\"\nlogger = Logger()\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    inject_payment_id(context=event)\n\n    return \"hello world\"\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\nlogger = Logger(child=True)\n\n\ndef inject_payment_id(context):\n    logger.append_keys(payment_id=context.get(\"payment_id\"))\n</code></pre>"},{"location":"core/logger/#overriding-log-records","title":"Overriding Log records","text":"<p>You might want to continue to use the same date formatting style, or override <code>location</code> to display the <code>package.function_name:line_number</code> as you previously had.</p> <p>Logger allows you to either change the format or suppress the following keys at initialization: <code>location</code>, <code>timestamp</code>, <code>xray_trace_id</code>.</p> overriding_log_records.pyoverriding_log_records_output.json <pre><code>from aws_lambda_powertools import Logger\n\nlocation_format = \"[%(funcName)s] %(module)s\"\n\n# override location and timestamp format\nlogger = Logger(service=\"payment\", location=location_format)\nlogger.info(\"Collecting payment\")\n\n# suppress keys with a None value\nlogger_two = Logger(service=\"loyalty\", location=None)\nlogger_two.info(\"Calculating points\")\n</code></pre> <pre><code>[\n{\n\"level\": \"INFO\",\n\"location\": \"[&lt;module&gt;] overriding_log_records\",\n\"message\": \"Collecting payment\",\n\"timestamp\": \"2022-10-28 14:40:43,801+0200\",\n\"service\": \"payment\"\n},\n{\n\"level\": \"INFO\",\n\"message\": \"Calculating points\",\n\"timestamp\": \"2022-10-28 14:40:43,801+0200\",\n\"service\": \"loyalty\"\n}\n]\n</code></pre>"},{"location":"core/logger/#reordering-log-keys-position","title":"Reordering log keys position","text":"<p>You can change the order of standard Logger keys or any keys that will be appended later at runtime via the <code>log_record_order</code> parameter.</p> reordering_log_keys.pyreordering_log_keys_output.json <pre><code>from aws_lambda_powertools import Logger\n\n# make message as the first key\nlogger = Logger(service=\"payment\", log_record_order=[\"message\"])\n# make request_id that will be added later as the first key\nlogger_two = Logger(service=\"order\", log_record_order=[\"request_id\"])\nlogger_two.append_keys(request_id=\"123\")\nlogger.info(\"hello world\")\nlogger_two.info(\"hello world\")\n</code></pre> <pre><code>[\n{\n\"message\": \"hello world\",\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:11\",\n\"timestamp\": \"2022-06-24 11:25:40,143+0200\",\n\"service\": \"payment\"\n},\n{\n\"request_id\": \"123\",\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:12\",\n\"timestamp\": \"2022-06-24 11:25:40,144+0200\",\n\"service\": \"order\",\n\"message\": \"hello universe\"\n}\n]\n</code></pre>"},{"location":"core/logger/#setting-timestamp-to-utc","title":"Setting timestamp to UTC","text":"<p>By default, this Logger and standard logging library emits records using local time timestamp. You can override this behavior via <code>utc</code> parameter:</p> setting_utc_timestamp.pysetting_utc_timestamp_output.json <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(service=\"payment\")\nlogger.info(\"Local time\")\n\nlogger_in_utc = Logger(service=\"order\", utc=True)\nlogger_in_utc.info(\"GMT time zone\")\n</code></pre> <pre><code>[\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:4\",\n\"message\": \"Local time\",\n\"timestamp\": \"2022-06-24 11:39:49,421+0200\",\n\"service\": \"payment\"\n},\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:7\",\n\"message\": \"GMT time zone\",\n\"timestamp\": \"2022-06-24 09:39:49,421+0100\",\n\"service\": \"order\"\n}\n]\n</code></pre>"},{"location":"core/logger/#custom-function-for-unserializable-values","title":"Custom function for unserializable values","text":"<p>By default, Logger uses <code>str</code> to handle values non-serializable by JSON. You can override this behavior via <code>json_default</code> parameter by passing a Callable:</p> unserializable_values.pyunserializable_values_output.json <pre><code>from datetime import date, datetime\n\nfrom aws_lambda_powertools import Logger\n\n\ndef custom_json_default(value: object) -&gt; str:\nif isinstance(value, (datetime, date)):\n        return value.isoformat()\n\n    return f\"&lt;non-serializable: {type(value).__name__}&gt;\"\n\n\nclass Unserializable:\n    pass\n\n\nlogger = Logger(service=\"payment\", json_default=custom_json_default)\nlogger.info({\"ingestion_time\": datetime.utcnow(), \"serialize_me\": Unserializable()})\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:19\",\n\"message\": {\n\"ingestion_time\": \"2022-06-24T10:12:09.526365\",\n\"serialize_me\": \"&lt;non-serializable: Unserializable&gt;\"\n},\n\"timestamp\": \"2022-06-24 12:12:09,526+0200\",\n\"service\": \"payment\"\n}\n</code></pre>"},{"location":"core/logger/#bring-your-own-handler","title":"Bring your own handler","text":"<p>By default, Logger uses StreamHandler and logs to standard output. You can override this behavior via <code>logger_handler</code> parameter:</p> Configure Logger to output to a file<pre><code>import logging\nfrom pathlib import Path\n\nfrom aws_lambda_powertools import Logger\n\nlog_file = Path(\"/tmp/log.json\")\nlog_file_handler = logging.FileHandler(filename=log_file)\nlogger = Logger(service=\"payment\", logger_handler=log_file_handler)\nlogger.info(\"hello world\")\n</code></pre>"},{"location":"core/logger/#bring-your-own-formatter","title":"Bring your own formatter","text":"<p>By default, Logger uses LambdaPowertoolsFormatter that persists its custom structure between non-cold start invocations. There could be scenarios where the existing feature set isn't sufficient to your formatting needs.</p> Info <p>The most common use cases are remapping keys by bringing your existing schema, and redacting sensitive information you know upfront.</p> <p>For these, you can override the <code>serialize</code> method from LambdaPowertoolsFormatter.</p> bring_your_own_formatter.pybring_your_own_formatter_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatter import LambdaPowertoolsFormatter\nfrom aws_lambda_powertools.logging.types import LogRecord\nclass CustomFormatter(LambdaPowertoolsFormatter):\ndef serialize(self, log: LogRecord) -&gt; str:\n\"\"\"Serialize final structured log dict to JSON str\"\"\"\n        # in this example, log[\"message\"] is a required field\n        # but we want to remap to \"event\" and delete \"message\", hence mypy ignore checks\nlog[\"event\"] = log.pop(\"message\")  # type: ignore[typeddict-unknown-key,misc]\nreturn self.json_serializer(log)\nlogger = Logger(service=\"payment\", logger_formatter=CustomFormatter())\nlogger.info(\"hello\")\n</code></pre> <pre><code>{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:16\",\n\"timestamp\": \"2021-12-30 13:41:53,413+0100\",\n\"service\": \"payment\",\n\"event\": \"hello\"\n}\n</code></pre> <p>The <code>log</code> argument is the final log record containing our standard keys, optionally Lambda context keys, and any custom key you might have added via append_keys or the extra parameter.</p> <p>For exceptional cases where you want to completely replace our formatter logic, you can subclass <code>BasePowertoolsFormatter</code>.</p> Warning <p>You will need to implement <code>append_keys</code>, <code>clear_state</code>, override <code>format</code>, and optionally <code>remove_keys</code> to keep the same feature set Powertools for AWS Lambda (Python) Logger provides. This also means keeping state of logging keys added.</p> bring_your_own_formatter_from_scratch.pybring_your_own_formatter_from_scratch_output.json <pre><code>import json\nimport logging\nfrom typing import Iterable, List, Optional\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatter import BasePowertoolsFormatter\nclass CustomFormatter(BasePowertoolsFormatter):\ndef __init__(self, log_record_order: Optional[List[str]] = None, *args, **kwargs):\nself.log_record_order = log_record_order or [\"level\", \"location\", \"message\", \"timestamp\"]\nself.log_format = dict.fromkeys(self.log_record_order)\nsuper().__init__(*args, **kwargs)\n\ndef append_keys(self, **additional_keys):\n# also used by `inject_lambda_context` decorator\n        self.log_format.update(additional_keys)\n\ndef remove_keys(self, keys: Iterable[str]):\nfor key in keys:\n            self.log_format.pop(key, None)\n\ndef clear_state(self):\nself.log_format = dict.fromkeys(self.log_record_order)\n\ndef format(self, record: logging.LogRecord) -&gt; str:  # noqa: A003\n\"\"\"Format logging record as structured JSON str\"\"\"\n        return json.dumps(\n            {\n                \"event\": super().format(record),\n                \"timestamp\": self.formatTime(record),\n                \"my_default_key\": \"test\",\n                **self.log_format,\n            },\n        )\n\n\nlogger = Logger(service=\"payment\", logger_formatter=CustomFormatter())\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    logger.info(\"Collecting payment\")\n</code></pre> <pre><code>{\n\"event\": \"Collecting payment\",\n\"timestamp\": \"2021-05-03 11:47:12,494\",\n\"my_default_key\": \"test\",\n\"cold_start\": true,\n\"function_name\": \"test\",\n\"function_memory_size\": 128,\n\"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n\"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"},{"location":"core/logger/#bring-your-own-json-serializer","title":"Bring your own JSON serializer","text":"<p>By default, Logger uses <code>json.dumps</code> and <code>json.loads</code> as serializer and deserializer respectively. There could be scenarios where you are making use of alternative JSON libraries like orjson.</p> <p>As parameters don't always translate well between them, you can pass any callable that receives a <code>dict</code> and return a <code>str</code>:</p> Using Rust orjson library as serializer<pre><code>import functools\nimport orjson\nfrom aws_lambda_powertools import Logger\n\ncustom_serializer = orjson.dumps\ncustom_deserializer = orjson.loads\nlogger = Logger(service=\"payment\", json_serializer=custom_serializer, json_deserializer=custom_deserializer)\n\n# NOTE: when using parameters, you can pass a partial\ncustom_serializer_with_parameters = functools.partial(orjson.dumps, option=orjson.OPT_SERIALIZE_NUMPY)\nlogger_two = Logger(\n    service=\"payment\",\n    json_serializer=custom_serializer_with_parameters,\n    json_deserializer=custom_deserializer,\n)\n</code></pre>"},{"location":"core/logger/#testing-your-code","title":"Testing your code","text":""},{"location":"core/logger/#inject-lambda-context","title":"Inject Lambda Context","text":"<p>When unit testing your code that makes use of <code>inject_lambda_context</code> decorator, you need to pass a dummy Lambda Context, or else Logger will fail.</p> <p>This is a Pytest sample that provides the minimum information necessary for Logger to succeed:</p> fake_lambda_context_for_logger.pyfake_lambda_context_for_logger_module.py <p>Note that dataclasses are available in Python 3.7+ only.</p> <pre><code>from dataclasses import dataclass\n\nimport fake_lambda_context_for_logger_module  # sample module for completeness\nimport pytest\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context):\n    test_event = {\"test\": \"event\"}\n    fake_lambda_context_for_logger_module.handler(test_event, lambda_context)\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> Tip <p>Check out the built-in Pytest caplog fixture to assert plain log messages</p>"},{"location":"core/logger/#pytest-live-log-feature","title":"Pytest live log feature","text":"<p>Pytest Live Log feature duplicates emitted log messages in order to style log statements according to their levels, for this to work use <code>POWERTOOLS_LOG_DEDUPLICATION_DISABLED</code> env var.</p> Disabling log deduplication to use Pytest live log<pre><code>POWERTOOLS_LOG_DEDUPLICATION_DISABLED=\"1\" pytest -o log_cli=1\n</code></pre> Warning <p>This feature should be used with care, as it explicitly disables our ability to filter propagated messages to the root logger (if configured).</p>"},{"location":"core/logger/#faq","title":"FAQ","text":""},{"location":"core/logger/#how-can-i-enable-boto3-and-botocore-library-logging","title":"How can I enable boto3 and botocore library logging?","text":"<p>You can enable the <code>botocore</code> and <code>boto3</code> logs by using the <code>set_stream_logger</code> method, this method will add a stream handler for the given name and level to the logging module. By default, this logs all boto3 messages to stdout.</p> Enabling AWS SDK logging<pre><code>from typing import Dict, List\n\nimport boto3\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nboto3.set_stream_logger()\nboto3.set_stream_logger(\"botocore\")\nlogger = Logger()\nclient = boto3.client(\"s3\")\n\n\ndef lambda_handler(event: Dict, context: LambdaContext) -&gt; List:\n    response = client.list_buckets()\n\n    return response.get(\"Buckets\", [])\n</code></pre>"},{"location":"core/logger/#how-can-i-enable-powertools-for-aws-lambda-python-logging-for-imported-libraries","title":"How can I enable Powertools for AWS Lambda (Python) logging for imported libraries?","text":"<p>You can copy the Logger setup to all or sub-sets of registered external loggers. Use the <code>copy_config_to_registered_logger</code> method to do this.</p> Tip <p>To help differentiate between loggers, we include the standard logger <code>name</code> attribute for all loggers we copied configuration to.</p> <p>By default all registered loggers will be modified. You can change this behavior by providing <code>include</code> and <code>exclude</code> attributes. You can also provide optional <code>log_level</code> attribute external loggers will be configured with.</p> Cloning Logger config to all other registered standard loggers<pre><code>import logging\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging import utils\n\nlogger = Logger()\n\nexternal_logger = logging.getLogger()\n\nutils.copy_config_to_registered_loggers(source_logger=logger)\nexternal_logger.info(\"test message\")\n</code></pre>"},{"location":"core/logger/#how-can-i-add-standard-library-logging-attributes-to-a-log-record","title":"How can I add standard library logging attributes to a log record?","text":"<p>The Python standard library log records contains a large set of attributes, however only a few are included in Powertools for AWS Lambda (Python) Logger log record by default.</p> <p>You can include any of these logging attributes as key value arguments (<code>kwargs</code>) when instantiating <code>Logger</code> or <code>LambdaPowertoolsFormatter</code>.</p> <p>You can also add them later anywhere in your code with <code>append_keys</code>, or remove them with <code>remove_keys</code> methods.</p> append_and_remove_keys.pyappend_and_remove_keys_output.json <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(service=\"payment\", name=\"%(name)s\")\nlogger.info(\"Name should be equal service value\")\n\nadditional_log_attributes = {\"process\": \"%(process)d\", \"processName\": \"%(processName)s\"}\nlogger.append_keys(**additional_log_attributes)\nlogger.info(\"This will include process ID and name\")\nlogger.remove_keys([\"processName\"])\n# further messages will not include processName\n</code></pre> <pre><code>[\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:16\",\n\"message\": \"Name should be equal service value\",\n\"name\": \"payment\",\n\"service\": \"payment\",\n\"timestamp\": \"2022-07-01 07:09:46,330+0000\"\n},\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:23\",\n\"message\": \"This will include process ID and name\",\n\"name\": \"payment\",\n\"process\": \"9\",\n\"processName\": \"MainProcess\",\n\"service\": \"payment\",\n\"timestamp\": \"2022-07-01 07:09:46,330+0000\"\n}\n]\n</code></pre> <p>For log records originating from Powertools for AWS Lambda (Python) Logger, the <code>name</code> attribute will be the same as <code>service</code>, for log records coming from standard library logger, it will be the name of the logger (i.e. what was used as name argument to <code>logging.getLogger</code>).</p>"},{"location":"core/logger/#whats-the-difference-between-append_keys-and-extra","title":"What's the difference between <code>append_keys</code> and <code>extra</code>?","text":"<p>Keys added with <code>append_keys</code> will persist across multiple log messages while keys added via <code>extra</code> will only be available in a given log message operation.</p> <p>Here's an example where we persist <code>payment_id</code> not <code>request_id</code>. Note that <code>payment_id</code> remains in both log messages while <code>booking_id</code> is only available in the first message.</p> append_keys_vs_extra.pyappend_keys_vs_extra_output.json <pre><code>import os\n\nimport requests\n\nfrom aws_lambda_powertools import Logger\n\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\nlogger = Logger(service=\"payment\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\ndef lambda_handler(event, context):\nlogger.append_keys(payment_id=\"123456789\")\ncharge_id = event.get(\"charge_id\", \"\")\n\n    try:\n        ret = requests.post(url=f\"{ENDPOINT}/collect\", data={\"charge_id\": charge_id})\n        ret.raise_for_status()\n\nlogger.info(\"Charge collected successfully\", extra={\"charge_id\": charge_id})\nreturn ret.json()\n    except requests.HTTPError as e:\n        raise PaymentError(f\"Unable to collect payment for charge {charge_id}\") from e\n\n    logger.info(\"goodbye\")\n</code></pre> <pre><code>[\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:22\",\n\"message\": \"Charge collected successfully\",\n\"timestamp\": \"2021-01-12 14:09:10,859\",\n\"service\": \"payment\",\n\"sampling_rate\": 0.0,\n\"payment_id\": \"123456789\",\n\"charge_id\": \"75edbad0-0857-4fc9-b547-6180e2f7959b\"\n},\n{\n\"level\": \"INFO\",\n\"location\": \"&lt;module&gt;:27\",\n\"message\": \"goodbye\",\n\"timestamp\": \"2021-01-12 14:09:10,860\",\n\"service\": \"payment\",\n\"sampling_rate\": 0.0,\n\"payment_id\": \"123456789\"\n}\n]\n</code></pre>"},{"location":"core/logger/#how-do-i-aggregate-and-search-powertools-for-aws-lambda-python-logs-across-accounts","title":"How do I aggregate and search Powertools for AWS Lambda (Python) logs across accounts?","text":"<p>As of now, ElasticSearch (ELK) or 3rd party solutions are best suited to this task. Please refer to this discussion for more details</p>"},{"location":"core/metrics/","title":"Metrics","text":"<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p>"},{"location":"core/metrics/#key-features","title":"Key features","text":"<ul> <li>Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob)</li> <li>Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc)</li> <li>Metrics are created asynchronously by CloudWatch service, no custom stacks needed</li> <li>Context manager to create a one off metric with a different dimension</li> </ul>"},{"location":"core/metrics/#terminologies","title":"Terminologies","text":"<p>If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> <li>Metric. It's the name of the metric, for example: <code>SuccessfulBooking</code> or <code>UpdatedBooking</code>.</li> <li>Unit. It's a value representing the unit of measure for the corresponding metric, for example: <code>Count</code> or <code>Seconds</code>.</li> <li>Resolution. It's a value representing the storage resolution for the corresponding metric. Metrics can be either Standard or High resolution. Read more here.</li> </ul> Metric terminology, visually explained"},{"location":"core/metrics/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>Metric has two global settings that will be used across all metrics emitted:</p> Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. <code>ServerlessAirline</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>namespace</code> Service Optionally, sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>service</code> Tip <p>Use your application or main service as the metric namespace to easily group all metrics.</p> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\nFunction:\nTimeout: 5\nRuntime: python3.10\nTracing: Active\nEnvironment:\nVariables:\nPOWERTOOLS_SERVICE_NAME: booking\nPOWERTOOLS_METRICS_NAMESPACE: ServerlessAirline\nLayers:\n# Find the latest Layer version in the official documentation\n# https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n- !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\n\nResources:\nCaptureLambdaHandlerExample:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: ../src\nHandler: capture_lambda_handler.handler\n</code></pre> Note <p>For brevity, all code snippets in this page will rely on environment variables above being set.</p> <p>This ensures we instantiate <code>metrics = Metrics()</code> over <code>metrics = Metrics(service=\"booking\", namespace=\"ServerlessAirline\")</code>, etc.</p>"},{"location":"core/metrics/#creating-metrics","title":"Creating metrics","text":"<p>You can create metrics using <code>add_metric</code>, and you can create dimensions for all your aggregate metrics using <code>add_dimension</code> method.</p> Tip <p>You can initialize Metrics in any other module too. It'll keep track of your aggregate metrics in memory to optimize costs (one blob instead of multiples).</p> add_metrics.pyadd_dimension.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\nmetrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\nmetrics.add_dimension(name=\"environment\", value=STAGE)\nmetrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> Tip: Autocomplete Metric Units <p><code>MetricUnit</code> enum facilitate finding a supported metric unit by CloudWatch. Alternatively, you can pass the value as a string if you already know them e.g. <code>unit=\"Count\"</code>.</p> Note: Metrics overflow <p>CloudWatch EMF supports a max of 100 metrics per batch. Metrics utility will flush all metrics when adding the 100th metric. Subsequent metrics (101th+) will be aggregated into a new EMF object, for your convenience.</p> Warning: Do not create metrics or dimensions outside the handler <p>Metrics or dimensions added in the global scope will only be added during cold start. Disregard if you that's the intended behavior.</p>"},{"location":"core/metrics/#adding-high-resolution-metrics","title":"Adding high-resolution metrics","text":"<p>You can create high-resolution metrics passing <code>resolution</code> parameter to <code>add_metric</code>.</p> When is it useful? <p>High-resolution metrics are data with a granularity of one second and are very useful in several situations such as telemetry, time series, real-time incident management, and others.</p> add_high_resolution_metrics.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricResolution, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\nmetrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.High)\n</code></pre> Tip: Autocomplete Metric Resolutions <p><code>MetricResolution</code> enum facilitates finding a supported metric resolution by CloudWatch. Alternatively, you can pass the values 1 or 60 (must be one of them) as an integer e.g. <code>resolution=1</code>.</p>"},{"location":"core/metrics/#adding-multi-value-metrics","title":"Adding multi-value metrics","text":"<p>You can call <code>add_metric()</code> with the same metric name multiple times. The values will be grouped together in a list.</p> add_multi_value_metrics.pyadd_multi_value_metrics_output.json <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_dimension(name=\"environment\", value=STAGE)\nmetrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\nmetrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656685750622,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"environment\",\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n\"Name\": \"TurbineReads\",\n\"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"environment\": \"dev\",\n    \"service\": \"booking\",\n\"TurbineReads\": [\n1.0,\n8.0\n]\n}\n</code></pre>"},{"location":"core/metrics/#adding-default-dimensions","title":"Adding default dimensions","text":"<p>You can use <code>set_default_dimensions</code> method, or <code>default_dimensions</code> parameter in <code>log_metrics</code> decorator, to persist dimensions across Lambda invocations.</p> <p>If you'd like to remove them at some point, you can use <code>clear_default_dimensions</code> method.</p> set_default_dimensions.pyset_default_dimensions_log_metrics.py <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\nmetrics.set_default_dimensions(environment=STAGE, another=\"one\")\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\nDEFAULT_DIMENSIONS = {\"environment\": STAGE, \"another\": \"one\"}\n# ensures metrics are flushed upon request completion/failure\n@metrics.log_metrics(default_dimensions=DEFAULT_DIMENSIONS)\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre>"},{"location":"core/metrics/#flushing-metrics","title":"Flushing metrics","text":"<p>As you finish adding all your metrics, you need to serialize and flush them to standard output. You can do that automatically with the <code>log_metrics</code> decorator.</p> <p>This decorator also validates, serializes, and flushes all your metrics. During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be raised.</p> add_metrics.pylog_metrics_output.json <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <pre><code>{\n\"_aws\": {\n\"Timestamp\": 1656686788803,\n\"CloudWatchMetrics\": [\n{\n\"Namespace\": \"ServerlessAirline\",\n\"Dimensions\": [\n[\n\"service\"\n]\n],\n\"Metrics\": [\n{\n\"Name\": \"SuccessfulBooking\",\n\"Unit\": \"Count\"\n}\n]\n}\n]\n},\n\"service\": \"booking\",\n\"SuccessfulBooking\": [\n1.0\n]\n}\n</code></pre> Tip: Metric validation <p>If metrics are provided, and any of the following criteria are not met, <code>SchemaValidationError</code> exception will be raised:</p> <ul> <li>Maximum of 29 user-defined dimensions</li> <li>Namespace is set, and no more than one</li> <li>Metric units must be supported by CloudWatch</li> </ul>"},{"location":"core/metrics/#raising-schemavalidationerror-on-empty-metrics","title":"Raising SchemaValidationError on empty metrics","text":"<p>If you want to ensure at least one metric is always emitted, you can pass <code>raise_on_empty_metrics</code> to the log_metrics decorator:</p> Raising SchemaValidationError exception if no metrics are added<pre><code>from aws_lambda_powertools.metrics import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(raise_on_empty_metrics=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    # no metrics being created will now raise SchemaValidationError\n    ...\n</code></pre> Suppressing warning messages on empty metrics <p>If you expect your function to execute without publishing metrics every time, you can suppress the warning with <code>warnings.filterwarnings(\"ignore\", \"No metrics to publish*\")</code>.</p>"},{"location":"core/metrics/#capturing-cold-start-metric","title":"Capturing cold start metric","text":"<p>You can optionally capture cold start metrics with <code>log_metrics</code> decorator via <code>capture_cold_start_metric</code> param.</p> capture_cold_start_metric.pycapture_cold_start_metric_output.json <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    ...\n</code></pre> <pre><code>{\n\"_aws\": {\n\"Timestamp\": 1656687493142,\n\"CloudWatchMetrics\": [\n{\n\"Namespace\": \"ServerlessAirline\",\n\"Dimensions\": [\n[\n\"function_name\",\n\"service\"\n]\n],\n\"Metrics\": [\n{\n\"Name\": \"ColdStart\",\n\"Unit\": \"Count\"\n}\n]\n}\n]\n},\n\"function_name\": \"test\",\n\"service\": \"booking\",\n\"ColdStart\": [\n1.0\n]\n}\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add <code>function_name</code> and <code>service</code> dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions.</p> Info <p>We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it.</p>"},{"location":"core/metrics/#advanced","title":"Advanced","text":""},{"location":"core/metrics/#adding-metadata","title":"Adding metadata","text":"<p>You can add high-cardinality data as part of your Metrics log with <code>add_metadata</code> method. This is useful when you want to search highly contextual information along with your metrics in your logs.</p> Info <p>This will not be available during metrics visualization - Use dimensions for this purpose</p> add_metadata.pyadd_metadata_output.json <pre><code>from uuid import uuid4\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n    metrics.add_metadata(key=\"booking_id\", value=f\"{uuid4()}\")\n</code></pre> <pre><code>{\n\"_aws\": {\n\"Timestamp\": 1656688250155,\n\"CloudWatchMetrics\": [\n{\n\"Namespace\": \"ServerlessAirline\",\n\"Dimensions\": [\n[\n\"service\"\n]\n],\n\"Metrics\": [\n{\n\"Name\": \"SuccessfulBooking\",\n\"Unit\": \"Count\"\n}\n]\n}\n]\n},\n\"service\": \"booking\",\n\"booking_id\": \"00347014-341d-4b8e-8421-a89d3d588ab3\",\n\"SuccessfulBooking\": [\n1.0\n]\n}\n</code></pre>"},{"location":"core/metrics/#single-metric-with-a-different-dimension","title":"Single metric with a different dimension","text":"<p>CloudWatch EMF uses the same dimensions across all your metrics. Use <code>single_metric</code> if you have a metric that should have different dimensions.</p> Info <p>Generally, this would be an edge case since you pay for unique metric. Keep the following formula in mind:</p> <p>unique metric = (metric_name + dimension_name + dimension_value)</p> single_metric.pysingle_metric_output.json <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\nwith single_metric(name=\"MySingleMetric\", unit=MetricUnit.Count, value=1) as metric:\nmetric.add_dimension(name=\"environment\", value=STAGE)\n</code></pre> <pre><code>{\n\"_aws\": {\n\"Timestamp\": 1656689267834,\n\"CloudWatchMetrics\": [\n{\n\"Namespace\": \"ServerlessAirline\",\n\"Dimensions\": [\n[\n\"environment\",\n\"service\"\n]\n],\n\"Metrics\": [\n{\n\"Name\": \"MySingleMetric\",\n\"Unit\": \"Count\"\n}\n]\n}\n]\n},\n\"environment\": \"dev\",\n\"service\": \"booking\",\n\"MySingleMetric\": [\n1.0\n]\n}\n</code></pre> <p>By default it will skip all previously defined dimensions including default dimensions. Use <code>default_dimensions</code> keyword argument if you want to reuse default dimensions or specify custom dimensions from a dictionary.</p> single_metric_default_dimensions_inherit.pysingle_metric_default_dimensions.py <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import Metrics, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\nmetrics = Metrics()\nmetrics.set_default_dimensions(environment=STAGE)\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(\nname=\"RecordsCount\",\nunit=MetricUnit.Count,\n        value=10,\n        default_dimensions=metrics.default_dimensions,\n    ) as metric:\n        metric.add_dimension(name=\"TableName\", value=\"Users\")\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(\nname=\"RecordsCount\",\nunit=MetricUnit.Count,\n        value=10,\n        default_dimensions={\"environment\": STAGE},\n    ) as metric:\n        metric.add_dimension(name=\"TableName\", value=\"Users\")\n</code></pre>"},{"location":"core/metrics/#flushing-metrics-manually","title":"Flushing metrics manually","text":"<p>If you are using the AWS Lambda Web Adapter project, or a middleware with custom metric logic, you can use <code>flush_metrics()</code>. This method will serialize, print metrics available to standard output, and clear in-memory metrics data.</p> Warning <p>This does not capture Cold Start metrics, and metric data validation still applies.</p> <p>Contrary to the <code>log_metrics</code> decorator, you are now also responsible to flush metrics in the event of an exception.</p> Manually flushing and clearing metrics from memory<pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\ndef book_flight(flight_id: str, **kwargs): \n    # logic to book flight\n    ...\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        book_flight(flight_id=event.get(\"flight_id\", \"\"))\n    finally:\nmetrics.flush_metrics()\n</code></pre>"},{"location":"core/metrics/#metrics-isolation","title":"Metrics isolation","text":"<p>You can use <code>EphemeralMetrics</code> class when looking to isolate multiple instances of metrics with distinct namespaces and/or dimensions.</p> <p>This is a typical use case is for multi-tenant, or emitting same metrics for distinct applications.</p> EphemeralMetrics usage<pre><code>from aws_lambda_powertools.metrics import EphemeralMetrics, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = EphemeralMetrics()\n@metrics.log_metrics\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>Differences between <code>EphemeralMetrics</code> and <code>Metrics</code></p> <p><code>EphemeralMetrics</code> has only two differences while keeping nearly the exact same set of features:</p> Feature Metrics EphemeralMetrics Share data across instances (metrics, dimensions, metadata, etc.) Yes - Default dimensions that persists across Lambda invocations (metric flush) Yes - <p>Why not changing the default <code>Metrics</code> behaviour to not share data across instances?</p> <p>This is an intentional design to prevent accidental data deduplication or data loss issues due to CloudWatch EMF metric dimension constraint.</p> <p>In CloudWatch, there are two metric ingestion mechanisms: EMF (async) and <code>PutMetricData</code> API (sync).</p> <p>The former creates metrics asynchronously via CloudWatch Logs, and the latter uses a synchronous and more flexible ingestion API.</p> <p>Key concept</p> <p>CloudWatch considers a metric unique by a combination of metric name, metric namespace, and zero or more metric dimensions.</p> <p>With EMF, metric dimensions are shared with any metrics you define. With <code>PutMetricData</code> API, you can set a list defining one or more metrics with distinct dimensions.</p> <p>This is a subtle yet important distinction. Imagine you had the following metrics to emit:</p> Metric Name Dimension Intent SuccessfulBooking service=\"booking\", tenant_id=\"sample\" Application metric IntegrationLatency service=\"booking\", function_name=\"sample\" Operational metric ColdStart service=\"booking\", function_name=\"sample\" Operational metric <p>The <code>tenant_id</code> dimension could vary leading to two common issues:</p> <ol> <li><code>ColdStart</code> metric will be created multiple times (N * number of unique tenant_id dimension value), despite the <code>function_name</code> being the same</li> <li><code>IntegrationLatency</code> metric will be also created multiple times due to <code>tenant_id</code> as well as <code>function_name</code> (may or not be intentional)</li> </ol> <p>These issues are exacerbated when you create (A) metric dimensions conditionally, (B) multiple metrics' instances throughout your code  instead of reusing them (globals). Subsequent metrics' instances will have (or lack) different metric dimensions resulting in different metrics and data points with the same name.</p> <p>Intentional design to address these scenarios</p> <p>On 1, when you enable capture_start_metric feature, we transparently create and flush an additional EMF JSON Blob that is independent from your application metrics. This prevents data pollution.</p> <p>On 2, you can use <code>EphemeralMetrics</code> to create an additional EMF JSON Blob from your application metric (<code>SuccessfulBooking</code>). This ensures that <code>IntegrationLatency</code> operational metric data points aren't tied to any dynamic dimension values like <code>tenant_id</code>.</p> <p>That is why <code>Metrics</code> shares data across instances by default, as that covers 80% of use cases and different personas using Powertools. This allows them to instantiate <code>Metrics</code> in multiple places throughout their code - be a separate file, a middleware, or an abstraction that sets default dimensions.</p>"},{"location":"core/metrics/#testing-your-code","title":"Testing your code","text":""},{"location":"core/metrics/#environment-variables","title":"Environment variables","text":"Tip <p>Ignore this section, if:</p> <ul> <li>You are explicitly setting namespace/default dimension via <code>namespace</code> and <code>service</code> parameters</li> <li>You're not instantiating <code>Metrics</code> in the global namespace</li> </ul> <p>For example, <code>Metrics(namespace=\"ServerlessAirline\", service=\"booking\")</code></p> <p>Make sure to set <code>POWERTOOLS_METRICS_NAMESPACE</code> and <code>POWERTOOLS_SERVICE_NAME</code> before running your tests to prevent failing on <code>SchemaValidation</code> exception. You can set it before you run tests or via pytest plugins like dotenv.</p> Injecting dummy Metric Namespace before running tests<pre><code>POWERTOOLS_SERVICE_NAME=\"booking\" POWERTOOLS_METRICS_NAMESPACE=\"ServerlessAirline\" python -m pytest\n</code></pre>"},{"location":"core/metrics/#clearing-metrics","title":"Clearing metrics","text":"<p><code>Metrics</code> keep metrics in memory across multiple instances. If you need to test this behavior, you can use the following Pytest fixture to ensure metrics are reset incl. cold start:</p> Clearing metrics between tests<pre><code>import pytest\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import metrics as metrics_global\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef reset_metric_set():\n    # Clear out every metric data prior to every test\n    metrics = Metrics()\n    metrics.clear_metrics()\n    metrics_global.is_cold_start = True  # ensure each test has cold start\n    metrics.clear_default_dimensions()  # remove persisted default dimensions, if any\n    yield\n</code></pre>"},{"location":"core/metrics/#functional-testing","title":"Functional testing","text":"<p>You can read standard output and assert whether metrics have been flushed. Here's an example using <code>pytest</code> with <code>capsys</code> built-in fixture:</p> assert_single_emf_blob.pyadd_metrics.pyassert_multiple_emf_blobs.pyassert_multiple_emf_blobs_module.py <pre><code>import json\n\nimport add_metrics\n\n\ndef test_log_metrics(capsys):\nadd_metrics.lambda_handler({}, {})\n\nlog = capsys.readouterr().out.strip()  # remove any extra line\nmetrics_output = json.loads(log)  # deserialize JSON str\n# THEN we should have no exceptions\n    # and a valid EMF object should be flushed correctly\n    assert \"SuccessfulBooking\" in log  # basic string assertion in JSON str\n    assert \"SuccessfulBooking\" in metrics_output[\"_aws\"][\"CloudWatchMetrics\"][0][\"Metrics\"][0][\"Name\"]\n</code></pre> <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>This will be needed when using <code>capture_cold_start_metric=True</code>, or when both <code>Metrics</code> and <code>single_metric</code> are used.</p> <pre><code>import json\nfrom dataclasses import dataclass\n\nimport assert_multiple_emf_blobs_module\nimport pytest\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n    return LambdaContext()\n\n\ndef capture_metrics_output_multiple_emf_objects(capsys):\nreturn [json.loads(line.strip()) for line in capsys.readouterr().out.split(\"\\n\") if line]\ndef test_log_metrics(capsys, lambda_context):\n    assert_multiple_emf_blobs_module.lambda_handler({}, lambda_context)\n\ncold_start_blob, custom_metrics_blob = capture_metrics_output_multiple_emf_objects(capsys)\n# Since `capture_cold_start_metric` is used\n    # we should have one JSON blob for cold start metric and one for the application\n    assert cold_start_blob[\"ColdStart\"] == [1.0]\n    assert cold_start_blob[\"function_name\"] == \"test\"\n\n    assert \"SuccessfulBooking\" in custom_metrics_blob\n</code></pre> <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> Tip <p>For more elaborate assertions and comparisons, check out our functional testing for Metrics utility.</p>"},{"location":"core/tracer/","title":"Tracer","text":"<p>Tracer is an opinionated thin wrapper for AWS X-Ray Python SDK.</p> <p></p>"},{"location":"core/tracer/#key-features","title":"Key features","text":"<ul> <li>Auto capture cold start as annotation, and responses or full exceptions as metadata</li> <li>Auto-disable when not running in AWS Lambda environment</li> <li>Support tracing async methods, generators, and context managers</li> <li>Auto patch supported modules by AWS X-Ray</li> </ul>"},{"location":"core/tracer/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>Tracer relies on AWS X-Ray SDK over OpenTelememetry Distro (ADOT) for optimal cold start (lower latency).</p>"},{"location":"core/tracer/#install","title":"Install","text":"<p>This is not necessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR</p> <p>Add <code>aws-lambda-powertools[tracer]</code> as a dependency in your preferred tool: e.g., requirements.txt, pyproject.toml. This will ensure you have the required dependencies before using Tracer.</p>"},{"location":"core/tracer/#permissions","title":"Permissions","text":"<p>Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray.</p> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\nFunction:\nTimeout: 5\nRuntime: python3.10\nTracing: Active\nEnvironment:\nVariables:\nPOWERTOOLS_SERVICE_NAME: payment\nLayers:\n# Find the latest Layer version in the official documentation\n# https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n- !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV2:37\n\nResources:\nCaptureLambdaHandlerExample:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: ../src\nHandler: capture_lambda_handler.handler\n</code></pre>"},{"location":"core/tracer/#lambda-handler","title":"Lambda handler","text":"<p>You can quickly start by initializing <code>Tracer</code> and use <code>capture_lambda_handler</code> decorator for your Lambda handler.</p> Tracing Lambda handler with capture_lambda_handler<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()  # Sets service via POWERTOOLS_SERVICE_NAME env var\n# OR tracer = Tracer(service=\"example\")\n\n\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <p><code>capture_lambda_handler</code> performs these additional tasks to ease operations:</p> <ul> <li>Creates a <code>ColdStart</code> annotation to easily filter traces that have had an initialization overhead</li> <li>Creates a <code>Service</code> annotation if <code>service</code> parameter or <code>POWERTOOLS_SERVICE_NAME</code> is set</li> <li>Captures any response, or full exceptions generated by the handler, and include as tracing metadata</li> </ul>"},{"location":"core/tracer/#annotations-metadata","title":"Annotations &amp; Metadata","text":"<p>Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions.</p> Adding annotations with put_annotation method<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\ndef collect_payment(charge_id: str) -&gt; str:\ntracer.put_annotation(key=\"PaymentId\", value=charge_id)\nreturn f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <p>Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object.</p> Adding arbitrary metadata with put_metadata method<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    payment_context = {\n        \"charge_id\": event.get(\"charge_id\", \"\"),\n        \"merchant_id\": event.get(\"merchant_id\", \"\"),\n        \"request_id\": context.aws_request_id,\n    }\n    payment_context[\"receipt_id\"] = collect_payment(charge_id=payment_context[\"charge_id\"])\ntracer.put_metadata(key=\"payment_response\", value=payment_context)\nreturn payment_context[\"receipt_id\"]\n</code></pre>"},{"location":"core/tracer/#synchronous-functions","title":"Synchronous functions","text":"<p>You can trace synchronous functions using the <code>capture_method</code> decorator.</p> Tracing an arbitrary function with capture_method<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; str:\n    tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> Note: Function responses are auto-captured and stored as JSON, by default. <p>Use capture_response parameter to override this behaviour.</p> <p>The serialization is performed by aws-xray-sdk via <code>jsonpickle</code> module. This can cause side effects for file-like objects like boto S3 <code>StreamingBody</code>, where its response will be read only once during serialization.</p>"},{"location":"core/tracer/#asynchronous-and-generator-functions","title":"Asynchronous and generator functions","text":"Warning <p>We do not support asynchronous Lambda handler</p> <p>You can trace asynchronous functions and generator functions (including context managers) using <code>capture_method</code>.</p> capture_method_async.pycapture_method_context_manager.pycapture_method_generators.py <pre><code>import asyncio\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\n@tracer.capture_method\nasync def collect_payment(charge_id: str) -&gt; str:\n    tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n    await asyncio.sleep(0.5)\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return asyncio.run(collect_payment(charge_id=charge_id))\n</code></pre> <pre><code>import contextlib\nfrom collections.abc import Generator\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n\n\n@contextlib.contextmanager\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; Generator[str, None, None]:\ntry:\n        yield f\"dummy payment collected for charge: {charge_id}\"\n    finally:\n        tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    with collect_payment(charge_id=charge_id) as receipt_id:\n        logger.info(f\"Processing payment collection for charge {charge_id} with receipt {receipt_id}\")\n\n    return receipt_id\n</code></pre> <pre><code>from collections.abc import Generator\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; Generator[str, None, None]:\n    yield f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return next(collect_payment(charge_id=charge_id))\n</code></pre>"},{"location":"core/tracer/#advanced","title":"Advanced","text":""},{"location":"core/tracer/#patching-modules","title":"Patching modules","text":"<p>Tracer automatically patches all supported libraries by X-Ray during initialization, by default. Underneath, AWS X-Ray SDK checks whether a supported library has been imported before patching.</p> <p>If you're looking to shave a few microseconds, or milliseconds depending on your function memory configuration, you can patch specific modules using <code>patch_modules</code> param:</p> Example of explicitly patching requests only<pre><code>import requests\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nMODULES = [\"requests\"]\n\ntracer = Tracer(patch_modules=MODULES)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    ret = requests.get(\"https://httpbin.org/get\")\n    ret.raise_for_status()\n\n    return ret.json()\n</code></pre>"},{"location":"core/tracer/#disabling-response-auto-capture","title":"Disabling response auto-capture","text":"<p>Use <code>capture_response=False</code> parameter in both <code>capture_lambda_handler</code> and <code>capture_method</code> decorators to instruct Tracer not to serialize function responses as metadata.</p> Info: This is useful in three common scenarios <ol> <li>You might return sensitive information you don't want it to be added to your traces</li> <li>You might manipulate streaming objects that can be read only once; this prevents subsequent calls from being empty</li> <li>You might return more than 64K of data e.g., <code>message too long</code> error</li> </ol> disable_capture_response.pydisable_capture_response_streaming_body.py <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method(capture_response=False)\ndef collect_payment(charge_id: str) -&gt; str:\n    tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n    logger.debug(\"Returning sensitive information....\")\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler(capture_response=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <pre><code>import os\n\nimport boto3\nfrom botocore.response import StreamingBody\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nBUCKET = os.getenv(\"BUCKET_NAME\", \"\")\nREPORT_KEY = os.getenv(\"REPORT_KEY\", \"\")\n\ntracer = Tracer()\nlogger = Logger()\n\nsession = boto3.Session()\ns3 = session.client(\"s3\")\n\n\n@tracer.capture_method(capture_response=False)\ndef fetch_payment_report(payment_id: str) -&gt; StreamingBody:\n    ret = s3.get_object(Bucket=BUCKET, Key=f\"{REPORT_KEY}/{payment_id}\")\n    logger.debug(\"Returning streaming body from S3 object....\")\n    return ret[\"body\"]\n\n\n@tracer.capture_lambda_handler(capture_response=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    payment_id = event.get(\"payment_id\", \"\")\n    report = fetch_payment_report(payment_id=payment_id)\n    return report.read().decode()\n</code></pre>"},{"location":"core/tracer/#disabling-exception-auto-capture","title":"Disabling exception auto-capture","text":"<p>Use <code>capture_error=False</code> parameter in both <code>capture_lambda_handler</code> and <code>capture_method</code> decorators to instruct Tracer not to serialize exceptions as metadata.</p> Info <p>Useful when returning sensitive information in exceptions/stack traces you don't control</p> Disabling exception auto-capture for tracing metadata<pre><code>import os\n\nimport requests\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@tracer.capture_method(capture_error=False)\ndef collect_payment(charge_id: str) -&gt; dict:\n    try:\n        ret = requests.post(url=f\"{ENDPOINT}/collect\", data={\"charge_id\": charge_id})\n        ret.raise_for_status()\n        return ret.json()\n    except requests.HTTPError as e:\n        raise PaymentError(f\"Unable to collect payment for charge {charge_id}\") from e\n\n\n@tracer.capture_lambda_handler(capture_error=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    ret = collect_payment(charge_id=charge_id)\n\n    return ret.get(\"receipt_id\", \"\")\n</code></pre>"},{"location":"core/tracer/#ignoring-certain-http-endpoints","title":"Ignoring certain HTTP endpoints","text":"<p>You might have endpoints you don't want requests to be traced, perhaps due to the volume of calls or sensitive URLs.</p> <p>You can use <code>ignore_endpoint</code> method with the hostname and/or URLs you'd like it to be ignored - globs (<code>*</code>) are allowed.</p> Ignoring certain HTTP endpoints from being traced<pre><code>import os\n\nimport requests\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\nIGNORE_URLS = [\"/collect\", \"/refund\"]\n\ntracer = Tracer()\ntracer.ignore_endpoint(hostname=ENDPOINT, urls=IGNORE_URLS)\ntracer.ignore_endpoint(hostname=f\"*.{ENDPOINT}\", urls=IGNORE_URLS)  # `&lt;stage&gt;.ENDPOINT`\nclass PaymentError(Exception):\n    ...\n\n\n@tracer.capture_method(capture_error=False)\ndef collect_payment(charge_id: str) -&gt; dict:\n    try:\n        ret = requests.post(url=f\"{ENDPOINT}/collect\", data={\"charge_id\": charge_id})\n        ret.raise_for_status()\n        return ret.json()\n    except requests.HTTPError as e:\n        raise PaymentError(f\"Unable to collect payment for charge {charge_id}\") from e\n\n\n@tracer.capture_lambda_handler(capture_error=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    ret = collect_payment(charge_id=charge_id)\n\n    return ret.get(\"receipt_id\", \"\")\n</code></pre>"},{"location":"core/tracer/#tracing-aiohttp-requests","title":"Tracing aiohttp requests","text":"Info <p>This snippet assumes you have aiohttp as a dependency</p> <p>You can use <code>aiohttp_trace_config</code> function to create a valid aiohttp trace_config object. This is necessary since X-Ray utilizes aiohttp trace hooks to capture requests end-to-end.</p> Tracing aiohttp requests<pre><code>import asyncio\nimport os\n\nimport aiohttp\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.tracing import aiohttp_trace_config\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\n\ntracer = Tracer()\n\n\n@tracer.capture_method\nasync def collect_payment(charge_id: str) -&gt; dict:\nasync with aiohttp.ClientSession(trace_configs=[aiohttp_trace_config()]) as session:\nasync with session.get(f\"{ENDPOINT}/collect\") as resp:\n            return await resp.json()\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    charge_id = event.get(\"charge_id\", \"\")\n    return asyncio.run(collect_payment(charge_id=charge_id))\n</code></pre>"},{"location":"core/tracer/#escape-hatch-mechanism","title":"Escape hatch mechanism","text":"<p>You can use <code>tracer.provider</code> attribute to access all methods provided by AWS X-Ray <code>xray_recorder</code> object.</p> <p>This is useful when you need a feature available in X-Ray that is not available in the Tracer utility, for example thread-safe, or context managers.</p> Tracing a code block with in_subsegment escape hatch<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\nwith tracer.provider.in_subsegment(\"## collect_payment\") as subsegment:\nsubsegment.put_annotation(key=\"PaymentId\", value=charge_id)\n        ret = collect_payment(charge_id=charge_id)\n        subsegment.put_metadata(key=\"payment_response\", value=ret)\n\n    return ret\n</code></pre>"},{"location":"core/tracer/#concurrent-asynchronous-functions","title":"Concurrent asynchronous functions","text":"Warning <p>X-Ray SDK will raise an exception when async functions are run and traced concurrently</p> <p>A safe workaround mechanism is to use <code>in_subsegment_async</code> available via Tracer escape hatch (<code>tracer.provider</code>).</p> Workaround to safely trace async concurrent functions<pre><code>import asyncio\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\nasync def another_async_task():\nasync with tracer.provider.in_subsegment_async(\"## another_async_task\") as subsegment:\nsubsegment.put_annotation(key=\"key\", value=\"value\")\n        subsegment.put_metadata(key=\"key\", value=\"value\", namespace=\"namespace\")\n        ...\n\n\nasync def another_async_task_2():\nasync with tracer.provider.in_subsegment_async(\"## another_async_task_2\") as subsegment:\nsubsegment.put_annotation(key=\"key\", value=\"value\")\n        subsegment.put_metadata(key=\"key\", value=\"value\", namespace=\"namespace\")\n        ...\n\n\nasync def collect_payment(charge_id: str) -&gt; str:\nawait asyncio.gather(another_async_task(), another_async_task_2())\nreturn f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return asyncio.run(collect_payment(charge_id=charge_id))\n</code></pre>"},{"location":"core/tracer/#reusing-tracer-across-your-code","title":"Reusing Tracer across your code","text":"<p>Tracer keeps a copy of its configuration after the first initialization. This is useful for scenarios where you want to use Tracer in more than one location across your code base.</p> Warning: Import order matters when using Lambda Layers or multiple modules <p>Do not set <code>auto_patch=False</code> when reusing Tracer in Lambda Layers, or in multiple modules.</p> <p>This can result in the first Tracer config being inherited by new instances, and their modules not being patched.</p> <p>Tracer will automatically ignore imported modules that have been patched.</p> tracer_reuse.pytracer_reuse_module.py <pre><code>from tracer_reuse_module import collect_payment\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <p>A new instance of Tracer will be created but will reuse the previous Tracer instance configuration, similar to a Singleton.</p> <pre><code>from aws_lambda_powertools import Tracer\n\ntracer = Tracer()\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n</code></pre>"},{"location":"core/tracer/#testing-your-code","title":"Testing your code","text":"<p>Tracer is disabled by default when not running in the AWS Lambda environment - This means no code changes or environment variables to be set.</p>"},{"location":"core/tracer/#tips","title":"Tips","text":"<ul> <li>Use annotations on key operations to slice and dice traces, create unique views, and create metrics from it via Trace Groups</li> <li>Use a namespace when adding metadata to group data more easily</li> <li>Annotations and metadata are added to the current subsegment opened. If you want them in a specific subsegment, use a context manager via the escape hatch mechanism</li> </ul>"},{"location":"core/event_handler/api_gateway/","title":"REST API","text":"<p>Event handler for Amazon API Gateway REST and HTTP APIs, Application Loader Balancer (ALB), Lambda Function URLs, and VPC Lattice.</p>"},{"location":"core/event_handler/api_gateway/#key-features","title":"Key Features","text":"<ul> <li>Lightweight routing to reduce boilerplate for API Gateway REST/HTTP API, ALB and Lambda Function URLs.</li> <li>Support for CORS, binary and Gzip compression, Decimals JSON encoding and bring your own JSON serializer</li> <li>Built-in integration with Event Source Data Classes utilities for self-documented event schema</li> </ul>"},{"location":"core/event_handler/api_gateway/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p>"},{"location":"core/event_handler/api_gateway/#required-resources","title":"Required resources","text":"<p>If you're using any API Gateway integration, you must have an existing API Gateway Proxy integration or ALB configured to invoke your Lambda function.</p> <p>In case of using VPC Lattice, you must have a service network configured to invoke your Lambda function.</p> <p>This is the sample infrastructure for API Gateway and Lambda Function URLs we are using for the examples in this documentation.</p> There is no additional permissions or dependencies required to use this utility. API Gateway SAM TemplateLambda Function URL SAM Template AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Hello world event handler API Gateway\n\nGlobals:\nApi:\nTracingEnabled: true\nCors: # see CORS section\nAllowOrigin: \"'https://example.com'\"\nAllowHeaders: \"'Content-Type,Authorization,X-Amz-Date'\"\nMaxAge: \"'300'\"\nBinaryMediaTypes: # see Binary responses section\n- \"*~1*\" # converts to */* for any binary type\nFunction:\nTimeout: 5\nRuntime: python3.9\nTracing: Active\nEnvironment:\nVariables:\nLOG_LEVEL: INFO\nPOWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\nPOWERTOOLS_LOGGER_LOG_EVENT: true\nPOWERTOOLS_SERVICE_NAME: example\n\nResources:\nApiFunction:\nType: AWS::Serverless::Function\nProperties:\nHandler: getting_started_rest_api_resolver.lambda_handler\nCodeUri: ../src\nDescription: API handler function\nEvents:\nAnyApiEvent:\nType: Api\nProperties:\n# NOTE: this is a catch-all rule to simplify the documentation.\n# explicit routes and methods are recommended for prod instead (see below)\nPath: /{proxy+} # Send requests on any path to the lambda function\nMethod: ANY # Send requests using any http method to the lambda function\n\n\n# GetAllTodos:\n#   Type: Api\n#   Properties:\n#     Path: /todos\n#     Method: GET\n# GetTodoById:\n#   Type: Api\n#   Properties:\n#     Path: /todos/{todo_id}\n#     Method: GET\n# CreateTodo:\n#   Type: Api\n#   Properties:\n#     Path: /todos\n#     Method: POST\n</code></pre> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Hello world event handler Lambda Function URL\n\nGlobals:\nFunction:\nTimeout: 5\nRuntime: python3.9\nTracing: Active\nEnvironment:\nVariables:\nLOG_LEVEL: INFO\nPOWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\nPOWERTOOLS_LOGGER_LOG_EVENT: true\nPOWERTOOLS_SERVICE_NAME: example\nFunctionUrlConfig:\nCors: # see CORS section\n# Notice that values here are Lists of Strings, vs comma-separated values on API Gateway\nAllowOrigins: [\"https://example.com\"]\nAllowHeaders: [\"Content-Type\", \"Authorization\", \"X-Amz-Date\"]\nMaxAge: 300\n\nResources:\nApiFunction:\nType: AWS::Serverless::Function\nProperties:\nHandler: getting_started_lambda_function_url_resolver.lambda_handler\nCodeUri: ../src\nDescription: API handler function\nFunctionUrlConfig:\nAuthType: NONE  # AWS_IAM for added security beyond sample documentation\n</code></pre>"},{"location":"core/event_handler/api_gateway/#event-resolvers","title":"Event Resolvers","text":"<p>Before you decorate your functions to handle a given path and HTTP method(s), you need to initialize a resolver.</p> <p>A resolver will handle request resolution, including one or more routers, and give you access to the current event via typed properties.</p> <p>For resolvers, we provide: <code>APIGatewayRestResolver</code>, <code>APIGatewayHttpResolver</code>, <code>ALBResolver</code>, <code>LambdaFunctionUrlResolver</code>, and <code>VPCLatticeResolver</code>. From here on, we will default to <code>APIGatewayRestResolver</code> across examples.</p> Auto-serialization <p>We serialize <code>Dict</code> responses as JSON, trim whitespace for compact responses, set content-type to <code>application/json</code>, and return a 200 OK HTTP status. You can optionally set a different HTTP status code as the second argument of the tuple:</p> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools.event_handler import ALBResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = ALBResolver()\n\n\n@app.post(\"/todo\")\ndef create_todo():\n    data: dict = app.current_event.json_body\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=data)\n\n# Returns the created todo object, with a HTTP 201 Created status\nreturn {\"todo\": todo.json()}, 201\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#api-gateway-rest-api","title":"API Gateway REST API","text":"<p>When using Amazon API Gateway REST API to front your Lambda functions, you can use <code>APIGatewayRestResolver</code>.</p> <p>Here's an example on how we can handle the <code>/todos</code> path.</p> Trailing slash in routes <p>For <code>APIGatewayRestResolver</code>, we seamless handle routes with a trailing slash (<code>/todos/</code>).</p> getting_started_rest_api_resolver.pygetting_started_rest_api_resolver.jsongetting_started_rest_api_resolver_output.json <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nreturn app.resolve(event, context)\n</code></pre> <p>This utility uses <code>path</code> and <code>httpMethod</code> to route to the right function. This helps make unit tests and local invocation easier too.</p> <pre><code>{\n\"body\": \"\",\n\"resource\": \"/todos\",\n\"path\": \"/todos\",\n\"httpMethod\": \"GET\",\n\"isBase64Encoded\": false,\n\"queryStringParameters\": {},\n\"multiValueQueryStringParameters\": {},\n\"pathParameters\": {},\n\"stageVariables\": {},\n\"headers\": {\n\"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n\"Accept-Encoding\": \"gzip, deflate, sdch\",\n\"Accept-Language\": \"en-US,en;q=0.8\",\n\"Cache-Control\": \"max-age=0\",\n\"CloudFront-Forwarded-Proto\": \"https\",\n\"CloudFront-Is-Desktop-Viewer\": \"true\",\n\"CloudFront-Is-Mobile-Viewer\": \"false\",\n\"CloudFront-Is-SmartTV-Viewer\": \"false\",\n\"CloudFront-Is-Tablet-Viewer\": \"false\",\n\"CloudFront-Viewer-Country\": \"US\",\n\"Host\": \"1234567890.execute-api.us-east-1.amazonaws.com\",\n\"Upgrade-Insecure-Requests\": \"1\",\n\"User-Agent\": \"Custom User Agent String\",\n\"Via\": \"1.1 08f323deadbeefa7af34d5feb414ce27.cloudfront.net (CloudFront)\",\n\"X-Amz-Cf-Id\": \"cDehVQoZnx43VYQb9j2-nvCh-9z396Uhbp027Y2JvkCPNLmGJHqlaA==\",\n\"X-Forwarded-For\": \"127.0.0.1, 127.0.0.2\",\n\"X-Forwarded-Port\": \"443\",\n\"X-Forwarded-Proto\": \"https\"\n},\n\"multiValueHeaders\": {},\n\"requestContext\": {\n\"accountId\": \"123456789012\",\n\"resourceId\": \"123456\",\n\"stage\": \"Prod\",\n\"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n\"requestTime\": \"25/Jul/2020:12:34:56 +0000\",\n\"requestTimeEpoch\": 1428582896000,\n\"identity\": {\n\"cognitoIdentityPoolId\": null,\n\"accountId\": null,\n\"cognitoIdentityId\": null,\n\"caller\": null,\n\"accessKey\": null,\n\"sourceIp\": \"127.0.0.1\",\n\"cognitoAuthenticationType\": null,\n\"cognitoAuthenticationProvider\": null,\n\"userArn\": null,\n\"userAgent\": \"Custom User Agent String\",\n\"user\": null\n},\n\"path\": \"/Prod/todos\",\n\"resourcePath\": \"/todos\",\n\"httpMethod\": \"GET\",\n\"apiId\": \"1234567890\",\n\"protocol\": \"HTTP/1.1\"\n}\n}\n</code></pre> <pre><code>{\n\"statusCode\": 200,\n\"multiValueHeaders\": {\n\"Content-Type\": [\"application/json\"]\n},\n\"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n\"isBase64Encoded\": false\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#api-gateway-http-api","title":"API Gateway HTTP API","text":"<p>When using Amazon API Gateway HTTP API to front your Lambda functions, you can use <code>APIGatewayHttpResolver</code>.</p> Note <p>Using HTTP API v1 payload? Use <code>APIGatewayRestResolver</code> instead. <code>APIGatewayHttpResolver</code> defaults to v2 payload.</p> Using HTTP API resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayHttpResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayHttpResolver()\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#application-load-balancer","title":"Application Load Balancer","text":"<p>When using Amazon Application Load Balancer (ALB) to front your Lambda functions, you can use <code>ALBResolver</code>.</p> Using ALB resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import ALBResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = ALBResolver()\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPLICATION_LOAD_BALANCER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#lambda-function-url","title":"Lambda Function URL","text":"<p>When using AWS Lambda Function URL, you can use <code>LambdaFunctionUrlResolver</code>.</p> getting_started_lambda_function_url_resolver.pygetting_started_lambda_function_url_resolver.json Using Lambda Function URL resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import LambdaFunctionUrlResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = LambdaFunctionUrlResolver()\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.LAMBDA_FUNCTION_URL)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Example payload delivered to the handler<pre><code>{\n\"version\": \"2.0\",\n\"routeKey\": \"$default\",\n\"rawPath\": \"/todos\",\n\"rawQueryString\": \"\",\n\"headers\": {\n\"x-amz-content-sha256\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n\"x-amzn-tls-version\": \"TLSv1.2\",\n\"x-amz-date\": \"20220803T092917Z\",\n\"x-forwarded-proto\": \"https\",\n\"x-forwarded-port\": \"443\",\n\"x-forwarded-for\": \"123.123.123.123\",\n\"accept\": \"application/xml\",\n\"x-amzn-tls-cipher-suite\": \"ECDHE-RSA-AES128-GCM-SHA256\",\n\"x-amzn-trace-id\": \"Root=1-63ea3fee-51ba94542feafa3928745ba3\",\n\"host\": \"xxxxxxxxxxxxx.lambda-url.eu-central-1.on.aws\",\n\"content-type\": \"application/json\",\n\"accept-encoding\": \"gzip, deflate\",\n\"user-agent\": \"Custom User Agent\"\n},\n\"requestContext\": {\n\"accountId\": \"123457890\",\n\"apiId\": \"xxxxxxxxxxxxxxxxxxxx\",\n\"authorizer\": {\n\"iam\": {\n\"accessKey\": \"AAAAAAAAAAAAAAAAAA\",\n\"accountId\": \"123457890\",\n\"callerId\": \"AAAAAAAAAAAAAAAAAA\",\n\"cognitoIdentity\": null,\n\"principalOrgId\": \"o-xxxxxxxxxxxx\",\n\"userArn\": \"arn:aws:iam::AAAAAAAAAAAAAAAAAA:user/user\",\n\"userId\": \"AAAAAAAAAAAAAAAAAA\"\n}\n},\n\"domainName\": \"xxxxxxxxxxxxx.lambda-url.eu-central-1.on.aws\",\n\"domainPrefix\": \"xxxxxxxxxxxxx\",\n\"http\": {\n\"method\": \"GET\",\n\"path\": \"/todos\",\n\"protocol\": \"HTTP/1.1\",\n\"sourceIp\": \"123.123.123.123\",\n\"userAgent\": \"Custom User Agent\"\n},\n\"requestId\": \"24f9ef37-8eb7-45fe-9dbc-a504169fd2f8\",\n\"routeKey\": \"$default\",\n\"stage\": \"$default\",\n\"time\": \"03/Aug/2022:09:29:18 +0000\",\n\"timeEpoch\": 1659518958068\n},\n\"isBase64Encoded\": false\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#vpc-lattice","title":"VPC Lattice","text":"<p>When using VPC Lattice with AWS Lambda, you can use <code>VPCLatticeResolver</code>.</p> getting_started_vpclattice_resolver.pygetting_started_vpclattice_resolver.json Using VPC Lattice resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import VPCLatticeResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = VPCLatticeResolver()\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPLICATION_LOAD_BALANCER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Example payload delivered to the handler<pre><code>{\n\"raw_path\": \"/testpath\",\n\"method\": \"GET\",\n\"headers\": {\n\"user_agent\": \"curl/7.64.1\",\n\"x-forwarded-for\": \"10.213.229.10\",\n\"host\": \"test-lambda-service-3908sdf9u3u.dkfjd93.vpc-lattice-svcs.us-east-2.on.aws\",\n\"accept\": \"*/*\"\n},\n\"query_string_parameters\": {\n\"order-id\": \"1\"\n},\n\"body\": \"eyJ0ZXN0IjogImV2ZW50In0=\",\n\"is_base64_encoded\": true\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#dynamic-routes","title":"Dynamic routes","text":"<p>You can use <code>/todos/&lt;todo_id&gt;</code> to configure dynamic URL paths, where <code>&lt;todo_id&gt;</code> will be resolved at runtime.</p> <p>Each dynamic route you set must be part of your function signature. This allows us to call your function using keyword arguments when matching your dynamic route.</p> Note <p>For brevity, we will only include the necessary keys for each sample request for the example to work.</p> dynamic_routes.pydynamic_routes.json <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\ntodos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"resource\": \"/todos/{id}\",\n\"path\": \"/todos/1\",\n\"httpMethod\": \"GET\"\n}\n</code></pre> Tip <p>You can also nest dynamic paths, for example <code>/todos/&lt;todo_id&gt;/&lt;todo_status&gt;</code>.</p>"},{"location":"core/event_handler/api_gateway/#catch-all-routes","title":"Catch-all routes","text":"Note <p>We recommend having explicit routes whenever possible; use catch-all routes sparingly.</p> <p>You can use a regex string to handle an arbitrary number of paths within a request, for example <code>.+</code>.</p> <p>You can also combine nested paths with greedy regex to catch in between routes.</p> Warning <p>We choose the most explicit registered route that matches an incoming event.</p> dynamic_routes_catch_all.pydynamic_routes_catch_all.json <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\".+\")\n@tracer.capture_method\ndef catch_any_route_get_method():\n    return {\"path_received\": app.current_event.path}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"resource\": \"/{proxy+}\",\n\"path\": \"/any/route/should/work\",\n\"httpMethod\": \"GET\"\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#http-methods","title":"HTTP Methods","text":"<p>You can use named decorators to specify the HTTP method that should be handled in your functions. That is, <code>app.&lt;http_method&gt;</code>, where the HTTP method could be <code>get</code>, <code>post</code>, <code>put</code>, <code>patch</code> and <code>delete</code>.</p> http_methods.pyhttp_methods.json <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.post(\"/todos\")\n@tracer.capture_method\ndef create_todo():\ntodo_data: dict = app.current_event.json_body  # deserialize json str to dict\ntodo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=todo_data)\n    todo.raise_for_status()\n\n    return {\"todo\": todo.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"resource\": \"/todos\",\n\"path\": \"/todos\",\n\"httpMethod\": \"POST\",\n\"body\": \"{\\\"title\\\": \\\"foo\\\", \\\"userId\\\": 1, \\\"completed\\\": false}\"\n}\n</code></pre> <p>If you need to accept multiple HTTP methods in a single function, you can use the <code>route</code> method and pass a list of HTTP methods.</p> Handling multiple HTTP Methods<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n# PUT and POST HTTP requests to the path /hello will route to this function\n@app.route(\"/todos\", method=[\"PUT\", \"POST\"])\n@tracer.capture_method\ndef create_todo():\n    todo_data: dict = app.current_event.json_body  # deserialize json str to dict\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=todo_data)\n    todo.raise_for_status()\n\n    return {\"todo\": todo.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Note <p>It is generally better to have separate functions for each HTTP method, as the functionality tends to differ depending on which method is used.</p>"},{"location":"core/event_handler/api_gateway/#accessing-request-details","title":"Accessing request details","text":"<p>Event Handler integrates with Event Source Data Classes utilities, and it exposes their respective resolver request details and convenient methods under <code>app.current_event</code>.</p> <p>That is why you see <code>app.resolve(event, context)</code> in every example. This allows Event Handler to resolve requests, and expose data like <code>app.lambda_context</code> and  <code>app.current_event</code>.</p>"},{"location":"core/event_handler/api_gateway/#query-strings-and-payload","title":"Query strings and payload","text":"<p>Within <code>app.current_event</code> property, you can access all available query strings as a dictionary via <code>query_string_parameters</code>, or a specific one via  <code>get_query_string_value</code> method.</p> <p>You can access the raw payload via <code>body</code> property, or if it's a JSON string you can quickly deserialize it via <code>json_body</code> property - like the earlier example in the HTTP Methods section.</p> Accessing query strings and raw payload<pre><code>from typing import Optional\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\ntodo_id: str = app.current_event.get_query_string_value(name=\"id\", default_value=\"\")\n# alternatively\n    _: Optional[str] = app.current_event.query_string_parameters.get(\"id\")\n\n    # Payload\n_: Optional[str] = app.current_event.body  # raw str | None\nendpoint = \"https://jsonplaceholder.typicode.com/todos\"\n    if todo_id:\n        endpoint = f\"{endpoint}/{todo_id}\"\n\n    todos: Response = requests.get(endpoint)\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#headers","title":"Headers","text":"<p>Similarly to Query strings, you can access headers as dictionary via <code>app.current_event.headers</code>, or by name via <code>get_header_value</code>.</p> Accessing HTTP Headers<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    endpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\napi_key: str = app.current_event.get_header_value(name=\"X-Api-Key\", case_sensitive=True, default_value=\"\")\ntodos: Response = requests.get(endpoint, headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#handling-not-found-routes","title":"Handling not found routes","text":"<p>By default, we return <code>404</code> for any unmatched route.</p> <p>You can use <code>not_found</code> decorator to override this behavior, and return a custom <code>Response</code>.</p> Handling not found<pre><code>import requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n    Response,\n    content_types,\n)\nfrom aws_lambda_powertools.event_handler.exceptions import NotFoundError\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.not_found\n@tracer.capture_method\ndef handle_not_found_errors(exc: NotFoundError) -&gt; Response:\n    logger.info(f\"Not found route: {app.current_event.path}\")\nreturn Response(status_code=418, content_type=content_types.TEXT_PLAIN, body=\"I'm a teapot!\")\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#exception-handling","title":"Exception handling","text":"<p>You can use <code>exception_handler</code> decorator with any Python exception. This allows you to handle a common exception outside your route, for example validation errors.</p> Exception handling<pre><code>import requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n    Response,\n    content_types,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.exception_handler(ValueError)\ndef handle_invalid_limit_qs(ex: ValueError):  # receives exception raised\nmetadata = {\"path\": app.current_event.path, \"query_strings\": app.current_event.query_string_parameters}\n    logger.error(f\"Malformed request: {ex}\", extra=metadata)\n\n    return Response(\n        status_code=400,\n        content_type=content_types.TEXT_PLAIN,\n        body=\"Invalid request parameters.\",\n    )\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    # educational purpose only: we should receive a `ValueError`\n    # if a query string value for `limit` cannot be coerced to int\n    max_results: int = int(app.current_event.get_query_string_value(name=\"limit\", default_value=0))\n\n    todos: requests.Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos?limit={max_results}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Info <p>The <code>exception_handler</code> also supports passing a list of exception types you wish to handle with one handler.</p>"},{"location":"core/event_handler/api_gateway/#raising-http-errors","title":"Raising HTTP errors","text":"<p>You can easily raise any HTTP Error back to the client using <code>ServiceError</code> exception. This ensures your Lambda function doesn't fail but return the correct HTTP response signalling the error.</p> Info <p>If you need to send custom headers, use Response class instead.</p> <p>We provide pre-defined errors for the most popular ones such as HTTP 400, 401, 404, 500.</p> Raising common HTTP Status errors (4xx, 5xx)<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.exceptions import (\nBadRequestError,\nInternalServerError,\nNotFoundError,\nServiceError,\nUnauthorizedError,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(rule=\"/bad-request-error\")\ndef bad_request_error():\nraise BadRequestError(\"Missing required parameter\")  # HTTP  400\n@app.get(rule=\"/unauthorized-error\")\ndef unauthorized_error():\nraise UnauthorizedError(\"Unauthorized\")  # HTTP 401\n@app.get(rule=\"/not-found-error\")\ndef not_found_error():\nraise NotFoundError  # HTTP 404\n@app.get(rule=\"/internal-server-error\")\ndef internal_server_error():\nraise InternalServerError(\"Internal server error\")  # HTTP 500\n@app.get(rule=\"/service-error\", cors=True)\ndef service_error():\nraise ServiceError(502, \"Something went wrong!\")\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#custom-domain-api-mappings","title":"Custom Domain API Mappings","text":"<p>When using Custom Domain API Mappings feature, you must use <code>strip_prefixes</code> param in the <code>APIGatewayRestResolver</code> constructor.</p> <p>Scenario: You have a custom domain <code>api.mydomain.dev</code>. Then you set <code>/payment</code> API Mapping to forward any payment requests to your Payments API.</p> <p>Challenge: This means your <code>path</code> value for any API requests will always contain <code>/payment/&lt;actual_request&gt;</code>, leading to HTTP 404 as Event Handler is trying to match what's after <code>payment/</code>. This gets further complicated with an arbitrary level of nesting.</p> <p>To address this API Gateway behavior, we use <code>strip_prefixes</code> parameter to account for these prefixes that are now injected into the path regardless of which type of API Gateway you're using.</p> custom_api_mapping.pycustom_api_mapping.json <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(strip_prefixes=[\"/payment\"])\n@app.get(\"/subscriptions/&lt;subscription&gt;\")\n@tracer.capture_method\ndef get_subscription(subscription):\n    return {\"subscription_id\": subscription}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"resource\": \"/subscriptions/{subscription}\",\n\"path\": \"/payment/subscriptions/123\",\n\"httpMethod\": \"GET\"\n}\n</code></pre> Note <p>After removing a path prefix with <code>strip_prefixes</code>, the new root path will automatically be mapped to the path argument of <code>/</code>.</p> <p>For example, when using <code>strip_prefixes</code> value of <code>/pay</code>, there is no difference between a request path of <code>/pay</code> and <code>/pay/</code>; and the path argument would be defined as <code>/</code>.</p>"},{"location":"core/event_handler/api_gateway/#advanced","title":"Advanced","text":""},{"location":"core/event_handler/api_gateway/#cors","title":"CORS","text":"<p>You can configure CORS at the <code>APIGatewayRestResolver</code> constructor via <code>cors</code> parameter using the <code>CORSConfig</code> class.</p> <p>This will ensure that CORS headers are returned as part of the response when your functions match the path invoked and the <code>Origin</code> matches one of the allowed values.</p> Tip <p>Optionally disable CORS on a per path basis with <code>cors=False</code> parameter.</p> setting_cors.pysetting_cors_output.jsonsetting_cors_extra_origins.pysetting_cors_extra_origins_output.json <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, CORSConfig\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n# CORS will match when Origin is only https://www.example.com\ncors_config = CORSConfig(allow_origin=\"https://www.example.com\", max_age=300)\napp = APIGatewayRestResolver(cors=cors_config)\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n@app.get(\"/healthcheck\", cors=False)  # optionally removes CORS for a given route\n@tracer.capture_method\ndef am_i_alive():\n    return {\"am_i_alive\": \"yes\"}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"statusCode\": 200,\n\"multiValueHeaders\": {\n\"Content-Type\": [\"application/json\"],\n\"Access-Control-Allow-Origin\": [\"https://www.example.com\"],\n\"Access-Control-Allow-Headers\": [\"Authorization,Content-Type,X-Amz-Date,X-Amz-Security-Token,X-Api-Key\"]\n},\n\"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n\"isBase64Encoded\": false\n}\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, CORSConfig\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n# CORS will match when Origin is https://www.example.com OR https://dev.example.com\ncors_config = CORSConfig(allow_origin=\"https://www.example.com\", extra_origins=[\"https://dev.example.com\"], max_age=300)\napp = APIGatewayRestResolver(cors=cors_config)\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n@app.get(\"/healthcheck\", cors=False)  # optionally removes CORS for a given route\n@tracer.capture_method\ndef am_i_alive():\n    return {\"am_i_alive\": \"yes\"}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"statusCode\": 200,\n\"multiValueHeaders\": {\n\"Content-Type\": [\"application/json\"],\n\"Access-Control-Allow-Origin\": [\"https://www.example.com\",\"https://dev.example.com\"],\n\"Access-Control-Allow-Headers\": [\"Authorization,Content-Type,X-Amz-Date,X-Amz-Security-Token,X-Api-Key\"]\n},\n\"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n\"isBase64Encoded\": false\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#pre-flight","title":"Pre-flight","text":"<p>Pre-flight (OPTIONS) calls are typically handled at the API Gateway or Lambda Function URL level as per our sample infrastructure, no Lambda integration is necessary. However, ALB expects you to handle pre-flight requests.</p> <p>For convenience, we automatically handle that for you as long as you setup CORS in the constructor level.</p>"},{"location":"core/event_handler/api_gateway/#defaults","title":"Defaults","text":"<p>For convenience, these are the default values when using <code>CORSConfig</code> to enable CORS:</p> Warning <p>Always configure <code>allow_origin</code> when using in production.</p> Multiple origins? <p>If you need to allow multiple origins, pass the additional origins using the <code>extra_origins</code> key.</p> Key Value Note allow_origin: <code>str</code> <code>*</code> Only use the default value for development. Never use <code>*</code> for production unless your use case requires it extra_origins: <code>List[str]</code> <code>[]</code> Additional origins to be allowed, in addition to the one specified in <code>allow_origin</code> allow_headers: <code>List[str]</code> <code>[Authorization, Content-Type, X-Amz-Date, X-Api-Key, X-Amz-Security-Token]</code> Additional headers will be appended to the default list for your convenience expose_headers: <code>List[str]</code> <code>[]</code> Any additional header beyond the safe listed by CORS specification. max_age: <code>int</code> `` Only for pre-flight requests if you choose to have your function to handle it instead of API Gateway allow_credentials: <code>bool</code> <code>False</code> Only necessary when you need to expose cookies, authorization headers or TLS client certificates."},{"location":"core/event_handler/api_gateway/#fine-grained-responses","title":"Fine grained responses","text":"<p>You can use the <code>Response</code> class to have full control over the response. For example, you might want to add additional headers, cookies, or set a custom Content-type.</p> Info <p>Powertools for AWS Lambda (Python) serializes headers and cookies according to the type of input event. Some event sources require headers and cookies to be encoded as <code>multiValueHeaders</code>.</p> Using multiple values for HTTP headers in ALB? <p>Make sure you enable the multi value headers feature to serialize response headers correctly.</p> fine_grained_responses.pyfine_grained_responses_output.json <pre><code>from http import HTTPStatus\nfrom uuid import uuid4\n\nimport requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\nResponse,\ncontent_types,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.shared.cookies import Cookie\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    custom_headers = {\"X-Transaction-Id\": [f\"{uuid4()}\"]}\n\nreturn Response(\nstatus_code=HTTPStatus.OK.value,  # 200\ncontent_type=content_types.APPLICATION_JSON,\nbody=todos.json()[:10],\nheaders=custom_headers,\ncookies=[Cookie(name=\"session_id\", value=\"12345\")],\n)\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"statusCode\": 200,\n\"multiValueHeaders\": {\n\"Content-Type\": [\"application/json\"],\n\"X-Transaction-Id\": [\"3490eea9-791b-47a0-91a4-326317db61a9\"],\n\"Set-Cookie\": [\"session_id=12345; Secure\"]\n},\n\"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n\"isBase64Encoded\": false\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#compress","title":"Compress","text":"<p>You can compress with gzip and base64 encode your responses via <code>compress</code> parameter. You have the option to pass the <code>compress</code> parameter when working with a specific route or using the Response object.</p> Info <p>The <code>compress</code> parameter used in the Response object takes precedence over the one used in the route.</p> Warning <p>The client must send the <code>Accept-Encoding</code> header, otherwise a normal response will be sent.</p> compressing_responses_using_route.pycompressing_responses_using_response.pycompressing_responses.jsoncompressing_responses_output.json <pre><code> import requests\n\n from aws_lambda_powertools import Logger, Tracer\n from aws_lambda_powertools.event_handler import (\n     APIGatewayRestResolver,\n     Response,\n     content_types,\n )\n from aws_lambda_powertools.logging import correlation_paths\n from aws_lambda_powertools.utilities.typing import LambdaContext\n\n tracer = Tracer()\n logger = Logger()\n app = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\", compress=True)\n@tracer.capture_method\n def get_todos():\n     todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n     todos.raise_for_status()\n\n     # for brevity, we'll limit to the first 10 only\n     return {\"todos\": todos.json()[:10]}\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\", compress=True)\n@tracer.capture_method\n def get_todo_by_id(todo_id: str):  # same example using Response class\n     todos: requests.Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n     todos.raise_for_status()\n\n     return Response(status_code=200, content_type=content_types.APPLICATION_JSON, body=todos.json())\n\n\n # You can continue to use other utilities just as before\n @logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n @tracer.capture_lambda_handler\n def lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n     return app.resolve(event, context)\n</code></pre> <pre><code> import requests\n\n from aws_lambda_powertools import Logger, Tracer\n from aws_lambda_powertools.event_handler import (\n     APIGatewayRestResolver,\n     Response,\n     content_types,\n )\n from aws_lambda_powertools.logging import correlation_paths\n from aws_lambda_powertools.utilities.typing import LambdaContext\n\n tracer = Tracer()\n logger = Logger()\n app = APIGatewayRestResolver()\n\n\n @app.get(\"/todos\")\n @tracer.capture_method\n def get_todos():\n     todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n     todos.raise_for_status()\n\n     # for brevity, we'll limit to the first 10 only\nreturn Response(status_code=200, content_type=content_types.APPLICATION_JSON, body=todos.json()[:10], compress=True)\n# You can continue to use other utilities just as before\n @logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n @tracer.capture_lambda_handler\n def lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n     return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"headers\": {\n\"Accept-Encoding\": \"gzip\"\n},\n\"resource\": \"/todos\",\n\"path\": \"/todos\",\n\"httpMethod\": \"GET\"\n}\n</code></pre> <pre><code>{\n\"statusCode\": 200,\n\"multiValueHeaders\": {\n\"Content-Type\": [\"application/json\"],\n\"Content-Encoding\": [\"gzip\"]\n},\n\"body\": \"H4sIAAAAAAACE42STU4DMQyFrxJl3QXln96AMyAW7sSDLCVxiJ0Kqerd8TCCUOgii1EmP/783pOPXjmw+N3L0TfB+hz8brvxtC5KGtHvfMCIkzZx0HT5MPmNnziViIr2dIYoeNr8Q1x3xHsjcVadIbkZJoq2RXU8zzQROLseQ9505NzeCNQdMJNBE+UmY4zbzjAJhWtlZ57sB84BWtul+rteH2HPlVgWARwjqXkxpklK5gmEHAQqJBMtFsGVygcKmNVRjG0wxvuzGF2L0dpVUOKMC3bfJNjJgWMrCuZk7cUp02AiD72D6WKHHwUDKbiJs6AZ0VZXKOUx4uNvzdxT+E4mLcMA+6G8nzrLQkaxkNEVrFKW2VGbJCoCY7q2V3+tiv5kGThyxfTecDWbgGz/NfYXhL6ePgF9PnFdPgMAAA==\",\n\"isBase64Encoded\": true\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#binary-responses","title":"Binary responses","text":"<p>For convenience, we automatically base64 encode binary responses. You can also use in combination with <code>compress</code> parameter if your client supports gzip.</p> <p>Like <code>compress</code> feature, the client must send the <code>Accept</code> header with the correct media type.</p> Warning <p>This feature requires API Gateway to configure binary media types, see our sample infrastructure for reference.</p> Note <p>Lambda Function URLs handle binary media types automatically.</p> binary_responses.pybinary_responses_logo.svgbinary_responses.jsonbinary_responses_output.json <pre><code>import os\nfrom pathlib import Path\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import (\n    APIGatewayRestResolver,\n    Response,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n\n\napp = APIGatewayRestResolver()\nlogo_file: bytes = Path(f\"{os.getenv('LAMBDA_TASK_ROOT')}/logo.svg\").read_bytes()\n@app.get(\"/logo\")\n@tracer.capture_method\ndef get_logo():\nreturn Response(status_code=200, content_type=\"image/svg+xml\", body=logo_file)\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;svg width=\"256px\" height=\"256px\" viewBox=\"0 0 256 256\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" preserveAspectRatio=\"xMidYMid\"&gt;\n&lt;title&gt;AWS Lambda&lt;/title&gt;\n&lt;defs&gt;\n&lt;linearGradient x1=\"0%\" y1=\"100%\" x2=\"100%\" y2=\"0%\" id=\"linearGradient-1\"&gt;\n&lt;stop stop-color=\"#C8511B\" offset=\"0%\"&gt;&lt;/stop&gt;\n&lt;stop stop-color=\"#FF9900\" offset=\"100%\"&gt;&lt;/stop&gt;\n&lt;/linearGradient&gt;\n&lt;/defs&gt;\n&lt;g&gt;\n&lt;rect fill=\"url(#linearGradient-1)\" x=\"0\" y=\"0\" width=\"256\" height=\"256\"&gt;&lt;/rect&gt;\n&lt;path d=\"M89.6241126,211.2 L49.8903277,211.2 L93.8354832,119.3472 L113.74728,160.3392 L89.6241126,211.2 Z M96.7029357,110.5696 C96.1640858,109.4656 95.0414813,108.7648 93.8162384,108.7648 L93.8066163,108.7648 C92.5717514,108.768 91.4491466,109.4752 90.9199187,110.5856 L41.9134208,213.0208 C41.4387197,214.0128 41.5060758,215.1776 42.0962451,216.1088 C42.6799994,217.0368 43.7063805,217.6 44.8065331,217.6 L91.654423,217.6 C92.8957027,217.6 94.0215149,216.8864 94.5539501,215.7696 L120.203859,161.6896 C120.617619,160.8128 120.614412,159.7984 120.187822,158.928 L96.7029357,110.5696 Z M207.985117,211.2 L168.507928,211.2 L105.173789,78.624 C104.644561,77.5104 103.515541,76.8 102.277469,76.8 L76.447943,76.8 L76.4768099,44.8 L127.103066,44.8 L190.145328,177.3728 C190.674556,178.4864 191.803575,179.2 193.041647,179.2 L207.985117,179.2 L207.985117,211.2 Z M211.192558,172.8 L195.071958,172.8 L132.029696,40.2272 C131.500468,39.1136 130.371449,38.4 129.130169,38.4 L73.272576,38.4 C71.5052758,38.4 70.0683421,39.8304 70.0651344,41.5968 L70.0298528,79.9968 C70.0298528,80.848 70.3634266,81.6608 70.969633,82.2624 C71.5694246,82.864 72.3841146,83.2 73.2372941,83.2 L100.253573,83.2 L163.59092,215.776 C164.123355,216.8896 165.24596,217.6 166.484032,217.6 L211.192558,217.6 C212.966274,217.6 214.4,216.1664 214.4,214.4 L214.4,176 C214.4,174.2336 212.966274,172.8 211.192558,172.8 L211.192558,172.8 Z\" fill=\"#FFFFFF\"&gt;&lt;/path&gt;\n&lt;/g&gt;\n&lt;/svg&gt;\n</code></pre> <pre><code>{\n\"headers\": {\n\"Accept\": \"image/svg+xml\"\n},\n\"resource\": \"/logo\",\n\"path\": \"/logo\",\n\"httpMethod\": \"GET\"\n}\n</code></pre> <pre><code>{\n\"body\": \"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\",\n\"multiValueHeaders\": {\n\"Content-Type\": [\"image/svg+xml\"]\n},\n\"isBase64Encoded\": true,\n\"statusCode\": 200\n}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#debug-mode","title":"Debug mode","text":"<p>You can enable debug mode via <code>debug</code> param, or via <code>POWERTOOLS_DEV</code> environment variable.</p> <p>This will enable full tracebacks errors in the response, print request and responses, and set CORS in development mode.</p> Danger <p>This might reveal sensitive information in your logs and relax CORS restrictions, use it sparingly.</p> <p>It's best to use for local development only!</p> Enabling debug mode<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(debug=True)\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#custom-serializer","title":"Custom serializer","text":"<p>You can instruct event handler to use a custom serializer to best suit your needs, for example take into account Enums when serializing.</p> Using a custom JSON serializer for responses<pre><code>import json\nfrom dataclasses import asdict, dataclass, is_dataclass\nfrom json import JSONEncoder\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@dataclass\nclass Todo:\n    userId: str\n    id: str  # noqa: A003 VNE003 \"id\" field is reserved\n    title: str\n    completed: bool\n\n\nclass DataclassCustomEncoder(JSONEncoder):\n\"\"\"A custom JSON encoder to serialize dataclass obj\"\"\"\n\n    def default(self, obj):\n        # Only called for values that aren't JSON serializable\n        # where `obj` will be an instance of Todo in this example\n        return asdict(obj) if is_dataclass(obj) else super().default(obj)\n\n\ndef custom_serializer(obj) -&gt; str:\n\"\"\"Your custom serializer function APIGatewayRestResolver will use\"\"\"\n    return json.dumps(obj, separators=(\",\", \":\"), cls=DataclassCustomEncoder)\n\n\napp = APIGatewayRestResolver(serializer=custom_serializer)\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    ret: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    ret.raise_for_status()\n    todos = [Todo(**todo) for todo in ret.json()]\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#split-routes-with-router","title":"Split routes with Router","text":"<p>As you grow the number of routes a given Lambda function should handle, it is natural to split routes into separate files to ease maintenance - That's where the <code>Router</code> feature is useful.</p> <p>Let's assume you have <code>split_route.py</code> as your Lambda function entrypoint and routes in <code>split_route_module.py</code>. This is how you'd use the <code>Router</code> feature.</p> split_route_module.pysplit_route.py <p>We import Router instead of APIGatewayRestResolver; syntax wise is exactly the same.</p> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import Router\ntracer = Tracer()\nrouter = Router()\n\nendpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n\n@router.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\napi_key: str = router.current_event.get_header_value(name=\"X-Api-Key\", case_sensitive=True, default_value=\"\")\ntodos: Response = requests.get(endpoint, headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@router.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\napi_key: str = router.current_event.get_header_value(name=\"X-Api-Key\", case_sensitive=True, default_value=\"\")  # type: ignore[assignment] # sentinel typing # noqa: E501\ntodos: Response = requests.get(f\"{endpoint}/{todo_id}\", headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n</code></pre> <p>We use <code>include_router</code> method and include all user routers registered in the <code>router</code> global object.</p> <pre><code>import split_route_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\napp.include_router(split_route_module.router)\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#route-prefix","title":"Route prefix","text":"<p>In the previous example, <code>split_route_module.py</code> routes had a <code>/todos</code> prefix. This might grow over time and become repetitive.</p> <p>When necessary, you can set a prefix when including a router object. This means you could remove <code>/todos</code> prefix altogether.</p> split_route_prefix.pysplit_route_prefix_module.py <pre><code>import split_route_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n# prefix '/todos' to any route in `split_route_module.router`\napp.include_router(split_route_module.router, prefix=\"/todos\")\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import Router\n\ntracer = Tracer()\nrouter = Router()\n\nendpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n\n@router.get(\"/\")\n@tracer.capture_method\ndef get_todos():\n    api_key: str = router.current_event.get_header_value(name=\"X-Api-Key\", case_sensitive=True, default_value=\"\")\n\n    todos: Response = requests.get(endpoint, headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@router.get(\"/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    api_key: str = router.current_event.get_header_value(name=\"X-Api-Key\", case_sensitive=True, default_value=\"\")  # type: ignore[assignment] # sentinel typing # noqa: E501\n\n    todos: Response = requests.get(f\"{endpoint}/{todo_id}\", headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# many more routes\n</code></pre>"},{"location":"core/event_handler/api_gateway/#specialized-router-types","title":"Specialized router types","text":"<p>You can use specialized router classes according to the type of event that you are resolving. This way you'll get type hints from your IDE as you access the <code>current_event</code> property.</p> Router Resolver <code>current_event</code> type APIGatewayRouter APIGatewayRestResolver APIGatewayProxyEvent APIGatewayHttpRouter APIGatewayHttpResolver APIGatewayProxyEventV2 ALBRouter ALBResolver ALBEvent LambdaFunctionUrlRouter LambdaFunctionUrlResolver LambdaFunctionUrlEvent <pre><code>from aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.router import APIGatewayRouter\n\napp = APIGatewayRestResolver()\nrouter = APIGatewayRouter()\n@router.get(\"/me\")\ndef get_self():\n# router.current_event is a APIGatewayProxyEvent\n    account_id = router.current_event.request_context.account_id\n\n    return {\"account_id\": account_id}\n\n\napp.include_router(router)\n\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#sharing-contextual-data","title":"Sharing contextual data","text":"<p>You can use <code>append_context</code> when you want to share data between your App and Router instances. Any data you share will be available via the <code>context</code> dictionary available in your App or Router context.</p> Info <p>For safety, we always clear any data available in the <code>context</code> dictionary after each invocation.</p> Tip <p>This can also be useful for middlewares injecting contextual information before a request is processed.</p> split_route_append_context.pysplit_route_append_context_module.py <pre><code>import split_route_append_context_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\napp.include_router(split_route_append_context_module.router)\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\napp.append_context(is_admin=True)  # arbitrary number of key=value data\nreturn app.resolve(event, context)\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import Router\n\ntracer = Tracer()\nrouter = Router()\n\nendpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n\n@router.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\nis_admin: bool = router.context.get(\"is_admin\", False)\ntodos = {}\n\n    if is_admin:\n        todos: Response = requests.get(endpoint)\n        todos.raise_for_status()\n        todos = todos.json()[:10]\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos}\n</code></pre>"},{"location":"core/event_handler/api_gateway/#sample-layout","title":"Sample layout","text":"<p>This is a sample project layout for a monolithic function with routes split in different files (<code>/todos</code>, <code>/health</code>).</p> Sample project layout<pre><code>.\n\u251c\u2500\u2500 pyproject.toml            # project app &amp; dev dependencies; poetry, pipenv, etc.\n\u251c\u2500\u2500 poetry.lock\n\u251c\u2500\u2500 src\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u251c\u2500\u2500 requirements.txt  # sam build detect it automatically due to CodeUri: src. poetry export --format src/requirements.txt\n\u2502       \u2514\u2500\u2500 todos\n\u2502           \u251c\u2500\u2500 __init__.py\n\u2502           \u251c\u2500\u2500 main.py       # this will be our todos Lambda fn; it could be split in folders if we want separate fns same code base\n\u2502           \u2514\u2500\u2500 routers       # routers module\n\u2502               \u251c\u2500\u2500 __init__.py\n\u2502               \u251c\u2500\u2500 health.py # /health routes. from routers import todos; health.router\n\u2502               \u2514\u2500\u2500 todos.py  # /todos routes. from .routers import todos; todos.router\n\u251c\u2500\u2500 template.yml              # SAM. CodeUri: src, Handler: todos.main.lambda_handler\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 unit\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u2514\u2500\u2500 test_todos.py     # unit tests for the todos router\n\u2502   \u2514\u2500\u2500 test_health.py    # unit tests for the health router\n\u2514\u2500\u2500 functional\n        \u251c\u2500\u2500 __init__.py\n        \u251c\u2500\u2500 conftest.py       # pytest fixtures for the functional tests\n\u2514\u2500\u2500 test_main.py      # functional tests for the main lambda handler\n</code></pre>"},{"location":"core/event_handler/api_gateway/#considerations","title":"Considerations","text":"<p>This utility is optimized for fast startup, minimal feature set, and to quickly on-board customers familiar with frameworks like Flask \u2014 it's not meant to be a fully fledged framework.</p> <p>Event Handler naturally leads to a single Lambda function handling multiple routes for a given service, which can be eventually broken into multiple functions.</p> <p>Both single (monolithic) and multiple functions (micro) offer different set of trade-offs worth knowing.</p> Tip <p>TL;DR. Start with a monolithic function, add additional functions with new handlers, and possibly break into micro functions if necessary.</p>"},{"location":"core/event_handler/api_gateway/#monolithic-function","title":"Monolithic function","text":"<p>A monolithic function means that your final code artifact will be deployed to a single function. This is generally the best approach to start.</p> <p>Benefits</p> <ul> <li>Code reuse. It's easier to reason about your service, modularize it and reuse code as it grows. Eventually, it can be turned into a standalone library.</li> <li>No custom tooling. Monolithic functions are treated just like normal Python packages; no upfront investment in tooling.</li> <li>Faster deployment and debugging. Whether you use all-at-once, linear, or canary deployments, a monolithic function is a single deployable unit. IDEs like PyCharm and VSCode have tooling to quickly profile, visualize, and step through debug any Python package.</li> </ul> <p>Downsides</p> <ul> <li>Cold starts. Frequent deployments and/or high load can diminish the benefit of monolithic functions depending on your latency requirements, due to Lambda scaling model. Always load test to pragmatically balance between your customer experience and development cognitive load.</li> <li>Granular security permissions. The micro function approach enables you to use fine-grained permissions &amp; access controls, separate external dependencies &amp; code signing at the function level. Conversely, you could have multiple functions while duplicating the final code artifact in a monolithic approach.<ul> <li>Regardless, least privilege can be applied to either approaches.</li> </ul> </li> <li>Higher risk per deployment. A misconfiguration or invalid import can cause disruption if not caught earlier in automated testing. Multiple functions can mitigate misconfigurations but they would still share the same code artifact. You can further minimize risks with multiple environments in your CI/CD pipeline.</li> </ul>"},{"location":"core/event_handler/api_gateway/#micro-function","title":"Micro function","text":"<p>A micro function means that your final code artifact will be different to each function deployed. This is generally the approach to start if you're looking for fine-grain control and/or high load on certain parts of your service.</p> <p>Benefits</p> <ul> <li>Granular scaling. A micro function can benefit from the Lambda scaling model to scale differently depending on each part of your application. Concurrency controls and provisioned concurrency can also be used at a granular level for capacity management.</li> <li>Discoverability. Micro functions are easier do visualize when using distributed tracing. Their high-level architectures can be self-explanatory, and complexity is highly visible \u2014 assuming each function is named to the business purpose it serves.</li> <li>Package size. An independent function can be significant smaller (KB vs MB) depending on external dependencies it require to perform its purpose. Conversely, a monolithic approach can benefit from Lambda Layers to optimize builds for external dependencies.</li> </ul> <p>Downsides</p> <ul> <li>Upfront investment. You need custom build tooling to bundle assets, including C bindings for runtime compatibility. Operations become more elaborate \u2014 you need to standardize tracing labels/annotations, structured logging, and metrics to pinpoint root causes.<ul> <li>Engineering discipline is necessary for both approaches. Micro-function approach however requires further attention in consistency as the number of functions grow, just like any distributed system.</li> </ul> </li> <li>Harder to share code. Shared code must be carefully evaluated to avoid unnecessary deployments when that changes. Equally, if shared code isn't a library, your development, building, deployment tooling need to accommodate the distinct layout.</li> <li>Slower safe deployments. Safely deploying multiple functions require coordination \u2014 AWS CodeDeploy deploys and verifies each function sequentially. This increases lead time substantially (minutes to hours) depending on the deployment strategy you choose. You can mitigate it by selectively enabling it in prod-like environments only, and where the risk profile is applicable.<ul> <li>Automated testing, operational and security reviews are essential to stability in either approaches.</li> </ul> </li> </ul>"},{"location":"core/event_handler/api_gateway/#testing-your-code","title":"Testing your code","text":"<p>You can test your routes by passing a proxy event request with required params.</p> API Gateway REST APIAPI Gateway HTTP APIApplication Load BalancerLambda Function URL assert_rest_api_resolver_response.pyassert_rest_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_rest_api_resolver_response\nimport pytest\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n        aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context):\n    minimal_event = {\n\"path\": \"/todos\",\n\"httpMethod\": \"GET\",\n\"requestContext\": {\"requestId\": \"227b78aa-779d-47d4-a48e-ce62120393b8\"},  # correlation ID\n}\n# Example of API Gateway REST API request event:\n    # https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html#apigateway-example-event\n    ret = assert_rest_api_resolver_response.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> assert_http_api_resolver_response.pyassert_http_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_http_api_response_module\nimport pytest\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n        aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context):\n    minimal_event = {\n\"rawPath\": \"/todos\",\n\"requestContext\": {\n\"requestContext\": {\"requestId\": \"227b78aa-779d-47d4-a48e-ce62120393b8\"},  # correlation ID\n\"http\": {\n\"method\": \"GET\",\n},\n\"stage\": \"$default\",\n},\n}\n# Example of API Gateway HTTP API request event:\n    # https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integrations-lambda.html\n\n    ret = assert_http_api_response_module.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayHttpResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayHttpResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> assert_alb_api_resolver_response.pyassert_alb_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_alb_api_response_module\nimport pytest\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n        aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context):\n    minimal_event = {\n\"path\": \"/todos\",\n\"httpMethod\": \"GET\",\n\"headers\": {\"x-amzn-trace-id\": \"b25827e5-0e30-4d52-85a8-4df449ee4c5a\"},\n}\n# Example of Application Load Balancer request event:\n    # https://docs.aws.amazon.com/lambda/latest/dg/services-alb.html\n\n    ret = assert_alb_api_response_module.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import ALBResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = ALBResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPLICATION_LOAD_BALANCER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> assert_function_url_api_resolver_response.pyassert_function_url_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_function_url_api_response_module\nimport pytest\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n        aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context):\n    minimal_event = {\n\"rawPath\": \"/todos\",\n\"requestContext\": {\n\"requestContext\": {\"requestId\": \"227b78aa-779d-47d4-a48e-ce62120393b8\"},  # correlation ID\n\"http\": {\n\"method\": \"GET\",\n},\n\"stage\": \"$default\",\n},\n}\n# Example of Lambda Function URL request event:\n    # https://docs.aws.amazon.com/lambda/latest/dg/urls-invocation.html#urls-payloads\n\n    ret = assert_function_url_api_response_module.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import LambdaFunctionUrlResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = LambdaFunctionUrlResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.LAMBDA_FUNCTION_URL)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/api_gateway/#faq","title":"FAQ","text":"<p>What's the difference between this utility and frameworks like Chalice?</p> <p>Chalice is a full featured microframework that manages application and infrastructure. This utility, however, is largely focused on routing to reduce boilerplate and expects you to setup and manage infrastructure with your framework of choice.</p> <p>That said, Chalice has native integration with Lambda Powertools if you're looking for a more opinionated and web framework feature set.</p> <p>What happened to <code>ApiGatewayResolver</code>?</p> <p>It's been superseded by more explicit resolvers like <code>APIGatewayRestResolver</code>, <code>APIGatewayHttpResolver</code>, and <code>ALBResolver</code>.</p> <p><code>ApiGatewayResolver</code> handled multiple types of event resolvers for convenience via <code>proxy_type</code> param. However, it made it impossible for static checkers like Mypy and IDEs IntelliSense to know what properties a <code>current_event</code> would have due to late bound resolution.</p> <p>This provided a suboptimal experience for customers not being able to find all properties available besides common ones between API Gateway REST, HTTP, and ALB - while manually annotating <code>app.current_event</code> would work it is not the experience we want to provide to customers.</p> <p><code>ApiGatewayResolver</code> will be deprecated in v2 and have appropriate warnings as soon as we have a v2 draft.</p>"},{"location":"core/event_handler/appsync/","title":"GraphQL API","text":"<p>Event handler for AWS AppSync Direct Lambda Resolver and Amplify GraphQL Transformer.</p>"},{"location":"core/event_handler/appsync/#key-features","title":"Key Features","text":"<ul> <li>Automatically parse API arguments to function arguments</li> <li>Choose between strictly match a GraphQL field name or all of them to a function</li> <li>Integrates with Data classes utilities to access resolver and identity information</li> <li>Works with both Direct Lambda Resolver and Amplify GraphQL Transformer <code>@function</code> directive</li> <li>Support async Python 3.8+ functions, and generators</li> </ul>"},{"location":"core/event_handler/appsync/#terminology","title":"Terminology","text":"<p>Direct Lambda Resolver. A custom AppSync Resolver to bypass the use of Apache Velocity Template (VTL) and automatically map your function's response to a GraphQL field.</p> <p>Amplify GraphQL Transformer. Custom GraphQL directives to define your application's data model using Schema Definition Language (SDL). Amplify CLI uses these directives to convert GraphQL SDL into full descriptive AWS CloudFormation templates.</p>"},{"location":"core/event_handler/appsync/#getting-started","title":"Getting started","text":""},{"location":"core/event_handler/appsync/#required-resources","title":"Required resources","text":"<p>You must have an existing AppSync GraphQL API and IAM permissions to invoke your Lambda function. That said, there is no additional permissions to use this utility.</p> <p>This is the sample infrastructure we are using for the initial examples with a AppSync Direct Lambda Resolver.</p> Tip: Designing GraphQL Schemas for the first time? <p>Visit AWS AppSync schema documentation for understanding how to define types, nesting, and pagination.</p> getting_started_schema.graphqltemplate.yml <pre><code>schema {\nquery: Query\nmutation: Mutation\n}\n\ntype Query {\n# these are fields you can attach resolvers to (field: Query, field: getTodo)\ngetTodo(id: ID!): Todo\nlistTodos: [Todo]\n}\n\ntype Mutation {\ncreateTodo(title: String!): Todo\n}\n\ntype Todo {\nid: ID!\nuserId: String\ntitle: String\ncompleted: Boolean\n}\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Hello world Direct Lambda Resolver\n\nGlobals:\nFunction:\nTimeout: 5\nRuntime: python3.9\nTracing: Active\nEnvironment:\nVariables:\n# Powertools for AWS Lambda (Python) env vars: https://docs.powertools.aws.dev/lambda/python/latest/#environment-variables\nLOG_LEVEL: INFO\nPOWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\nPOWERTOOLS_LOGGER_LOG_EVENT: true\nPOWERTOOLS_SERVICE_NAME: example\n\nResources:\nTodosFunction:\nType: AWS::Serverless::Function\nProperties:\nHandler: getting_started_graphql_api_resolver.lambda_handler\nCodeUri: ../src\nDescription: Sample Direct Lambda Resolver\n\n# IAM Permissions and Roles\n\nAppSyncServiceRole:\nType: \"AWS::IAM::Role\"\nProperties:\nAssumeRolePolicyDocument:\nVersion: \"2012-10-17\"\nStatement:\n- Effect: \"Allow\"\nPrincipal:\nService:\n- \"appsync.amazonaws.com\"\nAction:\n- \"sts:AssumeRole\"\n\nInvokeLambdaResolverPolicy:\nType: \"AWS::IAM::Policy\"\nProperties:\nPolicyName: \"DirectAppSyncLambda\"\nPolicyDocument:\nVersion: \"2012-10-17\"\nStatement:\n- Effect: \"Allow\"\nAction: \"lambda:invokeFunction\"\nResource:\n- !GetAtt TodosFunction.Arn\nRoles:\n- !Ref AppSyncServiceRole\n\n# GraphQL API\n\nTodosApi:\nType: \"AWS::AppSync::GraphQLApi\"\nProperties:\nName: TodosApi\nAuthenticationType: \"API_KEY\"\nXrayEnabled: true\n\nTodosApiKey:\nType: AWS::AppSync::ApiKey\nProperties:\nApiId: !GetAtt TodosApi.ApiId\n\nTodosApiSchema:\nType: \"AWS::AppSync::GraphQLSchema\"\nProperties:\nApiId: !GetAtt TodosApi.ApiId\nDefinitionS3Location: ../src/getting_started_schema.graphql\nMetadata:\ncfn-lint:\nconfig:\nignore_checks:\n- W3002 # allow relative path in DefinitionS3Location\n\n# Lambda Direct Data Source and Resolver\n\nTodosFunctionDataSource:\nType: \"AWS::AppSync::DataSource\"\nProperties:\nApiId: !GetAtt TodosApi.ApiId\nName: \"HelloWorldLambdaDirectResolver\"\nType: \"AWS_LAMBDA\"\nServiceRoleArn: !GetAtt AppSyncServiceRole.Arn\nLambdaConfig:\nLambdaFunctionArn: !GetAtt TodosFunction.Arn\n\nListTodosResolver:\nType: \"AWS::AppSync::Resolver\"\nProperties:\nApiId: !GetAtt TodosApi.ApiId\nTypeName: \"Query\"\nFieldName: \"listTodos\"\nDataSourceName: !GetAtt TodosFunctionDataSource.Name\n\nGetTodoResolver:\nType: \"AWS::AppSync::Resolver\"\nProperties:\nApiId: !GetAtt TodosApi.ApiId\nTypeName: \"Query\"\nFieldName: \"getTodo\"\nDataSourceName: !GetAtt TodosFunctionDataSource.Name\n\nCreateTodoResolver:\nType: \"AWS::AppSync::Resolver\"\nProperties:\nApiId: !GetAtt TodosApi.ApiId\nTypeName: \"Mutation\"\nFieldName: \"createTodo\"\nDataSourceName: !GetAtt TodosFunctionDataSource.Name\n\nOutputs:\nTodosFunction:\nDescription: \"Hello World Lambda Function ARN\"\nValue: !GetAtt TodosFunction.Arn\n\nTodosApi:\nValue: !GetAtt TodosApi.GraphQLUrl\n</code></pre>"},{"location":"core/event_handler/appsync/#resolver-decorator","title":"Resolver decorator","text":"<p>You can define your functions to match GraphQL types and fields with the <code>app.resolver()</code> decorator.</p> What is a type and field? <p>A type would be a top-level GraphQL Type like <code>Query</code>, <code>Mutation</code>, <code>Todo</code>. A GraphQL Field would be <code>listTodos</code> under <code>Query</code>, <code>createTodo</code> under <code>Mutation</code>, etc.</p> <p>Here's an example with two separate functions to resolve <code>getTodo</code> and <code>listTodos</code> fields within the <code>Query</code> type. For completion, we use Scalar type utilities to generate the right output based on our schema definition.</p> Important <p>GraphQL arguments are passed as function keyword arguments.</p> <p>Example</p> <p>The GraphQL Query <code>getTodo(id: \"todo_id_value\")</code> will call <code>get_todo</code> as <code>get_todo(id=\"todo_id_value\")</code>.</p> getting_started_graphql_api_resolver.pygetting_started_schema.graphqlsample events <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\nclass Todo(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    userId: str\n    title: str\n    completed: bool\n\n\n@app.resolver(type_name=\"Query\", field_name=\"getTodo\")\n@tracer.capture_method\ndef get_todo(\nid: str = \"\",  # noqa AA03 VNE003 shadows built-in id to match query argument, e.g., getTodo(id: \"some_id\")\n) -&gt; Todo:\n    logger.info(f\"Fetching Todo {id}\")\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{id}\")\n    todos.raise_for_status()\n\n    return todos.json()\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listTodos\")\n@tracer.capture_method\ndef list_todos() -&gt; List[Todo]:\ntodos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return todos.json()[:10]\n\n\n@app.resolver(type_name=\"Mutation\", field_name=\"createTodo\")\n@tracer.capture_method\ndef create_todo(title: str) -&gt; Todo:\npayload = {\"userId\": scalar_types_utils.make_id(), \"title\": title, \"completed\": False}  # dummy UUID str\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", json=payload)\n    todo.raise_for_status()\n\n    return todo.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nreturn app.resolve(event, context)\n</code></pre> <pre><code>schema {\nquery: Query\nmutation: Mutation\n}\n\ntype Query {\n# these are fields you can attach resolvers to (field: Query, field: getTodo)\ngetTodo(id: ID!): Todo\nlistTodos: [Todo]\n}\n\ntype Mutation {\ncreateTodo(title: String!): Todo\n}\n\ntype Todo {\nid: ID!\nuserId: String\ntitle: String\ncompleted: Boolean\n}\n</code></pre> getting_started_get_todo.jsongetting_started_list_todos.jsongetting_started_create_todo.json <pre><code>{\n\"arguments\": {\n\"id\": \"7e362732-c8cd-4405-b090-144ac9b38960\"\n},\n\"identity\": null,\n\"source\": null,\n\"request\": {\n\"headers\": {\n\"x-forwarded-for\": \"1.2.3.4, 5.6.7.8\",\n\"accept-encoding\": \"gzip, deflate, br\",\n\"cloudfront-viewer-country\": \"NL\",\n\"cloudfront-is-tablet-viewer\": \"false\",\n\"referer\": \"https://eu-west-1.console.aws.amazon.com/appsync/home?region=eu-west-1\",\n\"via\": \"2.0 9fce949f3749407c8e6a75087e168b47.cloudfront.net (CloudFront)\",\n\"cloudfront-forwarded-proto\": \"https\",\n\"origin\": \"https://eu-west-1.console.aws.amazon.com\",\n\"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\",\n\"content-type\": \"application/json\",\n\"x-amzn-trace-id\": \"Root=1-606eb2f2-1babc433453a332c43fb4494\",\n\"x-amz-cf-id\": \"SJw16ZOPuMZMINx5Xcxa9pB84oMPSGCzNOfrbJLvd80sPa0waCXzYQ==\",\n\"content-length\": \"114\",\n\"x-amz-user-agent\": \"AWS-Console-AppSync/\",\n\"x-forwarded-proto\": \"https\",\n\"host\": \"ldcvmkdnd5az3lm3gnf5ixvcyy.appsync-api.eu-west-1.amazonaws.com\",\n\"accept-language\": \"en-US,en;q=0.5\",\n\"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0\",\n\"cloudfront-is-desktop-viewer\": \"true\",\n\"cloudfront-is-mobile-viewer\": \"false\",\n\"accept\": \"*/*\",\n\"x-forwarded-port\": \"443\",\n\"cloudfront-is-smarttv-viewer\": \"false\"\n}\n},\n\"prev\": null,\n\"info\": {\n\"parentTypeName\": \"Query\",\n\"selectionSetList\": [\n\"title\",\n\"id\"\n],\n\"selectionSetGraphQL\": \"{\\n  title\\n  id\\n}\",\n\"fieldName\": \"getTodo\",\n\"variables\": {}\n},\n\"stash\": {}\n}\n</code></pre> <pre><code>{\n\"arguments\": {},\n\"identity\": null,\n\"source\": null,\n\"request\": {\n\"headers\": {\n\"x-forwarded-for\": \"1.2.3.4, 5.6.7.8\",\n\"accept-encoding\": \"gzip, deflate, br\",\n\"cloudfront-viewer-country\": \"NL\",\n\"cloudfront-is-tablet-viewer\": \"false\",\n\"referer\": \"https://eu-west-1.console.aws.amazon.com/appsync/home?region=eu-west-1\",\n\"via\": \"2.0 9fce949f3749407c8e6a75087e168b47.cloudfront.net (CloudFront)\",\n\"cloudfront-forwarded-proto\": \"https\",\n\"origin\": \"https://eu-west-1.console.aws.amazon.com\",\n\"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\",\n\"content-type\": \"application/json\",\n\"x-amzn-trace-id\": \"Root=1-606eb2f2-1babc433453a332c43fb4494\",\n\"x-amz-cf-id\": \"SJw16ZOPuMZMINx5Xcxa9pB84oMPSGCzNOfrbJLvd80sPa0waCXzYQ==\",\n\"content-length\": \"114\",\n\"x-amz-user-agent\": \"AWS-Console-AppSync/\",\n\"x-forwarded-proto\": \"https\",\n\"host\": \"ldcvmkdnd5az3lm3gnf5ixvcyy.appsync-api.eu-west-1.amazonaws.com\",\n\"accept-language\": \"en-US,en;q=0.5\",\n\"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0\",\n\"cloudfront-is-desktop-viewer\": \"true\",\n\"cloudfront-is-mobile-viewer\": \"false\",\n\"accept\": \"*/*\",\n\"x-forwarded-port\": \"443\",\n\"cloudfront-is-smarttv-viewer\": \"false\"\n}\n},\n\"prev\": null,\n\"info\": {\n\"parentTypeName\": \"Query\",\n\"selectionSetList\": [\n\"id\",\n\"title\"\n],\n\"selectionSetGraphQL\": \"{\\n  id\\n  title\\n}\",\n\"fieldName\": \"listTodos\",\n\"variables\": {}\n},\n\"stash\": {}\n}\n</code></pre> <pre><code> {\n\"arguments\": {\n\"title\": \"Sample todo mutation\"\n},\n\"identity\": null,\n\"source\": null,\n\"request\": {\n\"headers\": {\n\"x-forwarded-for\": \"203.0.113.1, 203.0.113.18\",\n\"cloudfront-viewer-country\": \"NL\",\n\"cloudfront-is-tablet-viewer\": \"false\",\n\"x-amzn-requestid\": \"fdc4f30b-44c2-475d-b2f9-9da0778d5275\",\n\"via\": \"2.0 f655cacd0d6f7c5dc935ea687af6f3c0.cloudfront.net (CloudFront)\",\n\"cloudfront-forwarded-proto\": \"https\",\n\"origin\": \"https://eu-west-1.console.aws.amazon.com\",\n\"content-length\": \"166\",\n\"x-forwarded-proto\": \"https\",\n\"accept-language\": \"en-US,en;q=0.5\",\n\"host\": \"kiuqayvn4jhhzio6whpnk7xj3a.appsync-api.eu-west-1.amazonaws.com\",\n\"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:102.0) Gecko/20100101 Firefox/102.0\",\n\"cloudfront-is-mobile-viewer\": \"false\",\n\"accept\": \"application/json, text/plain, */*\",\n\"cloudfront-viewer-asn\": \"1136\",\n\"cloudfront-is-smarttv-viewer\": \"false\",\n\"accept-encoding\": \"gzip, deflate, br\",\n\"referer\": \"https://eu-west-1.console.aws.amazon.com/\",\n\"content-type\": \"application/json\",\n\"x-api-key\": \"da2-vsqnxwyzgzf4nh6kvoaidtvs7y\",\n\"sec-fetch-mode\": \"cors\",\n\"x-amz-cf-id\": \"0kxqijFPsbGSWJ1u3Z_sUS4Wu2hRoG_2T77aJPuoh_Q4bXAB3x0a3g==\",\n\"x-amzn-trace-id\": \"Root=1-63fef2cf-6d566e9f4a35b99e6212388e\",\n\"sec-fetch-dest\": \"empty\",\n\"x-amz-user-agent\": \"AWS-Console-AppSync/\",\n\"cloudfront-is-desktop-viewer\": \"true\",\n\"sec-fetch-site\": \"cross-site\",\n\"x-forwarded-port\": \"443\"\n},\n\"domainName\": null\n},\n\"prev\": null,\n\"info\": {\n\"selectionSetList\": [\n\"id\",\n\"title\",\n\"completed\"\n],\n\"selectionSetGraphQL\": \"{\\n  id\\n  title\\n  completed\\n}\",\n\"fieldName\": \"createTodo\",\n\"parentTypeName\": \"Mutation\",\n\"variables\": {}\n},\n\"stash\": {}\n}\n</code></pre>"},{"location":"core/event_handler/appsync/#scalar-functions","title":"Scalar functions","text":"<p>When working with AWS AppSync Scalar types, you might want to generate the same values for data validation purposes.</p> <p>For convenience, the most commonly used values are available as functions within <code>scalar_types_utils</code> module.</p> Creating key scalar values with scalar_types_utils<pre><code>from aws_lambda_powertools.utilities.data_classes.appsync.scalar_types_utils import (\naws_date,\naws_datetime,\naws_time,\naws_timestamp,\nmake_id,\n)\n\n# Scalars: https://docs.aws.amazon.com/appsync/latest/devguide/scalars.html\n\nmy_id: str = make_id()  # Scalar: ID!\nmy_date: str = aws_date()  # Scalar: AWSDate\nmy_timestamp: str = aws_time()  # Scalar: AWSTime\nmy_datetime: str = aws_datetime()  # Scalar: AWSDateTime\nmy_epoch_timestamp: int = aws_timestamp()  # Scalar: AWSTimestamp\n</code></pre> <p>Here's a table with their related scalar as a quick reference:</p> Scalar type Scalar function Sample value ID <code>scalar_types_utils.make_id</code> <code>e916c84d-48b6-484c-bef3-cee3e4d86ebf</code> AWSDate <code>scalar_types_utils.aws_date</code> <code>2022-07-08Z</code> AWSTime <code>scalar_types_utils.aws_time</code> <code>15:11:00.189Z</code> AWSDateTime <code>scalar_types_utils.aws_datetime</code> <code>2022-07-08T15:11:00.189Z</code> AWSTimestamp <code>scalar_types_utils.aws_timestamp</code> <code>1657293060</code>"},{"location":"core/event_handler/appsync/#advanced","title":"Advanced","text":""},{"location":"core/event_handler/appsync/#nested-mappings","title":"Nested mappings","text":"Note <p>The following examples use a more advanced schema. These schemas differ from initial sample infrastructure we used earlier.</p> <p>You can nest <code>app.resolver()</code> decorator multiple times when resolving fields with the same return value.</p> nested_mappings.pynested_mappings_schema.graphql <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@app.resolver(field_name=\"listLocations\")\n@app.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\nreturn [{\"name\": name, \"description\": description}]\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nreturn app.resolve(event, context)\n</code></pre> <pre><code>schema {\nquery: Query\n}\n\ntype Query {\nlistLocations: [Location]\n}\n\ntype Location {\nid: ID!\nname: String!\ndescription: String\naddress: String\n}\n\ntype Merchant {\nid: String!\nname: String!\ndescription: String\nlocations: [Location]\n}\n</code></pre>"},{"location":"core/event_handler/appsync/#async-functions","title":"Async functions","text":"<p>For Lambda Python3.8+ runtime, this utility supports async functions when you use in conjunction with <code>asyncio.run</code>.</p> Resolving GraphQL resolvers async<pre><code>import asyncio\nimport sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nimport aiohttp\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.tracing import aiohttp_trace_config\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\nclass Todo(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    userId: str\n    title: str\n    completed: bool\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listTodos\")\nasync def list_todos() -&gt; List[Todo]:\nasync with aiohttp.ClientSession(trace_configs=[aiohttp_trace_config()]) as session:\n        async with session.get(\"https://jsonplaceholder.typicode.com/todos\") as resp:\n            return await resp.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nresult = app.resolve(event, context)\nreturn asyncio.run(result)\n</code></pre>"},{"location":"core/event_handler/appsync/#amplify-graphql-transformer","title":"Amplify GraphQL Transformer","text":"<p>Assuming you have Amplify CLI installed, create a new API using <code>amplify add api</code> and use the following GraphQL Schema.</p> Example GraphQL Schema<pre><code>@model\ntype Merchant {\nid: String!\nname: String!\ndescription: String\n# Resolves to `common_field`\ncommonField: String  @function(name: \"merchantInfo-${env}\")\n}\n\ntype Location {\nid: ID!\nname: String!\naddress: String\n# Resolves to `common_field`\ncommonField: String  @function(name: \"merchantInfo-${env}\")\n}\n\ntype Query {\n# List of locations resolves to `list_locations`\nlistLocations(page: Int, size: Int): [Location] @function(name: \"merchantInfo-${env}\")\n# List of locations resolves to `list_locations`\nfindMerchant(search: str): [Merchant] @function(name: \"searchMerchant-${env}\")\n}\n</code></pre> <p>Create two new basic Python functions via <code>amplify add function</code>.</p> Note <p>Amplify CLI generated functions use <code>Pipenv</code> as a dependency manager. Your function source code is located at <code>amplify/backend/function/your-function-name</code>.</p> <p>Within your function's folder, add Powertools for AWS Lambda (Python) as a dependency with <code>pipenv install aws-lambda-powertools</code>.</p> <p>Use the following code for <code>merchantInfo</code> and <code>searchMerchant</code> functions respectively.</p> graphql_transformer_merchant_info.pygraphql_transformer_search_merchant.pygraphql_transformer_list_locations.jsongraphql_transformer_common_field.jsongraphql_transformer_find_merchant.json <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n    commonField: str\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listLocations\")\ndef list_locations(page: int = 0, size: int = 10) -&gt; List[Location]:\nreturn [{\"id\": scalar_types_utils.make_id(), \"name\": \"Smooth Grooves\"}]\n\n\n@app.resolver(field_name=\"commonField\")\ndef common_field() -&gt; str:\n# Would match all fieldNames matching 'commonField'\n    return scalar_types_utils.make_id()\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nreturn app.resolve(event, context)\n</code></pre> <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = AppSyncResolver()\ntracer = Tracer()\nlogger = Logger()\n\n\nclass Merchant(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    commonField: str\n\n\n@app.resolver(type_name=\"Query\", field_name=\"findMerchant\")\ndef find_merchant(search: str) -&gt; List[Merchant]:\nmerchants: List[Merchant] = [\n        {\n            \"id\": scalar_types_utils.make_id(),\n            \"name\": \"Parry-Wood\",\n            \"description\": \"Possimus doloremque tempora harum deleniti eum.\",\n        },\n        {\n            \"id\": scalar_types_utils.make_id(),\n            \"name\": \"Shaw, Owen and Jones\",\n            \"description\": \"Aliquam iste architecto suscipit in.\",\n        },\n    ]\n\nreturn [merchant for merchant in merchants if search == merchant[\"name\"]]\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nreturn app.resolve(event, context)\n</code></pre> <pre><code>{\n\"typeName\": \"Query\",\n\"fieldName\": \"listLocations\",\n\"arguments\": {\n\"page\": 2,\n\"size\": 1\n},\n\"identity\": {\n\"claims\": {\n\"iat\": 1615366261\n},\n\"username\": \"treid\"\n},\n\"request\": {\n\"headers\": {\n\"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n\"x-forwarded-for\": \"127.0.0.1\",\n\"cloudfront-viewer-country\": \"NL\",\n\"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n}\n}\n}\n</code></pre> <pre><code>{\n\"typeName\": \"Merchant\",\n\"fieldName\": \"commonField\",\n\"arguments\": {},\n\"identity\": {\n\"claims\": {\n\"iat\": 1615366261\n},\n\"username\": \"marieellis\"\n},\n\"request\": {\n\"headers\": {\n\"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n\"x-forwarded-for\": \"127.0.0.1\"\n}\n},\n}\n</code></pre> <pre><code>{\n\"typeName\": \"Query\",\n\"fieldName\": \"findMerchant\",\n\"arguments\": {\n\"search\": \"Parry-Wood\"\n},\n\"identity\": {\n\"claims\": {\n\"iat\": 1615366261\n},\n\"username\": \"wwilliams\"\n},\n\"request\": {\n\"headers\": {\n\"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n\"x-forwarded-for\": \"127.0.0.1\"\n}\n},\n}\n</code></pre>"},{"location":"core/event_handler/appsync/#custom-data-models","title":"Custom data models","text":"<p>You can subclass AppSyncResolverEvent to bring your own set of methods to handle incoming events, by using <code>data_model</code> param in the <code>resolve</code> method.</p> custom_models.py.pynested_mappings_schema.graphqlgraphql_transformer_list_locations.json <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.data_classes.appsync_resolver_event import (\nAppSyncResolverEvent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n    commonField: str\n\n\nclass MyCustomModel(AppSyncResolverEvent):\n@property\ndef country_viewer(self) -&gt; str:\nreturn self.get_header_value(name=\"cloudfront-viewer-country\", default_value=\"\", case_sensitive=False)  # type: ignore[return-value] # sentinel typing # noqa: E501\n\n@property\ndef api_key(self) -&gt; str:\nreturn self.get_header_value(name=\"x-api-key\", default_value=\"\", case_sensitive=False)  # type: ignore[return-value] # sentinel typing # noqa: E501\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listLocations\")\ndef list_locations(page: int = 0, size: int = 10) -&gt; List[Location]:\n    # additional properties/methods will now be available under current_event\nlogger.debug(f\"Request country origin: {app.current_event.country_viewer}\")  # type: ignore[attr-defined]\nreturn [{\"id\": scalar_types_utils.make_id(), \"name\": \"Perry, James and Carroll\"}]\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nreturn app.resolve(event, context, data_model=MyCustomModel)\n</code></pre> <pre><code>schema {\nquery: Query\n}\n\ntype Query {\nlistLocations: [Location]\n}\n\ntype Location {\nid: ID!\nname: String!\ndescription: String\naddress: String\n}\n\ntype Merchant {\nid: String!\nname: String!\ndescription: String\nlocations: [Location]\n}\n</code></pre> <pre><code> {\n\"typeName\": \"Query\",\n\"fieldName\": \"listLocations\",\n\"arguments\": {\n\"page\": 2,\n\"size\": 1\n},\n\"identity\": {\n\"claims\": {\n\"iat\": 1615366261\n},\n\"username\": \"treid\"\n},\n\"request\": {\n\"headers\": {\n\"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n\"x-forwarded-for\": \"127.0.0.1\",\n\"cloudfront-viewer-country\": \"NL\",\n\"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n}\n}\n}\n</code></pre>"},{"location":"core/event_handler/appsync/#split-operations-with-router","title":"Split operations with Router","text":"Tip <p>Read the considerations section for trade-offs between monolithic and micro functions, as it's also applicable here.</p> <p>As you grow the number of related GraphQL operations a given Lambda function should handle, it is natural to split them into separate files to ease maintenance - That's when the <code>Router</code> feature comes handy.</p> <p>Let's assume you have <code>split_operation.py</code> as your Lambda function entrypoint and routes in <code>split_operation_module.py</code>. This is how you'd use the <code>Router</code> feature.</p> split_operation_module.pysplit_operation.py <p>We import Router instead of AppSyncResolver; syntax wise is exactly the same.</p> <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler.appsync import Router\ntracer = Tracer()\nlogger = Logger()\nrouter = Router()\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@router.resolver(field_name=\"listLocations\")\n@router.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\n    return [{\"name\": name, \"description\": description}]\n</code></pre> <p>We use <code>include_router</code> method and include all <code>location</code> operations registered in the <code>router</code> global object.</p> <pre><code>import split_operation_module\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\napp.include_router(split_operation_module.router)\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"},{"location":"core/event_handler/appsync/#sharing-contextual-data","title":"Sharing contextual data","text":"<p>You can use <code>append_context</code> when you want to share data between your App and Router instances. Any data you share will be available via the <code>context</code> dictionary available in your App or Router context.</p> Info <p>For safety, we always clear any data available in the <code>context</code> dictionary after each invocation.</p> Tip <p>This can also be useful for middlewares injecting contextual information before a request is processed.</p> split_route_append_context.pysplit_route_append_context_module.py <pre><code>import split_operation_append_context_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\napp.include_router(split_operation_append_context_module.router)\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\napp.append_context(is_admin=True)  # arbitrary number of key=value data\nreturn app.resolve(event, context)\n</code></pre> <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler.appsync import Router\n\ntracer = Tracer()\nlogger = Logger()\nrouter = Router()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@router.resolver(field_name=\"listLocations\")\n@router.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\nis_admin: bool = router.context.get(\"is_admin\", False)\nreturn [{\"name\": name, \"description\": description}] if is_admin else []\n</code></pre>"},{"location":"core/event_handler/appsync/#testing-your-code","title":"Testing your code","text":"<p>You can test your resolvers by passing a mocked or actual AppSync Lambda event that you're expecting.</p> <p>You can use either <code>app.resolve(event, context)</code> or simply <code>app(event, context)</code>.</p> <p>Here's an example of how you can test your synchronous resolvers:</p> assert_graphql_response.pyassert_graphql_response_module.pyassert_graphql_response.json <pre><code>import json\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nimport pytest\nfrom assert_graphql_response_module import Location, app  # instance of AppSyncResolver\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n        aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n    return LambdaContext()\n\n\ndef test_direct_resolver(lambda_context):\n    # GIVEN\n    fake_event = json.loads(Path(\"assert_graphql_response.json\").read_text())\n\n    # WHEN\nresult: list[Location] = app(fake_event, lambda_context)\n# THEN\nassert result[0][\"name\"] == \"Perkins-Reed\"\n</code></pre> <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@app.resolver(field_name=\"listLocations\")\n@app.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\n    return [{\"name\": name, \"description\": description}]\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"typeName\": \"Query\",\n\"fieldName\": \"listLocations\",\n\"arguments\": {\n\"name\": \"Perkins-Reed\",\n\"description\": \"Nulla sed amet. Earum libero qui sunt perspiciatis. Non aliquid accusamus.\"\n},\n\"selectionSetList\": [\n\"id\",\n\"name\"\n],\n\"identity\": {\n\"claims\": {\n\"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n\"email_verified\": true,\n\"iss\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n\"phone_number_verified\": false,\n\"cognito:username\": \"jdoe\",\n\"aud\": \"7471s60os7h0uu77i1tk27sp9n\",\n\"event_id\": \"bc334ed8-a938-4474-b644-9547e304e606\",\n\"token_use\": \"id\",\n\"auth_time\": 1599154213,\n\"phone_number\": \"+19999999999\",\n\"exp\": 1599157813,\n\"iat\": 1599154213,\n\"email\": \"jdoe@email.com\"\n},\n\"defaultAuthStrategy\": \"ALLOW\",\n\"groups\": null,\n\"issuer\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n\"sourceIp\": [\n\"1.1.1.1\"\n],\n\"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n\"username\": \"jdoe\"\n},\n\"request\": {\n\"headers\": {\n\"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n\"x-forwarded-for\": \"127.0.0.1\",\n\"cloudfront-viewer-country\": \"NL\",\n\"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n}\n}\n}\n</code></pre> <p>And an example for testing asynchronous resolvers. Note that this requires the <code>pytest-asyncio</code> package. This tests a specific async GraphQL operation.</p> Note <p>Alternatively, you can continue call <code>lambda_handler</code> function synchronously as it'd run <code>asyncio.run</code> to await for the coroutine to complete.</p> assert_async_graphql_response.pyassert_async_graphql_response_module.pyassert_async_graphql_response.json <pre><code>import json\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import List\n\nimport pytest\nfrom assert_async_graphql_response_module import (  # instance of AppSyncResolver\n    Todo,\n    app,\n)\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n        aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n    return LambdaContext()\n\n\n@pytest.mark.asyncio\nasync def test_async_direct_resolver(lambda_context):\n    # GIVEN\n    fake_event = json.loads(Path(\"assert_async_graphql_response.json\").read_text())\n\n    # WHEN\nresult: List[Todo] = await app(fake_event, lambda_context)\n# alternatively, you can also run a sync test against `lambda_handler`\n    # since `lambda_handler` awaits the coroutine to complete\n\n    # THEN\n    assert result[0][\"userId\"] == 1\n    assert result[0][\"id\"] == 1\n    assert result[0][\"completed\"] is False\n</code></pre> <pre><code>import sys\n\nif sys.version_info &gt;= (3, 8):\n    from typing import TypedDict\nelse:\n    from typing_extensions import TypedDict\n\nimport asyncio\nfrom typing import List\n\nimport aiohttp\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.tracing import aiohttp_trace_config\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\nclass Todo(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    userId: str\n    title: str\n    completed: bool\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listTodos\")\nasync def list_todos() -&gt; List[Todo]:\n    async with aiohttp.ClientSession(trace_configs=[aiohttp_trace_config()]) as session:\n        async with session.get(\"https://jsonplaceholder.typicode.com/todos\") as resp:\n            result: List[Todo] = await resp.json()\n            return result[:2]  # first two results to demo assertion\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    result = app.resolve(event, context)\n\n    return asyncio.run(result)\n</code></pre> <pre><code>{\n\"typeName\": \"Query\",\n\"fieldName\": \"listTodos\",\n\"arguments\": {},\n\"selectionSetList\": [\n\"id\",\n\"userId\",\n\"completed\"\n],\n\"identity\": {\n\"claims\": {\n\"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n\"email_verified\": true,\n\"iss\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n\"phone_number_verified\": false,\n\"cognito:username\": \"jdoe\",\n\"aud\": \"7471s60os7h0uu77i1tk27sp9n\",\n\"event_id\": \"bc334ed8-a938-4474-b644-9547e304e606\",\n\"token_use\": \"id\",\n\"auth_time\": 1599154213,\n\"phone_number\": \"+19999999999\",\n\"exp\": 1599157813,\n\"iat\": 1599154213,\n\"email\": \"jdoe@email.com\"\n},\n\"defaultAuthStrategy\": \"ALLOW\",\n\"groups\": null,\n\"issuer\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n\"sourceIp\": [\n\"1.1.1.1\"\n],\n\"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n\"username\": \"jdoe\"\n},\n\"request\": {\n\"headers\": {\n\"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n\"x-forwarded-for\": \"127.0.0.1\",\n\"cloudfront-viewer-country\": \"NL\",\n\"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n}\n}\n}\n</code></pre>"},{"location":"tutorial/","title":"Tutorial","text":"<p>This tutorial progressively introduces Powertools for AWS Lambda (Python) core utilities by using one feature at a time.</p>"},{"location":"tutorial/#requirements","title":"Requirements","text":"<ul> <li>AWS CLI and configured with your credentials.</li> <li>AWS SAM CLI installed.</li> </ul>"},{"location":"tutorial/#getting-started","title":"Getting started","text":"<p>Let's clone our sample project before we add one feature at a time.</p> Tip: Want to skip to the final project? <p>Bootstrap directly via SAM CLI:</p> <pre><code>sam init --app-template hello-world-powertools-python --name sam-app --package-type Zip --runtime python3.10 --no-tracing`\n</code></pre> Use SAM CLI to initialize the sample project<pre><code>sam init --runtime python3.10 --dependency-manager pip --app-template hello-world --name powertools-quickstart\n</code></pre>"},{"location":"tutorial/#project-structure","title":"Project structure","text":"<p>As we move forward, we will modify the following files within the <code>powertools-quickstart</code> folder:</p> <ul> <li>app.py - Application code.</li> <li>template.yaml - AWS infrastructure configuration using SAM.</li> <li>requirements.txt - List of extra Python packages needed.</li> </ul>"},{"location":"tutorial/#code-example","title":"Code example","text":"<p>Let's configure our base application to look like the following code snippet.</p> app.pytemplate.yaml <pre><code>import json\n\n\ndef hello():\n    return {\"statusCode\": 200, \"body\": json.dumps({\"message\": \"hello unknown!\"})}\n\n\ndef lambda_handler(event, context):\n    return hello()\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\nFunction:\nTimeout: 3\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: hello_world/\nHandler: app.lambda_handler\nRuntime: python3.9\nArchitectures:\n- x86_64\nEvents:\nHelloWorld:\nType: Api\nProperties:\nPath: /hello\nMethod: get\nOutputs:\nHelloWorldApi:\nDescription: \"API Gateway endpoint URL for Prod stage for Hello World function\"\nValue: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <p>Our Lambda code consists of an entry point function named <code>lambda_handler</code>, and a <code>hello</code> function.</p> <p>When API Gateway receives a HTTP GET request on <code>/hello</code> route, Lambda will call our <code>lambda_handler</code> function, subsequently calling the <code>hello</code> function. API Gateway will use this response to return the correct HTTP Status Code and payload back to the caller.</p> Warning <p>For simplicity, we do not set up authentication and authorization! You can find more information on how to implement it on AWS SAM documentation.</p>"},{"location":"tutorial/#run-your-code","title":"Run your code","text":"<p>At each point, you have two ways to run your code: locally and within your AWS account.</p>"},{"location":"tutorial/#local-test","title":"Local test","text":"<p>AWS SAM allows you to execute a serverless application locally by running <code>sam build &amp;&amp; sam local start-api</code> in your preferred shell.</p> Build and run API Gateway locally<pre><code>&gt; sam build &amp;&amp; sam local start-api\n...\n2021-11-26 17:43:08  * Running on http://127.0.0.1:3000/ (Press CTRL+C to quit)\n</code></pre> <p>As a result, a local API endpoint will be exposed and you can invoke it using your browser, or your preferred HTTP API client e.g., Postman, httpie, etc.</p> Invoking our function locally via curl<pre><code>&gt; curl http://127.0.0.1:3000/hello\n{\"message\": \"hello unknown!\"}\n</code></pre> Info <p>To learn more about local testing, please visit the AWS SAM CLI local testing documentation.</p>"},{"location":"tutorial/#live-test","title":"Live test","text":"<p>First, you need to deploy your application into your AWS Account by issuing <code>sam build &amp;&amp; sam deploy --guided</code> command. This command builds a ZIP package of your source code, and deploy it to your AWS Account.</p> Build and deploy your serverless application<pre><code>&gt; sam build &amp;&amp; sam deploy --guided\n...\nCloudFormation outputs from deployed stack\n------------------------------------------------------------------------------------------------------------------------------------------\nOutputs\n------------------------------------------------------------------------------------------------------------------------------------------\nKey                 HelloWorldFunctionIamRole\nDescription         Implicit IAM Role created for Hello World function\nValue               arn:aws:iam::123456789012:role/sam-app-HelloWorldFunctionRole-1T2W3H9LZHGGV\n\nKey                 HelloWorldApi\nDescription         API Gateway endpoint URL for Prod stage for Hello World function\nValue               https://1234567890.execute-api.eu-central-1.amazonaws.com/Prod/hello/\n\nKey                 HelloWorldFunction\nDescription         Hello World Lambda Function ARN\nValue               arn:aws:lambda:eu-central-1:123456789012:function:sam-app-HelloWorldFunction-dOcfAtYoEiGo\n------------------------------------------------------------------------------------------------------------------------------------------\nSuccessfully created/updated stack - sam-app in eu-central-1\n</code></pre> <p>At the end of the deployment, you will find the API endpoint URL within <code>Outputs</code> section. You can use this URL to test your serverless application.</p> Invoking our application via API endpoint<pre><code>&gt; curl https://1234567890.execute-api.eu-central-1.amazonaws.com/Prod/hello\n{\"message\": \"hello unknown!\"}%\n</code></pre> Info <p>For more details on AWS SAM deployment mechanism, see SAM Deploy reference docs.</p>"},{"location":"tutorial/#routing","title":"Routing","text":""},{"location":"tutorial/#adding-a-new-route","title":"Adding a new route","text":"<p>Let's expand our application with a new route - <code>/hello/{name}</code>. It will accept an username as a path input and return it in the response.</p> <p>For this to work, we could create a new Lambda function to handle incoming requests for <code>/hello/{name}</code> - It'd look like this:</p> hello_by_name.pytemplate.yaml <pre><code>import json\n\n\ndef hello_name(name):\n    return {\"statusCode\": 200, \"body\": json.dumps({\"message\": f\"hello {name}!\"})}\n\n\ndef lambda_handler(event, context):\n    name = event[\"pathParameters\"][\"name\"]\n    return hello_name(name)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\nFunction:\nTimeout: 3\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: hello_world/\nHandler: app.lambda_handler\nRuntime: python3.9\nEvents:\nHelloWorld:\nType: Api\nProperties:\nPath: /hello\nMethod: get\n\nHelloWorldByNameFunctionName:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: hello_world/\nHandler: hello_by_name.lambda_handler\nRuntime: python3.9\nEvents:\nHelloWorldName:\nType: Api\nProperties:\nPath: /hello/{name}\nMethod: get\nOutputs:\nHelloWorldApi:\nDescription: \"API Gateway endpoint URL for Prod stage for Hello World function\"\nValue: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> Question <p>But what happens if your application gets bigger and we need to cover numerous URL paths and HTTP methods for them?</p> <p>This would quickly become non-trivial to maintain. Adding new Lambda function for each path, or multiple if/else to handle several routes &amp; HTTP Methods can be error prone.</p>"},{"location":"tutorial/#creating-our-own-router","title":"Creating our own router","text":"Question <p>What if we create a simple router to reduce boilerplate?</p> <p>We could group similar routes and intents, separate read and write operations resulting in fewer functions. It doesn't address the boilerplate routing code, but maybe it will be easier to add additional URLs.</p> Info: You might be already asking yourself about mono vs micro-functions <p>If you want a more detailed explanation of these two approaches, head over to the trade-offs on each approach later.</p> <p>A first attempt at the routing logic might look similar to the following code snippet.</p> app.pytemplate.yaml <pre><code>import json\n\n\ndef hello_name(event, **kargs):\nusername = event[\"pathParameters\"][\"name\"]\n    return {\"statusCode\": 200, \"body\": json.dumps({\"message\": f\"hello {username}!\"})}\n\n\ndef hello(**kargs):\nreturn {\"statusCode\": 200, \"body\": json.dumps({\"message\": \"hello unknown!\"})}\n\n\nclass Router:\ndef __init__(self):\n        self.routes = {}\n\n    def set(self, path, method, handler):\n        self.routes[f\"{path}-{method}\"] = handler\n\n    def get(self, path, method):\n        try:\n            route = self.routes[f\"{path}-{method}\"]\n        except KeyError:\n            raise RuntimeError(f\"Cannot route request to the correct method. path={path}, method={method}\")\n        return route\n\nrouter = Router()\nrouter.set(path=\"/hello\", method=\"GET\", handler=hello)\nrouter.set(path=\"/hello/{name}\", method=\"GET\", handler=hello_name)\ndef lambda_handler(event, context):\n    path = event[\"resource\"]\n    http_method = event[\"httpMethod\"]\nmethod = router.get(path=path, method=http_method)\nreturn method(event=event)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\nFunction:\nTimeout: 3\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: hello_world/\nHandler: app.lambda_handler\nRuntime: python3.9\nEvents:\nHelloWorld:\nType: Api\nProperties:\nPath: /hello\nMethod: get\nHelloWorldName:\nType: Api\nProperties:\nPath: /hello/{name}\nMethod: get\nOutputs:\nHelloWorldApi:\nDescription: \"API Gateway endpoint URL for Prod stage for Hello World function\"\nValue: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <p>Let's break this down:</p> <ul> <li>L4,9: We defined two <code>hello_name</code> and <code>hello</code> functions to handle <code>/hello/{name}</code> and <code>/hello</code> routes.</li> <li>L13: We added a <code>Router</code> class to map a path, a method, and the function to call.</li> <li>L27-29: We create a <code>Router</code> instance and map both <code>/hello</code> and <code>/hello/{name}</code>.</li> <li>L35: We use Router's <code>get</code> method to retrieve a reference to the processing method (<code>hello</code> or <code>hello_name</code>).</li> <li>L36: Finally, we run this method and send the results back to API Gateway.</li> </ul> <p>This approach simplifies the configuration of our infrastructure since we have added all API Gateway paths in the <code>HelloWorldFunction</code> event section.</p> <p>However, it forces us to understand the internal structure of the API Gateway request events, responses, and it could lead to other errors such as CORS not being handled properly, error handling, etc.</p>"},{"location":"tutorial/#simplifying-with-event-handler","title":"Simplifying with Event Handler","text":"<p>We can massively simplify cross-cutting concerns while keeping it lightweight by using Event Handler.</p> Tip <p>This is available for both REST API (API Gateway, ALB) and GraphQL API (AppSync).</p> <p>Let's include Powertools for AWS Lambda (Python) as a dependency in <code>requirement.txt</code>, and use Event Handler to refactor our previous example.</p> app.pyrequirements.txt <pre><code>from aws_lambda_powertools.event_handler import APIGatewayRestResolver\napp = APIGatewayRestResolver()\n@app.get(\"/hello/&lt;name&gt;\")\ndef hello_name(name):\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\ndef hello():\n    return {\"message\": \"hello unknown!\"}\n\n\ndef lambda_handler(event, context):\nreturn app.resolve(event, context)\n</code></pre> <pre><code>aws-lambda-powertools[tracer]  # Tracer requires AWS X-Ray SDK dependency\n</code></pre> <p>Use <code>sam build &amp;&amp; sam local start-api</code> and try run it locally again.</p> Note <p>If you're coming from Flask, you will be familiar with this experience already. Event Handler for API Gateway uses <code>APIGatewayRestResolver</code> to give a Flask-like experience while staying true to our tenet <code>Keep it lean</code>.</p> <p>We have added the route annotation as the decorator for our methods. It enables us to use the parameters passed in the request directly, and our responses are simply dictionaries.</p> <p>Lastly, we used <code>return app.resolve(event, context)</code> so Event Handler can resolve routes, inject the current request, handle serialization, route validation, etc.</p> <p>From here, we could handle 404 routes, error handling, access query strings, payload, etc.</p> Tip <p>If you'd like to learn how python decorators work under the hood, you can follow Real Python's article.</p>"},{"location":"tutorial/#structured-logging","title":"Structured Logging","text":"<p>Over time, you realize that searching logs as text results in poor observability, it's hard to create metrics from, enumerate common exceptions, etc.</p> <p>Then, you decided to propose production quality logging capabilities to your Lambda code. You found out that by having logs as <code>JSON</code> you can structure them, so that you can use any Log Analytics tool out there to quickly analyze them.</p> <p>This helps not only in searching, but produces consistent logs containing enough context and data to ask arbitrary questions on the status of your system. We can take advantage of CloudWatch Logs and Cloudwatch Insight for this purpose.</p>"},{"location":"tutorial/#json-as-output","title":"JSON as output","text":"<p>The first option could be to use the standard Python Logger, and use a specialized library like <code>pythonjsonlogger</code> to create a JSON Formatter.</p> app.pyrequirements.txt <pre><code>import logging\nimport os\n\nfrom pythonjsonlogger import jsonlogger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nlogger = logging.getLogger(\"APP\")\nlogHandler = logging.StreamHandler()\nformatter = jsonlogger.JsonFormatter(fmt=\"%(asctime)s %(levelname)s %(name)s %(message)s\")\nlogHandler.setFormatter(formatter)\nlogger.addHandler(logHandler)\nlogger.setLevel(os.getenv(\"LOG_LEVEL\", \"INFO\"))\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\ndef hello_name(name):\nlogger.info(f\"Request from {name} received\")\nreturn {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\ndef hello():\nlogger.info(\"Request from unknown received\")\nreturn {\"message\": \"hello unknown!\"}\n\n\ndef lambda_handler(event, context):\nlogger.debug(event)\nreturn app.resolve(event, context)\n</code></pre> <pre><code>aws-lambda-powertools\npython-json-logger\n</code></pre> <p>With just a few lines our logs will now output to <code>JSON</code> format. We've taken the following steps to make that work:</p> <ul> <li>L7: Creates an application logger named <code>APP</code>.</li> <li>L8-11: Configures handler and formatter.</li> <li>L12: Sets the logging level set in the <code>LOG_LEVEL</code> environment variable, or <code>INFO</code> as a sentinel value.</li> </ul> <p>After that, we use this logger in our application code to record the required information. We see logs structured as follows:</p> JSON outputNormal output <pre><code>{\n\"asctime\": \"2021-11-22 15:32:02,145\",\n\"levelname\": \"INFO\",\n\"name\": \"APP\",\n\"message\": \"Request from unknown received\"\n}\n</code></pre> <pre><code>[INFO]  2021-11-22T15:32:02.145Z        ba3bea3d-fe3a-45db-a2ce-72e813d55b91    Request from unknown received\n</code></pre> <p>So far, so good! We can take a step further now by adding additional context to the logs.</p> <p>We could start by creating a dictionary with Lambda context information or something from the incoming event, which should always be logged. Additional attributes could be added on every <code>logger.info</code> using <code>extra</code> keyword like in any standard Python logger.</p>"},{"location":"tutorial/#simplifying-with-logger","title":"Simplifying with Logger","text":"Surely this could be easier, right? <p>Yes! Powertools for AWS Lambda (Python) Logger to the rescue :-)</p> <p>As we already have Powertools for AWS Lambda (Python) as a dependency, we can simply import Logger.</p> Refactoring with Powertools for AWS Lambda (Python) Logger<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nlogger = Logger(service=\"APP\")\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\ndef hello_name(name):\nlogger.info(f\"Request from {name} received\")\nreturn {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\ndef hello():\nlogger.info(\"Request from unknown received\")\nreturn {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <p>Let's break this down:</p> <ul> <li>L5: We add Powertools for AWS Lambda (Python) Logger; the boilerplate is now done for you. By default, we set <code>INFO</code> as the logging level if <code>LOG_LEVEL</code> env var isn't set.</li> <li>L22: We use <code>logger.inject_lambda_context</code> decorator to inject key information from Lambda context into every log.</li> <li>L22: We also instruct Logger to use the incoming API Gateway Request ID as a correlation id automatically.</li> <li>L22: Since we're in dev, we also use <code>log_event=True</code> to automatically log each incoming request for debugging. This can be also set via environment variables.</li> </ul> <p>This is how the logs would look like now:</p> Our logs are now structured consistently<pre><code>{\n\"level\":\"INFO\",\n\"location\":\"hello:17\",\n\"message\":\"Request from unknown received\",\n\"timestamp\":\"2021-10-22 16:29:58,367+0000\",\n\"service\":\"APP\",\n\"cold_start\":true,\n\"function_name\":\"HelloWorldFunction\",\n\"function_memory_size\":\"256\",\n\"function_arn\":\"arn:aws:lambda:us-east-1:123456789012:function:HelloWorldFunction\",\n\"function_request_id\":\"d50bb07a-7712-4b2d-9f5d-c837302221a2\",\n\"correlation_id\":\"bf9b584c-e5d9-4ad5-af3d-db953f2b10dc\"\n}\n</code></pre> <p>We can now search our logs by the request ID to find a specific operation. Additionally, we can also search our logs for function name, Lambda request ID, Lambda function ARN, find out whether an operation was a cold start, etc.</p> <p>From here, we could set specific keys to add additional contextual information about a given operation, log exceptions to easily enumerate them later, sample debug logs, etc.</p> <p>By having structured logs like this, we can easily search and analyse them in CloudWatch Logs Insight.</p> CloudWatch Logs Insight Example <p></p>"},{"location":"tutorial/#tracing","title":"Tracing","text":"Note <p>You won't see any traces in AWS X-Ray when executing your function locally.</p> <p>The next improvement is to add distributed tracing to your stack. Traces help you visualize end-to-end transactions or parts of it to easily debug upstream/downstream anomalies.</p> <p>Combined with structured logs, it is an important step to be able to observe how your application runs in production.</p>"},{"location":"tutorial/#generating-traces","title":"Generating traces","text":"<p>AWS X-Ray is the distributed tracing service we're going to use. But how do we generate application traces in the first place?</p> <p>It's a two-step process:</p> <ol> <li>Enable tracing in your Lambda function.</li> <li>Instrument your application code.</li> </ol> <p>Let's explore how we can instrument our code with AWS X-Ray SDK, and then simplify it with Powertools for AWS Lambda (Python) Tracer feature.</p> app.pytemplate.yamlrequirements.txt <pre><code>from aws_xray_sdk.core import xray_recorder\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"APP\")\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@xray_recorder.capture('hello_name')\ndef hello_name(name):\n    logger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@xray_recorder.capture('hello')\ndef hello():\n    logger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@xray_recorder.capture('handler')\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\nFunction:\nTimeout: 3\nApi:\nTracingEnabled: true\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: hello_world/\nHandler: app.lambda_handler\nRuntime: python3.9\nTracing: Active\nEvents:\nHelloWorld:\nType: Api\nProperties:\nPath: /hello\nMethod: get\nHelloWorldName:\nType: Api\nProperties:\nPath: /hello/{name}\nMethod: get\nOutputs:\nHelloWorldApi:\nDescription: \"API Gateway endpoint URL for Prod stage for Hello World function\"\nValue: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <pre><code>aws-lambda-powertools\naws-xray-sdk\n</code></pre> <p>Let's break it down:</p> <ul> <li>L1: First, we import AWS X-Ray SDK. <code>xray_recorder</code> records blocks of code being traced (subsegment). It also sends generated traces to the AWS X-Ray daemon running in the Lambda service who subsequently forwards them to AWS X-Ray service.</li> <li>L13,20,27: We decorate our function so the SDK traces the end-to-end execution, and the argument names the generated block being traced.</li> </ul> Question <p>But how do I enable tracing for the Lambda function and what permissions do I need?</p> <p>We've made the following changes in <code>template.yaml</code> for this to work seamless:</p> <ul> <li>L7-8: Enables tracing for Amazon API Gateway.</li> <li>L16: Enables tracing for our Serverless Function. This will also add a managed IAM Policy named AWSXRayDaemonWriteAccess to allow Lambda to send traces to AWS X-Ray.</li> </ul> <p>You can now build and deploy our updates with <code>sam build &amp;&amp; sam deploy</code>. Once deployed, try invoking the application via the API endpoint, and visit AWS X-Ray Console to see how much progress we've made so far!!</p> <p></p>"},{"location":"tutorial/#enriching-our-generated-traces","title":"Enriching our generated traces","text":"<p>What we've done helps bring an initial visibility, but we can do so much more.</p> Question <p>You're probably asking yourself at least the following questions:</p> <ul> <li>What if I want to search traces by customer name?</li> <li>What about grouping traces with cold starts?</li> <li>Better yet, what if we want to include the request or response of our functions as part of the trace?</li> </ul> <p>Within AWS X-Ray, we can answer these questions by using two features: tracing Annotations and Metadata.</p> <p>Annotations are simple key-value pairs that are indexed for use with filter expressions. Metadata are key-value pairs with values of any type, including objects and lists, but that are not indexed.</p> <p>Let's put them into action.</p> Enriching traces with annotations and metadata<pre><code>from aws_xray_sdk.core import patch_all, xray_recorder\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"APP\")\n\napp = APIGatewayRestResolver()\ncold_start = True\npatch_all()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@xray_recorder.capture('hello_name')\ndef hello_name(name):\nsubsegment = xray_recorder.current_subsegment()\nsubsegment.put_annotation(key=\"User\", value=name)\nlogger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@xray_recorder.capture('hello')\ndef hello():\nsubsegment = xray_recorder.current_subsegment()\nsubsegment.put_annotation(key=\"User\", value=\"unknown\")\nlogger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@xray_recorder.capture('handler')\ndef lambda_handler(event, context):\nglobal cold_start\nsubsegment = xray_recorder.current_subsegment()\nif cold_start:\nsubsegment.put_annotation(key=\"ColdStart\", value=cold_start)\ncold_start = False\nelse:\nsubsegment.put_annotation(key=\"ColdStart\", value=cold_start)\nresult = app.resolve(event, context)\nsubsegment.put_metadata(\"response\", result)\nreturn result\n</code></pre> <p>Let's break it down:</p> <ul> <li>L10: We track Lambda cold start by setting global variable outside the handler; this is executed once per sandbox Lambda creates. This information provides an overview of how often the sandbox is reused by Lambda, which directly impacts the performance of each transaction.</li> <li>L17-18: We use AWS X-Ray SDK to add <code>User</code> annotation on <code>hello_name</code> subsegment. This will allow us to filter traces using the <code>User</code> value.</li> <li>L26-27: We repeat what we did in L17-18 except we use the value <code>unknown</code> since we don't have that information.</li> <li>L35: We use <code>global</code> to modify our global variable defined in the outer scope.</li> <li>37-42: We add <code>ColdStart</code> annotation and flip the value of <code>cold_start</code> variable, so that subsequent requests annotates the value <code>false</code> when the sandbox is reused.</li> <li>L45: We include the final response under <code>response</code> key as part of the <code>handler</code> subsegment.</li> </ul> Info <p>If you want to understand how the Lambda execution environment (sandbox) works and why cold starts can occur, see this blog series on Lambda performance.</p> <p>Repeat the process of building, deploying, and invoking your application via the API endpoint.</p> <p>Within the AWS X-Ray Console, you should now be able to group traces by the <code>User</code> and <code>ColdStart</code> annotation.</p> <p></p> <p>If you choose any of the traces available, try opening the <code>handler</code> subsegment and you should see the response of your Lambda function under the <code>Metadata</code> tab.</p> <p></p>"},{"location":"tutorial/#simplifying-with-tracer","title":"Simplifying with Tracer","text":"<p>Cross-cutting concerns like filtering traces by Cold Start, including response as well as exceptions as tracing metadata can take a considerable amount of boilerplate.</p> <p>We can simplify our previous patterns by using Powertools for AWS Lambda (Python) Tracer; a thin wrapper on top of X-Ray SDK.</p> Note <p>You can now safely remove <code>aws-xray-sdk</code> from <code>requirements.txt</code>; keep <code>aws-lambda-powertools</code> only.</p> Refactoring with Powertools for AWS Lambda (Python) Tracer<pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"APP\")\ntracer = Tracer(service=\"APP\")\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@tracer.capture_method\ndef hello_name(name):\ntracer.put_annotation(key=\"User\", value=name)\nlogger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@tracer.capture_method\ndef hello():\ntracer.put_annotation(key=\"User\", value=\"unknown\")\nlogger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <p>Decorators, annotations and metadata are largely the same, except we now have a much cleaner code as the boilerplate is gone. Here's what's changed compared to AWS X-Ray SDK approach:</p> <ul> <li>L6: We initialize <code>Tracer</code> and define the name of our service (<code>APP</code>). We automatically run <code>patch_all</code> from AWS X-Ray SDK on your behalf. Any previously patched or non-imported library is simply ignored.</li> <li>L11: We use <code>@tracer.capture_method</code> decorator instead of <code>xray_recorder.capture</code>. We automatically create a subsegment named after the function name (<code>## hello_name</code>), and add the response/exception as tracing metadata.</li> <li>L13: Putting annotations remain exactly the same UX.</li> <li>L27: We use <code>@tracer.lambda_handler</code> so we automatically add <code>ColdStart</code> annotation within Tracer itself. We also add a new <code>Service</code> annotation using the value of <code>Tracer(service=\"APP\")</code>, so that you can filter traces by the service your function(s) represent.</li> </ul> <p>Another subtle difference is that you can now run your Lambda functions and unit test them locally without having to explicitly disable Tracer.</p> <p>Powertools for AWS Lambda (Python) optimizes for Lambda compute environment. As such, we add these and other common approaches to accelerate your development, so you don't worry about implementing every cross-cutting concern.</p> Tip <p>You can opt-out some of these behaviours like disabling response capturing,  explicitly patching only X modules, etc.</p> <p>Repeat the process of building, deploying, and invoking your application via the API endpoint. Within the AWS X-Ray Console, you should see a similar view:</p> <p></p> Tip <p>Consider using Amazon CloudWatch ServiceLens view as it aggregates AWS X-Ray traces and CloudWatch metrics and logs in one view.</p> <p>From here, you can browse to specific logs in CloudWatch Logs Insight, Metrics Dashboard or AWS X-Ray traces.</p> <p></p> Info <p>For more information on Amazon CloudWatch ServiceLens, please visit link.</p>"},{"location":"tutorial/#custom-metrics","title":"Custom Metrics","text":""},{"location":"tutorial/#creating-metrics","title":"Creating metrics","text":"<p>Let's add custom metrics to better understand our application and business behavior (e.g. number of reservations, etc.).</p> <p>By default, AWS Lambda adds invocation and performance metrics, and Amazon API Gateway adds latency and some HTTP metrics.</p> Tip <p>You can optionally enable detailed metrics per each API route, stage, and method in API Gateway.</p> <p>Let's expand our application with custom metrics using AWS SDK to see how it works, then let's upgrade it with Powertools for AWS Lambda (Python) :-)</p> app.pytemplate.yaml <pre><code>import os\n\nimport boto3\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\ncold_start = True\nmetric_namespace = \"MyApp\"\nlogger = Logger(service=\"APP\")\ntracer = Tracer(service=\"APP\")\nmetrics = boto3.client(\"cloudwatch\")\napp = APIGatewayRestResolver()\n\n\n@tracer.capture_method\ndef add_greeting_metric(service: str = \"APP\"):\nfunction_name = os.getenv(\"AWS_LAMBDA_FUNCTION_NAME\", \"undefined\")\nservice_dimension = {\"Name\": \"service\", \"Value\": service}\nfunction_dimension = {\"Name\": \"function_name\", \"Value\": function_name}\nis_cold_start = True\nglobal cold_start\nif cold_start:\ncold_start = False\nelse:\nis_cold_start = False\nreturn metrics.put_metric_data(\nMetricData=[\n{\n\"MetricName\": \"SuccessfulGreetings\",\n\"Dimensions\": [service_dimension],\n\"Unit\": \"Count\",\n\"Value\": 1,\n},\n{\n\"MetricName\": \"ColdStart\",\n\"Dimensions\": [service_dimension, function_dimension],\n\"Unit\": \"Count\",\n\"Value\": int(is_cold_start)\n}\n],\nNamespace=metric_namespace,\n)\n@app.get(\"/hello/&lt;name&gt;\")\n@tracer.capture_method\ndef hello_name(name):\n    tracer.put_annotation(key=\"User\", value=name)\n    logger.info(f\"Request from {name} received\")\nadd_greeting_metric()\nreturn {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@tracer.capture_method\ndef hello():\n    tracer.put_annotation(key=\"User\", value=\"unknown\")\n    logger.info(\"Request from unknown received\")\nadd_greeting_metric()\nreturn {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\nFunction:\nTimeout: 3\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nCodeUri: hello_world/\nHandler: app.lambda_handler\nRuntime: python3.9\nTracing: Active\nEvents:\nHelloWorld:\nType: Api\nProperties:\nPath: /hello\nMethod: get\nHelloWorldName:\nType: Api\nProperties:\nPath: /hello/{name}\nMethod: get\nPolicies:\n- CloudWatchPutMetricPolicy: {}\nOutputs:\nHelloWorldApi:\nDescription: \"API Gateway endpoint URL for Prod stage for Hello World function\"\nValue: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <p>There's a lot going on, let's break this down:</p> <ul> <li>L10: We define a container where all of our application metrics will live <code>MyApp</code>, a.k.a Metrics Namespace.</li> <li>L14: We initialize a CloudWatch client to send metrics later.</li> <li>L19-47: We create a custom function to prepare and send <code>ColdStart</code> and <code>SuccessfulGreetings</code> metrics using CloudWatch expected data structure. We also set dimensions of these metrics.<ul> <li>Think of them as metadata to define to slice and dice them later; an unique metric is a combination of metric name + metric dimension(s).</li> </ul> </li> <li>L55,64: We call our custom function to create metrics for every greeting received.</li> </ul> Question <p>But what permissions do I need to send metrics to CloudWatch?</p> <p>Within <code>template.yaml</code>, we add CloudWatchPutMetricPolicy policy in SAM.</p> Adding metrics via AWS SDK gives a lot of flexibility at a cost <p><code>put_metric_data</code> is a synchronous call to CloudWatch Metrics API. This means establishing a connection to CloudWatch endpoint, sending metrics payload, and waiting from a response.</p> <p>It will be visible in your AWS X-RAY traces as additional external call. Given your architecture scale, this approach might lead to disadvantages such as increased cost of measuring data collection and increased Lambda latency.</p>"},{"location":"tutorial/#simplifying-with-metrics","title":"Simplifying with Metrics","text":"<p>Powertools for AWS Lambda (Python) Metrics uses Amazon CloudWatch Embedded Metric Format (EMF) to create custom metrics asynchronously via a native integration with Lambda.</p> <p>In general terms, EMF is a specification that expects metrics in a JSON payload within CloudWatch Logs. Lambda ingests all logs emitted by a given function into CloudWatch Logs. CloudWatch automatically looks up for log entries that follow the EMF format and transforms them into a CloudWatch metric.</p> Info <p>If you are interested in the details of the EMF mechanism, follow blog post.</p> <p>Let's implement that using Metrics:</p> Refactoring with Powertools for AWS Lambda (Python) Metrics<pre><code>from aws_lambda_powertools import Logger, Tracer, Metrics\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.metrics import MetricUnit\nlogger = Logger(service=\"APP\")\ntracer = Tracer(service=\"APP\")\nmetrics = Metrics(namespace=\"MyApp\", service=\"APP\")\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@tracer.capture_method\ndef hello_name(name):\n    tracer.put_annotation(key=\"User\", value=name)\n    logger.info(f\"Request from {name} received\")\nmetrics.add_metric(name=\"SuccessfulGreetings\", unit=MetricUnit.Count, value=1)\nreturn {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@tracer.capture_method\ndef hello():\n    tracer.put_annotation(key=\"User\", value=\"unknown\")\n    logger.info(\"Request from unknown received\")\nmetrics.add_metric(name=\"SuccessfulGreetings\", unit=MetricUnit.Count, value=1)\nreturn {\"message\": \"hello unknown!\"}\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event, context):\n    try:\n        return app.resolve(event, context)\n    except Exception as e:\n        logger.exception(e)\n        raise\n</code></pre> <p>That's a lot less boilerplate code! Let's break this down:</p> <ul> <li>L9: We initialize <code>Metrics</code> with our service name (<code>APP</code>) and metrics namespace (<code>MyApp</code>), reducing the need to add the <code>service</code> dimension for every metric and setting the namespace later</li> <li>L18, 27: We use <code>add_metric</code> similarly to our custom function, except we now have an enum <code>MetricCount</code> to help us understand which Metric Units we have at our disposal</li> <li>L33: We use <code>@metrics.log_metrics</code> decorator to ensure that our metrics are aligned with the EMF output and validated before-hand, like in case we forget to set namespace, or accidentally use a metric unit as a string that doesn't exist in CloudWatch.</li> <li>L33: We also use <code>capture_cold_start_metric=True</code> so we don't have to handle that logic either. Note that Metrics does not publish a warm invocation metric (ColdStart=0) for cost reasons. As such, treat the absence (sparse metric) as a non-cold start invocation.</li> </ul> <p>Repeat the process of building, deploying, and invoking your application via the API endpoint a few times to generate metrics - Artillery and K6.io are quick ways to generate some load.</p> <p>Within CloudWatch Metrics view, you should see <code>MyApp</code> custom namespace with your custom metrics there and <code>SuccessfulGreetings</code> available to graph.</p> <p></p> <p>If you're curious about how the EMF portion of your function logs look like, you can quickly go to CloudWatch ServiceLens view, choose your function and open logs. You will see a similar entry that looks like this:</p> <pre><code>{\n\"_aws\": {\n\"Timestamp\": 1638115724269,\n\"CloudWatchMetrics\": [\n{\n\"Namespace\": \"CustomMetrics\",\n\"Dimensions\": [\n[\n\"method\",\n\"service\"\n]\n],\n\"Metrics\": [\n{\n\"Name\": \"AppMethodsInvocations\",\n\"Unit\": \"Count\"\n}\n]\n}\n]\n},\n\"method\": \"/hello/&lt;name&gt;\",\n\"service\": \"APP\",\n\"AppMethodsInvocations\": [\n1\n]\n}\n</code></pre>"},{"location":"tutorial/#final-considerations","title":"Final considerations","text":"<p>We covered a lot of ground here and we only scratched the surface of the feature set available within Powertools for AWS Lambda (Python).</p> <p>When it comes to the observability features (Tracer, Metrics, Logging), don't stop there! The goal here is to ensure you can ask arbitrary questions to assess your system's health; these features are only part of the wider story!</p> <p>This requires a change in mindset to ensure operational excellence is part of the software development lifecycle.</p> Tip <p>You can find more details on other leading practices described in the Well-Architected Serverless Lens.</p> <p>Powertools for AWS Lambda (Python) is largely designed to make some of these practices easier to adopt from day 1.</p> Have ideas for other tutorials? <p>You can open up a documentation issue, or via e-mail aws-lambda-powertools-feedback@amazon.com.</p>"},{"location":"utilities/batch/","title":"Batch Processing","text":"<p>The batch processing utility handles partial failures when processing batches from Amazon SQS, Amazon Kinesis Data Streams, and Amazon DynamoDB Streams.</p>"},{"location":"utilities/batch/#key-features","title":"Key features","text":"<ul> <li>Reports batch item failures to reduce number of retries for a record upon errors</li> <li>Simple interface to process each batch record</li> <li>Integrates with Event Source Data Classes and Parser (Pydantic) for self-documenting record schema</li> <li>Build your own batch processor by extending primitives</li> </ul>"},{"location":"utilities/batch/#background","title":"Background","text":"<p>When using SQS, Kinesis Data Streams, or DynamoDB Streams as a Lambda event source, your Lambda functions are triggered with a batch of messages.</p> <p>If your function fails to process any message from the batch, the entire batch returns to your queue or stream. This same batch is then retried until either condition happens first: a) your Lambda function returns a successful response, b) record reaches maximum retry attempts, or c) when records expire.</p> <p>With this utility, batch records are processed individually \u2013 only messages that failed to be processed return to the queue or stream for a further retry. This works when two mechanisms are in place:</p> <ol> <li><code>ReportBatchItemFailures</code> is set in your SQS, Kinesis, or DynamoDB event source properties</li> <li>A specific response is returned so Lambda knows which records should not be deleted during partial responses</li> </ol> Warning: This utility lowers the chance of processing records more than once; it does not guarantee it <p>We recommend implementing processing logic in an idempotent manner wherever possible.</p> <p>You can find more details on how Lambda works with either SQS, Kinesis, or DynamoDB in the AWS Documentation.</p>"},{"location":"utilities/batch/#getting-started","title":"Getting started","text":"<p>Regardless whether you're using SQS, Kinesis Data Streams or DynamoDB Streams, you must configure your Lambda function event source to use <code>ReportBatchItemFailures</code>.</p> <p>You do not need any additional IAM permissions to use this utility, except for what each event source requires.</p>"},{"location":"utilities/batch/#required-resources","title":"Required resources","text":"<p>The remaining sections of the documentation will rely on these samples. For completeness, this demonstrates IAM permissions and Dead Letter Queue where batch records will be sent after 2 retries were attempted.</p> SQSKinesis Data StreamsDynamoDB Streams template.yaml<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\nFunction:\nTimeout: 5\nMemorySize: 256\nRuntime: python3.10\nTracing: Active\nEnvironment:\nVariables:\nLOG_LEVEL: INFO\nPOWERTOOLS_SERVICE_NAME: hello\n\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nHandler: app.lambda_handler\nCodeUri: hello_world\nPolicies:\n- SQSPollerPolicy:\nQueueName: !GetAtt SampleQueue.QueueName\nEvents:\nBatch:\nType: SQS\nProperties:\nQueue: !GetAtt SampleQueue.Arn\nFunctionResponseTypes:\n- ReportBatchItemFailures\nSampleDLQ:\nType: AWS::SQS::Queue\n\nSampleQueue:\nType: AWS::SQS::Queue\nProperties:\nVisibilityTimeout: 30 # Fn timeout * 6\nSqsManagedSseEnabled: true\nRedrivePolicy:\nmaxReceiveCount: 2\ndeadLetterTargetArn: !GetAtt SampleDLQ.Arn\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\nFunction:\nTimeout: 5\nMemorySize: 256\nRuntime: python3.10\nTracing: Active\nEnvironment:\nVariables:\nLOG_LEVEL: INFO\nPOWERTOOLS_SERVICE_NAME: hello\n\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nHandler: app.lambda_handler\nCodeUri: hello_world\nPolicies:\n# Lambda Destinations require additional permissions\n# to send failure records to DLQ from Kinesis/DynamoDB\n- Version: \"2012-10-17\"\nStatement:\nEffect: \"Allow\"\nAction:\n- sqs:GetQueueAttributes\n- sqs:GetQueueUrl\n- sqs:SendMessage\nResource: !GetAtt SampleDLQ.Arn\nEvents:\nKinesisStream:\nType: Kinesis\nProperties:\nStream: !GetAtt SampleStream.Arn\nBatchSize: 100\nStartingPosition: LATEST\nMaximumRetryAttempts: 2\nDestinationConfig:\nOnFailure:\nDestination: !GetAtt SampleDLQ.Arn\nFunctionResponseTypes:\n- ReportBatchItemFailures\nSampleDLQ:\nType: AWS::SQS::Queue\n\nSampleStream:\nType: AWS::Kinesis::Stream\nProperties:\nShardCount: 1\nStreamEncryption:\nEncryptionType: KMS\nKeyId: alias/aws/kinesis\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\nFunction:\nTimeout: 5\nMemorySize: 256\nRuntime: python3.10\nTracing: Active\nEnvironment:\nVariables:\nLOG_LEVEL: INFO\nPOWERTOOLS_SERVICE_NAME: hello\n\nResources:\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nHandler: app.lambda_handler\nCodeUri: hello_world\nPolicies:\n# Lambda Destinations require additional permissions\n# to send failure records from Kinesis/DynamoDB\n- Version: \"2012-10-17\"\nStatement:\nEffect: \"Allow\"\nAction:\n- sqs:GetQueueAttributes\n- sqs:GetQueueUrl\n- sqs:SendMessage\nResource: !GetAtt SampleDLQ.Arn\nEvents:\nDynamoDBStream:\nType: DynamoDB\nProperties:\nStream: !GetAtt SampleTable.StreamArn\nStartingPosition: LATEST\nMaximumRetryAttempts: 2\nDestinationConfig:\nOnFailure:\nDestination: !GetAtt SampleDLQ.Arn\nFunctionResponseTypes:\n- ReportBatchItemFailures\nSampleDLQ:\nType: AWS::SQS::Queue\n\nSampleTable:\nType: AWS::DynamoDB::Table\nProperties:\nBillingMode: PAY_PER_REQUEST\nAttributeDefinitions:\n- AttributeName: pk\nAttributeType: S\n- AttributeName: sk\nAttributeType: S\nKeySchema:\n- AttributeName: pk\nKeyType: HASH\n- AttributeName: sk\nKeyType: RANGE\nSSESpecification:\nSSEEnabled: true\nStreamSpecification:\nStreamViewType: NEW_AND_OLD_IMAGES\n</code></pre>"},{"location":"utilities/batch/#processing-messages-from-sqs","title":"Processing messages from SQS","text":"<p>Processing batches from SQS works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.SQS</code> for the event type</li> <li>Define your function to handle each batch record, and use <code>SQSRecord</code> type annotation for autocompletion</li> <li>Use <code>process_partial_response</code> to kick off processing</li> </ol> Info <p>This code example optionally uses Tracer and Logger for completion.</p> RecommendedAs a context managerAs a decorator (legacy)Sample responseSample event <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nBatchProcessor,\nEventType,\nprocess_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\npayload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\npayload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\nwith processor(records=batch, handler=record_handler):\nprocessed_messages = processor.process()  # kick off processing, return list[tuple]\nlogger.info(f\"Processed ${len(processed_messages)} messages\")\n\nreturn processor.response()\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nBatchProcessor,\nEventType,\nbatch_processor,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\npayload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\nreturn processor.response()\n</code></pre> <p>The second record failed to be processed, therefore the processor added its message ID in the response.</p> <pre><code>{\n\"batchItemFailures\": [\n{\n\"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n}\n]\n}\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n\"body\": \"{\\\"Message\\\": \\\"success\\\"}\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n\"awsRegion\": \"us-east-1\"\n},\n{\n\"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n\"body\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n\"awsRegion\": \"us-east-1\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/batch/#fifo-queues","title":"FIFO queues","text":"<p>When using SQS FIFO queues, we will stop processing messages after the first failure, and return all failed and unprocessed messages in <code>batchItemFailures</code>. This helps preserve the ordering of messages in your queue.</p> RecommendedAs a context managerAs a decorator (legacy) <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nSqsFifoPartialProcessor,\nprocess_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = SqsFifoPartialProcessor()\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import SqsFifoPartialProcessor\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = SqsFifoPartialProcessor()\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, handler=record_handler):\n        processor.process()  # kick off processing, return List[Tuple]\n\n    return processor.response()\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nSqsFifoPartialProcessor,\nbatch_processor,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = SqsFifoPartialProcessor()\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre>"},{"location":"utilities/batch/#processing-messages-from-kinesis","title":"Processing messages from Kinesis","text":"<p>Processing batches from Kinesis works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.KinesisDataStreams</code> for the event type</li> <li>Define your function to handle each batch record, and use <code>KinesisStreamRecord</code> type annotation for autocompletion</li> <li>Use <code>process_partial_response</code> to kick off processing</li> </ol> Info <p>This code example optionally uses Tracer and Logger for completion.</p> RecommendedAs a context managerAs a decorator (legacy)Sample responseSample event <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nBatchProcessor,\nEventType,\nprocess_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\nKinesisStreamRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: KinesisStreamRecord):\nlogger.info(record.kinesis.data_as_text)\n    payload: dict = record.kinesis.data_as_json()\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\nKinesisStreamRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: KinesisStreamRecord):\nlogger.info(record.kinesis.data_as_text)\n    payload: dict = record.kinesis.data_as_json()\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nbatch = event[\"Records\"]\nwith processor(records=batch, handler=record_handler):\nprocessed_messages = processor.process()  # kick off processing, return list[tuple]\nlogger.info(f\"Processed ${len(processed_messages)} messages\")\n\nreturn processor.response()\n</code></pre> <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nBatchProcessor,\nEventType,\nbatch_processor,\n)\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\nKinesisStreamRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: KinesisStreamRecord):\nlogger.info(record.kinesis.data_as_text)\n    payload: dict = record.kinesis.data_as_json()\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre> <p>The second record failed to be processed, therefore the processor added its sequence number in the response.</p> <pre><code>{\n\"batchItemFailures\": [\n{\n\"itemIdentifier\": \"6006958808509702859251049540584488075644979031228738\"\n}\n]\n}\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"kinesis\": {\n\"kinesisSchemaVersion\": \"1.0\",\n\"partitionKey\": \"1\",\n\"sequenceNumber\": \"4107859083838847772757075850904226111829882106684065\",\n\"data\": \"eyJNZXNzYWdlIjogInN1Y2Nlc3MifQ==\",\n\"approximateArrivalTimestamp\": 1545084650.987\n},\n\"eventSource\": \"aws:kinesis\",\n\"eventVersion\": \"1.0\",\n\"eventID\": \"shardId-000000000006:4107859083838847772757075850904226111829882106684065\",\n\"eventName\": \"aws:kinesis:record\",\n\"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n\"awsRegion\": \"us-east-2\",\n\"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n},\n{\n\"kinesis\": {\n\"kinesisSchemaVersion\": \"1.0\",\n\"partitionKey\": \"1\",\n\"sequenceNumber\": \"6006958808509702859251049540584488075644979031228738\",\n\"data\": \"c3VjY2Vzcw==\",\n\"approximateArrivalTimestamp\": 1545084650.987\n},\n\"eventSource\": \"aws:kinesis\",\n\"eventVersion\": \"1.0\",\n\"eventID\": \"shardId-000000000006:6006958808509702859251049540584488075644979031228738\",\n\"eventName\": \"aws:kinesis:record\",\n\"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n\"awsRegion\": \"us-east-2\",\n\"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/batch/#processing-messages-from-dynamodb","title":"Processing messages from DynamoDB","text":"<p>Processing batches from DynamoDB Streams works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.DynamoDBStreams</code> for the event type</li> <li>Define your function to handle each batch record, and use <code>DynamoDBRecord</code> type annotation for autocompletion</li> <li>Use <code>process_partial_response</code> to kick off processing</li> </ol> Info <p>This code example optionally uses Tracer and Logger for completion.</p> RecommendedAs a context managerAs a decorator (legacy)Sample responseSample event <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nBatchProcessor,\nEventType,\nprocess_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\nDynamoDBRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: DynamoDBRecord):\nif record.dynamodb and record.dynamodb.new_image:\n        logger.info(record.dynamodb.new_image)\n        message = record.dynamodb.new_image.get(\"Message\")\n        if message:\n            payload: dict = json.loads(message)\n            logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\nDynamoDBRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: DynamoDBRecord):\nif record.dynamodb and record.dynamodb.new_image:\n        logger.info(record.dynamodb.new_image)\n        message = record.dynamodb.new_image.get(\"Message\")\n        if message:\n            payload: dict = json.loads(message)\n            logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nbatch = event[\"Records\"]\nwith processor(records=batch, handler=record_handler):\nprocessed_messages = processor.process()  # kick off processing, return list[tuple]\nlogger.info(f\"Processed ${len(processed_messages)} messages\")\n\nreturn processor.response()\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\nBatchProcessor,\nEventType,\nbatch_processor,\n)\nfrom aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\nDynamoDBRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: DynamoDBRecord):\nif record.dynamodb and record.dynamodb.new_image:\n        logger.info(record.dynamodb.new_image)\n        message = record.dynamodb.new_image.get(\"Message\")\n        if message:\n            payload: dict = json.loads(message)\n            logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre> <p>The second record failed to be processed, therefore the processor added its sequence number in the response.</p> <pre><code>{\n\"batchItemFailures\": [\n{\n\"itemIdentifier\": \"8640712661\"\n}\n]\n}\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"eventID\": \"1\",\n\"eventVersion\": \"1.0\",\n\"dynamodb\": {\n\"Keys\": {\n\"Id\": {\n\"N\": \"101\"\n}\n},\n\"NewImage\": {\n\"Message\": {\n\"S\": \"failure\"\n}\n},\n\"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n\"SequenceNumber\": \"3275880929\",\n\"SizeBytes\": 26\n},\n\"awsRegion\": \"us-west-2\",\n\"eventName\": \"INSERT\",\n\"eventSourceARN\": \"eventsource_arn\",\n\"eventSource\": \"aws:dynamodb\"\n},\n{\n\"eventID\": \"1\",\n\"eventVersion\": \"1.0\",\n\"dynamodb\": {\n\"Keys\": {\n\"Id\": {\n\"N\": \"101\"\n}\n},\n\"NewImage\": {\n\"SomethingElse\": {\n\"S\": \"success\"\n}\n},\n\"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n\"SequenceNumber\": \"8640712661\",\n\"SizeBytes\": 26\n},\n\"awsRegion\": \"us-west-2\",\n\"eventName\": \"INSERT\",\n\"eventSourceARN\": \"eventsource_arn\",\n\"eventSource\": \"aws:dynamodb\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/batch/#partial-failure-mechanics","title":"Partial failure mechanics","text":"<p>All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch:</p> <ul> <li>All records successfully processed. We will return an empty list of item failures <code>{'batchItemFailures': []}</code></li> <li>Partial success with some exceptions. We will return a list of all item IDs/sequence numbers that failed processing</li> <li>All records failed to be processed. We will raise <code>BatchProcessingError</code> exception with a list of all exceptions raised when processing</li> </ul>"},{"location":"utilities/batch/#processing-messages-asynchronously","title":"Processing messages asynchronously","text":"<p>New to AsyncIO? Read this comprehensive guide first.</p> <p>You can use <code>AsyncBatchProcessor</code> class and <code>async_process_partial_response</code> function to process messages concurrently.</p> When is this useful? <p>Your use case might be able to process multiple records at the same time without conflicting with one another.</p> <p>For example, imagine you need to process multiple loyalty points and incrementally save in a database. While you await the database to confirm your records are saved, you could start processing another request concurrently.</p> <p>The reason this is not the default behaviour is that not all use cases can handle concurrency safely (e.g., loyalty points must be updated in order).</p> High-concurrency with AsyncBatchProcessor<pre><code>import httpx  # external dependency\n\nfrom aws_lambda_powertools.utilities.batch import (\nAsyncBatchProcessor,\n    EventType,\n    async_process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = AsyncBatchProcessor(event_type=EventType.SQS)\nasync def async_record_handler(record: SQSRecord):\n# Yield control back to the event loop to schedule other tasks\n    # while you await from a response from httpbin.org\n    async with httpx.AsyncClient() as client:\n        ret = await client.get(\"https://httpbin.org/get\")\n\n    return ret.status_code\n\n\ndef lambda_handler(event, context: LambdaContext):\nreturn async_process_partial_response(\nevent=event,\nrecord_handler=async_record_handler,\nprocessor=processor,\n        context=context,\n    )\n</code></pre> Using tracer? <p><code>AsyncBatchProcessor</code> uses <code>asyncio.gather</code> which can cause side effects and reach trace limits at high concurrency.</p> <p>See Tracing concurrent asynchronous functions.</p>"},{"location":"utilities/batch/#advanced","title":"Advanced","text":""},{"location":"utilities/batch/#pydantic-integration","title":"Pydantic integration","text":"<p>You can bring your own Pydantic models via <code>model</code> parameter when inheriting from <code>SqsRecordModel</code>, <code>KinesisDataStreamRecord</code>, or <code>DynamoDBStreamRecordModel</code></p> <p>Inheritance is importance because we need to access message IDs and sequence numbers from these records in the event of failure. Mypy is fully integrated with this utility, so it should identify whether you're passing the incorrect Model.</p> SQSSQS - Sample Event Kinesis Data StreamsKinesis - Sample Event DynamoDB StreamsDynamoDB - Sample Event  <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.parser.models import SqsRecordModel\nfrom aws_lambda_powertools.utilities.parser.types import Json\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass Order(BaseModel):\n    item: dict\n\n\nclass OrderSqsRecord(SqsRecordModel):\nbody: Json[Order]  # deserialize order data from JSON string\n\n\nprocessor = BatchProcessor(event_type=EventType.SQS, model=OrderSqsRecord)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: OrderSqsRecord):\nlogger.info(record.body.item)\n    return record.body.item\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n\"body\": \"{\\\"item\\\": {\\\"laptop\\\": \\\"amd\\\"}}\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n\"awsRegion\": \"us-east-1\"\n},\n{\n\"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n\"body\": \"{\\\"item\\\": {\\\"keyboard\\\": \\\"classic\\\"}}\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n\"awsRegion\": \"us-east-1\"\n}\n]\n}\n</code></pre> <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.parser.models import (\nKinesisDataStreamRecord,\nKinesisDataStreamRecordPayload,\n)\nfrom aws_lambda_powertools.utilities.parser.types import Json\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass Order(BaseModel):\n    item: dict\n\n\nclass OrderKinesisPayloadRecord(KinesisDataStreamRecordPayload):\ndata: Json[Order]\n\n\nclass OrderKinesisRecord(KinesisDataStreamRecord):\n    kinesis: OrderKinesisPayloadRecord\n\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams, model=OrderKinesisRecord)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: OrderKinesisRecord):\nlogger.info(record.kinesis.data.item)\n    return record.kinesis.data.item\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"kinesis\": {\n\"kinesisSchemaVersion\": \"1.0\",\n\"partitionKey\": \"1\",\n\"sequenceNumber\": \"4107859083838847772757075850904226111829882106684065\",\n\"data\": \"eyJpdGVtIjogeyJsYXB0b3AiOiAiYW1kIn19Cg==\",\n\"approximateArrivalTimestamp\": 1545084650.987\n},\n\"eventSource\": \"aws:kinesis\",\n\"eventVersion\": \"1.0\",\n\"eventID\": \"shardId-000000000006:4107859083838847772757075850904226111829882106684065\",\n\"eventName\": \"aws:kinesis:record\",\n\"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n\"awsRegion\": \"us-east-2\",\n\"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n},\n{\n\"kinesis\": {\n\"kinesisSchemaVersion\": \"1.0\",\n\"partitionKey\": \"1\",\n\"sequenceNumber\": \"6006958808509702859251049540584488075644979031228738\",\n\"data\": \"eyJpdGVtIjogeyJrZXlib2FyZCI6ICJjbGFzc2ljIn19Cg==\",\n\"approximateArrivalTimestamp\": 1545084650.987\n},\n\"eventSource\": \"aws:kinesis\",\n\"eventVersion\": \"1.0\",\n\"eventID\": \"shardId-000000000006:6006958808509702859251049540584488075644979031228738\",\n\"eventName\": \"aws:kinesis:record\",\n\"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n\"awsRegion\": \"us-east-2\",\n\"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n}\n]\n}\n</code></pre> <pre><code>import json\nfrom typing import Dict, Optional\n\nfrom typing_extensions import Literal\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel, validator\nfrom aws_lambda_powertools.utilities.parser.models import (\nDynamoDBStreamChangedRecordModel,\nDynamoDBStreamRecordModel,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass Order(BaseModel):\n    item: dict\n\n\nclass OrderDynamoDB(BaseModel):\nMessage: Order\n\n    # auto transform json string\n    # so Pydantic can auto-initialize nested Order model\n    @validator(\"Message\", pre=True)\n    def transform_message_to_dict(cls, value: Dict[Literal[\"S\"], str]):\n        return json.loads(value[\"S\"])\n\n\nclass OrderDynamoDBChangeRecord(DynamoDBStreamChangedRecordModel):\nNewImage: Optional[OrderDynamoDB]\n    OldImage: Optional[OrderDynamoDB]\n\n\nclass OrderDynamoDBRecord(DynamoDBStreamRecordModel):\ndynamodb: OrderDynamoDBChangeRecord\n\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams, model=OrderDynamoDBRecord)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: OrderDynamoDBRecord):\nif record.dynamodb.NewImage and record.dynamodb.NewImage.Message:\n        logger.info(record.dynamodb.NewImage.Message.item)\n        return record.dynamodb.NewImage.Message.item\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"eventID\": \"1\",\n\"eventVersion\": \"1.0\",\n\"dynamodb\": {\n\"Keys\": {\n\"Id\": {\n\"N\": \"101\"\n}\n},\n\"NewImage\": {\n\"Message\": {\n\"S\": \"{\\\"item\\\": {\\\"laptop\\\": \\\"amd\\\"}}\"\n}\n},\n\"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n\"SequenceNumber\": \"3275880929\",\n\"SizeBytes\": 26\n},\n\"awsRegion\": \"us-west-2\",\n\"eventName\": \"INSERT\",\n\"eventSourceARN\": \"eventsource_arn\",\n\"eventSource\": \"aws:dynamodb\"\n},\n{\n\"eventID\": \"1\",\n\"eventVersion\": \"1.0\",\n\"dynamodb\": {\n\"Keys\": {\n\"Id\": {\n\"N\": \"101\"\n}\n},\n\"NewImage\": {\n\"SomethingElse\": {\n\"S\": \"success\"\n}\n},\n\"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n\"SequenceNumber\": \"8640712661\",\n\"SizeBytes\": 26\n},\n\"awsRegion\": \"us-west-2\",\n\"eventName\": \"INSERT\",\n\"eventSourceARN\": \"eventsource_arn\",\n\"eventSource\": \"aws:dynamodb\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/batch/#accessing-processed-messages","title":"Accessing processed messages","text":"<p>Use the context manager to access a list of all returned values from your <code>record_handler</code> function.</p> <ul> <li>When successful. We will include a tuple with <code>success</code>, the result of <code>record_handler</code>, and the batch record</li> <li>When failed. We will include a tuple with <code>fail</code>, exception as a string, and the batch record</li> </ul> Accessing processed messages via context manager<pre><code>from __future__ import annotations\n\nimport json\nfrom typing import List, Tuple\n\nfrom typing_extensions import Literal\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nbatch = event[\"Records\"]\nwith processor(records=batch, handler=record_handler):\nprocessed_messages: List[Tuple] = processor.process()\nfor message in processed_messages:\nstatus: Literal[\"success\"] | Literal[\"fail\"] = message[0]\n        record: SQSRecord = message[2]\n\n        logger.info(status, record=record)\n\n    return processor.response()\n</code></pre>"},{"location":"utilities/batch/#accessing-lambda-context","title":"Accessing Lambda Context","text":"<p>Within your <code>record_handler</code> function, you might need access to the Lambda context to determine how much time you have left before your function times out.</p> <p>We can automatically inject the Lambda context into your <code>record_handler</code> if your function signature has a parameter named <code>lambda_context</code>. When using a context manager, you also need to pass the Lambda context object like in the example below.</p> RecommendedAs a decorator (legacy)As a context manager <pre><code>from typing import Optional\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord, lambda_context: Optional[LambdaContext] = None):\nif lambda_context is not None:\n        remaining_time = lambda_context.get_remaining_time_in_millis()\n        logger.info(remaining_time)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>from typing import Optional\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    batch_processor,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord, lambda_context: Optional[LambdaContext] = None):\nif lambda_context is not None:\n        remaining_time = lambda_context.get_remaining_time_in_millis()\n        logger.info(remaining_time)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre> <pre><code>from typing import Optional\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord, lambda_context: Optional[LambdaContext] = None):\nif lambda_context is not None:\n        remaining_time = lambda_context.get_remaining_time_in_millis()\n        logger.info(remaining_time)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\nwith processor(records=batch, handler=record_handler, lambda_context=context):\nresult = processor.process()\n\n    return result\n</code></pre>"},{"location":"utilities/batch/#extending-batchprocessor","title":"Extending BatchProcessor","text":"<p>You might want to bring custom logic to the existing <code>BatchProcessor</code> to slightly override how we handle successes and failures.</p> <p>For these scenarios, you can subclass <code>BatchProcessor</code> and quickly override <code>success_handler</code> and <code>failure_handler</code> methods:</p> <ul> <li><code>success_handler()</code> \u2013 Keeps track of successful batch records</li> <li><code>failure_handler()</code> \u2013 Keeps track of failed batch records</li> </ul> Example <p>Let's suppose you'd like to add a metric named <code>BatchRecordFailures</code> for each batch record that failed processing</p> Extending failure handling mechanism in BatchProcessor<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Metrics, Tracer\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\nExceptionInfo,\nFailureResponse,\nprocess_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass MyProcessor(BatchProcessor):\ndef failure_handler(self, record: SQSRecord, exception: ExceptionInfo) -&gt; FailureResponse:\nmetrics.add_metric(name=\"BatchRecordFailures\", unit=MetricUnit.Count, value=1)\nreturn super().failure_handler(record, exception)\nprocessor = MyProcessor(event_type=EventType.SQS)\nmetrics = Metrics(namespace=\"test\")\nlogger = Logger()\ntracer = Tracer()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event, context: LambdaContext):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre>"},{"location":"utilities/batch/#create-your-own-partial-processor","title":"Create your own partial processor","text":"<p>You can create your own partial batch processor from scratch by inheriting the <code>BasePartialProcessor</code> class, and implementing <code>_prepare()</code>, <code>_clean()</code>, <code>_process_record()</code> and <code>_async_process_record()</code>.</p> <ul> <li><code>_process_record()</code> \u2013 handles all processing logic for each individual message of a batch, including calling the <code>record_handler</code> (self.handler)</li> <li><code>_prepare()</code> \u2013 called once as part of the processor initialization</li> <li><code>_clean()</code> \u2013 teardown logic called once after <code>_process_record</code> completes</li> <li><code>_async_process_record()</code> \u2013 If you need to implement asynchronous logic, use this method, otherwise define it in your class with empty logic</li> </ul> <p>You can then use this class as a context manager, or pass it to <code>batch_processor</code> to use as a decorator on your Lambda handler function.</p> Creating a custom batch processor<pre><code>import os\nimport sys\nfrom random import randint\nfrom typing import Any\n\nimport boto3\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.batch import (\nBasePartialBatchProcessor,\nEventType,\nprocess_partial_response,\n)\n\ntable_name = os.getenv(\"TABLE_NAME\", \"table_not_found\")\n\nlogger = Logger()\n\n\nclass MyPartialProcessor(BasePartialBatchProcessor):\n\"\"\"\n    Process a record and stores successful results at a Amazon DynamoDB Table\n\n    Parameters\n    ----------\n    table_name: str\n        DynamoDB table name to write results to\n    \"\"\"\n\n    def __init__(self, table_name: str):\n        self.table_name = table_name\n\n        super().__init__(event_type=EventType.SQS)\n\ndef _prepare(self):\n# It's called once, *before* processing\n        # Creates table resource and clean previous results\n        self.ddb_table = boto3.resource(\"dynamodb\").Table(self.table_name)\n        self.success_messages.clear()\n\ndef _clean(self):\n# It's called once, *after* closing processing all records (closing the context manager)\n        # Here we're sending, at once, all successful messages to a ddb table\n        with self.ddb_table.batch_writer() as batch:\n            for result in self.success_messages:\n                batch.put_item(Item=result)\n\ndef _process_record(self, record):\n# It handles how your record is processed\n        # Here we're keeping the status of each run\n        # where self.handler is the record_handler function passed as an argument\n        try:\n            result = self.handler(record)  # record_handler passed to decorator/context manager\n            return self.success_handler(record, result)\n        except Exception as exc:\n            logger.error(exc)\n            return self.failure_handler(record, sys.exc_info())\n\ndef success_handler(self, record, result: Any):\nentry = (\"success\", result, record)\n        self.success_messages.append(record)\n        return entry\n\nasync def _async_process_record(self, record: dict):\nraise NotImplementedError()\n\n\nprocessor = MyPartialProcessor(table_name)\ndef record_handler(record):\n    return randint(0, 100)\n\n\ndef lambda_handler(event, context):\nreturn process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre>"},{"location":"utilities/batch/#caveats","title":"Caveats","text":""},{"location":"utilities/batch/#tracer-response-auto-capture-for-large-batch-sizes","title":"Tracer response auto-capture for large batch sizes","text":"<p>When using Tracer to capture responses for each batch record processing, you might exceed 64K of tracing data depending on what you return from your <code>record_handler</code> function, or how big is your batch size.</p> <p>If that's the case, you can configure Tracer to disable response auto-capturing.</p> Disabling Tracer response auto-capturing<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method(capture_response=False)\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre>"},{"location":"utilities/batch/#testing-your-code","title":"Testing your code","text":"<p>As there is no external calls, you can unit test your code with <code>BatchProcessor</code> quite easily.</p> <p>Example:</p> <p>Given a SQS batch where the first batch record succeeds and the second fails processing, we should have a single item reported in the function response.</p> getting_started_with_test.pygetting_started_with_test_app.pySample SQS event <pre><code>import json\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nimport pytest\nfrom getting_started_with_test_app import lambda_handler, processor\n\n\ndef load_event(path: Path):\n    with path.open() as f:\n        return json.load(f)\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n    return LambdaContext()\n\n\n@pytest.fixture()\ndef sqs_event():\n\"\"\"Generates API GW Event\"\"\"\n    return load_event(path=Path(\"events/sqs_event.json\"))\n\n\ndef test_app_batch_partial_response(sqs_event, lambda_context):\n    # GIVEN\n    processor_result = processor  # access processor for additional assertions\n    successful_record = sqs_event[\"Records\"][0]\n    failed_record = sqs_event[\"Records\"][1]\n    expected_response = {\"batchItemFailures\": [{\"itemIdentifier\": failed_record[\"messageId\"]}]}\n\n    # WHEN\n    ret = lambda_handler(sqs_event, lambda_context)\n\n    # THEN\n    assert ret == expected_response\n    assert len(processor_result.fail_messages) == 1\n    assert processor_result.success_messages[0] == successful_record\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> events/sqs_event.json<pre><code>{\n\"Records\": [\n{\n\"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n\"body\": \"{\\\"Message\\\": \\\"success\\\"}\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n\"awsRegion\": \"us-east-1\"\n},\n{\n\"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n\"body\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n\"awsRegion\": \"us-east-1\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/batch/#faq","title":"FAQ","text":""},{"location":"utilities/batch/#choosing-between-method-and-context-manager","title":"Choosing between method and context manager","text":"<p>Use context manager when you want access to the processed messages or handle <code>BatchProcessingError</code> exception when all records within the batch fail to be processed.</p>"},{"location":"utilities/batch/#whats-the-difference-between-the-decorator-and-process_partial_response-functions","title":"What's the difference between the decorator and process_partial_response functions?","text":"<p><code>batch_processor</code> and <code>async_batch_processor</code> decorators are now considered legacy. Historically, they were kept due to backwards compatibility and to minimize code changes between V1 and V2.</p> <p>As 2.12.0, <code>process_partial_response</code> and <code>async_process_partial_response</code> are the recommended instead. It reduces boilerplate, smaller memory/CPU cycles, and it makes it less error prone - e.g., decorators required an additional return.</p>"},{"location":"utilities/batch/#integrating-exception-handling-with-sentryio","title":"Integrating exception handling with Sentry.io","text":"<p>When using Sentry.io for error monitoring, you can override <code>failure_handler</code> to capture each processing exception with Sentry SDK:</p> <p>Credits to Charles-Axel Dein</p> Integrating error tracking with Sentry.io<pre><code>from sentry_sdk import capture_exception\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, FailureResponse\n\n\nclass MyProcessor(BatchProcessor):\ndef failure_handler(self, record, exception) -&gt; FailureResponse:\ncapture_exception()  # send exception to Sentry\nreturn super().failure_handler(record, exception)\n</code></pre>"},{"location":"utilities/data_classes/","title":"Event Source Data Classes","text":"<p>Event Source Data Classes utility provides classes self-describing Lambda event sources.</p>"},{"location":"utilities/data_classes/#key-features","title":"Key features","text":"<ul> <li>Type hinting and code completion for common event types</li> <li>Helper functions for decoding/deserializing nested fields</li> <li>Docstrings for fields contained in event schemas</li> </ul> <p>Background</p> <p>When authoring Lambda functions, you often need to understand the schema of the event dictionary which is passed to the handler. There are several common event types which follow a specific schema, depending on the service triggering the Lambda function.</p>"},{"location":"utilities/data_classes/#getting-started","title":"Getting started","text":""},{"location":"utilities/data_classes/#utilizing-the-data-classes","title":"Utilizing the data classes","text":"<p>The classes are initialized by passing in the Lambda event object into the constructor of the appropriate data class or by using the <code>event_source</code> decorator.</p> <p>For example, if your Lambda function is being triggered by an API Gateway proxy integration, you can use the <code>APIGatewayProxyEvent</code> class.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import APIGatewayProxyEvent\ndef lambda_handler(event: dict, context):\nevent = APIGatewayProxyEvent(event)\nif 'helloworld' in event.path and event.http_method == 'GET':\n        do_something_with(event.body, user)\n</code></pre> <p>Same example as above, but using the <code>event_source</code> decorator</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, APIGatewayProxyEvent\n@event_source(data_class=APIGatewayProxyEvent)\ndef lambda_handler(event: APIGatewayProxyEvent, context):\n    if 'helloworld' in event.path and event.http_method == 'GET':\n        do_something_with(event.body, user)\n</code></pre> <p>Log Data Event for Troubleshooting</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, APIGatewayProxyEvent\nfrom aws_lambda_powertools.logging.logger import Logger\n\nlogger = Logger(service=\"hello_logs\", level=\"DEBUG\")\n@event_source(data_class=APIGatewayProxyEvent)\ndef lambda_handler(event: APIGatewayProxyEvent, context):\nlogger.debug(event)\n</code></pre> <p>Autocomplete with self-documented properties and methods</p> <p></p>"},{"location":"utilities/data_classes/#supported-event-sources","title":"Supported event sources","text":"Event Source Data_class Active MQ <code>ActiveMQEvent</code> API Gateway Authorizer <code>APIGatewayAuthorizerRequestEvent</code> API Gateway Authorizer V2 <code>APIGatewayAuthorizerEventV2</code> API Gateway Proxy <code>APIGatewayProxyEvent</code> API Gateway Proxy V2 <code>APIGatewayProxyEventV2</code> Application Load Balancer <code>ALBEvent</code> AppSync Authorizer <code>AppSyncAuthorizerEvent</code> AppSync Resolver <code>AppSyncResolverEvent</code> AWS Config Rule <code>AWSConfigRuleEvent</code> CloudWatch Dashboard Custom Widget <code>CloudWatchDashboardCustomWidgetEvent</code> CloudWatch Logs <code>CloudWatchLogsEvent</code> CodePipeline Job Event <code>CodePipelineJobEvent</code> Cognito User Pool Multiple available under <code>cognito_user_pool_event</code> Connect Contact Flow <code>ConnectContactFlowEvent</code> DynamoDB streams <code>DynamoDBStreamEvent</code>, <code>DynamoDBRecordEventName</code> EventBridge <code>EventBridgeEvent</code> Kafka <code>KafkaEvent</code> Kinesis Data Stream <code>KinesisStreamEvent</code> Kinesis Firehose Delivery Stream <code>KinesisFirehoseEvent</code> Lambda Function URL <code>LambdaFunctionUrlEvent</code> Rabbit MQ <code>RabbitMQEvent</code> S3 <code>S3Event</code> S3 Object Lambda <code>S3ObjectLambdaEvent</code> S3 EventBridge Notification <code>S3EventBridgeNotificationEvent</code> SES <code>SESEvent</code> SNS <code>SNSEvent</code> SQS <code>SQSEvent</code> VPC Lattice <code>VPCLatticeEvent</code> Info <p>The examples provided below are far from exhaustive - the data classes themselves are designed to provide a form of documentation inherently (via autocompletion, types and docstrings).</p>"},{"location":"utilities/data_classes/#active-mq","title":"Active MQ","text":"<p>It is used for Active MQ payloads, also see the AWS blog post for more details.</p> app.py <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.active_mq_event import ActiveMQEvent\nlogger = Logger()\n\n@event_source(data_class=ActiveMQEvent)\ndef lambda_handler(event: ActiveMQEvent, context):\nfor message in event.messages:\n        logger.debug(f\"MessageID: {message.message_id}\")\n        data: Dict = message.json_data\n        logger.debug(\"Process json in base64 encoded data str\", data)\n</code></pre>"},{"location":"utilities/data_classes/#api-gateway-authorizer","title":"API Gateway Authorizer","text":"<p>New in 1.20.0</p> <p>It is used for API Gateway Rest API Lambda Authorizer payload.</p> <p>Use <code>APIGatewayAuthorizerRequestEvent</code> for type <code>REQUEST</code> and <code>APIGatewayAuthorizerTokenEvent</code> for type <code>TOKEN</code>.</p> app_type_request.pyapp_type_token.py <p>This example uses the <code>APIGatewayAuthorizerResponse</code> to decline a given request if the user is not found.</p> <p>When the user is found, it includes the user details in the request context that will be available to the back-end, and returns a full access policy for admin users.</p> <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.api_gateway_authorizer_event import (\nDENY_ALL_RESPONSE,\nAPIGatewayAuthorizerRequestEvent,\nAPIGatewayAuthorizerResponse,\nHttpVerb,\n)\nfrom secrets import compare_digest\n\n\ndef get_user_by_token(token):\n    if compare_digest(token, \"admin-foo\"):\n        return {\"id\": 0, \"name\": \"Admin\", \"isAdmin\": True}\n    elif compare_digest(token, \"regular-foo\"):\n        return {\"id\": 1, \"name\": \"Joe\"}\n    else:\n        return None\n\n\n@event_source(data_class=APIGatewayAuthorizerRequestEvent)\ndef handler(event: APIGatewayAuthorizerRequestEvent, context):\n    user = get_user_by_token(event.get_header_value(\"Authorization\"))\n\n    if user is None:\n        # No user was found\n        # to return 401 - `{\"message\":\"Unauthorized\"}`, but pollutes lambda error count metrics\n        # raise Exception(\"Unauthorized\")\n        # to return 403 - `{\"message\":\"Forbidden\"}`\nreturn DENY_ALL_RESPONSE\n# parse the `methodArn` as an `APIGatewayRouteArn`\n    arn = event.parsed_arn\n\n    # Create the response builder from parts of the `methodArn`\n    # and set the logged in user id and context\npolicy = APIGatewayAuthorizerResponse(\nprincipal_id=user[\"id\"],\ncontext=user,\nregion=arn.region,\naws_account_id=arn.aws_account_id,\napi_id=arn.api_id,\nstage=arn.stage,\n)\n\n    # Conditional IAM Policy\n    if user.get(\"isAdmin\", False):\npolicy.allow_all_routes()\nelse:\npolicy.allow_route(HttpVerb.GET, \"/user-profile\")\nreturn policy.asdict()\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.api_gateway_authorizer_event import (\nAPIGatewayAuthorizerTokenEvent,\nAPIGatewayAuthorizerResponse,\n)\n@event_source(data_class=APIGatewayAuthorizerTokenEvent)\ndef handler(event: APIGatewayAuthorizerTokenEvent, context):\n    arn = event.parsed_arn\n\npolicy = APIGatewayAuthorizerResponse(\nprincipal_id=\"user\",\nregion=arn.region,\naws_account_id=arn.aws_account_id,\napi_id=arn.api_id,\nstage=arn.stage\n)\nif event.authorization_token == \"42\":\npolicy.allow_all_routes()\nelse:\npolicy.deny_all_routes()\nreturn policy.asdict()\n</code></pre>"},{"location":"utilities/data_classes/#api-gateway-authorizer-v2","title":"API Gateway Authorizer V2","text":"<p>New in 1.20.0</p> <p>It is used for API Gateway HTTP API Lambda Authorizer payload version 2. See also this blog post for more details.</p> app.py <p>This example looks up user details via <code>x-token</code> header. It uses <code>APIGatewayAuthorizerResponseV2</code> to return a deny policy when user is not found or authorized.</p> <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.api_gateway_authorizer_event import (\nAPIGatewayAuthorizerEventV2,\nAPIGatewayAuthorizerResponseV2,\n)\nfrom secrets import compare_digest\n\n\ndef get_user_by_token(token):\n    if compare_digest(token, \"Foo\"):\n        return {\"name\": \"Foo\"}\n    return None\n\n\n@event_source(data_class=APIGatewayAuthorizerEventV2)\ndef handler(event: APIGatewayAuthorizerEventV2, context):\n    user = get_user_by_token(event.get_header_value(\"x-token\"))\n\n    if user is None:\n        # No user was found, so we return not authorized\nreturn APIGatewayAuthorizerResponseV2().asdict()\n# Found the user and setting the details in the context\nreturn APIGatewayAuthorizerResponseV2(authorize=True, context=user).asdict()\n</code></pre>"},{"location":"utilities/data_classes/#api-gateway-proxy","title":"API Gateway Proxy","text":"<p>It is used for either API Gateway REST API or HTTP API using v1 proxy event.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, APIGatewayProxyEvent\n\n@event_source(data_class=APIGatewayProxyEvent)\ndef lambda_handler(event: APIGatewayProxyEvent, context):\n    if \"helloworld\" in event.path and event.http_method == \"GET\":\n        request_context = event.request_context\n        identity = request_context.identity\n        user = identity.user\n        do_something_with(event.json_body, user)\n</code></pre>"},{"location":"utilities/data_classes/#api-gateway-proxy-v2","title":"API Gateway Proxy V2","text":"<p>It is used for HTTP API using v2 proxy event.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, APIGatewayProxyEventV2\n\n@event_source(data_class=APIGatewayProxyEventV2)\ndef lambda_handler(event: APIGatewayProxyEventV2, context):\n    if \"helloworld\" in event.path and event.http_method == \"POST\":\n        do_something_with(event.json_body, event.query_string_parameters)\n</code></pre>"},{"location":"utilities/data_classes/#application-load-balancer","title":"Application Load Balancer","text":"<p>Is it used for Application load balancer event.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, ALBEvent\n\n@event_source(data_class=ALBEvent)\ndef lambda_handler(event: ALBEvent, context):\n    if \"helloworld\" in event.path and event.http_method == \"POST\":\n        do_something_with(event.json_body, event.query_string_parameters)\n</code></pre>"},{"location":"utilities/data_classes/#appsync-authorizer","title":"AppSync Authorizer","text":"<p>New in 1.20.0</p> <p>Used when building an AWS_LAMBDA Authorization with AppSync. See blog post Introducing Lambda authorization for AWS AppSync GraphQL APIs or read the Amplify documentation on using AWS Lambda for authorization with AppSync.</p> <p>In this example extract the <code>requestId</code> as the <code>correlation_id</code> for logging, used <code>@event_source</code> decorator and builds the AppSync authorizer using the <code>AppSyncAuthorizerResponse</code> helper.</p> app.py <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.logging.logger import Logger\nfrom aws_lambda_powertools.utilities.data_classes.appsync_authorizer_event import (\n    AppSyncAuthorizerEvent,\n    AppSyncAuthorizerResponse,\n)\nfrom aws_lambda_powertools.utilities.data_classes.event_source import event_source\n\nlogger = Logger()\n\n\ndef get_user_by_token(token: str):\n\"\"\"Look a user by token\"\"\"\n    ...\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_AUTHORIZER)\n@event_source(data_class=AppSyncAuthorizerEvent)\ndef lambda_handler(event: AppSyncAuthorizerEvent, context) -&gt; Dict:\n    user = get_user_by_token(event.authorization_token)\n\n    if not user:\n        # No user found, return not authorized\n        return AppSyncAuthorizerResponse().asdict()\n\n    return AppSyncAuthorizerResponse(\n        authorize=True,\n        resolver_context={\"id\": user.id},\n        # Only allow admins to delete events\n        deny_fields=None if user.is_admin else [\"Mutation.deleteEvent\"],\n    ).asdict()\n</code></pre>"},{"location":"utilities/data_classes/#appsync-resolver","title":"AppSync Resolver","text":"<p>New in 1.12.0</p> <p>Used when building Lambda GraphQL Resolvers with Amplify GraphQL Transform Library (<code>@function</code>), and AppSync Direct Lambda Resolvers.</p> <p>In this example, we also use the new Logger <code>correlation_id</code> and built-in <code>correlation_paths</code> to extract, if available, X-Ray Trace ID in AppSync request headers:</p> app.pyExample AppSync EventExample CloudWatch Log <pre><code>from aws_lambda_powertools.logging import Logger, correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync_resolver_event import (\nAppSyncResolverEvent,\nAppSyncIdentityCognito\n)\nlogger = Logger()\n\ndef get_locations(name: str = None, size: int = 0, page: int = 0):\n\"\"\"Your resolver logic here\"\"\"\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\ndef lambda_handler(event, context):\nevent: AppSyncResolverEvent = AppSyncResolverEvent(event)\n# Case insensitive look up of request headers\n    x_forwarded_for = event.get_header_value(\"x-forwarded-for\")\n\n# Support for AppSyncIdentityCognito or AppSyncIdentityIAM identity types\nassert isinstance(event.identity, AppSyncIdentityCognito)\nidentity: AppSyncIdentityCognito = event.identity\n# Logging with correlation_id\n    logger.debug({\n        \"x-forwarded-for\": x_forwarded_for,\n        \"username\": identity.username\n    })\n\nif event.type_name == \"Merchant\" and event.field_name == \"locations\":\nreturn get_locations(**event.arguments)\nraise ValueError(f\"Unsupported field resolver: {event.field_name}\")\n</code></pre> <pre><code>{\n\"typeName\": \"Merchant\",\n\"fieldName\": \"locations\",\n\"arguments\": {\n\"page\": 2,\n\"size\": 1,\n\"name\": \"value\"\n},\n\"identity\": {\n\"claims\": {\n\"iat\": 1615366261\n...\n},\n\"username\": \"mike\",\n...\n},\n\"request\": {\n\"headers\": {\n\"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n\"x-forwarded-for\": \"127.0.0.1\"\n...\n}\n},\n...\n}\n</code></pre> <pre><code>{\n\"level\":\"DEBUG\",\n\"location\":\"lambda_handler:22\",\n\"message\":{\n\"x-forwarded-for\":\"127.0.0.1\",\n\"username\":\"mike\"\n},\n\"timestamp\":\"2021-03-10 12:38:40,062\",\n\"service\":\"service_undefined\",\n\"sampling_rate\":0.0,\n\"cold_start\":true,\n\"function_name\":\"func_name\",\n\"function_memory_size\":512,\n\"function_arn\":\"func_arn\",\n\"function_request_id\":\"6735a29c-c000-4ae3-94e6-1f1c934f7f94\",\n\"correlation_id\":\"Root=1-60488877-0b0c4e6727ab2a1c545babd0\"\n}\n</code></pre>"},{"location":"utilities/data_classes/#aws-config-rule","title":"AWS Config Rule","text":"aws_config_rule.pyEvent - ItemChangedEvent - OversizedEvent - ScheduledNotification <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import (\nAWSConfigRuleEvent,\nevent_source,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@event_source(data_class=AWSConfigRuleEvent)\ndef lambda_handler(event: AWSConfigRuleEvent, context: LambdaContext):\n    message_type = event.invoking_event.message_type\n\n    logger.info(f\"Logging {message_type} event rule\", invoke_event=event.raw_invoking_event)\n\n    return {\"Success\": \"OK\"}\n</code></pre> <pre><code>{\n\"version\":\"1.0\",\n\"invokingEvent\":\"{\\\"configurationItemDiff\\\":{\\\"changedProperties\\\":{\\\"Configuration.InstanceType\\\":{\\\"previousValue\\\":\\\"t2.micro\\\",\\\"updatedValue\\\":\\\"t2.medium\\\",\\\"changeType\\\":\\\"UPDATE\\\"},\\\"Configuration.State.Name\\\":{\\\"previousValue\\\":\\\"running\\\",\\\"updatedValue\\\":\\\"stopped\\\",\\\"changeType\\\":\\\"UPDATE\\\"},\\\"Configuration.StateTransitionReason\\\":{\\\"previousValue\\\":\\\"\\\",\\\"updatedValue\\\":\\\"User initiated (2023-04-27 15:01:07 GMT)\\\",\\\"changeType\\\":\\\"UPDATE\\\"},\\\"Configuration.StateReason\\\":{\\\"previousValue\\\":null,\\\"updatedValue\\\":{\\\"code\\\":\\\"Client.UserInitiatedShutdown\\\",\\\"message\\\":\\\"Client.UserInitiatedShutdown: User initiated shutdown\\\"},\\\"changeType\\\":\\\"CREATE\\\"},\\\"Configuration.CpuOptions.CoreCount\\\":{\\\"previousValue\\\":1,\\\"updatedValue\\\":2,\\\"changeType\\\":\\\"UPDATE\\\"}},\\\"changeType\\\":\\\"UPDATE\\\"},\\\"configurationItem\\\":{\\\"relatedEvents\\\":[],\\\"relationships\\\":[{\\\"resourceId\\\":\\\"eipalloc-0ebb4367662263cc1\\\",\\\"resourceName\\\":null,\\\"resourceType\\\":\\\"AWS::EC2::EIP\\\",\\\"name\\\":\\\"Is attached to ElasticIp\\\"},{\\\"resourceId\\\":\\\"eni-034dd31c4b17ada8c\\\",\\\"resourceName\\\":null,\\\"resourceType\\\":\\\"AWS::EC2::NetworkInterface\\\",\\\"name\\\":\\\"Contains NetworkInterface\\\"},{\\\"resourceId\\\":\\\"eni-09a604c0ec356b06f\\\",\\\"resourceName\\\":null,\\\"resourceType\\\":\\\"AWS::EC2::NetworkInterface\\\",\\\"name\\\":\\\"Contains NetworkInterface\\\"},{\\\"resourceId\\\":\\\"sg-0fb295a327d9b4835\\\",\\\"resourceName\\\":null,\\\"resourceType\\\":\\\"AWS::EC2::SecurityGroup\\\",\\\"name\\\":\\\"Is associated with SecurityGroup\\\"},{\\\"resourceId\\\":\\\"subnet-cad1f2f4\\\",\\\"resourceName\\\":null,\\\"resourceType\\\":\\\"AWS::EC2::Subnet\\\",\\\"name\\\":\\\"Is contained in Subnet\\\"},{\\\"resourceId\\\":\\\"vol-0a288b5eb9fea4b30\\\",\\\"resourceName\\\":null,\\\"resourceType\\\":\\\"AWS::EC2::Volume\\\",\\\"name\\\":\\\"Is attached to Volume\\\"},{\\\"resourceId\\\":\\\"vpc-2d96be57\\\",\\\"resourceName\\\":null,\\\"resourceType\\\":\\\"AWS::EC2::VPC\\\",\\\"name\\\":\\\"Is contained in Vpc\\\"}],\\\"configuration\\\":{\\\"amiLaunchIndex\\\":0,\\\"imageId\\\":\\\"ami-09d95fab7fff3776c\\\",\\\"instanceId\\\":\\\"i-042dd005362091826\\\",\\\"instanceType\\\":\\\"t2.medium\\\",\\\"kernelId\\\":null,\\\"keyName\\\":\\\"mihaec2\\\",\\\"launchTime\\\":\\\"2023-04-27T14:57:16.000Z\\\",\\\"monitoring\\\":{\\\"state\\\":\\\"disabled\\\"},\\\"placement\\\":{\\\"availabilityZone\\\":\\\"us-east-1e\\\",\\\"affinity\\\":null,\\\"groupName\\\":\\\"\\\",\\\"partitionNumber\\\":null,\\\"hostId\\\":null,\\\"tenancy\\\":\\\"default\\\",\\\"spreadDomain\\\":null,\\\"hostResourceGroupArn\\\":null},\\\"platform\\\":null,\\\"privateDnsName\\\":\\\"ip-172-31-78-41.ec2.internal\\\",\\\"privateIpAddress\\\":\\\"172.31.78.41\\\",\\\"productCodes\\\":[],\\\"publicDnsName\\\":\\\"ec2-3-232-229-57.compute-1.amazonaws.com\\\",\\\"publicIpAddress\\\":\\\"3.232.229.57\\\",\\\"ramdiskId\\\":null,\\\"state\\\":{\\\"code\\\":80,\\\"name\\\":\\\"stopped\\\"},\\\"stateTransitionReason\\\":\\\"User initiated (2023-04-27 15:01:07 GMT)\\\",\\\"subnetId\\\":\\\"subnet-cad1f2f4\\\",\\\"vpcId\\\":\\\"vpc-2d96be57\\\",\\\"architecture\\\":\\\"x86_64\\\",\\\"blockDeviceMappings\\\":[{\\\"deviceName\\\":\\\"/dev/xvda\\\",\\\"ebs\\\":{\\\"attachTime\\\":\\\"2020-05-30T15:21:58.000Z\\\",\\\"deleteOnTermination\\\":true,\\\"status\\\":\\\"attached\\\",\\\"volumeId\\\":\\\"vol-0a288b5eb9fea4b30\\\"}}],\\\"clientToken\\\":\\\"\\\",\\\"ebsOptimized\\\":false,\\\"enaSupport\\\":true,\\\"hypervisor\\\":\\\"xen\\\",\\\"iamInstanceProfile\\\":{\\\"arn\\\":\\\"arn:aws:iam::0123456789012:instance-profile/AmazonSSMRoleForInstancesQuickSetup\\\",\\\"id\\\":\\\"AIPAS5S4WFUBL72S3QXW5\\\"},\\\"instanceLifecycle\\\":null,\\\"elasticGpuAssociations\\\":[],\\\"elasticInferenceAcceleratorAssociations\\\":[],\\\"networkInterfaces\\\":[{\\\"association\\\":{\\\"carrierIp\\\":null,\\\"ipOwnerId\\\":\\\"0123456789012\\\",\\\"publicDnsName\\\":\\\"ec2-3-232-229-57.compute-1.amazonaws.com\\\",\\\"publicIp\\\":\\\"3.232.229.57\\\"},\\\"attachment\\\":{\\\"attachTime\\\":\\\"2020-05-30T15:21:57.000Z\\\",\\\"attachmentId\\\":\\\"eni-attach-0a7e75dc9c1c291a0\\\",\\\"deleteOnTermination\\\":true,\\\"deviceIndex\\\":0,\\\"status\\\":\\\"attached\\\",\\\"networkCardIndex\\\":0},\\\"description\\\":\\\"\\\",\\\"groups\\\":[{\\\"groupName\\\":\\\"minhaec2\\\",\\\"groupId\\\":\\\"sg-0fb295a327d9b4835\\\"}],\\\"ipv6Addresses\\\":[],\\\"macAddress\\\":\\\"06:cf:00:c2:17:db\\\",\\\"networkInterfaceId\\\":\\\"eni-034dd31c4b17ada8c\\\",\\\"ownerId\\\":\\\"0123456789012\\\",\\\"privateDnsName\\\":\\\"ip-172-31-78-41.ec2.internal\\\",\\\"privateIpAddress\\\":\\\"172.31.78.41\\\",\\\"privateIpAddresses\\\":[{\\\"association\\\":{\\\"carrierIp\\\":null,\\\"ipOwnerId\\\":\\\"0123456789012\\\",\\\"publicDnsName\\\":\\\"ec2-3-232-229-57.compute-1.amazonaws.com\\\",\\\"publicIp\\\":\\\"3.232.229.57\\\"},\\\"primary\\\":true,\\\"privateDnsName\\\":\\\"ip-172-31-78-41.ec2.internal\\\",\\\"privateIpAddress\\\":\\\"172.31.78.41\\\"}],\\\"sourceDestCheck\\\":true,\\\"status\\\":\\\"in-use\\\",\\\"subnetId\\\":\\\"subnet-cad1f2f4\\\",\\\"vpcId\\\":\\\"vpc-2d96be57\\\",\\\"interfaceType\\\":\\\"interface\\\"},{\\\"association\\\":null,\\\"attachment\\\":{\\\"attachTime\\\":\\\"2020-11-26T23:46:04.000Z\\\",\\\"attachmentId\\\":\\\"eni-attach-0e6d150ebbd19966e\\\",\\\"deleteOnTermination\\\":false,\\\"deviceIndex\\\":1,\\\"status\\\":\\\"attached\\\",\\\"networkCardIndex\\\":0},\\\"description\\\":\\\"MINHAEC2AAAAAA\\\",\\\"groups\\\":[{\\\"groupName\\\":\\\"minhaec2\\\",\\\"groupId\\\":\\\"sg-0fb295a327d9b4835\\\"},{\\\"groupName\\\":\\\"default\\\",\\\"groupId\\\":\\\"sg-88105fa0\\\"}],\\\"ipv6Addresses\\\":[],\\\"macAddress\\\":\\\"06:0a:62:00:64:5f\\\",\\\"networkInterfaceId\\\":\\\"eni-09a604c0ec356b06f\\\",\\\"ownerId\\\":\\\"0123456789012\\\",\\\"privateDnsName\\\":\\\"ip-172-31-70-9.ec2.internal\\\",\\\"privateIpAddress\\\":\\\"172.31.70.9\\\",\\\"privateIpAddresses\\\":[{\\\"association\\\":null,\\\"primary\\\":true,\\\"privateDnsName\\\":\\\"ip-172-31-70-9.ec2.internal\\\",\\\"privateIpAddress\\\":\\\"172.31.70.9\\\"}],\\\"sourceDestCheck\\\":true,\\\"status\\\":\\\"in-use\\\",\\\"subnetId\\\":\\\"subnet-cad1f2f4\\\",\\\"vpcId\\\":\\\"vpc-2d96be57\\\",\\\"interfaceType\\\":\\\"interface\\\"}],\\\"outpostArn\\\":null,\\\"rootDeviceName\\\":\\\"/dev/xvda\\\",\\\"rootDeviceType\\\":\\\"ebs\\\",\\\"securityGroups\\\":[{\\\"groupName\\\":\\\"minhaec2\\\",\\\"groupId\\\":\\\"sg-0fb295a327d9b4835\\\"}],\\\"sourceDestCheck\\\":true,\\\"spotInstanceRequestId\\\":null,\\\"sriovNetSupport\\\":null,\\\"stateReason\\\":{\\\"code\\\":\\\"Client.UserInitiatedShutdown\\\",\\\"message\\\":\\\"Client.UserInitiatedShutdown: User initiated shutdown\\\"},\\\"tags\\\":[{\\\"key\\\":\\\"projeto\\\",\\\"value\\\":\\\"meetup\\\"},{\\\"key\\\":\\\"Name\\\",\\\"value\\\":\\\"Minha\\\"},{\\\"key\\\":\\\"CentroCusto\\\",\\\"value\\\":\\\"TI\\\"},{\\\"key\\\":\\\"Setor\\\",\\\"value\\\":\\\"Desenvolvimento\\\"}],\\\"virtualizationType\\\":\\\"hvm\\\",\\\"cpuOptions\\\":{\\\"coreCount\\\":2,\\\"threadsPerCore\\\":1},\\\"capacityReservationId\\\":null,\\\"capacityReservationSpecification\\\":{\\\"capacityReservationPreference\\\":\\\"open\\\",\\\"capacityReservationTarget\\\":null},\\\"hibernationOptions\\\":{\\\"configured\\\":false},\\\"licenses\\\":[],\\\"metadataOptions\\\":{\\\"state\\\":\\\"applied\\\",\\\"httpTokens\\\":\\\"optional\\\",\\\"httpPutResponseHopLimit\\\":1,\\\"httpEndpoint\\\":\\\"enabled\\\"},\\\"enclaveOptions\\\":{\\\"enabled\\\":false},\\\"bootMode\\\":null},\\\"supplementaryConfiguration\\\":{},\\\"tags\\\":{\\\"projeto\\\":\\\"meetup\\\",\\\"Setor\\\":\\\"Desenvolvimento\\\",\\\"CentroCusto\\\":\\\"TI\\\",\\\"Name\\\":\\\"Minha\\\"},\\\"configurationItemVersion\\\":\\\"1.3\\\",\\\"configurationItemCaptureTime\\\":\\\"2023-04-27T15:03:11.636Z\\\",\\\"configurationStateId\\\":1682607791636,\\\"awsAccountId\\\":\\\"0123456789012\\\",\\\"configurationItemStatus\\\":\\\"OK\\\",\\\"resourceType\\\":\\\"AWS::EC2::Instance\\\",\\\"resourceId\\\":\\\"i-042dd005362091826\\\",\\\"resourceName\\\":null,\\\"ARN\\\":\\\"arn:aws:ec2:us-east-1:0123456789012:instance/i-042dd005362091826\\\",\\\"awsRegion\\\":\\\"us-east-1\\\",\\\"availabilityZone\\\":\\\"us-east-1e\\\",\\\"configurationStateMd5Hash\\\":\\\"\\\",\\\"resourceCreationTime\\\":\\\"2023-04-27T14:57:16.000Z\\\"},\\\"notificationCreationTime\\\":\\\"2023-04-27T15:03:13.332Z\\\",\\\"messageType\\\":\\\"ConfigurationItemChangeNotification\\\",\\\"recordVersion\\\":\\\"1.3\\\"}\",\n\"ruleParameters\":\"{\\\"desiredInstanceType\\\": \\\"t2.micro\\\"}\",\n\"resultToken\":\"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\",\n\"eventLeftScope\":false,\n\"executionRoleArn\":\"arn:aws:iam::0123456789012:role/aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig\",\n\"configRuleArn\":\"arn:aws:config:us-east-1:0123456789012:config-rule/config-rule-i9y8j9\",\n\"configRuleName\":\"MyRule\",\n\"configRuleId\":\"config-rule-i9y8j9\",\n\"accountId\":\"0123456789012\",\n\"evaluationMode\":\"DETECTIVE\"\n}\n</code></pre> <pre><code>{\n\"invokingEvent\": \"{\\\"configurationItemSummary\\\": {\\\"changeType\\\": \\\"UPDATE\\\",\\\"configurationItemVersion\\\": \\\"1.2\\\",\\\"configurationItemCaptureTime\\\":\\\"2016-10-06T16:46:16.261Z\\\",\\\"configurationStateId\\\": 0,\\\"awsAccountId\\\":\\\"123456789012\\\",\\\"configurationItemStatus\\\": \\\"OK\\\",\\\"resourceType\\\": \\\"AWS::EC2::Instance\\\",\\\"resourceId\\\":\\\"i-00000000\\\",\\\"resourceName\\\":null,\\\"ARN\\\":\\\"arn:aws:ec2:us-west-2:123456789012:instance/i-00000000\\\",\\\"awsRegion\\\": \\\"us-west-2\\\",\\\"availabilityZone\\\":\\\"us-west-2a\\\",\\\"configurationStateMd5Hash\\\":\\\"8f1ee69b287895a0f8bc5753eca68e96\\\",\\\"resourceCreationTime\\\":\\\"2016-10-06T16:46:10.489Z\\\"},\\\"messageType\\\":\\\"OversizedConfigurationItemChangeNotification\\\", \\\"notificationCreationTime\\\": \\\"2016-10-06T16:46:16.261Z\\\", \\\"recordVersion\\\": \\\"1.0\\\"}\",\n\"ruleParameters\": \"{\\\"myParameterKey\\\":\\\"myParameterValue\\\"}\",\n\"resultToken\": \"myResultToken\",\n\"eventLeftScope\": false,\n\"executionRoleArn\": \"arn:aws:iam::123456789012:role/config-role\",\n\"configRuleArn\": \"arn:aws:config:us-east-2:123456789012:config-rule/config-rule-ec2-managed-instance-inventory\",\n\"configRuleName\": \"change-triggered-config-rule\",\n\"configRuleId\": \"config-rule-0123456\",\n\"accountId\": \"123456789012\",\n\"version\": \"1.0\"\n}\n</code></pre> <pre><code>{\n\"version\":\"1.0\",\n\"invokingEvent\":\"{\\\"awsAccountId\\\":\\\"0123456789012\\\",\\\"notificationCreationTime\\\":\\\"2023-04-27T13:26:17.741Z\\\",\\\"messageType\\\":\\\"ScheduledNxotification\\\",\\\"recordVersion\\\":\\\"1.0\\\"}\",\n\"ruleParameters\":\"{\\\"test\\\":\\\"x\\\"}\",\n\"resultToken\":\"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\",\n\"eventLeftScope\":false,\n\"executionRoleArn\":\"arn:aws:iam::0123456789012:role/aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig\",\n\"configRuleArn\":\"arn:aws:config:us-east-1:0123456789012:config-rule/config-rule-pdmyw1\",\n\"configRuleName\":\"rule-ec2-test\",\n\"configRuleId\":\"config-rule-pdmyw1\",\n\"accountId\":\"0123456789012\",\n\"evaluationMode\":\"DETECTIVE\"\n}\n</code></pre>"},{"location":"utilities/data_classes/#cloudwatch-dashboard-custom-widget","title":"CloudWatch Dashboard Custom Widget","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, CloudWatchDashboardCustomWidgetEvent\n\nconst DOCS = `\n## Echo\nA simple echo script. Anything passed in \\`\\`\\`echo\\`\\`\\` parameter is returned as the content of custom widget.\n\n### Widget parameters\n| Param    | Description              |\n| -------- | ------------------------ |\n| **echo** | The content to echo back |\n\n### Example parameters\n\\`\\`\\` yaml\necho: &lt;h1&gt;Hello world&lt;/h1&gt;\n\\`\\`\\`\n`\n\n@event_source(data_class=CloudWatchDashboardCustomWidgetEvent)\ndef lambda_handler(event: CloudWatchDashboardCustomWidgetEvent, context):\n\n    if event.describe:\n        return DOCS\n\n    # You can directly return HTML or JSON content\n    # Alternatively, you can return markdown that will be rendered by CloudWatch\n    echo = event.widget_context.params[\"echo\"]\n    return { \"markdown\": f\"# {echo}\" }\n</code></pre>"},{"location":"utilities/data_classes/#cloudwatch-logs","title":"CloudWatch Logs","text":"<p>CloudWatch Logs events by default are compressed and base64 encoded. You can use the helper function provided to decode, decompress and parse json data from the event.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, CloudWatchLogsEvent\nfrom aws_lambda_powertools.utilities.data_classes.cloud_watch_logs_event import CloudWatchLogsDecodedData\n\n@event_source(data_class=CloudWatchLogsEvent)\ndef lambda_handler(event: CloudWatchLogsEvent, context):\n    decompressed_log: CloudWatchLogsDecodedData = event.parse_logs_data()\n    log_events = decompressed_log.log_events\n    for event in log_events:\n        do_something_with(event.timestamp, event.message)\n</code></pre>"},{"location":"utilities/data_classes/#kinesis-integration","title":"Kinesis integration","text":"<p>When streaming CloudWatch Logs to a Kinesis Data Stream (cross-account or not), you can use <code>extract_cloudwatch_logs_from_event</code> to decode, decompress and extract logs as <code>CloudWatchLogsDecodedData</code> to ease log processing.</p> app.py <pre><code>from typing import List\n\nfrom aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.cloud_watch_logs_event import CloudWatchLogsDecodedData\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\nKinesisStreamEvent, extract_cloudwatch_logs_from_event)\n@event_source(data_class=KinesisStreamEvent)\ndef simple_handler(event: KinesisStreamEvent, context):\nlogs: List[CloudWatchLogsDecodedData] = extract_cloudwatch_logs_from_event(event)\nfor log in logs:\n        if log.message_type == \"DATA_MESSAGE\":\n            return \"success\"\n    return \"nothing to be processed\"\n</code></pre> <p>Alternatively, you can use <code>extract_cloudwatch_logs_from_record</code> to seamless integrate with the Batch utility for more robust log processing.</p> app.py <pre><code>from aws_lambda_powertools.utilities.batch import (BatchProcessor, EventType,\n                                                   batch_processor)\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\nKinesisStreamRecord, extract_cloudwatch_logs_from_record)\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\n\n\ndef record_handler(record: KinesisStreamRecord):\nlog = extract_cloudwatch_logs_from_record(record)\nreturn log.message_type == \"DATA_MESSAGE\"\n\n\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context):\n    return processor.response()\n</code></pre>"},{"location":"utilities/data_classes/#codepipeline-job","title":"CodePipeline Job","text":"<p>Data classes and utility functions to help create continuous delivery pipelines tasks with AWS Lambda</p> app.py <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import event_source, CodePipelineJobEvent\n\nlogger = Logger()\n\n@event_source(data_class=CodePipelineJobEvent)\ndef lambda_handler(event, context):\n\"\"\"The Lambda function handler\n\n    If a continuing job then checks the CloudFormation stack status\n    and updates the job accordingly.\n\n    If a new job then kick of an update or creation of the target\n    CloudFormation stack.\n    \"\"\"\n\n    # Extract the Job ID\n    job_id = event.get_id\n\n    # Extract the params\n    params: dict = event.decoded_user_parameters\n    stack = params[\"stack\"]\n    artifact_name = params[\"artifact\"]\n    template_file = params[\"file\"]\n\n    try:\n        if event.data.continuation_token:\n            # If we're continuing then the create/update has already been triggered\n            # we just need to check if it has finished.\n            check_stack_update_status(job_id, stack)\n        else:\n            template = event.get_artifact(artifact_name, template_file)\n            # Kick off a stack update or create\n            start_update_or_create(job_id, stack, template)\n    except Exception as e:\n        # If any other exceptions which we didn't expect are raised\n        # then fail the job and log the exception message.\n        logger.exception(\"Function failed due to exception.\")\n        put_job_failure(job_id, \"Function exception: \" + str(e))\n\n    logger.debug(\"Function complete.\")\n    return \"Complete.\"\n</code></pre>"},{"location":"utilities/data_classes/#cognito-user-pool","title":"Cognito User Pool","text":"<p>Cognito User Pools have several different Lambda trigger sources, all of which map to a different data class, which can be imported from <code>aws_lambda_powertools.data_classes.cognito_user_pool_event</code>:</p> Trigger/Event Source Data Class Custom message event <code>data_classes.cognito_user_pool_event.CustomMessageTriggerEvent</code> Post authentication <code>data_classes.cognito_user_pool_event.PostAuthenticationTriggerEvent</code> Post confirmation <code>data_classes.cognito_user_pool_event.PostConfirmationTriggerEvent</code> Pre authentication <code>data_classes.cognito_user_pool_event.PreAuthenticationTriggerEvent</code> Pre sign-up <code>data_classes.cognito_user_pool_event.PreSignUpTriggerEvent</code> Pre token generation <code>data_classes.cognito_user_pool_event.PreTokenGenerationTriggerEvent</code> User migration <code>data_classes.cognito_user_pool_event.UserMigrationTriggerEvent</code> Define Auth Challenge <code>data_classes.cognito_user_pool_event.DefineAuthChallengeTriggerEvent</code> Create Auth Challenge <code>data_classes.cognito_user_pool_event.CreateAuthChallengeTriggerEvent</code> Verify Auth Challenge <code>data_classes.cognito_user_pool_event.VerifyAuthChallengeResponseTriggerEvent</code>"},{"location":"utilities/data_classes/#post-confirmation-example","title":"Post Confirmation Example","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import PostConfirmationTriggerEvent\n\ndef lambda_handler(event, context):\n    event: PostConfirmationTriggerEvent = PostConfirmationTriggerEvent(event)\n\n    user_attributes = event.request.user_attributes\n    do_something_with(user_attributes)\n</code></pre>"},{"location":"utilities/data_classes/#define-auth-challenge-example","title":"Define Auth Challenge Example","text":"Note <p>In this example we are modifying the wrapped dict response fields, so we need to return the json serializable wrapped event in <code>event.raw_event</code>.</p> <p>This example is based on the AWS Cognito docs for Define Auth Challenge Lambda Trigger.</p> app.pySPR_A responsePASSWORD_VERIFIER success responseCUSTOM_CHALLENGE success response <pre><code>from aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import DefineAuthChallengeTriggerEvent\n\ndef handler(event: dict, context) -&gt; dict:\n    event: DefineAuthChallengeTriggerEvent = DefineAuthChallengeTriggerEvent(event)\n    if (\n        len(event.request.session) == 1\n        and event.request.session[0].challenge_name == \"SRP_A\"\n    ):\n        event.response.issue_tokens = False\n        event.response.fail_authentication = False\n        event.response.challenge_name = \"PASSWORD_VERIFIER\"\n    elif (\n        len(event.request.session) == 2\n        and event.request.session[1].challenge_name == \"PASSWORD_VERIFIER\"\n        and event.request.session[1].challenge_result\n    ):\n        event.response.issue_tokens = False\n        event.response.fail_authentication = False\n        event.response.challenge_name = \"CUSTOM_CHALLENGE\"\n    elif (\n        len(event.request.session) == 3\n        and event.request.session[2].challenge_name == \"CUSTOM_CHALLENGE\"\n        and event.request.session[2].challenge_result\n    ):\n        event.response.issue_tokens = True\n        event.response.fail_authentication = False\n    else:\n        event.response.issue_tokens = False\n        event.response.fail_authentication = True\n\n    return event.raw_event\n</code></pre> <pre><code>{\n\"version\": \"1\",\n\"region\": \"us-east-1\",\n\"userPoolId\": \"us-east-1_example\",\n\"userName\": \"UserName\",\n\"callerContext\": {\n\"awsSdkVersion\": \"awsSdkVersion\",\n\"clientId\": \"clientId\"\n},\n\"triggerSource\": \"DefineAuthChallenge_Authentication\",\n\"request\": {\n\"userAttributes\": {\n\"sub\": \"4A709A36-7D63-4785-829D-4198EF10EBDA\",\n\"email_verified\": \"true\",\n\"name\": \"First Last\",\n\"email\": \"define-auth@mail.com\"\n},\n\"session\": [\n{\n\"challengeName\": \"SRP_A\",\n\"challengeResult\": true\n}\n]\n},\n\"response\": {\n\"issueTokens\": false,\n\"failAuthentication\": false,\n\"challengeName\": \"PASSWORD_VERIFIER\"\n}\n}\n</code></pre> <pre><code>{\n\"version\": \"1\",\n\"region\": \"us-east-1\",\n\"userPoolId\": \"us-east-1_example\",\n\"userName\": \"UserName\",\n\"callerContext\": {\n\"awsSdkVersion\": \"awsSdkVersion\",\n\"clientId\": \"clientId\"\n},\n\"triggerSource\": \"DefineAuthChallenge_Authentication\",\n\"request\": {\n\"userAttributes\": {\n\"sub\": \"4A709A36-7D63-4785-829D-4198EF10EBDA\",\n\"email_verified\": \"true\",\n\"name\": \"First Last\",\n\"email\": \"define-auth@mail.com\"\n},\n\"session\": [\n{\n\"challengeName\": \"SRP_A\",\n\"challengeResult\": true\n},\n{\n\"challengeName\": \"PASSWORD_VERIFIER\",\n\"challengeResult\": true\n}\n]\n},\n\"response\": {\n\"issueTokens\": false,\n\"failAuthentication\": false,\n\"challengeName\": \"CUSTOM_CHALLENGE\"\n}\n}\n</code></pre> <pre><code>{\n\"version\": \"1\",\n\"region\": \"us-east-1\",\n\"userPoolId\": \"us-east-1_example\",\n\"userName\": \"UserName\",\n\"callerContext\": {\n\"awsSdkVersion\": \"awsSdkVersion\",\n\"clientId\": \"clientId\"\n},\n\"triggerSource\": \"DefineAuthChallenge_Authentication\",\n\"request\": {\n\"userAttributes\": {\n\"sub\": \"4A709A36-7D63-4785-829D-4198EF10EBDA\",\n\"email_verified\": \"true\",\n\"name\": \"First Last\",\n\"email\": \"define-auth@mail.com\"\n},\n\"session\": [\n{\n\"challengeName\": \"SRP_A\",\n\"challengeResult\": true\n},\n{\n\"challengeName\": \"PASSWORD_VERIFIER\",\n\"challengeResult\": true\n},\n{\n\"challengeName\": \"CUSTOM_CHALLENGE\",\n\"challengeResult\": true\n}\n]\n},\n\"response\": {\n\"issueTokens\": true,\n\"failAuthentication\": false\n}\n}\n</code></pre>"},{"location":"utilities/data_classes/#create-auth-challenge-example","title":"Create Auth Challenge Example","text":"<p>This example is based on the AWS Cognito docs for Create Auth Challenge Lambda Trigger.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import CreateAuthChallengeTriggerEvent\n\n@event_source(data_class=CreateAuthChallengeTriggerEvent)\ndef handler(event: CreateAuthChallengeTriggerEvent, context) -&gt; dict:\n    if event.request.challenge_name == \"CUSTOM_CHALLENGE\":\n        event.response.public_challenge_parameters = {\"captchaUrl\": \"url/123.jpg\"}\n        event.response.private_challenge_parameters = {\"answer\": \"5\"}\n        event.response.challenge_metadata = \"CAPTCHA_CHALLENGE\"\n    return event.raw_event\n</code></pre>"},{"location":"utilities/data_classes/#verify-auth-challenge-response-example","title":"Verify Auth Challenge Response Example","text":"<p>This example is based on the AWS Cognito docs for Verify Auth Challenge Response Lambda Trigger.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import VerifyAuthChallengeResponseTriggerEvent\n\n@event_source(data_class=VerifyAuthChallengeResponseTriggerEvent)\ndef handler(event: VerifyAuthChallengeResponseTriggerEvent, context) -&gt; dict:\n    event.response.answer_correct = (\n        event.request.private_challenge_parameters.get(\"answer\") == event.request.challenge_answer\n    )\n    return event.raw_event\n</code></pre>"},{"location":"utilities/data_classes/#connect-contact-flow","title":"Connect Contact Flow","text":"<p>New in 1.11.0</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes.connect_contact_flow_event import (\n    ConnectContactFlowChannel,\n    ConnectContactFlowEndpointType,\n    ConnectContactFlowEvent,\n    ConnectContactFlowInitiationMethod,\n)\n\ndef lambda_handler(event, context):\n    event: ConnectContactFlowEvent = ConnectContactFlowEvent(event)\n    assert event.contact_data.attributes == {\"Language\": \"en-US\"}\n    assert event.contact_data.channel == ConnectContactFlowChannel.VOICE\n    assert event.contact_data.customer_endpoint.endpoint_type == ConnectContactFlowEndpointType.TELEPHONE_NUMBER\n    assert event.contact_data.initiation_method == ConnectContactFlowInitiationMethod.API\n</code></pre>"},{"location":"utilities/data_classes/#dynamodb-streams","title":"DynamoDB Streams","text":"<p>The DynamoDB data class utility provides the base class for <code>DynamoDBStreamEvent</code>, as well as enums for stream view type (<code>StreamViewType</code>) and event type. (<code>DynamoDBRecordEventName</code>). The class automatically deserializes DynamoDB types into their equivalent Python types.</p> app.pymultiple_records_types.py <pre><code>from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\n    DynamoDBStreamEvent,\n    DynamoDBRecordEventName\n)\n\ndef lambda_handler(event, context):\n    event: DynamoDBStreamEvent = DynamoDBStreamEvent(event)\n\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        if record.event_name == DynamoDBRecordEventName.MODIFY:\n            do_something_with(record.dynamodb.new_image)\n            do_something_with(record.dynamodb.old_image)\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, DynamoDBStreamEvent\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=DynamoDBStreamEvent)\ndef lambda_handler(event: DynamoDBStreamEvent, context: LambdaContext):\n    for record in event.records:\n        # {\"N\": \"123.45\"} =&gt; Decimal(\"123.45\")\n        key: str = record.dynamodb.keys[\"id\"]\n        print(key)\n</code></pre>"},{"location":"utilities/data_classes/#eventbridge","title":"EventBridge","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, EventBridgeEvent\n\n@event_source(data_class=EventBridgeEvent)\ndef lambda_handler(event: EventBridgeEvent, context):\n    do_something_with(event.detail)\n</code></pre>"},{"location":"utilities/data_classes/#kafka","title":"Kafka","text":"<p>This example is based on the AWS docs for Amazon MSK and self-managed Apache Kafka.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, KafkaEvent\n\n@event_source(data_class=KafkaEvent)\ndef lambda_handler(event: KafkaEvent, context):\n    for record in event.records:\n        do_something_with(record.decoded_key, record.json_value)\n</code></pre>"},{"location":"utilities/data_classes/#kinesis-streams","title":"Kinesis streams","text":"<p>Kinesis events by default contain base64 encoded data. You can use the helper function to access the data either as json or plain text, depending on the original payload.</p> app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, KinesisStreamEvent\n\n@event_source(data_class=KinesisStreamEvent)\ndef lambda_handler(event: KinesisStreamEvent, context):\n    kinesis_record = next(event.records).kinesis\n\n    # if data was delivered as text\n    data = kinesis_record.data_as_text()\n\n    # if data was delivered as json\n    data = kinesis_record.data_as_json()\n\n    do_something_with(data)\n</code></pre>"},{"location":"utilities/data_classes/#kinesis-firehose-delivery-stream","title":"Kinesis Firehose delivery stream","text":"<p>Kinesis Firehose Data Transformation can use a Lambda Function to modify the records inline, and re-emit them back to the Delivery Stream.</p> <p>Similar to Kinesis Data Streams, the events contain base64 encoded data. You can use the helper function to access the data either as json or plain text, depending on the original payload.</p> app.py <pre><code>import base64\nimport json\n\nfrom aws_lambda_powertools.utilities.data_classes import (\n    KinesisFirehoseEvent,\n    event_source,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=KinesisFirehoseEvent)\ndef lambda_handler(event: KinesisFirehoseEvent, context: LambdaContext):\n    result = []\n\n    for record in event.records:\n        # if data was delivered as json; caches loaded value\n        data = record.data_as_json\n\n        processed_record = {\n            \"recordId\": record.record_id,\n            \"data\": base64.b64encode(json.dumps(data).encode(\"utf-8\")),\n            \"result\": \"Ok\",\n        }\n\n        result.append(processed_record)\n\n    # return transformed records\n    return {\"records\": result}\n</code></pre>"},{"location":"utilities/data_classes/#lambda-function-url","title":"Lambda Function URL","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, LambdaFunctionUrlEvent\n\n@event_source(data_class=LambdaFunctionUrlEvent)\ndef lambda_handler(event: LambdaFunctionUrlEvent, context):\n    do_something_with(event.body)\n</code></pre>"},{"location":"utilities/data_classes/#rabbit-mq","title":"Rabbit MQ","text":"<p>It is used for Rabbit MQ payloads, also see the blog post for more details.</p> app.py <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.rabbit_mq_event import RabbitMQEvent\nlogger = Logger()\n\n@event_source(data_class=RabbitMQEvent)\ndef lambda_handler(event: RabbitMQEvent, context):\nfor queue_name, messages in event.rmq_messages_by_queue.items():\n        logger.debug(f\"Messages for queue: {queue_name}\")\n        for message in messages:\n            logger.debug(f\"MessageID: {message.basic_properties.message_id}\")\n            data: Dict = message.json_data\n            logger.debug(\"Process json in base64 encoded data str\", data)\n</code></pre>"},{"location":"utilities/data_classes/#s3","title":"S3","text":"app.py <pre><code>from urllib.parse import unquote_plus\nfrom aws_lambda_powertools.utilities.data_classes import event_source, S3Event\n\n@event_source(data_class=S3Event)\ndef lambda_handler(event: S3Event, context):\n    bucket_name = event.bucket_name\n\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        object_key = unquote_plus(record.s3.get_object.key)\n\n        do_something_with(f\"{bucket_name}/{object_key}\")\n</code></pre>"},{"location":"utilities/data_classes/#s3-object-lambda","title":"S3 Object Lambda","text":"<p>This example is based on the AWS Blog post Introducing Amazon S3 Object Lambda \u2013 Use Your Code to Process Data as It Is Being Retrieved from S3.</p> app.py <pre><code>import boto3\nimport requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.correlation_paths import S3_OBJECT_LAMBDA\nfrom aws_lambda_powertools.utilities.data_classes.s3_object_event import S3ObjectLambdaEvent\nlogger = Logger()\nsession = boto3.Session()\ns3 = session.client(\"s3\")\n\n@logger.inject_lambda_context(correlation_id_path=S3_OBJECT_LAMBDA, log_event=True)\ndef lambda_handler(event, context):\nevent = S3ObjectLambdaEvent(event)\n# Get object from S3\n    response = requests.get(event.input_s3_url)\n    original_object = response.content.decode(\"utf-8\")\n\n    # Make changes to the object about to be returned\n    transformed_object = original_object.upper()\n\n    # Write object back to S3 Object Lambda\n    s3.write_get_object_response(\n        Body=transformed_object, RequestRoute=event.request_route, RequestToken=event.request_token\n    )\n\n    return {\"status_code\": 200}\n</code></pre>"},{"location":"utilities/data_classes/#s3-eventbridge-notification","title":"S3 EventBridge Notification","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, S3EventBridgeNotificationEvent\n\n@event_source(data_class=S3EventBridgeNotificationEvent)\ndef lambda_handler(event: S3EventBridgeNotificationEvent, context):\n    bucket_name = event.detail.bucket.name\n    file_key = event.detail.object.key\n</code></pre>"},{"location":"utilities/data_classes/#ses","title":"SES","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, SESEvent\n\n@event_source(data_class=SESEvent)\ndef lambda_handler(event: SESEvent, context):\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        mail = record.ses.mail\n        common_headers = mail.common_headers\n\n        do_something_with(common_headers.to, common_headers.subject)\n</code></pre>"},{"location":"utilities/data_classes/#sns","title":"SNS","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, SNSEvent\n\n@event_source(data_class=SNSEvent)\ndef lambda_handler(event: SNSEvent, context):\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        message = record.sns.message\n        subject = record.sns.subject\n\n        do_something_with(subject, message)\n</code></pre>"},{"location":"utilities/data_classes/#sqs","title":"SQS","text":"app.py <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source, SQSEvent\n\n@event_source(data_class=SQSEvent)\ndef lambda_handler(event: SQSEvent, context):\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        do_something_with(record.body)\n</code></pre>"},{"location":"utilities/data_classes/#vpc-lattice","title":"VPC Lattice","text":"<p>You can register your Lambda functions as targets within an Amazon VPC Lattice service network. By doing this, your Lambda function becomes a service within the network, and clients that have access to the VPC Lattice service network can call your service.</p> <p>Click here for more information about using AWS Lambda with Amazon VPC Lattice.</p> app.pyLattice Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import VPCLatticeEvent, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@event_source(data_class=VPCLatticeEvent)\ndef lambda_handler(event: VPCLatticeEvent, context: LambdaContext):\n    logger.info(event.body)\n\n    response = {\n        \"isBase64Encoded\": False,\n        \"statusCode\": 200,\n        \"headers\": {\"Content-Type\": \"application/text\"},\n        \"body\": \"Event Response to VPC Lattice \ud83d\udd25\ud83d\ude80\ud83d\udd25\",\n    }\n\n    return response\n</code></pre> <pre><code>{\n\"raw_path\": \"/testpath\",\n\"method\": \"GET\",\n\"headers\": {\n\"user_agent\": \"curl/7.64.1\",\n\"x-forwarded-for\": \"10.213.229.10\",\n\"host\": \"test-lambda-service-3908sdf9u3u.dkfjd93.vpc-lattice-svcs.us-east-2.on.aws\",\n\"accept\": \"*/*\"\n},\n\"query_string_parameters\": {\n\"order-id\": \"1\"\n},\n\"body\": \"eyJ0ZXN0IjogImV2ZW50In0=\",\n\"is_base64_encoded\": true\n}\n</code></pre>"},{"location":"utilities/data_classes/#advanced","title":"Advanced","text":""},{"location":"utilities/data_classes/#debugging","title":"Debugging","text":"<p>Alternatively, you can print out the fields to obtain more information. All classes come with a <code>__str__</code> method that generates a dictionary string which can be quite useful for debugging.</p> <p>However, certain events may contain sensitive fields such as <code>secret_access_key</code> and <code>session_token</code>, which are labeled as <code>[SENSITIVE]</code> to prevent any accidental disclosure of confidential information.</p> <p>If we fail to deserialize a field value (e.g., JSON), they will appear as <code>[Cannot be deserialized]</code></p> debugging.pydebugging_event.jsondebugging_output.json <pre><code>from aws_lambda_powertools.utilities.data_classes import (\n    CodePipelineJobEvent,\n    event_source,\n)\n\n\n@event_source(data_class=CodePipelineJobEvent)\ndef lambda_handler(event, context):\nprint(event)\n</code></pre> <pre><code>{\n\"CodePipeline.job\": {\n\"id\": \"11111111-abcd-1111-abcd-111111abcdef\",\n\"accountId\": \"111111111111\",\n\"data\": {\n\"actionConfiguration\": {\n\"configuration\": {\n\"FunctionName\": \"MyLambdaFunctionForAWSCodePipeline\",\n\"UserParameters\": \"some-input-such-as-a-URL\"\n}\n},\n\"inputArtifacts\": [\n{\n\"name\": \"ArtifactName\",\n\"revision\": null,\n\"location\": {\n\"type\": \"S3\",\n\"s3Location\": {\n\"bucketName\": \"the name of the bucket configured as the pipeline artifact store in Amazon S3, for example codepipeline-us-east-2-1234567890\",\n\"objectKey\": \"the name of the application, for example CodePipelineDemoApplication.zip\"\n}\n}\n}\n],\n\"outputArtifacts\": [],\n\"artifactCredentials\": {\n\"accessKeyId\": \"AKIAIOSFODNN7EXAMPLE\",\n\"secretAccessKey\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\",\n\"sessionToken\": \"MIICiTCCAfICCQD6m7oRw0uXOjANBgkqhkiG9w0BAQUFADCBiDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQHEwdTZWF0dGxlMQ8wDQYDVQQKEwZBbWF6b24xFDASBgNVBAsTC0lBTSBDb25zb2xlMRIwEAYDVQQDEwlUZXN0Q2lsYWMxHzAdBgkqhkiG9w0BCQEWEG5vb25lQGFtYXpvbi5jb20wHhcNMTEwNDI1MjA0NTIxWhcNMTIwNDI0MjA0NTIxWjCBiDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQHEwdTZWF0dGxlMQ8wDQYDVQQKEwZBbWF6b24xFDASBgNVBAsTC0lBTSBDb25zb2xlMRIwEAYDVQQDEwlUZXN0Q2lsYWMxHzAdBgkqhkiG9w0BCQEWEG5vb25lQGFtYXpvbi5jb20wgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAMaK0dn+a4GmWIWJ21uUSfwfEvySWtC2XADZ4nB+BLYgVIk60CpiwsZ3G93vUEIO3IyNoH/f0wYK8m9TrDHudUZg3qX4waLG5M43q7Wgc/MbQITxOUSQv7c7ugFFDzQGBzZswY6786m86gpEIbb3OhjZnzcvQAaRHhdlQWIMm2nrAgMBAAEwDQYJKoZIhvcNAQEFBQADgYEAtCu4nUhVVxYUntneD9+h8Mg9q6q+auNKyExzyLwaxlAoo7TJHidbtS4J5iNmZgXL0FkbFFBjvSfpJIlJ00zbhNYS5f6GuoEDmFJl0ZxBHjJnyp378OD8uTs7fLvjx79LjSTbNYiytVbZPQUQ5Yaxu2jXnimvw3rrszlaEXAMPLE=\"\n},\n\"continuationToken\": \"A continuation token if continuing job\"\n}\n}\n}\n</code></pre> <p><pre><code>{\n\"account_id\":\"111111111111\",\n\"data\":{\n\"action_configuration\":{\n\"configuration\":{\n\"decoded_user_parameters\":\"[Cannot be deserialized]\",\n\"function_name\":\"MyLambdaFunctionForAWSCodePipeline\",\n\"raw_event\":\"[SENSITIVE]\",\n\"user_parameters\":\"some-input-such-as-a-URL\"\n},\n\"raw_event\":\"[SENSITIVE]\"\n},\n\"artifact_credentials\":{\n\"access_key_id\":\"AKIAIOSFODNN7EXAMPLE\",\n\"expiration_time\":\"None\",\n\"raw_event\":\"[SENSITIVE]\",\n\"secret_access_key\":\"[SENSITIVE]\",\n\"session_token\":\"[SENSITIVE]\"\n},\n\"continuation_token\":\"A continuation token if continuing job\",\n\"encryption_key\":\"None\",\n\"input_artifacts\":[\n{\n\"location\":{\n\"get_type\":\"S3\",\n\"raw_event\":\"[SENSITIVE]\",\n\"s3_location\":{\n\"bucket_name\":\"the name of the bucket configured as the pipeline artifact store in Amazon S3, for example codepipeline-us-east-2-1234567890\",\n\"key\":\"the name of the application, for example CodePipelineDemoApplication.zip\",\n\"object_key\":\"the name of the application, for example CodePipelineDemoApplication.zip\",\n\"raw_event\":\"[SENSITIVE]\"\n}\n},\n\"name\":\"ArtifactName\",\n\"raw_event\":\"[SENSITIVE]\",\n\"revision\":\"None\"\n}\n],\n\"output_artifacts\":[\n\n],\n\"raw_event\":\"[SENSITIVE]\"\n},\n\"decoded_user_parameters\":\"[Cannot be deserialized]\",\n\"get_id\":\"11111111-abcd-1111-abcd-111111abcdef\",\n\"input_bucket_name\":\"the name of the bucket configured as the pipeline artifact store in Amazon S3, for example codepipeline-us-east-2-1234567890\",\n\"input_object_key\":\"the name of the application, for example CodePipelineDemoApplication.zip\",\n\"raw_event\":\"[SENSITIVE]\",\n\"user_parameters\":\"some-input-such-as-a-URL\"\n}\n</code></pre> ```</p>"},{"location":"utilities/feature_flags/","title":"Feature flags","text":"<p>The feature flags utility provides a simple rule engine to define when one or multiple features should be enabled depending on the input.</p> Info <p>When using <code>AppConfigStore</code>, we currently only support AppConfig using freeform configuration profile  .</p>"},{"location":"utilities/feature_flags/#key-features","title":"Key features","text":"<ul> <li>Define simple feature flags to dynamically decide when to enable a feature</li> <li>Fetch one or all feature flags enabled for a given application context</li> <li>Support for static feature flags to simply turn on/off a feature without rules</li> <li>Support for time based feature flags</li> <li>Bring your own Feature Flags Store Provider</li> </ul>"},{"location":"utilities/feature_flags/#terminology","title":"Terminology","text":"<p>Feature flags are used to modify behaviour without changing the application's code. These flags can be static or dynamic.</p> <p>Static flags. Indicates something is simply <code>on</code> or <code>off</code>, for example <code>TRACER_ENABLED=True</code>.</p> <p>Dynamic flags. Indicates something can have varying states, for example enable a list of premium features for customer X not Y.</p> Tip <p>You can use Parameters utility for static flags while this utility can do both static and dynamic feature flags.</p> Warning <p>Be mindful that feature flags can increase the complexity of your application over time; use them sparingly.</p> <p>If you want to learn more about feature flags, their variations and trade-offs, check these articles:</p> <ul> <li>Feature Toggles (aka Feature Flags) - Pete Hodgson</li> <li>AWS Lambda Feature Toggles Made Simple - Ran Isenberg</li> <li>Feature Flags Getting Started - CloudBees</li> </ul> Note <p>AWS AppConfig requires two API calls to fetch configuration for the first time. You can improve latency by consolidating your feature settings in a single Configuration.</p>"},{"location":"utilities/feature_flags/#getting-started","title":"Getting started","text":""},{"location":"utilities/feature_flags/#iam-permissions","title":"IAM Permissions","text":"<p>When using the default store <code>AppConfigStore</code>, your Lambda function IAM Role must have <code>appconfig:GetLatestConfiguration</code> and <code>appconfig:StartConfigurationSession</code> IAM permissions before using this feature.</p>"},{"location":"utilities/feature_flags/#required-resources","title":"Required resources","text":"<p>By default, this utility provides AWS AppConfig as a configuration store.</p> <p>The following sample infrastructure will be used throughout this documentation:</p> template.yamlCDK <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nDescription: Lambda Powertools for Python Feature flags sample template\nResources:\nFeatureStoreApp:\nType: AWS::AppConfig::Application\nProperties:\nDescription: \"AppConfig Application for feature toggles\"\nName: product-catalogue\n\nFeatureStoreDevEnv:\nType: AWS::AppConfig::Environment\nProperties:\nApplicationId: !Ref FeatureStoreApp\nDescription: \"Development Environment for the App Config Store\"\nName: dev\n\nFeatureStoreConfigProfile:\nType: AWS::AppConfig::ConfigurationProfile\nProperties:\nApplicationId: !Ref FeatureStoreApp\nName: features\nLocationUri: \"hosted\"\n\nHostedConfigVersion:\nType: AWS::AppConfig::HostedConfigurationVersion\nProperties:\nApplicationId: !Ref FeatureStoreApp\nConfigurationProfileId: !Ref FeatureStoreConfigProfile\nDescription: 'A sample hosted configuration version'\nContent: |\n{\n\"premium_features\": {\n\"default\": false,\n\"rules\": {\n\"customer tier equals premium\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n}\n]\n}\n}\n},\n\"ten_percent_off_campaign\": {\n\"default\": false\n}\n}\nContentType: 'application/json'\n\nConfigDeployment:\nType: AWS::AppConfig::Deployment\nProperties:\nApplicationId: !Ref FeatureStoreApp\nConfigurationProfileId: !Ref FeatureStoreConfigProfile\nConfigurationVersion: !Ref HostedConfigVersion\nDeploymentStrategyId: \"AppConfig.AllAtOnce\"\nEnvironmentId: !Ref FeatureStoreDevEnv\n</code></pre> <pre><code>import json\n\nimport aws_cdk.aws_appconfig as appconfig\nfrom aws_cdk import core\n\n\nclass SampleFeatureFlagStore(core.Construct):\n    def __init__(self, scope: core.Construct, id_: str) -&gt; None:\n        super().__init__(scope, id_)\n\nfeatures_config = {\n\"premium_features\": {\n\"default\": False,\n\"rules\": {\n\"customer tier equals premium\": {\n\"when_match\": True,\n\"conditions\": [{\"action\": \"EQUALS\", \"key\": \"tier\", \"value\": \"premium\"}],\n}\n},\n},\n\"ten_percent_off_campaign\": {\"default\": True},\n}\nself.config_app = appconfig.CfnApplication(\nself,\n            id=\"app\",\n            name=\"product-catalogue\",\n        )\nself.config_env = appconfig.CfnEnvironment(\nself,\n            id=\"env\",\n            application_id=self.config_app.ref,\n            name=\"dev-env\",\n        )\nself.config_profile = appconfig.CfnConfigurationProfile(\nself,\n            id=\"profile\",\n            application_id=self.config_app.ref,\n            location_uri=\"hosted\",\n            name=\"features\",\n        )\nself.hosted_cfg_version = appconfig.CfnHostedConfigurationVersion(\nself,\n            \"version\",\n            application_id=self.config_app.ref,\n            configuration_profile_id=self.config_profile.ref,\n            content=json.dumps(features_config),\n            content_type=\"application/json\",\n        )\nself.app_config_deployment = appconfig.CfnDeployment(\nself,\n            id=\"deploy\",\n            application_id=self.config_app.ref,\n            configuration_profile_id=self.config_profile.ref,\n            configuration_version=self.hosted_cfg_version.ref,\n            deployment_strategy_id=\"AppConfig.AllAtOnce\",\n            environment_id=self.config_env.ref,\n        )\n</code></pre>"},{"location":"utilities/feature_flags/#evaluating-a-single-feature-flag","title":"Evaluating a single feature flag","text":"<p>To get started, you'd need to initialize <code>AppConfigStore</code> and <code>FeatureFlags</code>. Then call <code>FeatureFlags</code> <code>evaluate</code> method to fetch, validate, and evaluate your feature.</p> <p>The <code>evaluate</code> method supports two optional parameters:</p> <ul> <li>context: Value to be evaluated against each rule defined for the given feature</li> <li>default: Sentinel value to use in case we experience any issues with our store, or feature doesn't exist</li> </ul> getting_started_single_feature_flag.pygetting_started_single_feature_flag_payload.jsongetting_started_single_feature_flag_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This feature flag is enabled under the following conditions:\n    - The request payload contains a field 'tier' with the value 'premium'.\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n            {\n                \"action\": \"EQUALS\",\n                \"key\": \"tier\",\n                \"value\": \"premium\"\n            }\n        ]\n    \"\"\"\n\n    # Get customer's tier from incoming request\nctx = {\"tier\": event.get(\"tier\", \"standard\")}\n# Evaluate whether customer's tier has access to premium features\n    # based on `has_premium_features` rules\nhas_premium_features: Any = feature_flags.evaluate(name=\"premium_features\", context=ctx, default=False)\nif has_premium_features:\n        # enable premium features\n        ...\n</code></pre> <pre><code>{\n\"username\": \"lessa\",\n\"tier\": \"premium\",\n\"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n\"premium_features\": {\n\"default\": false,\n\"rules\": {\n\"customer tier equals premium\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n}\n]\n}\n}\n},\n\"ten_percent_off_campaign\": {\n\"default\": false\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#static-flags","title":"Static flags","text":"<p>We have a static flag named <code>ten_percent_off_campaign</code>. Meaning, there are no conditional rules, it's either ON or OFF for all customers.</p> <p>In this case, we could omit the <code>context</code> parameter and simply evaluate whether we should apply the 10% discount.</p> getting_started_static_flag.pygetting_started_static_flag_payload.jsongetting_started_static_flag_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This feature flag is enabled by default for all requests.\n    \"\"\"\n\napply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\nprice: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n\"product\": \"laptop\",\n\"price\": 1000\n}\n</code></pre> <pre><code>{\n\"ten_percent_off_campaign\": {\n\"default\": true\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#getting-all-enabled-features","title":"Getting all enabled features","text":"<p>As you might have noticed, each <code>evaluate</code> call means an API call to the Store and the more features you have the more costly this becomes.</p> <p>You can use <code>get_enabled_features</code> method for scenarios where you need a list of all enabled features according to the input context.</p> getting_all_enabled_features.pygetting_all_enabled_features_payload.jsongetting_all_enabled_features_features.json <pre><code>from aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver()\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n@app.get(\"/products\")\ndef list_products():\n    # getting fields from request\n    # https://docs.powertools.aws.dev/lambda/python/latest/core/event_handler/api_gateway/#accessing-request-details\n    json_body = app.current_event.json_body\n    headers = app.current_event.headers\n\n    ctx = {**headers, **json_body}\n\n    # getting price from payload\n    price: float = float(json_body.get(\"price\"))\n    percent_discount: int = 0\n\n    # all_features is evaluated to [\"premium_features\", \"geo_customer_campaign\", \"ten_percent_off_campaign\"]\nall_features: list[str] = feature_flags.get_enabled_features(context=ctx)\nif \"geo_customer_campaign\" in all_features:\n        # apply 20% discounts for customers in NL\n        percent_discount += 20\n\n    if \"ten_percent_off_campaign\" in all_features:\n        # apply additional 10% for all customers\n        percent_discount += 10\n\n    price = price * (100 - percent_discount) / 100\n\n    return {\"price\": price}\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"body\": \"{\\\"username\\\": \\\"lessa\\\", \\\"tier\\\": \\\"premium\\\", \\\"basked_id\\\": \\\"random_id\\\", \\\"price\\\": 1000}\",\n\"resource\": \"/products\",\n\"path\": \"/products\",\n\"httpMethod\": \"GET\",\n\"isBase64Encoded\": false,\n\"headers\": {\n\"CloudFront-Viewer-Country\": \"NL\"\n}\n}\n</code></pre> <pre><code>{\n\"premium_features\": {\n\"default\": false,\n\"rules\": {\n\"customer tier equals premium\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n}\n]\n}\n}\n},\n\"ten_percent_off_campaign\": {\n\"default\": true\n},\n\"geo_customer_campaign\": {\n\"default\": false,\n\"rules\": {\n\"customer in temporary discount geo\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"KEY_IN_VALUE\",\n\"key\": \"CloudFront-Viewer-Country\",\n\"value\": [\n\"NL\",\n\"IE\",\n\"UK\",\n\"PL\",\n\"PT\"\n]\n}\n]\n}\n}\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#time-based-feature-flags","title":"Time based feature flags","text":"<p>Feature flags can also return enabled features based on time or datetime ranges. This allows you to have features that are only enabled on certain days of the week, certain time intervals or between certain calendar dates.</p> <p>Use cases:</p> <ul> <li>Enable maintenance mode during a weekend</li> <li>Disable support/chat feature after working hours</li> <li>Launch a new feature on a specific date and time</li> </ul> <p>You can also have features enabled only at certain times of the day for premium tier customers</p> timebased_feature.pytimebased_feature_event.jsontimebased_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This feature flag is enabled under the following conditions:\n    - The request payload contains a field 'tier' with the value 'premium'.\n    - If the current day is either Saturday or Sunday in America/New_York timezone.\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"EQUALS\",\n            \"key\": \"tier\",\n            \"value\": \"premium\"\n          },\n          {\n            \"action\": \"SCHEDULE_BETWEEN_DAYS_OF_WEEK\",\n            \"key\": \"CURRENT_DAY_OF_WEEK\",\n            \"value\": {\n              \"DAYS\": [\n                \"SATURDAY\",\n                \"SUNDAY\"\n              ],\n              \"TIMEZONE\": \"America/New_York\"\n            }\n          }\n        ]\n    \"\"\"\n\n    # Get customer's tier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\")}\n\n    # Checking if the weekend premum discount is enable\nweekend_premium_discount = feature_flags.evaluate(name=\"weekend_premium_discount\", default=False, context=ctx)\nif weekend_premium_discount:\n        # Enable special discount on weekend for premium users:\n        return {\"message\": \"The weekend premium discount is enabled.\"}\n\n    return {\"message\": \"The weekend premium discount is not enabled.\"}\n</code></pre> <pre><code>{\n\"username\": \"rubefons\",\n\"tier\": \"premium\",\n\"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n\"weekend_premium_discount\": {\n\"default\": false,\n\"rules\": {\n\"customer tier equals premium and its time for a discount\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n},\n{\n\"action\": \"SCHEDULE_BETWEEN_DAYS_OF_WEEK\",\n\"key\": \"CURRENT_DAY_OF_WEEK\",\n\"value\": {\n\"DAYS\": [\n\"SATURDAY\",\n\"SUNDAY\"\n],\n\"TIMEZONE\": \"America/New_York\"\n}\n}\n]\n}\n}\n}\n}\n</code></pre> <p>You can also have features enabled only at certain times of the day.</p> timebased_happyhour_feature.pytimebased_happyhour_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This feature flag is enabled under the following conditions:\n    - Every day between 17:00 to 19:00 in Europe/Copenhagen timezone\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"SCHEDULE_BETWEEN_TIME_RANGE\",\n            \"key\": \"CURRENT_TIME\",\n            \"value\": {\n              \"START\": \"17:00\",\n              \"END\": \"19:00\",\n              \"TIMEZONE\": \"Europe/Copenhagen\"\n            }\n          }\n        ]\n    \"\"\"\n\n    # Checking if the happy hour discount is enable\nis_happy_hour = feature_flags.evaluate(name=\"happy_hour\", default=False)\nif is_happy_hour:\n        # Enable special discount on happy hour:\n        return {\"message\": \"The happy hour discount is enabled.\"}\n\n    return {\"message\": \"The happy hour discount is not enabled.\"}\n</code></pre> <pre><code>{\n\"happy_hour\": {\n\"default\": false,\n\"rules\": {\n\"is happy hour\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"SCHEDULE_BETWEEN_TIME_RANGE\",\n\"key\": \"CURRENT_TIME\",\n\"value\": {\n\"START\": \"17:00\",\n\"END\": \"19:00\",\n\"TIMEZONE\": \"Europe/Copenhagen\"\n}\n}\n]\n}\n}\n}\n}\n</code></pre> <p>You can also have features enabled only at specific days, for example: enable christmas sale discount during specific dates.</p> datetime_feature.pydatetime_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This feature flag is enabled under the following conditions:\n    - Start date: December 25th, 2022 at 12:00:00 PM EST\n    - End date: December 31st, 2022 at 11:59:59 PM EST\n    - Timezone: America/New_York\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"SCHEDULE_BETWEEN_DATETIME_RANGE\",\n            \"key\": \"CURRENT_DATETIME\",\n            \"value\": {\n              \"START\": \"2022-12-25T12:00:00\",\n              \"END\": \"2022-12-31T23:59:59\",\n              \"TIMEZONE\": \"America/New_York\"\n            }\n          }\n        ]\n    \"\"\"\n\n    # Checking if the Christmas discount is enable\nxmas_discount = feature_flags.evaluate(name=\"christmas_discount\", default=False)\nif xmas_discount:\n        # Enable special discount on christmas:\n        return {\"message\": \"The Christmas discount is enabled.\"}\n\n    return {\"message\": \"The Christmas discount is not enabled.\"}\n</code></pre> <pre><code>{\n\"christmas_discount\": {\n\"default\": false,\n\"rules\": {\n\"enable discount during christmas\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"SCHEDULE_BETWEEN_DATETIME_RANGE\",\n\"key\": \"CURRENT_DATETIME\",\n\"value\": {\n\"START\": \"2022-12-25T12:00:00\",\n\"END\": \"2022-12-31T23:59:59\",\n\"TIMEZONE\": \"America/New_York\"\n}\n}\n]\n}\n}\n}\n}\n</code></pre> How should I use timezones? <p>You can use any IANA time zone (as originally specified in PEP 615) as part of your rules definition. Powertools for AWS Lambda (Python) takes care of converting and calculate the correct timestamps for you.</p> <p>When using <code>SCHEDULE_BETWEEN_DATETIME_RANGE</code>, use timestamps without timezone information, and specify the timezone manually. This way, you'll avoid hitting problems with day light savings.</p>"},{"location":"utilities/feature_flags/#modulo-range-segmented-experimentation","title":"Modulo Range Segmented Experimentation","text":"<p>Feature flags can also be used to run experiments on a segment of users based on modulo range conditions on context variables. This allows you to have features that are only enabled for a certain segment of users, comparing across multiple variants of the same experiment.</p> <p>Use cases:</p> <ul> <li>Enable an experiment for a percentage of users</li> <li>Scale up an experiment incrementally in production - canary release</li> <li>Run multiple experiments or variants simultaneously by assigning a spectrum segment to each experiment variant.</li> </ul> <p>The modulo range condition takes three values - <code>BASE</code>, <code>START</code> and <code>END</code>.</p> <p>The condition evaluates <code>START &lt;= CONTEXT_VALUE % BASE &lt;= END</code>.</p> modulo_range_feature.pymodulo_range_feature_event.jsonmodulo_range_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This feature flag is enabled under the following conditions:\n    - The request payload contains a field 'tier' with the value 'standard'.\n    - If the user_id belongs to the spectrum 0-19 modulo 100, (20% users) on whom we want to run the sale experiment.\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"EQUALS\",\n            \"key\": \"tier\",\n            \"value\": \"standard\"\n          },\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 100,\n              \"START\": 0,\n              \"END\": 19\n            }\n          }\n        ]\n    \"\"\"\n\n    # Get customer's tier and identifier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\"), \"user_id\": event.get(\"user_id\", 0)}\n\n    # Checking if the sale_experiment is enable\nsale_experiment = feature_flags.evaluate(name=\"sale_experiment\", default=False, context=ctx)\nif sale_experiment:\n        # Enable special discount for sale experiment segment users:\n        return {\"message\": \"The sale experiment is enabled.\"}\n\n    return {\"message\": \"The sale experiment is not enabled.\"}\n</code></pre> <pre><code>{\n\"user_id\": 134532511,\n\"tier\": \"standard\",\n\"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n\"sale_experiment\": {\n\"default\": false,\n\"rules\": {\n\"experiment 1 segment - 20% users\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"standard\"\n},\n{\n\"action\": \"MODULO_RANGE\",\n\"key\": \"user_id\",\n\"value\": {\n\"BASE\": 100,\n\"START\": 0,\n\"END\": 19\n}\n}\n]\n}\n}\n}\n}\n</code></pre> <p>You can run multiple experiments on your users with the spectrum of your choice.</p> modulo_range_multiple_feature.pymodulo_range_multiple_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This non-boolean feature flag returns the percentage discount depending on the sale experiment segment:\n    - 10% standard discount if the user_id belongs to the spectrum 0-3 modulo 10, (40% users).\n    - 15% experiment discount if the user_id belongs to the spectrum 4-6 modulo 10, (30% users).\n    - 18% experiment discount if the user_id belongs to the spectrum 7-9 modulo 10, (30% users).\n\n    Rule conditions to be evaluated:\n    \"rules\": {\n      \"control group - standard 10% discount segment\": {\n        \"when_match\": 10,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 0,\n              \"END\": 3\n            }\n          }\n        ]\n      },\n      \"test experiment 1 - 15% discount segment\": {\n        \"when_match\": 15,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 4,\n              \"END\": 6\n            }\n          }\n        ]\n      },\n      \"test experiment 2 - 18% discount segment\": {\n        \"when_match\": 18,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 7,\n              \"END\": 9\n            }\n          }\n        ]\n      }\n    }\n    \"\"\"\n\n    # Get customer's tier and identifier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\"), \"user_id\": event.get(\"user_id\", 0)}\n\n    # Get sale discount percentage from feature flag.\nsale_experiment_discount = feature_flags.evaluate(name=\"sale_experiment_discount\", default=0, context=ctx)\nreturn {\"message\": f\" {sale_experiment_discount}% discount applied.\"}\n</code></pre> <pre><code>{\n\"sale_experiment_discount\": {\n\"boolean_type\": false,\n\"default\": 0,\n\"rules\": {\n\"control group - standard 10% discount segment\": {\n\"when_match\": 10,\n\"conditions\": [\n{\n\"action\": \"MODULO_RANGE\",\n\"key\": \"user_id\",\n\"value\": {\n\"BASE\": 10,\n\"START\": 0,\n\"END\": 3\n}\n}\n]\n},\n\"test experiment 1 - 15% discount segment\": {\n\"when_match\": 15,\n\"conditions\": [\n{\n\"action\": \"MODULO_RANGE\",\n\"key\": \"user_id\",\n\"value\": {\n\"BASE\": 10,\n\"START\": 4,\n\"END\": 6\n}\n}\n]\n},\n\"test experiment 2 - 18% discount segment\": {\n\"when_match\": 18,\n\"conditions\": [\n{\n\"action\": \"MODULO_RANGE\",\n\"key\": \"user_id\",\n\"value\": {\n\"BASE\": 10,\n\"START\": 7,\n\"END\": 9\n}\n}\n]\n}\n}\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#beyond-boolean-feature-flags","title":"Beyond boolean feature flags","text":"When is this useful? <p>You might have a list of features to unlock for premium customers, unlock a specific set of features for admin users, etc.</p> <p>Feature flags can return any JSON values when <code>boolean_type</code> parameter is set to <code>false</code>. These can be dictionaries, list, string, integers, etc.</p> beyond_boolean.pybeyond_boolean_payload.jsonbeyond_boolean_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"comments\", name=\"config\")\n\nfeature_flags = FeatureFlags(store=app_config)\ndef lambda_handler(event: dict, context: LambdaContext):\n    # Get customer's tier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\")}\n\n    # Evaluate `has_premium_features` based on customer's tier\npremium_features: Any = feature_flags.evaluate(name=\"premium_features\", context=ctx, default=[])\nreturn {\"Premium features enabled\": premium_features}\n</code></pre> <pre><code>{\n\"username\": \"lessa\",\n\"tier\": \"premium\",\n\"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n\"premium_features\": {\n\"boolean_type\": false,\n\"default\": [],\n\"rules\": {\n\"customer tier equals premium\": {\n\"when_match\": [\n\"no_ads\",\n\"no_limits\",\n\"chat\"\n],\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n}\n]\n}\n}\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#advanced","title":"Advanced","text":""},{"location":"utilities/feature_flags/#adjusting-in-memory-cache","title":"Adjusting in-memory cache","text":"<p>By default, we cache configuration retrieved from the Store for 5 seconds for performance and reliability reasons.</p> <p>You can override <code>max_age</code> parameter when instantiating the store.</p> getting_started_with_cache.pygetting_started_with_cache_payload.jsongetting_started_with_cache_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\", max_age=300)\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\"\"\"\n    This feature flag is enabled by default for all requests.\n    \"\"\"\n\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n\"product\": \"laptop\",\n\"price\": 1000\n}\n</code></pre> <pre><code>{\n\"ten_percent_off_campaign\": {\n\"default\": true\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#getting-fetched-configuration","title":"Getting fetched configuration","text":"When is this useful? <p>You might have application configuration in addition to feature flags in your store.</p> <p>This means you don't need to make another call only to fetch app configuration.</p> <p>You can access the configuration fetched from the store via <code>get_raw_configuration</code> property within the store instance.</p> getting_stored_features.py <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\n\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"configuration\",\n    envelope=\"feature_flags\",\n)\nfeature_flags = FeatureFlags(store=app_config)\n\nconfig = app_config.get_raw_configuration\n...\n</code></pre>"},{"location":"utilities/feature_flags/#schema","title":"Schema","text":"<p>This utility expects a certain schema to be stored as JSON within AWS AppConfig.</p>"},{"location":"utilities/feature_flags/#features","title":"Features","text":"<p>A feature can simply have its name and a <code>default</code> value. This is either on or off, also known as a static flag.</p> minimal_schema.json <pre><code>{\n\"global_feature\": {\n\"default\": true\n},\n\"non_boolean_global_feature\": {\n\"default\": {\"group\": \"read-only\"},\n\"boolean_type\": false\n}\n}\n</code></pre> <p>If you need more control and want to provide context such as user group, permissions, location, etc., you need to add rules to your feature flag configuration.</p>"},{"location":"utilities/feature_flags/#rules","title":"Rules","text":"<p>When adding <code>rules</code> to a feature, they must contain:</p> <ol> <li>A rule name as a key</li> <li><code>when_match</code> boolean or JSON value that should be used when conditions match</li> <li>A list of <code>conditions</code> for evaluation</li> </ol> feature_with_rules.json <pre><code>{\n\"premium_feature\": {\n\"default\": false,\n\"rules\": {\n\"customer tier equals premium\": {\n\"when_match\": true,\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n}\n]\n}\n}\n},\n\"non_boolean_premium_feature\": {\n\"default\": [],\n\"rules\": {\n\"customer tier equals premium\": {\n\"when_match\": [\"remove_limits\", \"remove_ads\"],\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n}\n]\n}\n}\n}\n}\n</code></pre> <p>You can have multiple rules with different names. The rule engine will return the first result <code>when_match</code> of the matching rule configuration, or <code>default</code> value when none of the rules apply.</p>"},{"location":"utilities/feature_flags/#conditions","title":"Conditions","text":"<p>The <code>conditions</code> block is a list of conditions that contain <code>action</code>, <code>key</code>, and <code>value</code> keys:</p> conditions.json <pre><code>{\n\"conditions\": [\n{\n\"action\": \"EQUALS\",\n\"key\": \"tier\",\n\"value\": \"premium\"\n}\n]\n}\n</code></pre> <p>The <code>action</code> configuration can have the following values, where the expressions <code>a</code> is the <code>key</code> and <code>b</code> is the <code>value</code> above:</p> Action Equivalent expression EQUALS <code>lambda a, b: a == b</code> NOT_EQUALS <code>lambda a, b: a != b</code> KEY_GREATER_THAN_VALUE <code>lambda a, b: a &gt; b</code> KEY_GREATER_THAN_OR_EQUAL_VALUE <code>lambda a, b: a &gt;= b</code> KEY_LESS_THAN_VALUE <code>lambda a, b: a &lt; b</code> KEY_LESS_THAN_OR_EQUAL_VALUE <code>lambda a, b: a &lt;= b</code> STARTSWITH <code>lambda a, b: a.startswith(b)</code> ENDSWITH <code>lambda a, b: a.endswith(b)</code> KEY_IN_VALUE <code>lambda a, b: a in b</code> KEY_NOT_IN_VALUE <code>lambda a, b: a not in b</code> VALUE_IN_KEY <code>lambda a, b: b in a</code> VALUE_NOT_IN_KEY <code>lambda a, b: b not in a</code> SCHEDULE_BETWEEN_TIME_RANGE <code>lambda a, b: b.start &lt;= time(a) &lt;= b.end</code> SCHEDULE_BETWEEN_DATETIME_RANGE <code>lambda a, b: b.start &lt;= datetime(a) &lt;= b.end</code> SCHEDULE_BETWEEN_DAYS_OF_WEEK <code>lambda a, b: day_of_week(a) in b</code> MODULO_RANGE <code>lambda a, b: b.start &lt;= a % b.base &lt;= b.end</code> Info <p>The <code>key</code> and <code>value</code> will be compared to the input from the <code>context</code> parameter.</p> Time based keys <p>For time based keys, we provide a list of predefined keys. These will automatically get converted to the corresponding timestamp on each invocation of your Lambda function.</p> Key Meaning CURRENT_TIME The current time, 24 hour format (HH:mm) CURRENT_DATETIME The current datetime (ISO8601) CURRENT_DAY_OF_WEEK The current day of the week (Monday-Sunday) <p>If not specified, the timezone used for calculations will be UTC.</p> <p>For multiple conditions, we will evaluate the list of conditions as a logical <code>AND</code>, so all conditions needs to match to return <code>when_match</code> value.</p>"},{"location":"utilities/feature_flags/#rule-engine-flowchart","title":"Rule engine flowchart","text":"<p>Now that you've seen all properties of a feature flag schema, this flowchart describes how the rule engine decides what value to return.</p> <p></p>"},{"location":"utilities/feature_flags/#envelope","title":"Envelope","text":"<p>There are scenarios where you might want to include feature flags as part of an existing application configuration.</p> <p>For this to work, you need to use a JMESPath expression via the <code>envelope</code> parameter to extract that key as the feature flags configuration.</p> extracting_envelope.pyextracting_envelope_payload.jsonextracting_envelope_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(\nenvironment=\"dev\",\napplication=\"product-catalogue\",\n    name=\"features\",\n    envelope=\"feature_flags\",\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n\"product\": \"laptop\",\n\"price\": 1000\n}\n</code></pre> <pre><code>{\n\"logging\": {\n\"level\": \"INFO\",\n\"sampling_rate\": 0.1\n},\n\"features\": {\n\"ten_percent_off_campaign\": {\n\"default\": true\n}\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#built-in-store-provider","title":"Built-in store provider","text":""},{"location":"utilities/feature_flags/#appconfig","title":"AppConfig","text":"<p>AppConfig store provider fetches any JSON document from AWS AppConfig.</p> <p>These are the available options for further customization.</p> Parameter Default Description environment <code>\"\"</code> AWS AppConfig Environment, e.g. <code>dev</code> application <code>\"\"</code> AWS AppConfig Application, e.g. <code>product-catalogue</code> name <code>\"\"</code> AWS AppConfig Configuration name, e.g <code>features</code> envelope <code>None</code> JMESPath expression to use to extract feature flags configuration from AWS AppConfig configuration max_age <code>5</code> Number of seconds to cache feature flags configuration fetched from AWS AppConfig sdk_config <code>None</code> Botocore Config object jmespath_options <code>None</code> For advanced use cases when you want to bring your own JMESPath functions logger <code>logging.Logger</code> Logger to use for debug.  You can optionally supply an instance of Powertools for AWS Lambda (Python) Logger. appconfig_provider_options.pyappconfig_provider_options_payload.jsonappconfig_provider_options_features.json <pre><code>from typing import Any\n\nfrom botocore.config import Config\nfrom jmespath.functions import Functions, signature\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nboto_config = Config(read_timeout=10, retries={\"total_max_attempts\": 2})\n# Custom JMESPath functions\nclass CustomFunctions(Functions):\n@signature({\"types\": [\"object\"]})\ndef _func_special_decoder(self, features):\n# You can add some logic here\nreturn features\ncustom_jmespath_options = {\"custom_functions\": CustomFunctions()}\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"features\",\n    max_age=120,\nenvelope=\"special_decoder(features)\",  # using a custom function defined in CustomFunctions Class\nsdk_config=boto_config,\njmespath_options=custom_jmespath_options,\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n\"product\": \"laptop\",\n\"price\": 1000\n}\n</code></pre> <pre><code>{\n\"logging\": {\n\"level\": \"INFO\",\n\"sampling_rate\": 0.1\n},\n\"features\": {\n\"ten_percent_off_campaign\": {\n\"default\": true\n}\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#create-your-own-store-provider","title":"Create your own store provider","text":"<p>You can create your own custom FeatureFlags store provider by inheriting the <code>StoreProvider</code> class, and implementing both <code>get_raw_configuration()</code> and <code>get_configuration()</code> methods to retrieve the configuration from your custom store.</p> <ul> <li><code>get_raw_configuration()</code> \u2013 get the raw configuration from the store provider and return the parsed JSON dictionary</li> <li><code>get_configuration()</code> \u2013 get the configuration from the store provider, parsing it as a JSON dictionary. If an envelope is set, extract the envelope data</li> </ul> <p>Here are an example of implementing a custom store provider using Amazon S3, a popular object storage.</p> Note <p>This is just one example of how you can create your own store provider. Before creating a custom store provider, carefully evaluate your requirements and consider factors such as performance, scalability, and ease of maintenance.</p> working_with_own_s3_store_provider.pycustom_s3_store_provider.pyworking_with_own_s3_store_provider_payload.jsonworking_with_own_s3_store_provider_features.json <pre><code>from typing import Any\n\nfrom custom_s3_store_provider import S3StoreProvider\nfrom aws_lambda_powertools.utilities.feature_flags import FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ns3_config_store = S3StoreProvider(\"your-bucket-name\", \"working_with_own_s3_store_provider_features.json\")\nfeature_flags = FeatureFlags(store=s3_config_store)\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>import json\nfrom typing import Any, Dict\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\nfrom aws_lambda_powertools.utilities.feature_flags.base import StoreProvider\nfrom aws_lambda_powertools.utilities.feature_flags.exceptions import (\n    ConfigurationStoreError,\n)\n\n\nclass S3StoreProvider(StoreProvider):\n    def __init__(self, bucket_name: str, object_key: str):\n        # Initialize the client to your custom store provider\n\n        super().__init__()\n\n        self.bucket_name = bucket_name\n        self.object_key = object_key\n        self.client = boto3.client(\"s3\")\n\n    def _get_s3_object(self) -&gt; Dict[str, Any]:\n        # Retrieve the object content\n        parameters = {\"Bucket\": self.bucket_name, \"Key\": self.object_key}\n\n        try:\n            response = self.client.get_object(**parameters)\n            return json.loads(response[\"Body\"].read().decode())\n        except ClientError as exc:\n            raise ConfigurationStoreError(\"Unable to get S3 Store Provider configuration file\") from exc\n\ndef get_configuration(self) -&gt; Dict[str, Any]:\nreturn self._get_s3_object()\n\n    @property\ndef get_raw_configuration(self) -&gt; Dict[str, Any]:\nreturn self._get_s3_object()\n</code></pre> <pre><code>{\n\"product\": \"laptop\",\n\"price\": 1000\n}\n</code></pre> <pre><code>{\n\"ten_percent_off_campaign\": {\n\"default\": true\n}\n}\n</code></pre>"},{"location":"utilities/feature_flags/#testing-your-code","title":"Testing your code","text":"<p>You can unit test your feature flags locally and independently without setting up AWS AppConfig.</p> <p><code>AppConfigStore</code> only fetches a JSON document with a specific schema. This allows you to mock the response and use it to verify the rule evaluation.</p> Warning <p>This excerpt relies on <code>pytest</code> and <code>pytest-mock</code> dependencies.</p> Testing your code <pre><code>from aws_lambda_powertools.utilities.feature_flags import (\n    AppConfigStore,\n    FeatureFlags,\n    RuleAction,\n)\n\n\ndef init_feature_flags(mocker, mock_schema, envelope=\"\") -&gt; FeatureFlags:\n\"\"\"Mock AppConfig Store get_configuration method to use mock schema instead\"\"\"\n\nmethod_to_mock = \"aws_lambda_powertools.utilities.feature_flags.AppConfigStore.get_configuration\"\nmocked_get_conf = mocker.patch(method_to_mock)\nmocked_get_conf.return_value = mock_schema\napp_conf_store = AppConfigStore(\n        environment=\"test_env\",\n        application=\"test_app\",\n        name=\"test_conf_name\",\n        envelope=envelope,\n    )\n\n    return FeatureFlags(store=app_conf_store)\n\n\ndef test_flags_condition_match(mocker):\n    # GIVEN\n    expected_value = True\n    mocked_app_config_schema = {\n        \"my_feature\": {\n            \"default\": False,\n            \"rules\": {\n                \"tenant id equals 12345\": {\n                    \"when_match\": expected_value,\n                    \"conditions\": [\n                        {\n                            \"action\": RuleAction.EQUALS.value,\n                            \"key\": \"tenant_id\",\n                            \"value\": \"12345\",\n                        },\n                    ],\n                },\n            },\n        },\n    }\n\n    # WHEN\n    ctx = {\"tenant_id\": \"12345\", \"username\": \"a\"}\n    feature_flags = init_feature_flags(mocker=mocker, mock_schema=mocked_app_config_schema)\n    flag = feature_flags.evaluate(name=\"my_feature\", context=ctx, default=False)\n\n    # THEN\n    assert flag == expected_value\n</code></pre>"},{"location":"utilities/feature_flags/#feature-flags-vs-parameters-vs-env-vars","title":"Feature flags vs Parameters vs Env vars","text":"Method When to use Requires new deployment on changes Supported services Environment variables Simple configuration that will rarely if ever change, because changing it requires a Lambda function deployment. Yes Lambda Parameters utility Access to secrets, or fetch parameters in different formats from AWS System Manager Parameter Store or Amazon DynamoDB. No Parameter Store, DynamoDB, Secrets Manager, AppConfig Feature flags utility Rule engine to define when one or multiple features should be enabled depending on the input. No AppConfig"},{"location":"utilities/idempotency/","title":"Idempotency","text":"<p>The idempotency utility provides a simple solution to convert your Lambda functions into idempotent operations which are safe to retry.</p>"},{"location":"utilities/idempotency/#key-features","title":"Key features","text":"<ul> <li>Prevent Lambda handler from executing more than once on the same event payload during a time window</li> <li>Ensure Lambda handler returns the same result when called with the same payload</li> <li>Select a subset of the event as the idempotency key using JMESPath expressions</li> <li>Set a time window in which records with the same payload should be considered duplicates</li> <li>Expires in-progress executions if the Lambda function times out halfway through</li> </ul>"},{"location":"utilities/idempotency/#terminology","title":"Terminology","text":"<p>The property of idempotency means that an operation does not cause additional side effects if it is called more than once with the same input parameters.</p> <p>Idempotent operations will return the same result when they are called multiple times with the same parameters. This makes idempotent operations safe to retry.</p> <p>Idempotency key is a hash representation of either the entire event or a specific configured subset of the event, and invocation results are JSON serialized and stored in your persistence storage layer.</p> <p>Idempotency record is the data representation of an idempotent request saved in your preferred  storage layer. We use it to coordinate whether a request is idempotent, whether it's still valid or expired based on timestamps, etc.</p> <p> <pre><code>classDiagram\n    direction LR\n    class IdempotencyRecord {\n        idempotency_key str\n        status Status\n        expiry_timestamp int\n        in_progress_expiry_timestamp int\n        response_data Json~str~\n        payload_hash str\n    }\n    class Status {\n        &lt;&lt;Enumeration&gt;&gt;\n        INPROGRESS\n        COMPLETE\n        EXPIRED internal_only\n    }\n    IdempotencyRecord -- Status</code></pre> <p>Idempotency record representation </p>"},{"location":"utilities/idempotency/#getting-started","title":"Getting started","text":""},{"location":"utilities/idempotency/#iam-permissions","title":"IAM Permissions","text":"<p>Your Lambda function IAM Role must have <code>dynamodb:GetItem</code>, <code>dynamodb:PutItem</code>, <code>dynamodb:UpdateItem</code> and <code>dynamodb:DeleteItem</code> IAM permissions before using this feature.</p> Note <p>If you're using our example AWS Serverless Application Model (SAM), AWS Cloud Development Kit (CDK), or Terraform it already adds the required permissions.</p>"},{"location":"utilities/idempotency/#required-resources","title":"Required resources","text":"<p>Before getting started, you need to create a persistent storage layer where the idempotency utility can store its state - your lambda functions will need read and write access to it.</p> <p>As of now, Amazon DynamoDB is the only supported persistent storage layer, so you'll need to create a table first.</p> <p>Default table configuration</p> <p>If you're not changing the default configuration for the DynamoDB persistence layer, this is the expected default configuration:</p> Configuration Value Notes Partition key <code>id</code> TTL attribute name <code>expiration</code> This can only be configured after your table is created if you're using AWS Console Tip: You can share a single state table for all functions <p>You can reuse the same DynamoDB table to store idempotency state. We add <code>module_name</code> and qualified name for classes and functions in addition to the idempotency key as a hash key.</p> AWS Serverless Application Model (SAM) exampleAWS Cloud Development Kit (CDK)Terraform <pre><code>Transform: AWS::Serverless-2016-10-31\nResources:\nIdempotencyTable:\nType: AWS::DynamoDB::Table\nProperties:\nAttributeDefinitions:\n- AttributeName: id\nAttributeType: S\nKeySchema:\n- AttributeName: id\nKeyType: HASH\nTimeToLiveSpecification:\nAttributeName: expiration\nEnabled: true\nBillingMode: PAY_PER_REQUEST\n\nHelloWorldFunction:\nType: AWS::Serverless::Function\nProperties:\nRuntime: python3.10\nHandler: app.py\nPolicies:\n- Statement:\n- Sid: AllowDynamodbReadWrite\nEffect: Allow\nAction:\n- dynamodb:PutItem\n- dynamodb:GetItem\n- dynamodb:UpdateItem\n- dynamodb:DeleteItem\nResource: !GetAtt IdempotencyTable.Arn\n</code></pre> <pre><code>from aws_cdk import RemovalPolicy\nfrom aws_cdk import aws_dynamodb as dynamodb\nfrom aws_cdk import aws_iam as iam\nfrom constructs import Construct\n\n\nclass IdempotencyConstruct(Construct):\n    def __init__(self, scope: Construct, name: str, lambda_role: iam.Role) -&gt; None:\n        super().__init__(scope, name)\nself.idempotency_table = dynamodb.Table(\nself,\n            \"IdempotencyTable\",\npartition_key=dynamodb.Attribute(name=\"id\", type=dynamodb.AttributeType.STRING),\nbilling_mode=dynamodb.BillingMode.PAY_PER_REQUEST,\n            removal_policy=RemovalPolicy.DESTROY,\ntime_to_live_attribute=\"expiration\",\npoint_in_time_recovery=True,\n        )\nself.idempotency_table.grant(\nlambda_role,\n\"dynamodb:PutItem\",\n\"dynamodb:GetItem\",\n            \"dynamodb:UpdateItem\",\n            \"dynamodb:DeleteItem\",\n        )\n</code></pre> <pre><code>terraform {\nrequired_providers {\naws = {\nsource  = \"hashicorp/aws\"\nversion = \"~&gt; 4.0\"\n}\n}\n}\n\nprovider \"aws\" {\nregion = \"us-east-1\" # Replace with your desired AWS region\n}\n\nresource \"aws_dynamodb_table\" \"IdempotencyTable\" {\nname         = \"IdempotencyTable\"\nbilling_mode = \"PAY_PER_REQUEST\"\nhash_key     = \"id\"\nattribute {\nname = \"id\"\ntype = \"S\"\n}\nttl {\nattribute_name = \"expiration\"\nenabled        = true\n}\n}\nresource \"aws_lambda_function\" \"IdempotencyFunction\" {\nfunction_name = \"IdempotencyFunction\"\nrole          = aws_iam_role.IdempotencyFunctionRole.arn\nruntime       = \"python3.10\"\nhandler       = \"app.lambda_handler\"\nfilename      = \"lambda.zip\"\n\n}\n\nresource \"aws_iam_role\" \"IdempotencyFunctionRole\" {\nname = \"IdempotencyFunctionRole\"\n\nassume_role_policy = jsonencode({\nVersion = \"2012-10-17\"\nStatement = [\n{\nSid    = \"\"\nEffect = \"Allow\"\nPrincipal = {\nService = \"lambda.amazonaws.com\"\n}\nAction = \"sts:AssumeRole\"\n},\n]\n})\n}\n\nresource \"aws_iam_policy\" \"LambdaDynamoDBPolicy\" {\nname        = \"LambdaDynamoDBPolicy\"\ndescription = \"IAM policy for Lambda function to access DynamoDB\"\npolicy = jsonencode({\nVersion = \"2012-10-17\"\nStatement = [\n{\nSid    = \"AllowDynamodbReadWrite\"\nEffect = \"Allow\"\nAction = [\n\"dynamodb:PutItem\",\n\"dynamodb:GetItem\",\n\"dynamodb:UpdateItem\",\n\"dynamodb:DeleteItem\",\n]\nResource = aws_dynamodb_table.IdempotencyTable.arn\n},\n]\n})\n}\n\nresource \"aws_iam_role_policy_attachment\" \"IdempotencyFunctionRoleAttachment\" {\nrole       = aws_iam_role.IdempotencyFunctionRole.name\npolicy_arn = aws_iam_policy.LambdaDynamoDBPolicy.arn\n}\n</code></pre> Warning: Large responses with DynamoDB persistence layer <p>When using this utility with DynamoDB, your function's responses must be smaller than 400KB.</p> <p>Larger items cannot be written to DynamoDB and will cause exceptions.</p> Info: DynamoDB <p>Each function invocation will generally make 2 requests to DynamoDB. If the result returned by your Lambda is less than 1kb, you can expect 2 WCUs per invocation. For retried invocations, you will see 1WCU and 1RCU. Review the DynamoDB pricing documentation to estimate the cost.</p>"},{"location":"utilities/idempotency/#idempotent-decorator","title":"Idempotent decorator","text":"<p>You can quickly start by initializing the <code>DynamoDBPersistenceLayer</code> class and using it with the <code>idempotent</code> decorator on your lambda handler.</p> Note <p>In this example, the entire Lambda handler is treated as a single idempotent operation. If your Lambda handler can cause multiple side effects, or you're only interested in making a specific logic idempotent, use <code>idempotent_function</code> instead.</p> <p>See Choosing a payload subset for idempotency for more elaborate use cases.</p> Idempotent decoratorSample event <pre><code>from dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\nDynamoDBPersistenceLayer,\nidempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> <pre><code>{\n\"user_id\": \"xyz\",\n\"product_id\": \"123456789\"\n}\n</code></pre> <p>After processing this request successfully, a second request containing the exact same payload above will now return the same response, ensuring our customer isn't charged twice.</p> <p>New to idempotency concept? Please review our Terminology section if you haven't yet.</p>"},{"location":"utilities/idempotency/#idempotent_function-decorator","title":"Idempotent_function decorator","text":"<p>Similar to idempotent decorator, you can use <code>idempotent_function</code> decorator for any synchronous Python function.</p> <p>When using <code>idempotent_function</code>, you must tell us which keyword parameter in your function signature has the data we should use via <code>data_keyword_argument</code>.</p> <p>We support JSON serializable data, Python Dataclasses, Parser/Pydantic Models, and our Event Source Data Classes.</p> Limitation <p>Make sure to call your decorated function using keyword arguments.</p> Using DataclassesUsing Pydantic <pre><code>from dataclasses import dataclass\n\nfrom aws_lambda_powertools.utilities.idempotency import (\nDynamoDBPersistenceLayer,\nIdempotencyConfig,\nidempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n@dataclass\nclass OrderItem:\n    sku: str\n    description: str\n\n\n@dataclass\nclass Order:\n    item: OrderItem\n    order_id: int\n\n\n@idempotent_function(data_keyword_argument=\"order\", config=config, persistence_store=dynamodb)\ndef process_order(order: Order):\n    return f\"processed order {order.order_id}\"\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\nprocess_order(order=order)\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.idempotency import (\nDynamoDBPersistenceLayer,\nIdempotencyConfig,\nidempotent_function,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\nclass OrderItem(BaseModel):\n    sku: str\n    description: str\n\n\nclass Order(BaseModel):\n    item: OrderItem\n    order_id: int\n\n\n@idempotent_function(data_keyword_argument=\"order\", config=config, persistence_store=dynamodb)\ndef process_order(order: Order):\n    return f\"processed order {order.order_id}\"\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\nprocess_order(order=order)\n</code></pre>"},{"location":"utilities/idempotency/#batch-integration","title":"Batch integration","text":"<p>You can can easily integrate with Batch utility via context manager. This ensures that you process each record in an idempotent manner, and guard against a Lambda timeout idempotent situation.</p> Choosing an unique batch record attribute <p>In this example, we choose <code>messageId</code> as our idempotency key since we know it'll be unique.</p> <p>Depending on your use case, it might be more accurate to choose another field your producer intentionally set to define uniqueness.</p> Integration with Batch ProcessorSample event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\nprocessor = BatchProcessor(event_type=EventType.SQS)\ndynamodb = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\nconfig = IdempotencyConfig(\nevent_key_jmespath=\"messageId\",  # see Choosing a payload subset section\n)\n\n\n@idempotent_function(data_keyword_argument=\"record\", config=config, persistence_store=dynamodb)\ndef record_handler(record: SQSRecord):\n    return {\"message\": record.body}\n\n\ndef lambda_handler(event: SQSRecord, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n\n    # with Lambda context registered for Idempotency\n    # we can now kick in the Bach processing logic\n    batch = event[\"Records\"]\nwith processor(records=batch, handler=record_handler):\n# in case you want to access each record processed by your record_handler\n        # otherwise ignore the result variable assignment\n        processed_messages = processor.process()\nlogger.info(processed_messages)\nreturn processor.response()\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n\"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n\"body\": \"Test message.\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1545082649183\",\n\"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n\"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n},\n\"messageAttributes\": {\n\"testAttr\": {\n\"stringValue\": \"100\",\n\"binaryValue\": \"base64Str\",\n\"dataType\": \"Number\"\n}\n},\n\"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n\"awsRegion\": \"us-east-2\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/idempotency/#choosing-a-payload-subset-for-idempotency","title":"Choosing a payload subset for idempotency","text":"Tip: Dealing with always changing payloads <p>When dealing with a more elaborate payload, where parts of the payload always change, you should use <code>event_key_jmespath</code> parameter.</p> <p>Use <code>IdempotencyConfig</code> to instruct the idempotent decorator to only use a portion of your payload to verify whether a request is idempotent, and therefore it should not be retried.</p> <p>Payment scenario</p> <p>In this example, we have a Lambda handler that creates a payment for a user subscribing to a product. We want to ensure that we don't accidentally charge our customer by subscribing them more than once.</p> <p>Imagine the function executes successfully, but the client never receives the response due to a connection issue. It is safe to retry in this instance, as the idempotent decorator will return a previously saved response.</p> <p>What we want here is to instruct Idempotency to use <code>user_id</code> and <code>product_id</code> fields from our incoming payload as our idempotency key. If we were to treat the entire request as our idempotency key, a simple HTTP header change would cause our customer to be charged twice.</p> Deserializing JSON strings in payloads for increased accuracy. <p>The payload extracted by the <code>event_key_jmespath</code> is treated as a string by default. This means there could be differences in whitespace even when the JSON payload itself is identical.</p> <p>To alter this behaviour, we can use the JMESPath built-in function <code>powertools_json()</code> to treat the payload as a JSON object (dict) rather than a string.</p> Payment functionSample event <pre><code>import json\nfrom dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\nDynamoDBPersistenceLayer,\nIdempotencyConfig,\nidempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n# Deserialize JSON string under the \"body\" key\n# then extract \"user\" and \"product_id\" data\nconfig = IdempotencyConfig(event_key_jmespath='powertools_json(body).[\"user_id\", \"product_id\"]')\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment_info: str = event.get(\"body\", \"\")\n        payment: Payment = create_subscription_payment(json.loads(payment_info))\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> <pre><code>{\n\"version\": \"2.0\",\n\"routeKey\": \"ANY /createpayment\",\n\"rawPath\": \"/createpayment\",\n\"rawQueryString\": \"\",\n\"headers\": {\n\"Header1\": \"value1\",\n\"Header2\": \"value2\"\n},\n\"requestContext\": {\n\"accountId\": \"123456789012\",\n\"apiId\": \"api-id\",\n\"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n\"domainPrefix\": \"id\",\n\"http\": {\n\"method\": \"POST\",\n\"path\": \"/createpayment\",\n\"protocol\": \"HTTP/1.1\",\n\"sourceIp\": \"ip\",\n\"userAgent\": \"agent\"\n},\n\"requestId\": \"id\",\n\"routeKey\": \"ANY /createpayment\",\n\"stage\": \"$default\",\n\"time\": \"10/Feb/2021:13:40:43 +0000\",\n\"timeEpoch\": 1612964443723\n},\n\"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\",\n\"isBase64Encoded\": false\n}\n</code></pre>"},{"location":"utilities/idempotency/#lambda-timeouts","title":"Lambda timeouts","text":"Note <p>This is automatically done when you decorate your Lambda handler with @idempotent decorator.</p> <p>To prevent against extended failed retries when a Lambda function times out, Powertools for AWS Lambda (Python) calculates and includes the remaining invocation available time as part of the idempotency record.</p> Example <p>If a second invocation happens after this timestamp, and the record is marked as <code>INPROGRESS</code>, we will execute the invocation again as if it was in the <code>EXPIRED</code> state (e.g, <code>expire_seconds</code> field elapsed).</p> <p>This means that if an invocation expired during execution, it will be quickly executed again on the next retry.</p> Important <p>If you are only using the @idempotent_function decorator to guard isolated parts of your code, you must use <code>register_lambda_context</code> available in the idempotency config object to benefit from this protection.</p> <p>Here is an example on how you register the Lambda context in your handler:</p> Registering the Lambda context <pre><code>from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\nconfig = IdempotencyConfig()\n@idempotent_function(data_keyword_argument=\"record\", persistence_store=persistence_layer, config=config)\ndef record_handler(record: SQSRecord):\n    return {\"message\": record[\"body\"]}\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\nconfig.register_lambda_context(context)\nreturn record_handler(event)\n</code></pre>"},{"location":"utilities/idempotency/#handling-exceptions","title":"Handling exceptions","text":"<p>If you are using the <code>idempotent</code> decorator on your Lambda handler, any unhandled exceptions that are raised during the code execution will cause the record in the persistence layer to be deleted. This means that new invocations will execute your code again despite having the same payload. If you don't want the record to be deleted, you need to catch exceptions within the idempotent function and return a successful response.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n    activate Persistence Layer\n    Note right of Persistence Layer: Locked during this time. Prevents multiple&lt;br/&gt;Lambda invocations with the same&lt;br/&gt;payload running concurrently.\n    Lambda--xLambda: Call handler (event).&lt;br/&gt;Raises exception\n    Lambda-&gt;&gt;Persistence Layer: Delete record (id=event.search(payload))\n    deactivate Persistence Layer\n    Lambda--&gt;&gt;Client: Return error response</code></pre> Idempotent sequence exception </p> <p>If you are using <code>idempotent_function</code>, any unhandled exceptions that are raised inside the decorated function will cause the record in the persistence layer to be deleted, and allow the function to be executed again if retried.</p> <p>If an Exception is raised outside the scope of the decorated function and after your function has been called, the persistent record will not be affected. In this case, idempotency will be maintained for your decorated function. Example:</p> Handling exceptions <pre><code>import requests\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\nconfig = IdempotencyConfig()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # If an exception is raised here, no idempotent record will ever get created as the\n    # idempotent function does not get called\ntry:\nendpoint = \"https://jsonplaceholder.typicode.com/comments/\"  # change this endpoint to force an exception\nrequests.get(endpoint)\nexcept Exception as exc:\nreturn str(exc)\ncall_external_service(data={\"user\": \"user1\", \"id\": 5})\n\n    # This exception will not cause the idempotent record to be deleted, since it\n    # happens after the decorated function has been successfully called\nraise Exception\n@idempotent_function(data_keyword_argument=\"data\", config=config, persistence_store=persistence_layer)\ndef call_external_service(data: dict):\n    result: requests.Response = requests.post(\n        \"https://jsonplaceholder.typicode.com/comments/\",\n        json={\"user\": data[\"user\"], \"transaction_id\": data[\"id\"]},\n    )\n    return result.json()\n</code></pre> Warning <p>We will raise <code>IdempotencyPersistenceLayerError</code> if any of the calls to the persistence layer fail unexpectedly.</p> <p>As this happens outside the scope of your decorated function, you are not able to catch it if you're using the <code>idempotent</code> decorator on your Lambda handler.</p>"},{"location":"utilities/idempotency/#idempotency-request-flow","title":"Idempotency request flow","text":"<p>The following sequence diagrams explain how the Idempotency feature behaves under different scenarios.</p>"},{"location":"utilities/idempotency/#successful-request","title":"Successful request","text":"<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request </p>"},{"location":"utilities/idempotency/#successful-request-with-cache-enabled","title":"Successful request with cache enabled","text":"<p>In-memory cache is disabled by default.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n      activate Persistence Layer\n      Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      Lambda--&gt;&gt;Lambda: Call your function\n      Lambda-&gt;&gt;Persistence Layer: Update record with result\n      deactivate Persistence Layer\n      Persistence Layer--&gt;&gt;Persistence Layer: Update record\n      Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n      Lambda--&gt;&gt;Lambda: Save record and result in memory\n      Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda--&gt;&gt;Lambda: Get idempotency_key=hash(payload)\n      Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n      Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request cached </p>"},{"location":"utilities/idempotency/#expired-idempotency-records","title":"Expired idempotency records","text":"<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE but expired hours ago\n        loop Repeat initial request process\n            Note over Lambda,Persistence Layer: 1. Set record to INPROGRESS, &lt;br&gt; 2. Call your function, &lt;br&gt; 3. Set record to COMPLETE\n        end\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Previous Idempotent request expired </p>"},{"location":"utilities/idempotency/#concurrent-identical-in-flight-requests","title":"Concurrent identical in-flight requests","text":"<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n    activate Persistence Layer\n    Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      par Second request\n          Client-&gt;&gt;Lambda: Invoke (event)\n          Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n          Lambda--xLambda: IdempotencyAlreadyInProgressError\n          Lambda-&gt;&gt;Client: Error sent to client if unhandled\n      end\n    Lambda--&gt;&gt;Lambda: Call your function\n    Lambda-&gt;&gt;Persistence Layer: Update record with result\n    deactivate Persistence Layer\n    Persistence Layer--&gt;&gt;Persistence Layer: Update record\n    Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n    Lambda--&gt;&gt;Client: Response sent to client</code></pre> Concurrent identical in-flight requests </p>"},{"location":"utilities/idempotency/#lambda-request-timeout","title":"Lambda request timeout","text":"<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Note right of Lambda: Time out\n        Lambda--xLambda: Time out error\n        Lambda--&gt;&gt;Client: Return error response\n        deactivate Persistence Layer\n    else retry after Lambda timeout elapses\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Reset in_progress_expiry attribute\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Idempotent request during and after Lambda timeouts </p>"},{"location":"utilities/idempotency/#optional-idempotency-key","title":"Optional idempotency key","text":"<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt request with idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else request(s) without idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Note over Lambda: Idempotency key is missing\n        Note over Persistence Layer: Skips any operation to fetch, update, and delete\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Optional idempotency key </p>"},{"location":"utilities/idempotency/#advanced","title":"Advanced","text":""},{"location":"utilities/idempotency/#persistence-layers","title":"Persistence layers","text":""},{"location":"utilities/idempotency/#dynamodbpersistencelayer","title":"DynamoDBPersistenceLayer","text":"<p>This persistence layer is built-in, and you can either use an existing DynamoDB table or create a new one dedicated for idempotency state (recommended).</p> Customizing DynamoDBPersistenceLayer to suit your table structure <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(\ntable_name=\"IdempotencyTable\",\nkey_attr=\"idempotency_key\",\nexpiry_attr=\"expires_at\",\nin_progress_expiry_attr=\"in_progress_expires_at\",\nstatus_attr=\"current_status\",\ndata_attr=\"result_data\",\nvalidation_key_attr=\"validation_key\",\n)\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <p>When using DynamoDB as a persistence layer, you can alter the attribute names by passing these parameters when initializing the persistence layer:</p> Parameter Required Default Description table_name Table name to store state key_attr <code>id</code> Partition key of the table. Hashed representation of the payload (unless sort_key_attr is specified) expiry_attr <code>expiration</code> Unix timestamp of when record expires in_progress_expiry_attr <code>in_progress_expiration</code> Unix timestamp of when record expires while in progress (in case of the invocation times out) status_attr <code>status</code> Stores status of the lambda execution during and after invocation data_attr <code>data</code> Stores results of successfully executed Lambda handlers validation_key_attr <code>validation</code> Hashed representation of the parts of the event used for validation sort_key_attr Sort key of the table (if table is configured with a sort key). static_pk_value <code>idempotency#{LAMBDA_FUNCTION_NAME}</code> Static value to use as the partition key. Only used when sort_key_attr is set."},{"location":"utilities/idempotency/#customizing-the-default-behavior","title":"Customizing the default behavior","text":"<p>Idempotent decorator can be further configured with <code>IdempotencyConfig</code> as seen in the previous example. These are the available options for further configuration</p> Parameter Default Description event_key_jmespath <code>\"\"</code> JMESPath expression to extract the idempotency key from the event record using built-in functions payload_validation_jmespath <code>\"\"</code> JMESPath expression to validate whether certain parameters have changed in the event while the event payload raise_on_no_idempotency_key <code>False</code> Raise exception if no idempotency key was found in the request expires_after_seconds 3600 The number of seconds to wait before a record is expired use_local_cache <code>False</code> Whether to locally cache idempotency results local_cache_max_items 256 Max number of items to store in local cache hash_function <code>md5</code> Function to use for calculating hashes, as provided by hashlib in the standard library."},{"location":"utilities/idempotency/#handling-concurrent-executions-with-the-same-payload","title":"Handling concurrent executions with the same payload","text":"<p>This utility will raise an <code>IdempotencyAlreadyInProgressError</code> exception if you receive multiple invocations with the same payload while the first invocation hasn't completed yet.</p> Info <p>If you receive <code>IdempotencyAlreadyInProgressError</code>, you can safely retry the operation.</p> <p>This is a locking mechanism for correctness. Since we don't know the result from the first invocation yet, we can't safely allow another concurrent execution.</p>"},{"location":"utilities/idempotency/#using-in-memory-cache","title":"Using in-memory cache","text":"<p>By default, in-memory local caching is disabled, since we don't know how much memory you consume per invocation compared to the maximum configured in your Lambda function.</p> Note: This in-memory cache is local to each Lambda execution environment <p>This means it will be effective in cases where your function's concurrency is low in comparison to the number of \"retry\" invocations with the same payload, because cache might be empty.</p> <p>You can enable in-memory caching with the <code>use_local_cache</code> parameter:</p> Caching idempotent transactions in-memory to prevent multiple calls to storageSample event <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\nconfig = IdempotencyConfig(\n    event_key_jmespath=\"body\",\nuse_local_cache=True,\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context: LambdaContext):\n    return event\n</code></pre> <pre><code>{\n\"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre> <p>When enabled, the default is to cache a maximum of 256 records in each Lambda execution environment - You can change it with the <code>local_cache_max_items</code> parameter.</p>"},{"location":"utilities/idempotency/#expiring-idempotency-records","title":"Expiring idempotency records","text":"<p>By default, we expire idempotency records after an hour (3600 seconds).</p> <p>In most cases, it is not desirable to store the idempotency records forever. Rather, you want to guarantee that the same payload won't be executed within a period of time.</p> <p>You can change this window with the <code>expires_after_seconds</code> parameter:</p> Adjusting idempotency record expirationSample event <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\nconfig = IdempotencyConfig(\n    event_key_jmespath=\"body\",\nexpires_after_seconds=5 * 60,  # 5 minutes\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context: LambdaContext):\n    return event\n</code></pre> <pre><code>{\n\"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre> <p>This will mark any records older than 5 minutes as expired, and your function will be executed as normal if it is invoked with a matching payload.</p> Idempotency record expiration vs DynamoDB time-to-live (TTL) <p>DynamoDB TTL is a feature to remove items after a certain period of time, it may occur within 48 hours of expiration.</p> <p>We don't rely on DynamoDB or any persistence storage layer to determine whether a record is expired to avoid eventual inconsistency states.</p> <p>Instead, Idempotency records saved in the storage layer contain timestamps that can be verified upon retrieval and double checked within Idempotency feature.</p> <p>Why?</p> <p>A record might still be valid (<code>COMPLETE</code>) when we retrieved, but in some rare cases it might expire a second later. A record could also be cached in memory. You might also want to have idempotent transactions that should expire in seconds.</p>"},{"location":"utilities/idempotency/#payload-validation","title":"Payload validation","text":"Question: What if your function is invoked with the same payload except some outer parameters have changed? <p>Example: A payment transaction for a given productID was requested twice for the same customer, however the amount to be paid has changed in the second transaction.</p> <p>By default, we will return the same result as it returned before, however in this instance it may be misleading; we provide a fail fast payload validation to address this edge case.</p> <p>With <code>payload_validation_jmespath</code>, you can provide an additional JMESPath expression to specify which part of the event body should be validated against previous idempotent invocations</p> Payload validationSample event 1Sample event 2 <pre><code>from dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\nconfig = IdempotencyConfig(event_key_jmespath='[\"user_id\", \"product_id\"]', payload_validation_jmespath=\"amount\")\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    charge_type: str\namount: int\npayment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> <pre><code>{\n\"user_id\": 1,\n\"product_id\": 1500,\n\"charge_type\": \"subscription\",\n\"amount\": 500\n}\n</code></pre> <pre><code>{\n\"user_id\": 1,\n\"product_id\": 1500,\n\"charge_type\": \"subscription\",\n\"amount\": 10\n}\n</code></pre> <p>In this example, the <code>user_id</code> and <code>product_id</code> keys are used as the payload to generate the idempotency key, as per <code>event_key_jmespath</code> parameter.</p> Note <p>If we try to send the same request but with a different amount, we will raise <code>IdempotencyValidationError</code>.</p> <p>Without payload validation, we would have returned the same result as we did for the initial request. Since we're also returning an amount in the response, this could be quite confusing for the client.</p> <p>By using <code>payload_validation_jmespath=\"amount\"</code>, we prevent this potentially confusing behavior and instead raise an Exception.</p>"},{"location":"utilities/idempotency/#making-idempotency-key-required","title":"Making idempotency key required","text":"<p>If you want to enforce that an idempotency key is required, you can set <code>raise_on_no_idempotency_key</code> to <code>True</code>.</p> <p>This means that we will raise <code>IdempotencyKeyError</code> if the evaluation of <code>event_key_jmespath</code> is <code>None</code>.</p> Warning <p>To prevent errors, transactions will not be treated as idempotent if <code>raise_on_no_idempotency_key</code> is set to <code>False</code> and the evaluation of <code>event_key_jmespath</code> is <code>None</code>. Therefore, no data will be fetched, stored, or deleted in the idempotency storage layer.</p> Idempotency key requiredSuccess EventFailure Event <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\nconfig = IdempotencyConfig(\n    event_key_jmespath='[\"user.uid\", \"order_id\"]',\nraise_on_no_idempotency_key=True,\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <pre><code>{\n\"user\": {\n\"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n\"name\": \"Foo\"\n},\n\"order_id\": 10000\n}\n</code></pre> <pre><code>{\n\"user\": {\n\"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n\"name\": \"Foo\",\n\"order_id\": 10000\n}\n}\n</code></pre>"},{"location":"utilities/idempotency/#customizing-boto-configuration","title":"Customizing boto configuration","text":"<p>The <code>boto_config</code> and <code>boto3_session</code> parameters enable you to pass in a custom botocore config object or a custom boto3 session when constructing the persistence store.</p> Custom sessionCustom configSample Event <pre><code>import boto3\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# See: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#module-boto3.session\nboto3_session = boto3.session.Session()\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\", boto3_session=boto3_session)\nconfig = IdempotencyConfig(event_key_jmespath=\"body\")\n\n\n@idempotent(persistence_store=persistence_layer, config=config)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <pre><code>from botocore.config import Config\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# See: https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html#botocore-config\nboto_config = Config()\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\", boto_config=boto_config)\nconfig = IdempotencyConfig(event_key_jmespath=\"body\")\n\n\n@idempotent(persistence_store=persistence_layer, config=config)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <pre><code>{\n\"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre>"},{"location":"utilities/idempotency/#using-a-dynamodb-table-with-a-composite-primary-key","title":"Using a DynamoDB table with a composite primary key","text":"<p>When using a composite primary key table (hash+range key), use <code>sort_key_attr</code> parameter when initializing your persistence layer.</p> <p>With this setting, we will save the idempotency key in the sort key instead of the primary key. By default, the primary key will now be set to <code>idempotency#{LAMBDA_FUNCTION_NAME}</code>.</p> <p>You can optionally set a static value for the partition key using the <code>static_pk_value</code> parameter.</p> Reusing a DynamoDB table that uses a composite primary keySample Event <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\", sort_key_attr=\"sort_key\")\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    user_id: str = event.get(\"body\", \"\")[\"user_id\"]\n    return {\"message\": \"success\", \"user_id\": user_id}\n</code></pre> <pre><code>{\n\"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre> <p>The example function above would cause data to be stored in DynamoDB like this:</p> id sort_key expiration status data idempotency#MyLambdaFunction 1e956ef7da78d0cb890be999aecc0c9e 1636549553 COMPLETED {\"user_id\": 12391, \"message\": \"success\"} idempotency#MyLambdaFunction 2b2cdb5f86361e97b4383087c1ffdf27 1636549571 COMPLETED {\"user_id\": 527212, \"message\": \"success\"} idempotency#MyLambdaFunction f091d2527ad1c78f05d54cc3f363be80 1636549585 IN_PROGRESS"},{"location":"utilities/idempotency/#bring-your-own-persistent-store","title":"Bring your own persistent store","text":"<p>This utility provides an abstract base class (ABC), so that you can implement your choice of persistent storage layer.</p> <p>You can create your own persistent store from scratch by inheriting the <code>BasePersistenceLayer</code> class, and implementing <code>_get_record()</code>, <code>_put_record()</code>, <code>_update_record()</code> and <code>_delete_record()</code>.</p> <ul> <li><code>_get_record()</code> \u2013 Retrieves an item from the persistence store using an idempotency key and returns it as a <code>DataRecord</code> instance.</li> <li><code>_put_record()</code> \u2013 Adds a <code>DataRecord</code> to the persistence store if it doesn't already exist with that key. Raises an <code>ItemAlreadyExists</code> exception if a non-expired entry already exists.</li> <li><code>_update_record()</code> \u2013 Updates an item in the persistence store.</li> <li><code>_delete_record()</code> \u2013 Removes an item from the persistence store.</li> </ul> Bring your own persistent store <pre><code>import datetime\nimport logging\nfrom typing import Any, Dict, Optional\n\nimport boto3\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities.idempotency import BasePersistenceLayer\nfrom aws_lambda_powertools.utilities.idempotency.exceptions import (\n    IdempotencyItemAlreadyExistsError,\n    IdempotencyItemNotFoundError,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.base import DataRecord\n\nlogger = logging.getLogger(__name__)\n\n\nclass MyOwnPersistenceLayer(BasePersistenceLayer):\ndef __init__(\n        self,\n        table_name: str,\n        key_attr: str = \"id\",\n        expiry_attr: str = \"expiration\",\n        status_attr: str = \"status\",\n        data_attr: str = \"data\",\n        validation_key_attr: str = \"validation\",\n        boto_config: Optional[Config] = None,\n        boto3_session: Optional[boto3.session.Session] = None,\n    ):\n        boto_config = boto_config or Config()\n        session = boto3_session or boto3.session.Session()\n        self._ddb_resource = session.resource(\"dynamodb\", config=boto_config)\n        self.table_name = table_name\n        self.table = self._ddb_resource.Table(self.table_name)\n        self.key_attr = key_attr\n        self.expiry_attr = expiry_attr\n        self.status_attr = status_attr\n        self.data_attr = data_attr\n        self.validation_key_attr = validation_key_attr\n        super(MyOwnPersistenceLayer, self).__init__()\n\n    def _item_to_data_record(self, item: Dict[str, Any]) -&gt; DataRecord:\n\"\"\"\n        Translate raw item records from DynamoDB to DataRecord\n\n        Parameters\n        ----------\n        item: Dict[str, Union[str, int]]\n                Item format from dynamodb response\n\n        Returns\n        -------\n        DataRecord\n                representation of item\n\n        \"\"\"\n        return DataRecord(\n            idempotency_key=item[self.key_attr],\n            status=item[self.status_attr],\n            expiry_timestamp=item[self.expiry_attr],\n            response_data=item.get(self.data_attr, \"\"),\n            payload_hash=item.get(self.validation_key_attr, \"\"),\n        )\n\ndef _get_record(self, idempotency_key) -&gt; DataRecord:\nresponse = self.table.get_item(Key={self.key_attr: idempotency_key}, ConsistentRead=True)\n\n        try:\n            item = response[\"Item\"]\n        except KeyError:\n            raise IdempotencyItemNotFoundError\n        return self._item_to_data_record(item)\n\ndef _put_record(self, data_record: DataRecord) -&gt; None:\nitem = {\n            self.key_attr: data_record.idempotency_key,\n            self.expiry_attr: data_record.expiry_timestamp,\n            self.status_attr: data_record.status,\n        }\n\n        if self.payload_validation_enabled:\n            item[self.validation_key_attr] = data_record.payload_hash\n\n        now = datetime.datetime.now()\n        try:\n            logger.debug(f\"Putting record for idempotency key: {data_record.idempotency_key}\")\n            self.table.put_item(\n                Item=item,\n                ConditionExpression=f\"attribute_not_exists({self.key_attr}) OR {self.expiry_attr} &lt; :now\",\n                ExpressionAttributeValues={\":now\": int(now.timestamp())},\n            )\n        except self._ddb_resource.meta.client.exceptions.ConditionalCheckFailedException:\n            logger.debug(f\"Failed to put record for already existing idempotency key: {data_record.idempotency_key}\")\n            raise IdempotencyItemAlreadyExistsError\n\ndef _update_record(self, data_record: DataRecord):\nlogger.debug(f\"Updating record for idempotency key: {data_record.idempotency_key}\")\n        update_expression = \"SET #response_data = :response_data, #expiry = :expiry, #status = :status\"\n        expression_attr_values = {\n            \":expiry\": data_record.expiry_timestamp,\n            \":response_data\": data_record.response_data,\n            \":status\": data_record.status,\n        }\n        expression_attr_names = {\n            \"#response_data\": self.data_attr,\n            \"#expiry\": self.expiry_attr,\n            \"#status\": self.status_attr,\n        }\n\n        if self.payload_validation_enabled:\n            update_expression += \", #validation_key = :validation_key\"\n            expression_attr_values[\":validation_key\"] = data_record.payload_hash\n            expression_attr_names[\"#validation_key\"] = self.validation_key_attr\n\n        kwargs = {\n            \"Key\": {self.key_attr: data_record.idempotency_key},\n            \"UpdateExpression\": update_expression,\n            \"ExpressionAttributeValues\": expression_attr_values,\n            \"ExpressionAttributeNames\": expression_attr_names,\n        }\n\n        self.table.update_item(**kwargs)\n\ndef _delete_record(self, data_record: DataRecord) -&gt; None:\nlogger.debug(f\"Deleting record for idempotency key: {data_record.idempotency_key}\")\n        self.table.delete_item(\n            Key={self.key_attr: data_record.idempotency_key},\n        )\n</code></pre> Danger <p>Pay attention to the documentation for each - you may need to perform additional checks inside these methods to ensure the idempotency guarantees remain intact.</p> <p>For example, the <code>_put_record</code> method needs to raise an exception if a non-expired record already exists in the data store with a matching key.</p>"},{"location":"utilities/idempotency/#compatibility-with-other-utilities","title":"Compatibility with other utilities","text":""},{"location":"utilities/idempotency/#batch","title":"Batch","text":"<p>See Batch integration above.</p>"},{"location":"utilities/idempotency/#validation-utility","title":"Validation utility","text":"<p>The idempotency utility can be used with the <code>validator</code> decorator. Ensure that idempotency is the innermost decorator.</p> Warning <p>If you use an envelope with the validator, the event received by the idempotency utility will be the unwrapped event - not the \"raw\" event Lambda was invoked with.</p> <p>Make sure to account for this behaviour, if you set the <code>event_key_jmespath</code>.</p> Using Idempotency with JSONSchema Validation utilitySample Event <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import envelopes, validator\n\nconfig = IdempotencyConfig(event_key_jmespath='[\"message\", \"username\"]')\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n\n@validator(envelope=envelopes.API_GATEWAY_HTTP)\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context: LambdaContext):\n    return {\"message\": event[\"message\"], \"statusCode\": 200}\n</code></pre> <pre><code>{\n\"version\": \"2.0\",\n\"routeKey\": \"$default\",\n\"rawPath\": \"/my/path\",\n\"rawQueryString\": \"parameter1=value1&amp;parameter1=value2&amp;parameter2=value\",\n\"cookies\": [\n\"cookie1\",\n\"cookie2\"\n],\n\"headers\": {\n\"Header1\": \"value1\",\n\"Header2\": \"value1,value2\"\n},\n\"queryStringParameters\": {\n\"parameter1\": \"value1,value2\",\n\"parameter2\": \"value\"\n},\n\"requestContext\": {\n\"accountId\": \"123456789012\",\n\"apiId\": \"api-id\",\n\"authentication\": {\n\"clientCert\": {\n\"clientCertPem\": \"CERT_CONTENT\",\n\"subjectDN\": \"www.example.com\",\n\"issuerDN\": \"Example issuer\",\n\"serialNumber\": \"a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1\",\n\"validity\": {\n\"notBefore\": \"May 28 12:30:02 2019 GMT\",\n\"notAfter\": \"Aug  5 09:36:04 2021 GMT\"\n}\n}\n},\n\"authorizer\": {\n\"jwt\": {\n\"claims\": {\n\"claim1\": \"value1\",\n\"claim2\": \"value2\"\n},\n\"scopes\": [\n\"scope1\",\n\"scope2\"\n]\n}\n},\n\"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n\"domainPrefix\": \"id\",\n\"http\": {\n\"method\": \"POST\",\n\"path\": \"/my/path\",\n\"protocol\": \"HTTP/1.1\",\n\"sourceIp\": \"192.168.0.1/32\",\n\"userAgent\": \"agent\"\n},\n\"requestId\": \"id\",\n\"routeKey\": \"$default\",\n\"stage\": \"$default\",\n\"time\": \"12/Mar/2020:19:03:58 +0000\",\n\"timeEpoch\": 1583348638390\n},\n\"body\": \"{\\\"message\\\": \\\"hello world\\\", \\\"username\\\": \\\"tom\\\"}\",\n\"pathParameters\": {\n\"parameter1\": \"value1\"\n},\n\"isBase64Encoded\": false,\n\"stageVariables\": {\n\"stageVariable1\": \"value1\",\n\"stageVariable2\": \"value2\"\n}\n}\n</code></pre> Tip: JMESPath Powertools for AWS Lambda (Python) functions are also available <p>Built-in functions known in the validation utility like <code>powertools_json</code>, <code>powertools_base64</code>, <code>powertools_base64_gzip</code> are also available to use in this utility.</p>"},{"location":"utilities/idempotency/#testing-your-code","title":"Testing your code","text":"<p>The idempotency utility provides several routes to test your code.</p>"},{"location":"utilities/idempotency/#disabling-the-idempotency-utility","title":"Disabling the idempotency utility","text":"<p>When testing your code, you may wish to disable the idempotency logic altogether and focus on testing your business logic. To do this, you can set the environment variable <code>POWERTOOLS_IDEMPOTENCY_DISABLED</code> with a truthy value. If you prefer setting this for specific tests, and are using Pytest, you can use monkeypatch fixture:</p> test_disabling_idempotency_utility.pyapp_test_disabling_idempotency_utility.py <pre><code>from dataclasses import dataclass\n\nimport app_test_disabling_idempotency_utility\nimport pytest\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n        def get_remaining_time_in_millis(self) -&gt; int:\n            return 5\n\n    return LambdaContext()\n\n\ndef test_idempotent_lambda_handler(monkeypatch, lambda_context):\n# Set POWERTOOLS_IDEMPOTENCY_DISABLED before calling decorated functions\nmonkeypatch.setenv(\"POWERTOOLS_IDEMPOTENCY_DISABLED\", 1)\nresult = app_test_disabling_idempotency_utility.lambda_handler({}, lambda_context)\n\n    assert result\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    print(\"expensive operation\")\n    return {\n        \"payment_id\": 12345,\n        \"message\": \"success\",\n        \"statusCode\": 200,\n    }\n</code></pre>"},{"location":"utilities/idempotency/#testing-with-dynamodb-local","title":"Testing with DynamoDB Local","text":"<p>To test with DynamoDB Local, you can replace the <code>DynamoDB client</code> used by the persistence layer with one you create inside your tests. This allows you to set the endpoint_url.</p> test_with_dynamodb_local.pyapp_test_dynamodb_local.py <pre><code>from dataclasses import dataclass\n\nimport app_test_dynamodb_local\nimport boto3\nimport pytest\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n        def get_remaining_time_in_millis(self) -&gt; int:\n            return 5\n\n    return LambdaContext()\n\n\ndef test_idempotent_lambda(lambda_context):\n    # Configure the boto3 to use the endpoint for the DynamoDB Local instance\ndynamodb_local_client = boto3.client(\"dynamodb\", endpoint_url=\"http://localhost:8000\")\napp_test_dynamodb_local.persistence_layer.client = dynamodb_local_client\n# If desired, you can use a different DynamoDB Local table name than what your code already uses\n    # app.persistence_layer.table_name = \"another table name\" # noqa: ERA001\n\n    result = app_test_dynamodb_local.handler({\"testkey\": \"testvalue\"}, lambda_context)\n    assert result[\"payment_id\"] == 12345\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    print(\"expensive operation\")\n    return {\n        \"payment_id\": 12345,\n        \"message\": \"success\",\n        \"statusCode\": 200,\n    }\n</code></pre>"},{"location":"utilities/idempotency/#how-do-i-mock-all-dynamodb-io-operations","title":"How do I mock all DynamoDB I/O operations","text":"<p>The idempotency utility lazily creates the dynamodb Table which it uses to access DynamoDB. This means it is possible to pass a mocked Table resource, or stub various methods.</p> test_with_io_operations.pyapp_test_io_operations.py <pre><code>from dataclasses import dataclass\nfrom unittest.mock import MagicMock\n\nimport app_test_io_operations\nimport pytest\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n        def get_remaining_time_in_millis(self) -&gt; int:\n            return 5\n\n    return LambdaContext()\n\n\ndef test_idempotent_lambda(lambda_context):\nmock_client = MagicMock()\napp_test_io_operations.persistence_layer.client = mock_client\nresult = app_test_io_operations.handler({\"testkey\": \"testvalue\"}, lambda_context)\nmock_client.put_item.assert_called()\nassert result\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    print(\"expensive operation\")\n    return {\n        \"payment_id\": 12345,\n        \"message\": \"success\",\n        \"statusCode\": 200,\n    }\n</code></pre>"},{"location":"utilities/idempotency/#extra-resources","title":"Extra resources","text":"<p>If you're interested in a deep dive on how Amazon uses idempotency when building our APIs, check out this article.</p>"},{"location":"utilities/jmespath_functions/","title":"JMESPath Functions","text":"Tip <p>JMESPath is a query language for JSON used by AWS CLI, AWS Python SDK, and Powertools for AWS Lambda (Python).</p> <p>Built-in JMESPath Functions to easily deserialize common encoded JSON payloads in Lambda functions.</p>"},{"location":"utilities/jmespath_functions/#key-features","title":"Key features","text":"<ul> <li>Deserialize JSON from JSON strings, base64, and compressed data</li> <li>Use JMESPath to extract and combine data recursively</li> <li>Provides commonly used JMESPath expression with popular event sources</li> </ul>"},{"location":"utilities/jmespath_functions/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>You might have events that contains encoded JSON payloads as string, base64, or even in compressed format. It is a common use case to decode and extract them partially or fully as part of your Lambda function invocation.</p> <p>Powertools for AWS Lambda (Python) also have utilities like validation, idempotency, or feature flags where you might need to extract a portion of your data before using them.</p> Terminology <p>Envelope is the terminology we use for the JMESPath expression to extract your JSON object from your data input. We might use those two terms interchangeably.</p>"},{"location":"utilities/jmespath_functions/#extracting-data","title":"Extracting data","text":"<p>You can use the <code>extract_data_from_envelope</code> function with any JMESPath expression.</p> Tip <p>Another common use case is to fetch deeply nested data, filter, flatten, and more.</p> extract_data_from_envelope.pyextract_data_from_envelope.json <pre><code>from aws_lambda_powertools.utilities.jmespath_utils import extract_data_from_envelope\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\npayload = extract_data_from_envelope(data=event, envelope=\"powertools_json(body)\")\ncustomer_id = payload.get(\"customerId\")  # now deserialized\n\n    # also works for fetching and flattening deeply nested data\nsome_data = extract_data_from_envelope(data=event, envelope=\"deeply_nested[*].some_data[]\")\nreturn {\"customer_id\": customer_id, \"message\": \"success\", \"context\": some_data, \"statusCode\": 200}\n</code></pre> <pre><code>{\n\"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\"}\",\n\"deeply_nested\": [\n{\n\"some_data\": [\n1,\n2,\n3\n]\n}\n]\n}\n</code></pre>"},{"location":"utilities/jmespath_functions/#built-in-envelopes","title":"Built-in envelopes","text":"<p>We provide built-in envelopes for popular AWS Lambda event sources to easily decode and/or deserialize JSON objects.</p> extract_data_from_builtin_envelope.pyextract_data_from_builtin_envelope.json <pre><code>from __future__ import annotations\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\nenvelopes,\n    extract_data_from_envelope,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nlogger = Logger()\n\n\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\n    records: list = extract_data_from_envelope(data=event, envelope=envelopes.SQS)\n    for record in records:  # records is a list\n        logger.info(record.get(\"customerId\"))  # now deserialized\n\n    return {\"message\": \"success\", \"statusCode\": 200}\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"messageId\": \"19dd0b57-b21e-4ac1-bd88-01bbb068cb78\",\n\"receiptHandle\": \"MessageReceiptHandle\",\n\"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\",\\\"booking\\\":{\\\"id\\\":\\\"5b2c4803-330b-42b7-811a-c68689425de1\\\",\\\"reference\\\":\\\"ySz7oA\\\",\\\"outboundFlightId\\\":\\\"20c0d2f2-56a3-4068-bf20-ff7703db552d\\\"},\\\"payment\\\":{\\\"receipt\\\":\\\"https:\\/\\/pay.stripe.com\\/receipts\\/acct_1Dvn7pF4aIiftV70\\/ch_3JTC14F4aIiftV700iFq2CHB\\/rcpt_K7QsrFln9FgFnzUuBIiNdkkRYGxUL0X\\\",\\\"amount\\\":100}}\",\n\"attributes\": {\n\"ApproximateReceiveCount\": \"1\",\n\"SentTimestamp\": \"1523232000000\",\n\"SenderId\": \"123456789012\",\n\"ApproximateFirstReceiveTimestamp\": \"1523232000001\"\n},\n\"messageAttributes\": {},\n\"md5OfBody\": \"7b270e59b47ff90a553787216d55d91d\",\n\"eventSource\": \"aws:sqs\",\n\"eventSourceARN\": \"arn:aws:sqs:us-east-1:123456789012:MyQueue\",\n\"awsRegion\": \"us-east-1\"\n}\n]\n}\n</code></pre> <p>These are all built-in envelopes you can use along with their expression as a reference:</p> Envelope JMESPath expression <code>API_GATEWAY_HTTP</code> <code>powertools_json(body)</code> <code>API_GATEWAY_REST</code> <code>powertools_json(body)</code> <code>CLOUDWATCH_EVENTS_SCHEDULED</code> <code>detail</code> <code>CLOUDWATCH_LOGS</code> <code>awslogs.powertools_base64_gzip(data)                                                     | powertools_json(@).logEvents[*]</code> <code>EVENTBRIDGE</code> <code>detail</code> <code>KINESIS_DATA_STREAM</code> <code>Records[*].kinesis.powertools_json(powertools_base64(data))</code> <code>S3_EVENTBRIDGE_SQS</code> <code>Records[*].powertools_json(body).detail</code> <code>S3_KINESIS_FIREHOSE</code> <code>records[*].powertools_json(powertools_base64(data)).Records[0]</code> <code>S3_SNS_KINESIS_FIREHOSE</code> <code>records[*].powertools_json(powertools_base64(data)).powertools_json(Message).Records[0]</code> <code>S3_SNS_SQS</code> <code>Records[*].powertools_json(body).powertools_json(Message).Records[0]</code> <code>S3_SQS</code> <code>Records[*].powertools_json(body).Records[0]</code> <code>SNS</code> <code>Records[0].Sns.Message                                                                   | powertools_json(@)</code> <code>SQS</code> <code>Records[*].powertools_json(body)</code> Using SNS? <p>If you don't require SNS metadata, enable raw message delivery. It will reduce multiple payload layers and size, when using SNS in combination with other services (e.g., SQS, S3, etc).</p>"},{"location":"utilities/jmespath_functions/#advanced","title":"Advanced","text":""},{"location":"utilities/jmespath_functions/#built-in-jmespath-functions","title":"Built-in JMESPath functions","text":"<p>You can use our built-in JMESPath functions within your envelope expression. They handle deserialization for common data formats found in AWS Lambda event sources such as JSON strings, base64, and uncompress gzip data.</p> Info <p>We use these everywhere in Powertools for AWS Lambda (Python) to easily decode and unwrap events from Amazon API Gateway, Amazon Kinesis, AWS CloudWatch Logs, etc.</p>"},{"location":"utilities/jmespath_functions/#powertools_json-function","title":"powertools_json function","text":"<p>Use <code>powertools_json</code> function to decode any JSON string anywhere a JMESPath expression is allowed.</p> <p>Validation scenario</p> <p>This sample will deserialize the JSON string within the <code>data</code> key before validation.</p> powertools_json_jmespath_function.pypowertools_json_jmespath_schema.pypowertools_json_jmespath_payload.json <pre><code>import json\nfrom dataclasses import asdict, dataclass, field, is_dataclass\nfrom uuid import uuid4\n\nimport powertools_json_jmespath_schema as schemas\nfrom jmespath.exceptions import JMESPathTypeError\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\n\n@dataclass\nclass Order:\n    user_id: int\n    product_id: int\n    quantity: int\n    price: float\n    currency: str\n    order_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass DataclassCustomEncoder(json.JSONEncoder):\n\"\"\"A custom JSON encoder to serialize dataclass obj\"\"\"\n\n    def default(self, obj):\n        # Only called for values that aren't JSON serializable\n        # where `obj` will be an instance of Order in this example\n        return asdict(obj) if is_dataclass(obj) else super().default(obj)\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        # Validate order against our schema\nvalidate(event=event, schema=schemas.INPUT, envelope=\"powertools_json(payload)\")\n# Deserialize JSON string order as dict\n        # alternatively, extract_data_from_envelope works here too\n        order_payload: dict = json.loads(event.get(\"payload\"))\n\n        return {\n            \"order\": json.dumps(Order(**order_payload), cls=DataclassCustomEncoder),\n            \"message\": \"order created\",\n            \"success\": True,\n        }\nexcept JMESPathTypeError:\n# The powertools_json() envelope function must match a valid path\n        return return_error_message(\"Invalid request.\")\nexcept SchemaValidationError as exception:\n# SchemaValidationError indicates where a data mismatch is\n        return return_error_message(str(exception))\nexcept json.JSONDecodeError:\nreturn return_error_message(\"Payload must be valid JSON (base64 encoded).\")\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"order\": None, \"message\": message, \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample order schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n\"examples\": [{\"user_id\": 123, \"product_id\": 1, \"quantity\": 2, \"price\": 10.40, \"currency\": \"USD\"}],\n\"required\": [\"user_id\", \"product_id\", \"quantity\", \"price\", \"currency\"],\n\"properties\": {\n\"user_id\": {\n\"$id\": \"#/properties/user_id\",\n\"type\": \"integer\",\n\"title\": \"The unique identifier of the user\",\n            \"examples\": [123],\n            \"maxLength\": 10,\n        },\n\"product_id\": {\n\"$id\": \"#/properties/product_id\",\n\"type\": \"integer\",\n\"title\": \"The unique identifier of the product\",\n            \"examples\": [1],\n            \"maxLength\": 10,\n        },\n\"quantity\": {\n\"$id\": \"#/properties/quantity\",\n\"type\": \"integer\",\n\"title\": \"The quantity of the product\",\n            \"examples\": [2],\n            \"maxLength\": 10,\n        },\n\"price\": {\n\"$id\": \"#/properties/price\",\n\"type\": \"number\",\n\"title\": \"The individual price of the product\",\n            \"examples\": [10.40],\n            \"maxLength\": 10,\n        },\n\"currency\": {\n\"$id\": \"#/properties/currency\",\n\"type\": \"string\",\n\"title\": \"The currency\",\n            \"examples\": [\"The currency of the order\"],\n            \"maxLength\": 100,\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"payload\":\"{\\\"user_id\\\": 123, \\\"product_id\\\": 1, \\\"quantity\\\": 2, \\\"price\\\": 10.40, \\\"currency\\\": \\\"USD\\\"}\"\n}\n</code></pre> <p>Idempotency scenario</p> <p>This sample will deserialize the JSON string within the <code>body</code> key before Idempotency processes it.</p> powertools_json_idempotency_jmespath.pypowertools_json_idempotency_jmespath.json <pre><code>import json\nfrom uuid import uuid4\n\nimport requests\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n# Treat everything under the \"body\" key\n# in the event json object as our payload\nconfig = IdempotencyConfig(event_key_jmespath=\"powertools_json(body)\")\nclass PaymentError(Exception):\n    ...\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef handler(event, context) -&gt; dict:\n    body = json.loads(event[\"body\"])\n    try:\n        payment: dict = create_subscription_payment(user=body[\"user\"], product_id=body[\"product_id\"])\n        return {\"payment_id\": payment.get(\"id\"), \"message\": \"success\", \"statusCode\": 200}\n    except requests.HTTPError as e:\n        raise PaymentError(\"Unable to create payment subscription\") from e\n\n\ndef create_subscription_payment(user: str, product_id: str) -&gt; dict:\n    payload = {\"user\": user, \"product_id\": product_id}\n    ret: requests.Response = requests.post(url=\"https://httpbin.org/anything\", data=payload)\n    ret.raise_for_status()\n\n    return {\"id\": f\"{uuid4()}\", \"message\": \"paid\"}\n</code></pre> <pre><code>{\n\"version\":\"2.0\",\n\"routeKey\":\"ANY /createpayment\",\n\"rawPath\":\"/createpayment\",\n\"rawQueryString\":\"\",\n\"headers\": {\n\"Header1\": \"value1\",\n\"Header2\": \"value2\"\n},\n\"requestContext\":{\n\"accountId\":\"123456789012\",\n\"apiId\":\"api-id\",\n\"domainName\":\"id.execute-api.us-east-1.amazonaws.com\",\n\"domainPrefix\":\"id\",\n\"http\":{\n\"method\":\"POST\",\n\"path\":\"/createpayment\",\n\"protocol\":\"HTTP/1.1\",\n\"sourceIp\":\"ip\",\n\"userAgent\":\"agent\"\n},\n\"requestId\":\"id\",\n\"routeKey\":\"ANY /createpayment\",\n\"stage\":\"$default\",\n\"time\":\"10/Feb/2021:13:40:43 +0000\",\n\"timeEpoch\":1612964443723\n},\n\"body\":\"{\\\"user\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\",\n\"isBase64Encoded\":false\n}\n</code></pre>"},{"location":"utilities/jmespath_functions/#powertools_base64-function","title":"powertools_base64 function","text":"<p>Use <code>powertools_base64</code> function to decode any base64 data.</p> <p>This sample will decode the base64 value within the <code>data</code> key, and deserialize the JSON string before validation.</p> powertools_base64_jmespath_function.pypowertools_base64_jmespath_schema.pypowertools_base64_jmespath_payload.json <pre><code>import base64\nimport binascii\nimport json\nfrom dataclasses import asdict, dataclass, field, is_dataclass\nfrom uuid import uuid4\n\nimport powertools_base64_jmespath_schema as schemas\nfrom jmespath.exceptions import JMESPathTypeError\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\n\n@dataclass\nclass Order:\n    user_id: int\n    product_id: int\n    quantity: int\n    price: float\n    currency: str\n    order_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass DataclassCustomEncoder(json.JSONEncoder):\n\"\"\"A custom JSON encoder to serialize dataclass obj\"\"\"\n\n    def default(self, obj):\n        # Only called for values that aren't JSON serializable\n        # where `obj` will be an instance of Todo in this example\n        return asdict(obj) if is_dataclass(obj) else super().default(obj)\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    # Try to validate the schema\n    try:\n        validate(event=event, schema=schemas.INPUT, envelope=\"powertools_json(powertools_base64(payload))\")\n# alternatively, extract_data_from_envelope works here too\n        payload_decoded = base64.b64decode(event[\"payload\"]).decode()\n\n        order_payload: dict = json.loads(payload_decoded)\n\n        return {\n            \"order\": json.dumps(Order(**order_payload), cls=DataclassCustomEncoder),\n            \"message\": \"order created\",\n            \"success\": True,\n        }\n    except JMESPathTypeError:\nreturn return_error_message(\n\"The powertools_json(powertools_base64()) envelope function must match a valid path.\",\n        )\n    except binascii.Error:\nreturn return_error_message(\"Payload must be a valid base64 encoded string\")\nexcept json.JSONDecodeError:\nreturn return_error_message(\"Payload must be valid JSON (base64 encoded).\")\nexcept SchemaValidationError as exception:\n# SchemaValidationError indicates where a data mismatch is\nreturn return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"order\": None, \"message\": message, \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample order schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n\"examples\": [{\"user_id\": 123, \"product_id\": 1, \"quantity\": 2, \"price\": 10.40, \"currency\": \"USD\"}],\n\"required\": [\"user_id\", \"product_id\", \"quantity\", \"price\", \"currency\"],\n\"properties\": {\n\"user_id\": {\n\"$id\": \"#/properties/user_id\",\n\"type\": \"integer\",\n\"title\": \"The unique identifier of the user\",\n            \"examples\": [123],\n            \"maxLength\": 10,\n        },\n\"product_id\": {\n\"$id\": \"#/properties/product_id\",\n\"type\": \"integer\",\n\"title\": \"The unique identifier of the product\",\n            \"examples\": [1],\n            \"maxLength\": 10,\n        },\n\"quantity\": {\n\"$id\": \"#/properties/quantity\",\n\"type\": \"integer\",\n\"title\": \"The quantity of the product\",\n            \"examples\": [2],\n            \"maxLength\": 10,\n        },\n\"price\": {\n\"$id\": \"#/properties/price\",\n\"type\": \"number\",\n\"title\": \"The individual price of the product\",\n            \"examples\": [10.40],\n            \"maxLength\": 10,\n        },\n\"currency\": {\n\"$id\": \"#/properties/currency\",\n\"type\": \"string\",\n\"title\": \"The currency\",\n            \"examples\": [\"The currency of the order\"],\n            \"maxLength\": 100,\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"payload\":\"eyJ1c2VyX2lkIjogMTIzLCAicHJvZHVjdF9pZCI6IDEsICJxdWFudGl0eSI6IDIsICJwcmljZSI6IDEwLjQwLCAiY3VycmVuY3kiOiAiVVNEIn0=\"\n}\n</code></pre>"},{"location":"utilities/jmespath_functions/#powertools_base64_gzip-function","title":"powertools_base64_gzip function","text":"<p>Use <code>powertools_base64_gzip</code> function to decompress and decode base64 data.</p> <p>This sample will decompress and decode base64 data from Cloudwatch Logs, then use JMESPath pipeline expression to pass the result for decoding its JSON string.</p> powertools_base64_gzip_jmespath_function.pypowertools_base64_gzip_jmespath_schema.pypowertools_base64_gzip_jmespath_payload.json <pre><code>import base64\nimport binascii\nimport gzip\nimport json\n\nimport powertools_base64_gzip_jmespath_schema as schemas\nfrom jmespath.exceptions import JMESPathTypeError\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\nvalidate(event=event, schema=schemas.INPUT, envelope=\"powertools_base64_gzip(payload) | powertools_json(@)\")\n# Alternatively, extract_data_from_envelope works here too\n        encoded_payload = base64.b64decode(event[\"payload\"])\n        uncompressed_payload = gzip.decompress(encoded_payload).decode()\n        log: dict = json.loads(uncompressed_payload)\n\n        return {\n            \"message\": \"Logs processed\",\n            \"log_group\": log.get(\"logGroup\"),\n            \"owner\": log.get(\"owner\"),\n            \"success\": True,\n        }\n\nexcept JMESPathTypeError:\nreturn return_error_message(\"The powertools_base64_gzip() envelope function must match a valid path.\")\nexcept binascii.Error:\nreturn return_error_message(\"Payload must be a valid base64 encoded string\")\nexcept json.JSONDecodeError:\nreturn return_error_message(\"Payload must be valid JSON (base64 encoded).\")\nexcept SchemaValidationError as exception:\n# SchemaValidationError indicates where a data mismatch is\n        return return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"message\": message, \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n\"examples\": [\n{\n\"owner\": \"123456789012\",\n\"logGroup\": \"/aws/lambda/powertools-example\",\n\"logStream\": \"2022/08/07/[$LATEST]d3a8dcaffc7f4de2b8db132e3e106660\",\n\"logEvents\": {},\n},\n],\n\"required\": [\"owner\", \"logGroup\", \"logStream\", \"logEvents\"],\n\"properties\": {\n\"owner\": {\n\"$id\": \"#/properties/owner\",\n\"type\": \"string\",\n\"title\": \"The owner\",\n            \"examples\": [\"123456789012\"],\n            \"maxLength\": 12,\n        },\n\"logGroup\": {\n\"$id\": \"#/properties/logGroup\",\n\"type\": \"string\",\n\"title\": \"The logGroup\",\n            \"examples\": [\"/aws/lambda/powertools-example\"],\n            \"maxLength\": 100,\n        },\n\"logStream\": {\n\"$id\": \"#/properties/logStream\",\n\"type\": \"string\",\n\"title\": \"The logGroup\",\n            \"examples\": [\"2022/08/07/[$LATEST]d3a8dcaffc7f4de2b8db132e3e106660\"],\n            \"maxLength\": 100,\n        },\n\"logEvents\": {\n\"$id\": \"#/properties/logEvents\",\n\"type\": \"array\",\n\"title\": \"The logEvents\",\n            \"examples\": [\n                \"{'id': 'eventId1', 'message': {'username': 'lessa', 'message': 'hello world'}, 'timestamp': 1440442987000}\"  # noqa E501\n            ],\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"payload\": \"H4sIACZAXl8C/52PzUrEMBhFX2UILpX8tPbHXWHqIOiq3Q1F0ubrWEiakqTWofTdTYYB0YWL2d5zvnuTFellBIOedoiyKH5M0iwnlKH7HZL6dDB6ngLDfLFYctUKjie9gHFaS/sAX1xNEq525QxwFXRGGMEkx4Th491rUZdV3YiIZ6Ljfd+lfSyAtZloacQgAkqSJCGhxM6t7cwwuUGPz4N0YKyvO6I9WDeMPMSo8Z4Ca/kJ6vMEYW5f1MX7W1lVxaG8vqX8hNFdjlc0iCBBSF4ERT/3Pl7RbMGMXF2KZMh/C+gDpNS7RRsp0OaRGzx0/t8e0jgmcczyLCWEePhni/23JWalzjdu0a3ZvgEaNLXeugEAAA==\"\n}\n</code></pre>"},{"location":"utilities/jmespath_functions/#bring-your-own-jmespath-function","title":"Bring your own JMESPath function","text":"Warning <p>This should only be used for advanced use cases where you have special formats not covered by the built-in functions.</p> <p>For special binary formats that you want to decode before applying JSON Schema validation, you can bring your own JMESPath function and any additional option via <code>jmespath_options</code> param. To keep Powertools for AWS Lambda (Python) built-in functions, you can subclass from <code>PowertoolsFunctions</code>.</p> <p>Here is an example of how to decompress messages using snappy:</p> powertools_custom_jmespath_function.pypowertools_custom_jmespath_function.json <pre><code>import base64\nimport binascii\n\nimport snappy\nfrom jmespath.exceptions import JMESPathTypeError\nfrom jmespath.functions import signature\n\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\nPowertoolsFunctions,\nextract_data_from_envelope,\n)\n\n\nclass CustomFunctions(PowertoolsFunctions):\n# only decode if value is a string\n    # see supported data types: https://jmespath.org/specification.html#built-in-functions\n@signature({\"types\": [\"string\"]})\ndef _func_decode_snappy_compression(self, payload: str):\ndecoded: bytes = base64.b64decode(payload)\n        return snappy.uncompress(decoded)\n\n\ncustom_jmespath_options = {\"custom_functions\": CustomFunctions()}\ndef lambda_handler(event, context) -&gt; dict:\n    try:\n        logs = []\n        logs.append(\n            extract_data_from_envelope(\n                data=event,\n                # NOTE: Use the prefix `_func_` before the name of the function\n                envelope=\"Records[*].decode_snappy_compression(log)\",\njmespath_options=custom_jmespath_options,\n),\n        )\n        return {\"logs\": logs, \"message\": \"Extracted messages\", \"success\": True}\n    except JMESPathTypeError:\nreturn return_error_message(\"The envelope function must match a valid path.\")\nexcept snappy.UncompressError:\nreturn return_error_message(\"Log must be a valid snappy compressed binary\")\nexcept binascii.Error:\nreturn return_error_message(\"Log must be a valid base64 encoded string\")\ndef return_error_message(message: str) -&gt; dict:\n    return {\"logs\": None, \"message\": message, \"success\": False}\n</code></pre> <pre><code>{\n\"Records\": [\n{\n\"user\": \"integration-kafka\",\n\"datetime\": \"2022-01-01T00:00:00.000Z\",\n\"log\": \"/QGIMjAyMi8wNi8xNiAxNjoyNTowMCBbY3JpdF0gMzA1MTg5MCMNCPBEOiAqMSBjb25uZWN0KCkg\\ndG8gMTI3LjAuMC4xOjUwMDAgZmFpbGVkICgxMzogUGVybWlzc2lvbiBkZW5pZWQpIHdoaWxlEUEI\\naW5nAUJAdXBzdHJlYW0sIGNsaWVudDoZVKgsIHNlcnZlcjogXywgcmVxdWVzdDogIk9QVElPTlMg\\nLyBIVFRQLzEuMSIsFUckOiAiaHR0cDovLzabABQvIiwgaG8FQDAxMjcuMC4wLjE6ODEi\\n\"\n},\n{\n\"user\": \"integration-kafka\",\n\"datetime\": \"2022-01-01T00:00:01.000Z\",\n\"log\": \"tQHwnDEyNy4wLjAuMSAtIC0gWzE2L0p1bi8yMDIyOjE2OjMwOjE5ICswMTAwXSAiT1BUSU9OUyAv\\nIEhUVFAvMS4xIiAyMDQgMCAiLSIgIk1vemlsbGEvNS4wIChYMTE7IExpbnV4IHg4Nl82NCkgQXBw\\nbGVXZWJLaXQvNTM3LjM2IChLSFRNTCwgbGlrZSBHZWNrbykgQ2hyb21lLzEwMi4BmUwwIFNhZmFy\\naS81MzcuMzYiICItIg==\\n\"\n}\n]\n}\n</code></pre>"},{"location":"utilities/middleware_factory/","title":"Middleware factory","text":"<p>Middleware factory provides a decorator factory to create your own middleware to run logic before, and after each Lambda invocation synchronously.</p>"},{"location":"utilities/middleware_factory/#key-features","title":"Key features","text":"<ul> <li>Run logic before, after, and handle exceptions</li> <li>Built-in tracing opt-in capability</li> </ul>"},{"location":"utilities/middleware_factory/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>You might need a custom middleware to abstract non-functional code. These are often custom authorization or any reusable logic you might need to run before/after a Lambda function invocation.</p>"},{"location":"utilities/middleware_factory/#middleware-with-no-params","title":"Middleware with no params","text":"<p>You can create your own middleware using <code>lambda_handler_decorator</code>. The decorator factory expects 3 arguments in your function signature:</p> <ul> <li>handler - Lambda function handler</li> <li>event - Lambda function invocation event</li> <li>context - Lambda function context object</li> </ul>"},{"location":"utilities/middleware_factory/#middleware-with-before-logic","title":"Middleware with before logic","text":"getting_started_middleware_before_logic_function.pygetting_started_middleware_before_logic_payload.json <pre><code>from dataclasses import dataclass, field\nfrom typing import Callable\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\n    envelopes,\n    extract_data_from_envelope,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    order_id: str\n    amount: float\n    status_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@lambda_handler_decorator\ndef middleware_before(handler, event, context) -&gt; Callable:\n# extract payload from a EventBridge event\n    detail: dict = extract_data_from_envelope(data=event, envelope=envelopes.EVENTBRIDGE)\n\n    # check if status_id exists in payload, otherwise add default state before processing payment\nif \"status_id\" not in detail:\nevent[\"detail\"][\"status_id\"] = \"pending\"\nresponse = handler(event, context)\nreturn response\n\n\n@middleware_before\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\ntry:\n        payment_payload: dict = extract_data_from_envelope(data=event, envelope=envelopes.EVENTBRIDGE)\n        return {\n            \"order\": Payment(**payment_payload).__dict__,\n            \"message\": \"payment created\",\n            \"success\": True,\n        }\n    except Exception as e:\n        raise PaymentError(\"Unable to create payment\") from e\n</code></pre> <pre><code>{\n\"version\": \"0\",\n\"id\": \"9c95e8e4-96a4-ef3f-b739-b6aa5b193afb\",\n\"detail-type\": \"PaymentCreated\",\n\"source\": \"app.payment\",\n\"account\": \"0123456789012\",\n\"time\": \"2022-08-08T20:41:53Z\",\n\"region\": \"eu-east-1\",\n\"detail\": {\n\"amount\": \"150.00\",\n\"order_id\": \"8f1f1710-1b30-48a5-a6bd-153fd23b866b\",\n\"user_id\": \"f80e3c51-5b8c-49d5-af7d-c7804966235f\"\n}\n}\n</code></pre>"},{"location":"utilities/middleware_factory/#middleware-with-after-logic","title":"Middleware with after logic","text":"getting_started_middleware_after_logic_function.pygetting_started_middleware_after_logic_payload.json <pre><code>import time\nfrom typing import Callable\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver()\n\n\n@lambda_handler_decorator\ndef middleware_after(handler, event, context) -&gt; Callable:\nstart_time = time.time()\n    response = handler(event, context)\n    execution_time = time.time() - start_time\n\n# adding custom headers in response object after lambda executing\nresponse[\"headers\"][\"execution_time\"] = execution_time\nresponse[\"headers\"][\"aws_request_id\"] = context.aws_request_id\nreturn response\n\n\n@app.post(\"/todos\")\ndef create_todo() -&gt; dict:\n    todo_data: dict = app.current_event.json_body  # deserialize json str to dict\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=todo_data)\n    todo.raise_for_status()\n\n    return {\"todo\": todo.json()}\n\n\n@middleware_after\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"resource\": \"/todos\",\n\"path\": \"/todos\",\n\"httpMethod\": \"POST\",\n\"body\": \"{\\\"title\\\": \\\"foo\\\", \\\"userId\\\": 1, \\\"completed\\\": false}\"\n}\n</code></pre>"},{"location":"utilities/middleware_factory/#middleware-with-params","title":"Middleware with params","text":"<p>You can also have your own keyword arguments after the mandatory arguments.</p> getting_started_middleware_with_params_function.pygetting_started_middleware_with_params_payload.json <pre><code>import base64\nfrom dataclasses import dataclass, field\nfrom typing import Any, Callable, List\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\n    envelopes,\n    extract_data_from_envelope,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@dataclass\nclass Booking:\n    days: int\n    date_from: str\n    date_to: str\n    hotel_id: int\n    country: str\n    city: str\n    guest: dict\n    booking_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass BookingError(Exception):\n    ...\n\n\n@lambda_handler_decorator\ndef obfuscate_sensitive_data(handler, event, context, fields: List) -&gt; Callable:\n# extracting payload from a EventBridge event\ndetail: dict = extract_data_from_envelope(data=event, envelope=envelopes.EVENTBRIDGE)\n    guest_data: Any = detail.get(\"guest\")\n\n# Obfuscate fields (email, vat, passport) before calling Lambda handler\nfor guest_field in fields:\n        if guest_data.get(guest_field):\n            event[\"detail\"][\"guest\"][guest_field] = obfuscate_data(str(guest_data.get(guest_field)))\n\n    response = handler(event, context)\n\n    return response\n\n\ndef obfuscate_data(value: str) -&gt; bytes:\n    # base64 is not effective for obfuscation, this is an example\n    return base64.b64encode(value.encode(\"ascii\"))\n\n\n@obfuscate_sensitive_data(fields=[\"email\", \"passport\", \"vat\"])\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\ntry:\n        booking_payload: dict = extract_data_from_envelope(data=event, envelope=envelopes.EVENTBRIDGE)\n        return {\n            \"book\": Booking(**booking_payload).__dict__,\n            \"message\": \"booking created\",\n            \"success\": True,\n        }\n    except Exception as e:\n        raise BookingError(\"Unable to create booking\") from e\n</code></pre> <pre><code>{\n\"version\": \"0\",\n\"id\": \"9c95e8e4-96a4-ef3f-b739-b6aa5b193afb\",\n\"detail-type\": \"BookingCreated\",\n\"source\": \"app.booking\",\n\"account\": \"0123456789012\",\n\"time\": \"2022-08-08T20:41:53Z\",\n\"region\": \"eu-east-1\",\n\"detail\": {\n\"days\": 5,\n\"date_from\": \"2020-08-08\",\n\"date_to\": \"2020-08-13\",\n\"hotel_id\": \"1\",\n\"country\": \"Portugal\",\n\"city\": \"Lisbon\",\n\"guest\": {\n\"name\": \"Lambda\",\n\"email\": \"lambda@powertool.tools\",\n\"passport\": \"AA123456\",\n\"vat\": \"123456789\"\n}\n}\n}\n</code></pre>"},{"location":"utilities/middleware_factory/#advanced","title":"Advanced","text":"<p>For advanced use cases, you can instantiate Tracer inside your middleware, and add annotations as well as metadata for additional operational insights.</p> advanced_middleware_tracer_function.pyadvanced_middleware_tracer_payload.json <pre><code>import time\nfrom typing import Callable\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n\n@lambda_handler_decorator(trace_execution=True)\ndef middleware_with_advanced_tracing(handler, event, context) -&gt; Callable:\ntracer.put_metadata(key=\"resource\", value=event.get(\"resource\"))\nstart_time = time.time()\n    response = handler(event, context)\n    execution_time = time.time() - start_time\n\ntracer.put_annotation(key=\"TotalExecutionTime\", value=str(execution_time))\n# adding custom headers in response object after lambda executing\n    response[\"headers\"][\"execution_time\"] = execution_time\n    response[\"headers\"][\"aws_request_id\"] = context.aws_request_id\n\n    return response\n\n\n@app.get(\"/products\")\ndef create_product() -&gt; dict:\n    product: Response = requests.get(\"https://dummyjson.com/products/1\")\n    product.raise_for_status()\n\n    return {\"product\": product.json()}\n\n\n@middleware_with_advanced_tracing\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"resource\": \"/products\",\n\"path\": \"/products\",\n\"httpMethod\": \"GET\"\n}\n</code></pre> <p></p>"},{"location":"utilities/middleware_factory/#tracing-middleware-execution","title":"Tracing middleware execution","text":"<p>If you are making use of Tracer, you can trace the execution of your middleware to ease operations.</p> <p>This makes use of an existing Tracer instance that you may have initialized anywhere in your code.</p> Warning <p>You must enable Active Tracing in your Lambda function when using this feature, otherwise Lambda cannot send traces to XRay.</p> getting_started_middleware_tracer_function.pygetting_started_middleware_tracer_payload.json <pre><code>import time\nfrom typing import Callable\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver()\n\n\n@lambda_handler_decorator(trace_execution=True)\ndef middleware_with_tracing(handler, event, context) -&gt; Callable:\nstart_time = time.time()\n    response = handler(event, context)\n    execution_time = time.time() - start_time\n\n    # adding custom headers in response object after lambda executing\n    response[\"headers\"][\"execution_time\"] = execution_time\n    response[\"headers\"][\"aws_request_id\"] = context.aws_request_id\n\n    return response\n\n\n@app.get(\"/products\")\ndef create_product() -&gt; dict:\n    product: Response = requests.get(\"https://dummyjson.com/products/1\")\n    product.raise_for_status()\n\n    return {\"product\": product.json()}\n\n\n@middleware_with_tracing\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n\"resource\": \"/products\",\n\"path\": \"/products\",\n\"httpMethod\": \"GET\"\n}\n</code></pre> <p>When executed, your middleware name will appear in AWS X-Ray Trace details as <code>## middleware_name</code>, in this example the middleware name is <code>## middleware_with_tracing</code>.</p> <p></p>"},{"location":"utilities/middleware_factory/#combining-powertools-for-aws-lambda-python-utilities","title":"Combining Powertools for AWS Lambda (Python) utilities","text":"<p>You can create your own middleware and combine many features of Powertools for AWS Lambda (Python) such as trace, logs, feature flags, validation, jmespath_functions and others to abstract non-functional code.</p> <p>In the example below, we create a Middleware with the following features:</p> <ul> <li>Logs and traces</li> <li>Validate if the payload contains a specific header</li> <li>Extract specific keys from event</li> <li>Automatically add security headers on every execution</li> <li>Validate if a specific feature flag is enabled</li> <li>Save execution history to a DynamoDB table</li> </ul> combining_powertools_utilities_function.pycombining_powertools_utilities_schema.pycombining_powertools_utilities_event.jsonSAM TEMPLATE <pre><code>import json\nfrom typing import Callable\n\nimport boto3\nimport combining_powertools_utilities_schema as schemas\nimport requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.exceptions import InternalServerError\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.shared.types import JSONType\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.jmespath_utils import extract_data_from_envelope\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\napp = APIGatewayRestResolver()\ntracer = Tracer()\nlogger = Logger()\n\ntable_historic = boto3.resource(\"dynamodb\").Table(\"HistoricTable\")\n\napp_config = AppConfigStore(environment=\"dev\", application=\"comments\", name=\"features\")\nfeature_flags = FeatureFlags(store=app_config)\n\n\n@lambda_handler_decorator(trace_execution=True)\ndef middleware_custom(handler: Callable, event: dict, context: LambdaContext):\n# validating the INPUT with the given schema\n    # X-Customer-Id header must be informed in all requests\n    try:\n        validate(event=event, schema=schemas.INPUT)\n    except SchemaValidationError as e:\n        return {\n            \"statusCode\": 400,\n            \"body\": json.dumps(str(e)),\n        }\n\n    # extracting headers and requestContext from event\n    headers = extract_data_from_envelope(data=event, envelope=\"headers\")\n    request_context = extract_data_from_envelope(data=event, envelope=\"requestContext\")\n\n    logger.debug(f\"X-Customer-Id =&gt; {headers.get('X-Customer-Id')}\")\n    tracer.put_annotation(key=\"CustomerId\", value=headers.get(\"X-Customer-Id\"))\n\n    response = handler(event, context)\n\n    # automatically adding security headers to all responses\n    # see: https://securityheaders.com/\n    logger.info(\"Injecting security headers\")\nresponse[\"headers\"][\"Referrer-Policy\"] = \"no-referrer\"\nresponse[\"headers\"][\"Strict-Transport-Security\"] = \"max-age=15552000; includeSubDomains; preload\"\n    response[\"headers\"][\"X-DNS-Prefetch-Control\"] = \"off\"\n    response[\"headers\"][\"X-Content-Type-Options\"] = \"nosniff\"\n    response[\"headers\"][\"X-Permitted-Cross-Domain-Policies\"] = \"none\"\n    response[\"headers\"][\"X-Download-Options\"] = \"noopen\"\n\n    logger.info(\"Saving api call in history table\")\n    save_api_execution_history(str(event.get(\"path\")), headers, request_context)\n# return lambda execution\n    return response\n\n\n@tracer.capture_method\ndef save_api_execution_history(path: str, headers: dict, request_context: dict) -&gt; None:\n    try:\n        # using the feature flags utility to check if the new feature \"save api call to history\" is enabled by default\n        # see: https://docs.powertools.aws.dev/lambda/python/latest/utilities/feature_flags/#static-flags\n        save_history: JSONType = feature_flags.evaluate(name=\"save_history\", default=False)\n        if save_history:\n# saving history in dynamodb table\ntracer.put_metadata(key=\"execution detail\", value=request_context)\n            table_historic.put_item(\n                Item={\n                    \"customer_id\": headers.get(\"X-Customer-Id\"),\n                    \"request_id\": request_context.get(\"requestId\"),\n                    \"path\": path,\n                    \"request_time\": request_context.get(\"requestTime\"),\n                    \"source_ip\": request_context.get(\"identity\", {}).get(\"sourceIp\"),\n                    \"http_method\": request_context.get(\"httpMethod\"),\n                },\n            )\n\n        return None\n    except Exception:\n        # you can add more logic here to handle exceptions or even save this to a DLQ\n        # but not to make this example too long, we just return None since the Lambda has been successfully executed\n        return None\n\n\n@app.get(\"/comments\")\n@tracer.capture_method\ndef get_comments():\n    try:\n        comments: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/comments\")\n        comments.raise_for_status()\n\n        return {\"comments\": comments.json()[:10]}\n    except Exception as exc:\n        raise InternalServerError(str(exc))\n\n\n@app.get(\"/comments/&lt;comment_id&gt;\")\n@tracer.capture_method\ndef get_comments_by_id(comment_id: str):\n    try:\n        comments: requests.Response = requests.get(f\"https://jsonplaceholder.typicode.com/comments/{comment_id}\")\n        comments.raise_for_status()\n\n        return {\"comments\": comments.json()}\n    except Exception as exc:\n        raise InternalServerError(str(exc))\n\n\n@middleware_custom\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\nreturn app.resolve(event, context)\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1661012141.json\",\n    \"title\": \"Root\",\n    \"type\": \"object\",\n    \"required\": [\"headers\"],\n    \"properties\": {\n        \"headers\": {\n            \"$id\": \"#root/headers\",\n            \"title\": \"Headers\",\n            \"type\": \"object\",\n\"required\": [\"X-Customer-Id\"],\n\"properties\": {\n\"X-Customer-Id\": {\n\"$id\": \"#root/headers/X-Customer-Id\",\n                    \"title\": \"X-customer-id\",\n                    \"type\": \"string\",\n                    \"default\": \"\",\n                    \"examples\": [\"1\"],\n                    \"pattern\": \"^.*$\",\n                },\n            },\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"body\":\"None\",\n    \"headers\":{\n       \"Accept\":\"*/*\",\n       \"Accept-Encoding\":\"gzip, deflate, br\",\n       \"Connection\":\"keep-alive\",\n       \"Host\":\"127.0.0.1:3001\",\n       \"Postman-Token\":\"a9d49365-ebe1-4bb0-8627-d5e37cdce86d\",\n       \"User-Agent\":\"PostmanRuntime/7.29.0\",\n\"X-Customer-Id\":\"1\",\n\"X-Forwarded-Port\":\"3001\",\n       \"X-Forwarded-Proto\":\"http\"\n    },\n    \"httpMethod\":\"GET\",\n    \"isBase64Encoded\":false,\n    \"multiValueHeaders\":{\n       \"Accept\":[\n          \"*/*\"\n       ],\n       \"Accept-Encoding\":[\n          \"gzip, deflate, br\"\n       ],\n       \"Connection\":[\n          \"keep-alive\"\n       ],\n       \"Host\":[\n          \"127.0.0.1:3001\"\n       ],\n       \"Postman-Token\":[\n          \"a9d49365-ebe1-4bb0-8627-d5e37cdce86d\"\n       ],\n       \"User-Agent\":[\n          \"PostmanRuntime/7.29.0\"\n       ],\n       \"X-Customer-Id\":[\n          \"1\"\n       ],\n       \"X-Forwarded-Port\":[\n          \"3001\"\n       ],\n       \"X-Forwarded-Proto\":[\n          \"http\"\n       ]\n    },\n    \"multiValueQueryStringParameters\":\"None\",\n    \"path\":\"/comments\",\n    \"pathParameters\":\"None\",\n    \"queryStringParameters\":\"None\",\n    \"requestContext\":{\n       \"accountId\":\"123456789012\",\n       \"apiId\":\"1234567890\",\n       \"domainName\":\"127.0.0.1:3001\",\n       \"extendedRequestId\":\"None\",\n       \"httpMethod\":\"GET\",\n       \"identity\":{\n          \"accountId\":\"None\",\n          \"apiKey\":\"None\",\n          \"caller\":\"None\",\n          \"cognitoAuthenticationProvider\":\"None\",\n          \"cognitoAuthenticationType\":\"None\",\n          \"cognitoIdentityPoolId\":\"None\",\n          \"sourceIp\":\"127.0.0.1\",\n          \"user\":\"None\",\n          \"userAgent\":\"Custom User Agent String\",\n          \"userArn\":\"None\"\n       },\n       \"path\":\"/comments\",\n       \"protocol\":\"HTTP/1.1\",\n       \"requestId\":\"56d1a102-6d9d-4f13-b4f7-26751c10a131\",\n       \"requestTime\":\"20/Aug/2022:18:18:58 +0000\",\n       \"requestTimeEpoch\":1661019538,\n       \"resourceId\":\"123456\",\n       \"resourcePath\":\"/comments\",\n       \"stage\":\"Prod\"\n    },\n    \"resource\":\"/comments\",\n    \"stageVariables\":\"None\",\n    \"version\":\"1.0\"\n }\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: Middleware-powertools-utilities example\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.9\n    Tracing: Active\n    Architectures:\n      - x86_64\n    Environment:\n      Variables:\n        LOG_LEVEL: DEBUG\n        POWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\n        POWERTOOLS_LOGGER_LOG_EVENT: true\n        POWERTOOLS_SERVICE_NAME: middleware\n\nResources:\n  MiddlewareFunction:\n    Type: AWS::Serverless::Function # More info about Function Resource: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#awsserverlessfunction\n    Properties:\n      CodeUri: middleware/\n      Handler: app.lambda_handler\n      Description: Middleware function\n      Policies:\n      - AWSLambdaBasicExecutionRole # Managed Policy\n      - Version: '2012-10-17' # Policy Document\n        Statement:\n          - Effect: Allow\n            Action:\n              - dynamodb:PutItem\n            Resource: !GetAtt HistoryTable.Arn\n          - Effect: Allow\n            Action: # https://docs.aws.amazon.com/appconfig/latest/userguide/getting-started-with-appconfig-permissions.html\n              - ssm:GetDocument\n              - ssm:ListDocuments\n              - appconfig:GetLatestConfiguration\n              - appconfig:StartConfigurationSession\n              - appconfig:ListApplications\n              - appconfig:GetApplication\n              - appconfig:ListEnvironments\n              - appconfig:GetEnvironment\n              - appconfig:ListConfigurationProfiles\n              - appconfig:GetConfigurationProfile\n              - appconfig:ListDeploymentStrategies\n              - appconfig:GetDeploymentStrategy\n              - appconfig:GetConfiguration\n              - appconfig:ListDeployments\n              - appconfig:GetDeployment\n            Resource: \"*\"\n      Events:\n        GetComments:\n          Type: Api\n          Properties:\n            Path: /comments\n            Method: GET\n        GetCommentsById:\n          Type: Api\n          Properties:\n            Path: /comments/{comment_id}\n            Method: GET\n\n  # DynamoDB table to store historical data\n  HistoryTable:\nType: AWS::DynamoDB::Table\nProperties:\n      TableName: \"HistoryTable\"\n      AttributeDefinitions:\n        - AttributeName: customer_id\n          AttributeType: S\n        - AttributeName: request_id\n          AttributeType: S\n      KeySchema:\n        - AttributeName: customer_id\n          KeyType: HASH\n        - AttributeName: request_id\n          KeyType: \"RANGE\"\n      BillingMode: PAY_PER_REQUEST\n\n  # Feature flags using AppConfig\n  FeatureCommentApp:\nType: AWS::AppConfig::Application\nProperties:\n      Description: \"Comments Application for feature toggles\"\n      Name: comments\n\n  FeatureCommentDevEnv:\nType: AWS::AppConfig::Environment\nProperties:\n      ApplicationId: !Ref FeatureCommentApp\n      Description: \"Development Environment for the App Config Comments\"\n      Name: dev\n\n  FeatureCommentConfigProfile:\nType: AWS::AppConfig::ConfigurationProfile\nProperties:\n      ApplicationId: !Ref FeatureCommentApp\n      Name: features\n      LocationUri: \"hosted\"\n\n  HostedConfigVersion:\nType: AWS::AppConfig::HostedConfigurationVersion\nProperties:\n      ApplicationId: !Ref FeatureCommentApp\n      ConfigurationProfileId: !Ref FeatureCommentConfigProfile\n      Description: 'A sample hosted configuration version'\nContent: |\n{\n\"save_history\": {\n\"default\": true\n}\n}\nContentType: 'application/json'\n\n  # this is just an example\n  # change this values according your deployment strategy\n  BasicDeploymentStrategy:\nType: AWS::AppConfig::DeploymentStrategy\nProperties:\n      Name: \"Deployment\"\n      Description: \"Deployment strategy for comments app.\"\n      DeploymentDurationInMinutes: 1\n      FinalBakeTimeInMinutes: 1\n      GrowthFactor: 100\n      GrowthType: LINEAR\n      ReplicateTo: NONE\n\n  ConfigDeployment:\nType: AWS::AppConfig::Deployment\nProperties:\n      ApplicationId: !Ref FeatureCommentApp\n      ConfigurationProfileId: !Ref FeatureCommentConfigProfile\n      ConfigurationVersion: !Ref HostedConfigVersion\n      DeploymentStrategyId: !Ref BasicDeploymentStrategy\n      EnvironmentId: !Ref FeatureCommentDevEnv\n</code></pre>"},{"location":"utilities/middleware_factory/#tips","title":"Tips","text":"<ul> <li>Use <code>trace_execution</code> to quickly understand the performance impact of your middlewares, and reduce or merge tasks when necessary</li> <li>When nesting multiple middlewares, always return the handler with event and context, or response</li> <li>Keep in mind Python decorators execution order. Lambda handler is actually called once (top-down)</li> <li>Async middlewares are not supported</li> </ul>"},{"location":"utilities/parameters/","title":"Parameters","text":"<p>The parameters utility provides high-level functions to retrieve one or multiple parameter values from AWS Systems Manager Parameter Store, AWS Secrets Manager, AWS AppConfig, Amazon DynamoDB, or bring your own.</p>"},{"location":"utilities/parameters/#key-features","title":"Key features","text":"<ul> <li>Retrieve one or multiple parameters from the underlying provider</li> <li>Cache parameter values for a given amount of time (defaults to 5 seconds)</li> <li>Transform parameter values from JSON or base 64 encoded strings</li> <li>Bring Your Own Parameter Store Provider</li> </ul>"},{"location":"utilities/parameters/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>By default, we fetch parameters from System Manager Parameter Store, secrets from Secrets Manager, and application configuration from AppConfig.</p>"},{"location":"utilities/parameters/#iam-permissions","title":"IAM Permissions","text":"<p>This utility requires additional permissions to work as expected.</p> Note <p>Different parameter providers require different permissions.</p> Provider Function/Method IAM Permission SSM <code>get_parameter</code>, <code>SSMProvider.get</code> <code>ssm:GetParameter</code> SSM <code>get_parameters</code>, <code>SSMProvider.get_multiple</code> <code>ssm:GetParametersByPath</code> SSM <code>get_parameters_by_name</code>, <code>SSMProvider.get_parameters_by_name</code> <code>ssm:GetParameter</code> and <code>ssm:GetParameters</code> SSM If using <code>decrypt=True</code> You must add an additional permission <code>kms:Decrypt</code> Secrets <code>get_secret</code>, <code>SecretsProvider.get</code> <code>secretsmanager:GetSecretValue</code> DynamoDB <code>DynamoDBProvider.get</code> <code>dynamodb:GetItem</code> DynamoDB <code>DynamoDBProvider.get_multiple</code> <code>dynamodb:Query</code> AppConfig <code>get_app_config</code>, <code>AppConfigProvider.get_app_config</code> <code>appconfig:GetLatestConfiguration</code> and <code>appconfig:StartConfigurationSession</code>"},{"location":"utilities/parameters/#fetching-parameters","title":"Fetching parameters","text":"<p>You can retrieve a single parameter using the <code>get_parameter</code> high-level function.</p> getting_started_single_ssm_parameter.py <pre><code>import requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        # Retrieve a single parameter\nendpoint_comments: str = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")  # type: ignore[assignment] # noqa: E501\n# the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <p>For multiple parameters, you can use either:</p> <ul> <li><code>get_parameters</code> to recursively fetch all parameters by path.</li> <li><code>get_parameters_by_name</code> to fetch distinct parameters by their full name. It also accepts custom caching, transform, decrypt per parameter.</li> </ul> getting_started_recursive_ssm_parameter.pygetting_started_parameter_by_name.py <pre><code>import requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\nall_parameters: dict = parameters.get_parameters(\"/lambda-powertools/\", max_age=20)\nendpoint_comments = None\n\nfor parameter, value in all_parameters.items():\nif parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        if endpoint_comments is None:\n            return {\"comments\": None}\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.parameters.ssm import get_parameters_by_name\nparameters = {\n    \"/develop/service/commons/telemetry/config\": {\"max_age\": 300, \"transform\": \"json\"},\n    \"/no_cache_param\": {\"max_age\": 0},\n    # inherit default values\n    \"/develop/service/payment/api/capture/url\": {},\n}\n\n\ndef handler(event, context):\n# This returns a dict with the parameter name as key\nresponse: dict[str, Any] = get_parameters_by_name(parameters=parameters, max_age=60)\n    for parameter, value in response.items():\n        print(f\"{parameter}: {value}\")\n</code></pre> <code>get_parameters_by_name</code> supports graceful error handling <p>By default, we will raise <code>GetParameterError</code> when any parameter fails to be fetched. You can override it by setting <code>raise_on_error=False</code>.</p> <p>When disabled, we take the following actions:</p> <ul> <li>Add failed parameter name in the <code>_errors</code> key, e.g., <code>{_errors: [\"/param1\", \"/param2\"]}</code></li> <li>Keep only successful parameter names and their values in the response</li> <li>Raise <code>GetParameterError</code> if any of your parameters is named <code>_errors</code></li> </ul> get_parameter_by_name_error_handling.py <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.parameters.ssm import get_parameters_by_name\nparameters = {\n\"/develop/service/commons/telemetry/config\": {\"max_age\": 300, \"transform\": \"json\"},\n    # it would fail by default\n    \"/this/param/does/not/exist\": {},\n}\n\n\ndef handler(event, context):\nvalues: dict[str, Any] = get_parameters_by_name(parameters=parameters, raise_on_error=False)\nerrors: list[str] = values.get(\"_errors\", [])\n# Handle gracefully, since '/this/param/does/not/exist' will only be available in `_errors`\n    if errors:\n        ...\n\n    for parameter, value in values.items():\n        print(f\"{parameter}: {value}\")\n</code></pre>"},{"location":"utilities/parameters/#fetching-secrets","title":"Fetching secrets","text":"<p>You can fetch secrets stored in Secrets Manager using <code>get_secret</code>.</p> getting_started_secret.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\napi_key: Any = parameters.get_secret(\"/lambda-powertools/api-key\")\nheaders: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#fetching-app-configurations","title":"Fetching app configurations","text":"<p>You can fetch application configurations in AWS AppConfig using <code>get_app_config</code>.</p> <p>The following will retrieve the latest version and store it in the cache.</p> Warning <p>We make two API calls to fetch each unique configuration name during the first time. This is by design in AppConfig. Please consider adjusting <code>max_age</code> parameter to enhance performance.</p> getting_started_appconfig.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\nendpoint_comments: Any = parameters.get_app_config(name=\"config\", environment=\"dev\", application=\"comments\")\n# the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#advanced","title":"Advanced","text":""},{"location":"utilities/parameters/#adjusting-cache-ttl","title":"Adjusting cache TTL","text":"Tip <p><code>max_age</code> parameter is also available in underlying provider functions like <code>get()</code>, <code>get_multiple()</code>, etc.</p> <p>By default, we cache parameters retrieved in-memory for 5 seconds. If you want to change this default value and set the same TTL for all parameters, you can set the <code>POWERTOOLS_PARAMETERS_MAX_AGE</code> environment variable. You can still set <code>max_age</code> for individual parameters.</p> <p>You can adjust how long we should keep values in cache by using the param <code>max_age</code>, when using  <code>get_parameter()</code>, <code>get_parameters()</code> and <code>get_secret()</code> methods across all providers.</p> single_ssm_parameter_with_cache.pyrecursive_ssm_parameter_with_cache.pysecret_with_cache.pyappconfig_with_cache.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter with 20s cache\nendpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\", max_age=20)\n# the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\nall_parameters: Any = parameters.get_parameters(\"/lambda-powertools/\", max_age=20)\nendpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n\n        for parameter, value in all_parameters.items():\n\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\napi_key: Any = parameters.get_secret(\"/lambda-powertools/api-key\", max_age=20)\nheaders: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\nendpoint_comments: Any = parameters.get_app_config(\nname=\"config\",\nenvironment=\"dev\",\napplication=\"comments\",\n            max_age=20,\n        )\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#always-fetching-the-latest","title":"Always fetching the latest","text":"<p>If you'd like to always ensure you fetch the latest parameter from the store regardless if already available in cache, use <code>force_fetch</code> param.</p> single_ssm_parameter_force_fetch.pyrecursive_ssm_parameter_force_fetch.pysecret_force_fetch.pyappconfig_force_fetch.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter with 20s cache\nendpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\", force_fetch=True)\n# the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\nall_parameters: Any = parameters.get_parameters(\"/lambda-powertools/\", force_fetch=True)\nendpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n\n        for parameter, value in all_parameters.items():\n\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\napi_key: Any = parameters.get_secret(\"/lambda-powertools/api-key\", force_fetch=True)\nheaders: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\nendpoint_comments: Any = parameters.get_app_config(\nname=\"config\",\nenvironment=\"dev\",\napplication=\"comments\",\n            force_fetch=True,\n        )\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#built-in-provider-class","title":"Built-in provider class","text":"<p>For greater flexibility such as configuring the underlying SDK client used by built-in providers, you can use their respective Provider Classes directly.</p> Tip <p>This is useful when you need to customize parameters for the SDK client, such as region, credentials, retries and others. For more information, read botocore.config and boto3.session.</p>"},{"location":"utilities/parameters/#ssmprovider","title":"SSMProvider","text":"builtin_provider_ssm_single_parameter.pybuiltin_provider_ssm_recursive_parameter.py <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# changing region_name, connect_timeout and retrie configurations\n# see: https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html\nconfig = Config(region_name=\"sa-east-1\", connect_timeout=1, retries={\"total_max_attempts\": 2, \"max_attempts\": 5})\nssm_provider = parameters.SSMProvider(config=config)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = ssm_provider.get(\"/lambda-powertools/endpoint_comments\")\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport boto3\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# assuming role from another account to get parameter there\n# see: https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html\nsts_client = boto3.client(\"sts\")\nassumed_role_object = sts_client.assume_role(\n    RoleArn=\"arn:aws:iam::account-of-role-to-assume:role/name-of-role\",\n    RoleSessionName=\"RoleAssume1\",\n)\ncredentials = assumed_role_object[\"Credentials\"]\n\n# using temporary credentials in your SSMProvider provider\n# see: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#module-boto3.session\nboto3_session = boto3.session.Session(\nregion_name=\"us-east-1\",\naws_access_key_id=credentials[\"AccessKeyId\"],\naws_secret_access_key=credentials[\"SecretAccessKey\"],\naws_session_token=credentials[\"SessionToken\"],\n)\nssm_provider = parameters.SSMProvider(boto3_session=boto3_session)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\n        all_parameters: Any = ssm_provider.get_multiple(\"/lambda-powertools/\")\n        endpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n\n        for parameter, value in all_parameters.items():\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <p>The AWS Systems Manager Parameter Store provider supports two additional arguments for the <code>get()</code> and <code>get_multiple()</code> methods:</p> Parameter Default Description decrypt <code>False</code> Will automatically decrypt the parameter. recursive <code>True</code> For <code>get_multiple()</code> only, will fetch all parameter values recursively based on a path prefix. <p>You can create <code>SecureString</code> parameters, which are parameters that have a plaintext parameter name and an encrypted parameter value. If you don't use the <code>decrypt</code> argument, you will get an encrypted value. Read here about best practices using KMS to secure your parameters.</p> Tip <p>If you want to always decrypt parameters, you can set the <code>POWERTOOLS_PARAMETERS_SSM_DECRYPT=true</code> environment variable. This will override the default value of <code>false</code> but you can still set the <code>decrypt</code> option for individual parameters.</p> builtin_provider_ssm_with_decrypt.pybuiltin_provider_ssm_with_no_recursive.py <pre><code>from typing import Any\nfrom uuid import uuid4\n\nimport boto3\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nec2 = boto3.resource(\"ec2\")\nssm_provider = parameters.SSMProvider()\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve the key pair from secure string parameter\nec2_pem: Any = ssm_provider.get(\"/lambda-powertools/ec2_pem\", decrypt=True)\nname_key_pair = f\"kp_{uuid4()}\"\n\n        ec2.import_key_pair(KeyName=name_key_pair, PublicKeyMaterial=ec2_pem)\n\n        ec2.create_instances(\n            ImageId=\"ami-026b57f3c383c2eec\",\n            InstanceType=\"t2.micro\",\n            MinCount=1,\n            MaxCount=1,\n            KeyName=name_key_pair,\n        )\n\n        return {\"message\": \"EC2 created\", \"success\": True}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"message\": f\"Error creating EC2 =&gt; {str(error)}\", \"success\": False}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nssm_provider = parameters.SSMProvider()\nclass ConfigNotFound(Exception):\n    ...\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\n        # /config = root\n        # /config/endpoint = url\n        # /config/endpoint/query = querystring\nall_parameters: Any = ssm_provider.get_multiple(\"/config\", recursive=False)\nendpoint_comments = \"https://jsonplaceholder.typicode.com/comments/\"\n\n        for parameter, value in all_parameters.items():\n\n            # query parameter is used to query endpoint\n            if \"query\" in parameter:\n                endpoint_comments = f\"{endpoint_comments}{value}\"\n                break\n        else:\n            # scheme config was not found because get_multiple is not recursive\n            raise ConfigNotFound(\"URL query parameter was not found\")\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#secretsprovider","title":"SecretsProvider","text":"builtin_provider_secret.py <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nconfig = Config(region_name=\"sa-east-1\", connect_timeout=1, retries={\"total_max_attempts\": 2, \"max_attempts\": 5})\nssm_provider = parameters.SecretsProvider(config=config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\n        api_key: Any = ssm_provider.get(\"/lambda-powertools/api-key\")\n\n        headers: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#dynamodbprovider","title":"DynamoDBProvider","text":"<p>The DynamoDB Provider does not have any high-level functions, as it needs to know the name of the DynamoDB table containing the parameters.</p> <p>DynamoDB table structure for single parameters</p> <p>For single parameters, you must use <code>id</code> as the partition key for that table.</p> Example <p>DynamoDB table with <code>id</code> partition key and <code>value</code> as attribute</p> id value my-parameter my-value <p>With this table, <code>dynamodb_provider.get(\"my-parameter\")</code> will return <code>my-value</code>.</p> builtin_provider_dynamodb_single_parameter.pysam_dynamodb_table_single.yaml <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(table_name=\"ParameterTable\")\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in DynamoDB Table\nendpoint_comments: Any = dynamodb_provider.get(\"comments_endpoint\")\ncomments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: 'DynamoDB Table example'\nResources:\nParameterTable:\nType: AWS::DynamoDB::Table\nProperties:\nTableName: ParameterTable\nAttributeDefinitions:\n-   AttributeName: id\nAttributeType: S\nKeySchema:\n-   AttributeName: id\nKeyType: HASH\nTimeToLiveSpecification:\nAttributeName: expiration\nEnabled: true\nBillingMode: PAY_PER_REQUEST\n</code></pre> <p>You can initialize the DynamoDB provider pointing to DynamoDB Local using <code>endpoint_url</code> parameter:</p> builtin_provider_dynamodb_custom_endpoint.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(table_name=\"ParameterTable\", endpoint_url=\"http://localhost:8000\")\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in DynamoDB Table\nendpoint_comments: Any = dynamodb_provider.get(\"comments_endpoint\")\ncomments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <p>DynamoDB table structure for multiple values parameters</p> <p>You can retrieve multiple parameters sharing the same <code>id</code> by having a sort key named <code>sk</code>.</p> Example <p>DynamoDB table with <code>id</code> primary key, <code>sk</code> as sort key and <code>value</code> as attribute</p> id sk value config endpoint_comments https://jsonplaceholder.typicode.com/comments/ config limit 10 <p>With this table, <code>dynamodb_provider.get_multiple(\"config\")</code> will return a dictionary response in the shape of <code>sk:value</code>.</p> builtin_provider_dynamodb_recursive_parameter.pysam_dynamodb_table_recursive.yaml <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(table_name=\"ParameterTable\")\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Retrieve multiple parameters using HASH KEY\nall_parameters: Any = dynamodb_provider.get_multiple(\"config\")\nendpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n        limit = 2\n\n        for parameter, value in all_parameters.items():\n\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n            if parameter == \"limit\":\n                limit = int(value)\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[limit]}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: 'DynamoDB Table example'\nResources:\nParameterTable:\nType: AWS::DynamoDB::Table\nProperties:\nTableName: ParameterTable\nAttributeDefinitions:\n-   AttributeName: id\nAttributeType: S\n-   AttributeName: sk\nAttributeType: S\nKeySchema:\n-   AttributeName: id\nKeyType: HASH\n-   AttributeName: sk\nKeyType: RANGE\nTimeToLiveSpecification:\nAttributeName: expiration\nEnabled: true\nBillingMode: PAY_PER_REQUEST\n</code></pre> <p>Customizing DynamoDBProvider</p> <p>DynamoDB provider can be customized at initialization to match your table structure:</p> Parameter Mandatory Default Description table_name Yes (N/A) Name of the DynamoDB table containing the parameter values. key_attr No <code>id</code> Hash key for the DynamoDB table. sort_attr No <code>sk</code> Range key for the DynamoDB table. You don't need to set this if you don't use the <code>get_multiple()</code> method. value_attr No <code>value</code> Name of the attribute containing the parameter value. builtin_provider_dynamodb_custom_fields.pysam_dynamodb_custom_fields.yaml <pre><code>from typing import Any\n\nimport requests\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(\ntable_name=\"ParameterTable\",\nkey_attr=\"IdKeyAttr\",\nsort_attr=\"SkKeyAttr\",\n    value_attr=\"ValueAttr\",\n)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\ntry:\n# Usually an endpoint is not sensitive data, so we store it in DynamoDB Table\n        endpoint_comments: Any = dynamodb_provider.get(\"comments_endpoint\")\n\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: 'DynamoDB Table example'\nResources:\nParameterTable:\nType: AWS::DynamoDB::Table\nProperties:\nTableName: ParameterTable\nAttributeDefinitions:\n-   AttributeName: IdKeyAttr\nAttributeType: S\n-   AttributeName: SkKeyAttr\nAttributeType: S\nKeySchema:\n-   AttributeName: IdKeyAttr\nKeyType: HASH\n-   AttributeName: SkKeyAttr\nKeyType: RANGE\nTimeToLiveSpecification:\nAttributeName: expiration\nEnabled: true\nBillingMode: PAY_PER_REQUEST\n</code></pre>"},{"location":"utilities/parameters/#appconfigprovider","title":"AppConfigProvider","text":"builtin_provider_appconfig.py <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nconfig = Config(region_name=\"sa-east-1\")\nappconf_provider = parameters.AppConfigProvider(environment=\"dev\", application=\"comments\", config=config)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\nendpoint_comments: Any = appconf_provider.get(\"config\")\n# the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#create-your-own-provider","title":"Create your own provider","text":"<p>You can create your own custom parameter store provider by inheriting the <code>BaseProvider</code> class, and implementing both <code>_get()</code> and <code>_get_multiple()</code> methods to retrieve a single, or multiple parameters from your custom store.</p> <p>All transformation and caching logic is handled by the <code>get()</code> and <code>get_multiple()</code> methods from the base provider class.</p> <p>Here are two examples of implementing a custom parameter store. One using an external service like Hashicorp Vault, a widely popular key-value and secret storage and the other one using Amazon S3, a popular object storage.</p> working_with_own_provider_vault.pycustom_provider_vault.pyworking_with_own_provider_s3.pycustom_provider_s3.py <pre><code>from typing import Any\n\nimport hvac\nimport requests\nfrom custom_provider_vault import VaultProvider\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n# In production you must use Vault over HTTPS and certificates.\nvault_provider = VaultProvider(vault_url=\"http://192.168.68.105:8200/\", vault_token=\"YOUR_TOKEN\")\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Retrieve a single parameter\nendpoint_comments: Any = vault_provider.get(\"comments_endpoint\", transform=\"json\")\n# you can get all parameters using get_multiple and specifying vault mount point\n        # # for testing purposes we will not use it\nall_parameters: Any = vault_provider.get_multiple(\"/\")\nlogger.info(all_parameters)\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments[\"url\"])\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except hvac.exceptions.InvalidPath as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>import json\nfrom typing import Dict\n\nfrom hvac import Client\n\nfrom aws_lambda_powertools.utilities.parameters import BaseProvider\nclass VaultProvider(BaseProvider):\ndef __init__(self, vault_url: str, vault_token: str) -&gt; None:\n\n        super().__init__()\n\n        self.vault_client = Client(url=vault_url, verify=False, timeout=10)\n        self.vault_client.token = vault_token\n\ndef _get(self, name: str, **sdk_options) -&gt; str:\n# for example proposal, the mountpoint is always /secret\n        kv_configuration = self.vault_client.secrets.kv.v2.read_secret(path=name)\n\n        return json.dumps(kv_configuration[\"data\"][\"data\"])\n\ndef _get_multiple(self, path: str, **sdk_options) -&gt; Dict[str, str]:\nlist_secrets = {}\n        all_secrets = self.vault_client.secrets.kv.v2.list_secrets(path=path)\n\n        # for example proposal, the mountpoint is always /secret\n        for secret in all_secrets[\"data\"][\"keys\"]:\n            kv_configuration = self.vault_client.secrets.kv.v2.read_secret(path=secret)\n\n            for key, value in kv_configuration[\"data\"][\"data\"].items():\n                list_secrets[key] = value\n\n        return list_secrets\n</code></pre> <pre><code>from typing import Any\n\nimport requests\nfrom custom_provider_s3 import S3Provider\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\ns3_provider = S3Provider(bucket_name=\"bucket_name\")\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Retrieve a single parameter using key\nendpoint_comments: Any = s3_provider.get(\"comments_endpoint\")\n# you can get all parameters using get_multiple and specifying a bucket prefix\n        # # for testing purposes we will not use it\nall_parameters: Any = s3_provider.get_multiple(\"/\")\nlogger.info(all_parameters)\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>import copy\nfrom typing import Dict\n\nimport boto3\n\nfrom aws_lambda_powertools.utilities.parameters import BaseProvider\nclass S3Provider(BaseProvider):\ndef __init__(self, bucket_name: str):\n        # Initialize the client to your custom parameter store\n        # E.g.:\n\n        super().__init__()\n\n        self.bucket_name = bucket_name\n        self.client = boto3.client(\"s3\")\n\ndef _get(self, name: str, **sdk_options) -&gt; str:\n# Retrieve a single value\n        # E.g.:\n\n        sdk_options[\"Bucket\"] = self.bucket_name\n        sdk_options[\"Key\"] = name\n\n        response = self.client.get_object(**sdk_options)\n        return response[\"Body\"].read().decode()\n\ndef _get_multiple(self, path: str, **sdk_options) -&gt; Dict[str, str]:\n# Retrieve multiple values\n        # E.g.:\n\n        list_sdk_options = copy.deepcopy(sdk_options)\n\n        list_sdk_options[\"Bucket\"] = self.bucket_name\n        list_sdk_options[\"Prefix\"] = path\n\n        list_response = self.client.list_objects_v2(**list_sdk_options)\n\n        parameters = {}\n\n        for obj in list_response.get(\"Contents\", []):\n            get_sdk_options = copy.deepcopy(sdk_options)\n\n            get_sdk_options[\"Bucket\"] = self.bucket_name\n            get_sdk_options[\"Key\"] = obj[\"Key\"]\n\n            get_response = self.client.get_object(**get_sdk_options)\n\n            parameters[obj[\"Key\"]] = get_response[\"Body\"].read().decode()\n\n        return parameters\n</code></pre>"},{"location":"utilities/parameters/#deserializing-values-with-transform-parameter","title":"Deserializing values with transform parameter","text":"<p>For parameters stored in JSON or Base64 format, you can use the <code>transform</code> argument for deserialization.</p> Info <p>The <code>transform</code> argument is available across all providers, including the high level functions.</p> working_with_transform_high_level.pyworking_with_transform_provider.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        # Retrieve a single parameter\nendpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\", transform=\"json\")\n# the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nconfig = Config(region_name=\"sa-east-1\")\nappconf_provider = parameters.AppConfigProvider(environment=\"dev\", application=\"comments\", config=config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\nendpoint_comments: Any = appconf_provider.get(\"config\", transform=\"json\")\n# the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"},{"location":"utilities/parameters/#partial-transform-failures-with-get_multiple","title":"Partial transform failures with <code>get_multiple()</code>","text":"<p>If you use <code>transform</code> with <code>get_multiple()</code>, you can have a single malformed parameter value. To prevent failing the entire request, the method will return a <code>None</code> value for the parameters that failed to transform.</p> <p>You can override this by setting the <code>raise_on_transform_error</code> argument to <code>True</code>. If you do so, a single transform error will raise a <code>TransformParameterError</code> exception.</p> <p>For example, if you have three parameters, /param/a, /param/b and /param/c, but /param/c is malformed:</p> handling_error_transform.py <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nssm_provider = parameters.SSMProvider()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # This will display:\n    # /param/a: [some value]\n    # /param/b: [some value]\n    # /param/c: None\nvalues: Any = ssm_provider.get_multiple(\"/param\", transform=\"json\")\nfor key, value in values.items():\n        print(f\"{key}: {value}\")\n\n    try:\n        # This will raise a TransformParameterError exception\nvalues = ssm_provider.get_multiple(\"/param\", transform=\"json\", raise_on_transform_error=True)\nexcept parameters.exceptions.TransformParameterError:\n        ...\n</code></pre>"},{"location":"utilities/parameters/#auto-transform-values-on-suffix","title":"Auto-transform values on suffix","text":"<p>If you use <code>transform</code> with <code>get_multiple()</code>, you might want to retrieve and transform parameters encoded in different formats.</p> <p>You can do this with a single request by using <code>transform=\"auto\"</code>. This will instruct any Parameter to to infer its type based on the suffix and transform it accordingly.</p> Info <p><code>transform=\"auto\"</code> feature is available across all providers, including the high level functions.</p> working_with_auto_transform.py <pre><code>from aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nssm_provider = parameters.SSMProvider()\ndef lambda_handler(event: dict, context: LambdaContext):\nvalues = ssm_provider.get_multiple(\"/param\", transform=\"auto\")\nreturn values\n</code></pre> <p>For example, if you have two parameters with the following suffixes <code>.json</code> and <code>.binary</code>:</p> Parameter name Parameter value /param/a.json [some encoded value] /param/a.binary [some encoded value] <p>The return of <code>ssm_provider.get_multiple(\"/param\", transform=\"auto\")</code> call will be a dictionary like:</p> <pre><code>{\n\"a.json\": [some value],\n\"b.binary\": [some value]\n}\n</code></pre>"},{"location":"utilities/parameters/#passing-additional-sdk-arguments","title":"Passing additional SDK arguments","text":"<p>You can use arbitrary keyword arguments to pass it directly to the underlying SDK method.</p> working_with_sdk_additional_arguments.py <pre><code>from aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nsecrets_provider = parameters.SecretsProvider()\ndef lambda_handler(event: dict, context: LambdaContext):\n    # The 'VersionId' argument will be passed to the underlying get_secret_value() call.\nvalue = secrets_provider.get(\"my-secret\", VersionId=\"e62ec170-6b01-48c7-94f3-d7497851a8d2\")\nreturn value\n</code></pre> <p>Here is the mapping between this utility's functions and methods and the underlying SDK:</p> Provider Function/Method Client name Function name SSM Parameter Store <code>get_parameter</code> <code>ssm</code> get_parameter SSM Parameter Store <code>get_parameters</code> <code>ssm</code> get_parameters_by_path SSM Parameter Store <code>SSMProvider.get</code> <code>ssm</code> get_parameter SSM Parameter Store <code>SSMProvider.get_multiple</code> <code>ssm</code> get_parameters_by_path Secrets Manager <code>get_secret</code> <code>secretsmanager</code> get_secret_value Secrets Manager <code>SecretsProvider.get</code> <code>secretsmanager</code> get_secret_value DynamoDB <code>DynamoDBProvider.get</code> <code>dynamodb</code> (Table resource) DynamoDB <code>DynamoDBProvider.get_multiple</code> <code>dynamodb</code> (Table resource) App Config <code>get_app_config</code> <code>appconfigdata</code> start_configuration_session and get_latest_configuration"},{"location":"utilities/parameters/#bring-your-own-boto-client","title":"Bring your own boto client","text":"<p>You can use <code>boto3_client</code> parameter via any of the available Provider Classes. Some providers expect a low level boto3 client while others expect a high level boto3 client, here is the mapping for each of them:</p> Provider Type Boto client construction SSMProvider low level <code>boto3.client(\"ssm\")</code> SecretsProvider low level <code>boto3.client(\"secrets\")</code> AppConfigProvider low level <code>boto3.client(\"appconfigdata\")</code> DynamoDBProvider high level <code>boto3.resource(\"dynamodb\")</code> <p>Bringing them together in a single code snippet would look like this:</p> custom_boto3_all_providers.py <pre><code>import boto3\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nconfig = Config(region_name=\"us-west-1\")\n# construct boto clients with any custom configuration\nssm = boto3.client(\"ssm\", config=config)\nsecrets = boto3.client(\"secrets\", config=config)\nappconfig = boto3.client(\"appconfigdata\", config=config)\ndynamodb = boto3.resource(\"dynamodb\", config=config)\n\nssm_provider = parameters.SSMProvider(boto3_client=ssm)\nsecrets_provider = parameters.SecretsProvider(boto3_client=secrets)\nappconf_provider = parameters.AppConfigProvider(boto3_client=appconfig, environment=\"my_env\", application=\"my_app\")\ndynamodb_provider = parameters.DynamoDBProvider(boto3_client=dynamodb, table_name=\"my-table\")\n</code></pre> When is this useful? <p>Injecting a custom boto3 client can make unit/snapshot testing easier, including SDK customizations.</p>"},{"location":"utilities/parameters/#customizing-boto-configuration","title":"Customizing boto configuration","text":"<p>The <code>config</code> , <code>boto3_session</code>, and <code>boto3_client</code>  parameters enable you to pass in a custom botocore config object, boto3 session, or  a boto3 client when constructing any of the built-in provider classes.</p> Tip <p>You can use a custom session for retrieving parameters cross-account/region and for snapshot testing.</p> <p>When using VPC private endpoints, you can pass a custom client altogether. It's also useful for testing when injecting fake instances.</p> custom_boto_session.pycustom_boto_config.pycustom_boto_client.py <pre><code>import boto3\n\nfrom aws_lambda_powertools.utilities import parameters\n\nboto3_session = boto3.session.Session()\nssm_provider = parameters.SSMProvider(boto3_session=boto3_session)\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = ssm_provider.get(\"/my/parameter\")\n\n    return value\n</code></pre> <pre><code>from botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\n\nboto_config = Config()\nssm_provider = parameters.SSMProvider(config=boto_config)\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = ssm_provider.get(\"/my/parameter\")\n\n    return value\n</code></pre> <pre><code>import boto3\n\nfrom aws_lambda_powertools.utilities import parameters\n\nboto3_client = boto3.client(\"ssm\")\nssm_provider = parameters.SSMProvider(boto3_client=boto3_client)\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = ssm_provider.get(\"/my/parameter\")\n\n    return value\n</code></pre>"},{"location":"utilities/parameters/#testing-your-code","title":"Testing your code","text":""},{"location":"utilities/parameters/#mocking-parameter-values","title":"Mocking parameter values","text":"<p>For unit testing your applications, you can mock the calls to the parameters utility to avoid calling AWS APIs. This can be achieved in a number of ways - in this example, we use the pytest monkeypatch fixture to patch the <code>parameters.get_parameter</code> method:</p> test_single_mock.pysingle_mock.py <pre><code>from src import single_mock\n\n\ndef test_handler(monkeypatch):\ndef mockreturn(name):\n        return \"mock_value\"\n\nmonkeypatch.setattr(single_mock.parameters, \"get_parameter\", mockreturn)\nreturn_val = single_mock.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <pre><code>from aws_lambda_powertools.utilities import parameters\n\n\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = parameters.get_parameter(\"my-parameter-name\")\n    return {\"message\": value}\n</code></pre> <p>If we need to use this pattern across multiple tests, we can avoid repetition by refactoring to use our own pytest fixture:</p> test_with_fixture.py <pre><code>import pytest\nfrom src import single_mock\n\n\n@pytest.fixture\ndef mock_parameter_response(monkeypatch):\n    def mockreturn(name):\n        return \"mock_value\"\n\nmonkeypatch.setattr(single_mock.parameters, \"get_parameter\", mockreturn)\n# Pass our fixture as an argument to all tests where we want to mock the get_parameter response\ndef test_handler(mock_parameter_response):\n    return_val = single_mock.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <p>Alternatively, if we need more fully featured mocking (for example checking the arguments passed to <code>get_parameter</code>), we can use unittest.mock from the python stdlib instead of pytest's <code>monkeypatch</code> fixture. In this example, we use the patch decorator to replace the <code>aws_lambda_powertools.utilities.parameters.get_parameter</code> function with a MagicMock object named <code>get_parameter_mock</code>.</p> test_with_monkeypatch.py <pre><code>from unittest.mock import patch\n\nfrom src import single_mock\n\n\n# Replaces \"aws_lambda_powertools.utilities.parameters.get_parameter\" with a Mock object\n@patch(\"aws_lambda_powertools.utilities.parameters.get_parameter\")\ndef test_handler(get_parameter_mock):\n    get_parameter_mock.return_value = \"mock_value\"\n\n    return_val = single_mock.handler({}, {})\nget_parameter_mock.assert_called_with(\"my-parameter-name\")\nassert return_val.get(\"message\") == \"mock_value\"\n</code></pre>"},{"location":"utilities/parameters/#clearing-cache","title":"Clearing cache","text":"<p>Parameters utility caches all parameter values for performance and cost reasons. However, this can have unintended interference in tests using the same parameter name.</p> <p>Within your tests, you can use <code>clear_cache</code> method available in every provider. When using multiple providers or higher level functions like <code>get_parameter</code>, use <code>clear_caches</code> standalone function to clear cache globally.</p> test_clear_cache_method.pytest_clear_cache_global.pyapp.py <pre><code>import pytest\nfrom src import app\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef clear_parameters_cache():\n    yield\napp.ssm_provider.clear_cache()  # This will clear SSMProvider cache\n@pytest.fixture\ndef mock_parameter_response(monkeypatch):\n    def mockreturn(name):\n        return \"mock_value\"\n\n    monkeypatch.setattr(app.ssm_provider, \"get\", mockreturn)\n\n\n# Pass our fixture as an argument to all tests where we want to mock the get_parameter response\ndef test_handler(mock_parameter_response):\n    return_val = app.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <pre><code>import pytest\nfrom src import app\n\nfrom aws_lambda_powertools.utilities import parameters\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef clear_parameters_cache():\n    yield\nparameters.clear_caches()  # This will clear all providers cache\n@pytest.fixture\ndef mock_parameter_response(monkeypatch):\n    def mockreturn(name):\n        return \"mock_value\"\n\n    monkeypatch.setattr(app.ssm_provider, \"get\", mockreturn)\n\n\n# Pass our fixture as an argument to all tests where we want to mock the get_parameter response\ndef test_handler(mock_parameter_response):\n    return_val = app.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <pre><code>from botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\n\nssm_provider = parameters.SSMProvider(config=Config(region_name=\"us-west-1\"))\n\n\ndef handler(event, context):\n    value = ssm_provider.get(\"/my/parameter\")\n    return {\"message\": value}\n</code></pre>"},{"location":"utilities/parser/","title":"Parser (Pydantic)","text":"<p>This utility provides data parsing and deep validation using Pydantic.</p>"},{"location":"utilities/parser/#key-features","title":"Key features","text":"<ul> <li>Defines data in pure Python classes, then parse, validate and extract only what you want</li> <li>Built-in envelopes to unwrap, extend, and validate popular event sources payloads</li> <li>Enforces type hints at runtime with user-friendly errors</li> </ul>"},{"location":"utilities/parser/#getting-started","title":"Getting started","text":""},{"location":"utilities/parser/#install","title":"Install","text":"<p>This is not necessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR</p> <p>Add <code>aws-lambda-powertools[parser]</code> as a dependency in your preferred tool: e.g., requirements.txt, pyproject.toml. This will ensure you have the required dependencies before using Parser.</p> Warning <p>This will increase the compressed package size by &gt;10MB due to the Pydantic dependency.</p> <p>To reduce the impact on the package size at the expense of 30%-50% of its performance Pydantic can also be installed without binary files:</p> <p>Pip example: <code>SKIP_CYTHON=1 pip install --no-binary pydantic aws-lambda-powertools[parser]</code></p>"},{"location":"utilities/parser/#defining-models","title":"Defining models","text":"<p>You can define models to parse incoming events by inheriting from <code>BaseModel</code>.</p> Defining an Order data model<pre><code>from aws_lambda_powertools.utilities.parser import BaseModel\nfrom typing import List, Optional\n\nclass OrderItem(BaseModel):\n    id: int\n    quantity: int\n    description: str\n\nclass Order(BaseModel):\n    id: int\n    description: str\n    items: List[OrderItem] # nesting models are supported\n    optional_field: Optional[str] # this field may or may not be available when parsing\n</code></pre> <p>These are simply Python classes that inherit from BaseModel. Parser enforces type hints declared in your model at runtime.</p>"},{"location":"utilities/parser/#parsing-events","title":"Parsing events","text":"<p>You can parse inbound events using event_parser decorator, or the standalone <code>parse</code> function. Both are also able to parse either dictionary or JSON string as an input.</p>"},{"location":"utilities/parser/#event_parser-decorator","title":"event_parser decorator","text":"<p>Use the decorator for fail fast scenarios where you want your Lambda function to raise an exception in the event of a malformed payload.</p> <p><code>event_parser</code> decorator will throw a <code>ValidationError</code> if your event cannot be parsed according to the model.</p> Note <p>This decorator will replace the <code>event</code> object with the parsed model if successful. This means you might be careful when nesting other decorators that expect <code>event</code> to be a <code>dict</code>.</p> Parsing and validating upon invocation with event_parser decorator<pre><code>from aws_lambda_powertools.utilities.parser import event_parser, BaseModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom typing import List, Optional\n\nimport json\n\nclass OrderItem(BaseModel):\n    id: int\n    quantity: int\n    description: str\n\nclass Order(BaseModel):\n    id: int\n    description: str\n    items: List[OrderItem] # nesting models are supported\n    optional_field: Optional[str] # this field may or may not be available when parsing\n\n\n@event_parser(model=Order)\ndef handler(event: Order, context: LambdaContext):\n    print(event.id)\n    print(event.description)\n    print(event.items)\n\n    order_items = [item for item in event.items]\n    ...\n\npayload = {\n    \"id\": 10876546789,\n    \"description\": \"My order\",\n    \"items\": [\n        {\n            \"id\": 1015938732,\n            \"quantity\": 1,\n            \"description\": \"item xpto\"\n        }\n    ]\n}\n\nhandler(event=payload, context=LambdaContext())\nhandler(event=json.dumps(payload), context=LambdaContext()) # also works if event is a JSON string\n</code></pre>"},{"location":"utilities/parser/#parse-function","title":"parse function","text":"<p>Use this standalone function when you want more control over the data validation process, for example returning a 400 error for malformed payloads.</p> Using standalone parse function for more flexibility<pre><code>from aws_lambda_powertools.utilities.parser import parse, BaseModel, ValidationError\nfrom typing import List, Optional\n\nclass OrderItem(BaseModel):\n    id: int\n    quantity: int\n    description: str\n\nclass Order(BaseModel):\n    id: int\n    description: str\n    items: List[OrderItem] # nesting models are supported\n    optional_field: Optional[str] # this field may or may not be available when parsing\n\n\npayload = {\n    \"id\": 10876546789,\n    \"description\": \"My order\",\n    \"items\": [\n        {\n# this will cause a validation error\n\"id\": [1015938732],\n            \"quantity\": 1,\n            \"description\": \"item xpto\"\n        }\n    ]\n}\n\ndef my_function():\n    try:\nparsed_payload: Order = parse(event=payload, model=Order)\n# payload dict is now parsed into our model\n        return parsed_payload.items\n    except ValidationError:\n        return {\n            \"status_code\": 400,\n            \"message\": \"Invalid order\"\n        }\n</code></pre>"},{"location":"utilities/parser/#built-in-models","title":"Built-in models","text":"<p>Parser comes with the following built-in models:</p> Model name Description AlbModel Lambda Event Source payload for Amazon Application Load Balancer APIGatewayProxyEventModel Lambda Event Source payload for Amazon API Gateway APIGatewayProxyEventV2Model Lambda Event Source payload for Amazon API Gateway v2 payload CloudFormationCustomResourceCreateModel Lambda Event Source payload for AWS CloudFormation <code>CREATE</code> operation CloudFormationCustomResourceUpdateModel Lambda Event Source payload for AWS CloudFormation <code>UPDATE</code> operation CloudFormationCustomResourceDeleteModel Lambda Event Source payload for AWS CloudFormation <code>DELETE</code> operation CloudwatchLogsModel Lambda Event Source payload for Amazon CloudWatch Logs DynamoDBStreamModel Lambda Event Source payload for Amazon DynamoDB Streams EventBridgeModel Lambda Event Source payload for Amazon EventBridge KafkaMskEventModel Lambda Event Source payload for AWS MSK payload KafkaSelfManagedEventModel Lambda Event Source payload for self managed Kafka payload KinesisDataStreamModel Lambda Event Source payload for Amazon Kinesis Data Streams KinesisFirehoseModel Lambda Event Source payload for Amazon Kinesis Firehose KinesisFirehoseSqsModel Lambda Event Source payload for SQS messages wrapped in Kinesis Firehose records LambdaFunctionUrlModel Lambda Event Source payload for Lambda Function URL payload S3EventNotificationEventBridgeModel Lambda Event Source payload for Amazon S3 Event Notification to EventBridge. S3Model Lambda Event Source payload for Amazon S3 S3ObjectLambdaEvent Lambda Event Source payload for Amazon S3 Object Lambda S3SqsEventNotificationModel Lambda Event Source payload for S3 event notifications wrapped in SQS event (S3-&gt;SQS) SesModel Lambda Event Source payload for Amazon Simple Email Service SnsModel Lambda Event Source payload for Amazon Simple Notification Service SqsModel Lambda Event Source payload for Amazon SQS VpcLatticeModel Lambda Event Source payload for Amazon VPC Lattice"},{"location":"utilities/parser/#extending-built-in-models","title":"Extending built-in models","text":"<p>You can extend them to include your own models, and yet have all other known fields parsed along the way.</p> Tip <p>For Mypy users, we only allow type override for fields where payload is injected e.g. <code>detail</code>, <code>body</code>, etc.</p> Extending EventBridge model as an example<pre><code>from aws_lambda_powertools.utilities.parser import parse, BaseModel\nfrom aws_lambda_powertools.utilities.parser.models import EventBridgeModel\n\nfrom typing import List, Optional\n\nclass OrderItem(BaseModel):\n    id: int\n    quantity: int\n    description: str\n\nclass Order(BaseModel):\n    id: int\n    description: str\n    items: List[OrderItem]\n\nclass OrderEventModel(EventBridgeModel):\ndetail: Order\npayload = {\n    \"version\": \"0\",\n    \"id\": \"6a7e8feb-b491-4cf7-a9f1-bf3703467718\",\n    \"detail-type\": \"OrderPurchased\",\n    \"source\": \"OrderService\",\n    \"account\": \"111122223333\",\n    \"time\": \"2020-10-22T18:43:48Z\",\n    \"region\": \"us-west-1\",\n    \"resources\": [\"some_additional\"],\n\"detail\": {\n\"id\": 10876546789,\n        \"description\": \"My order\",\n        \"items\": [\n            {\n                \"id\": 1015938732,\n                \"quantity\": 1,\n                \"description\": \"item xpto\"\n            }\n        ]\n    }\n}\n\nret = parse(model=OrderEventModel, event=payload)\nassert ret.source == \"OrderService\"\nassert ret.detail.description == \"My order\"\nassert ret.detail_type == \"OrderPurchased\" # we rename it to snake_case since detail-type is an invalid name\n\nfor order_item in ret.detail.items:\n    ...\n</code></pre> <p>What's going on here, you might ask:</p> <ol> <li>We imported our built-in model <code>EventBridgeModel</code> from the parser utility</li> <li>Defined how our <code>Order</code> should look like</li> <li>Defined how part of our EventBridge event should look like by overriding <code>detail</code> key within our <code>OrderEventModel</code></li> <li>Parser parsed the original event against <code>OrderEventModel</code></li> </ol> Tip <p>When extending a <code>string</code> field containing JSON, you need to wrap the field with Pydantic's Json Type:</p> <pre><code>from pydantic import BaseModel, Json\n\nfrom aws_lambda_powertools.utilities.parser import event_parser\nfrom aws_lambda_powertools.utilities.parser.models import APIGatewayProxyEventV2Model\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass CancelOrder(BaseModel):\n    order_id: int\n    reason: str\n\n\nclass CancelOrderModel(APIGatewayProxyEventV2Model):\nbody: Json[CancelOrder]  # type: ignore[assignment]\n@event_parser(model=CancelOrderModel)\ndef handler(event: CancelOrderModel, context: LambdaContext):\ncancel_order: CancelOrder = event.body\nassert cancel_order.order_id is not None\n</code></pre> <p>Alternatively, you could use a Pydantic validator to transform the JSON string into a dict before the mapping:</p> <pre><code>import json\n\nfrom pydantic import BaseModel, validator\n\nfrom aws_lambda_powertools.utilities.parser import event_parser\nfrom aws_lambda_powertools.utilities.parser.models import APIGatewayProxyEventV2Model\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass CancelOrder(BaseModel):\n    order_id: int\n    reason: str\n\n\nclass CancelOrderModel(APIGatewayProxyEventV2Model):\n    body: CancelOrder  # type: ignore[assignment]\n\n@validator(\"body\", pre=True)\ndef transform_body_to_dict(cls, value: str):\nreturn json.loads(value)\n@event_parser(model=CancelOrderModel)\ndef handler(event: CancelOrderModel, context: LambdaContext):\ncancel_order: CancelOrder = event.body\nassert cancel_order.order_id is not None\n</code></pre>"},{"location":"utilities/parser/#envelopes","title":"Envelopes","text":"<p>When trying to parse your payloads wrapped in a known structure, you might encounter the following situations:</p> <ul> <li>Your actual payload is wrapped around a known structure, for example Lambda Event Sources like EventBridge</li> <li>You're only interested in a portion of the payload, for example parsing the <code>detail</code> of custom events in EventBridge, or <code>body</code> of SQS records</li> </ul> <p>You can either solve these situations by creating a model of these known structures, parsing them, then extracting and parsing a key where your payload is.</p> <p>This can become difficult quite quickly. Parser makes this problem easier through a feature named <code>Envelope</code>.</p> <p>Envelopes can be used via <code>envelope</code> parameter available in both <code>parse</code> function and <code>event_parser</code> decorator.</p> <p>Here's an example of parsing a model found in an event coming from EventBridge, where all you want is what's inside the <code>detail</code> key.</p> Parsing payload in a given key only using envelope feature<pre><code>from aws_lambda_powertools.utilities.parser import event_parser, parse, BaseModel, envelopes\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nclass UserModel(BaseModel):\n    username: str\n    password1: str\n    password2: str\n\npayload = {\n    \"version\": \"0\",\n    \"id\": \"6a7e8feb-b491-4cf7-a9f1-bf3703467718\",\n    \"detail-type\": \"CustomerSignedUp\",\n    \"source\": \"CustomerService\",\n    \"account\": \"111122223333\",\n    \"time\": \"2020-10-22T18:43:48Z\",\n    \"region\": \"us-west-1\",\n    \"resources\": [\"some_additional_\"],\n\"detail\": {\n\"username\": \"universe\",\n\"password1\": \"myp@ssword\",\n\"password2\": \"repeat password\"\n}\n}\n\nret = parse(model=UserModel, envelope=envelopes.EventBridgeEnvelope, event=payload)\n# Parsed model only contains our actual model, not the entire EventBridge + Payload parsed\nassert ret.password1 == ret.password2\n\n# Same behaviour but using our decorator\n@event_parser(model=UserModel, envelope=envelopes.EventBridgeEnvelope)\ndef handler(event: UserModel, context: LambdaContext):\n    assert event.password1 == event.password2\n</code></pre> <p>What's going on here, you might ask:</p> <ol> <li>We imported built-in <code>envelopes</code> from the parser utility</li> <li>Used <code>envelopes.EventBridgeEnvelope</code> as the envelope for our <code>UserModel</code> model</li> <li>Parser parsed the original event against the EventBridge model</li> <li>Parser then parsed the <code>detail</code> key using <code>UserModel</code></li> </ol>"},{"location":"utilities/parser/#built-in-envelopes","title":"Built-in envelopes","text":"<p>Parser comes with the following built-in envelopes, where <code>Model</code> in the return section is your given model.</p> Envelope name Behaviour Return DynamoDBStreamEnvelope 1. Parses data using <code>DynamoDBStreamModel</code>.  2. Parses records in <code>NewImage</code> and <code>OldImage</code> keys using your model.  3. Returns a list with a dictionary containing <code>NewImage</code> and <code>OldImage</code> keys <code>List[Dict[str, Optional[Model]]]</code> EventBridgeEnvelope 1. Parses data using <code>EventBridgeModel</code>.  2. Parses <code>detail</code> key using your model and returns it. <code>Model</code> SqsEnvelope 1. Parses data using <code>SqsModel</code>.  2. Parses records in <code>body</code> key using your model and return them in a list. <code>List[Model]</code> CloudWatchLogsEnvelope 1. Parses data using <code>CloudwatchLogsModel</code> which will base64 decode and decompress it.  2. Parses records in <code>message</code> key using your model and return them in a list. <code>List[Model]</code> KinesisDataStreamEnvelope 1. Parses data using <code>KinesisDataStreamModel</code> which will base64 decode it.  2. Parses records in in <code>Records</code> key using your model and returns them in a list. <code>List[Model]</code> KinesisFirehoseEnvelope 1. Parses data using <code>KinesisFirehoseModel</code> which will base64 decode it.  2. Parses records in in <code>Records</code> key using your model and returns them in a list. <code>List[Model]</code> SnsEnvelope 1. Parses data using <code>SnsModel</code>.  2. Parses records in <code>body</code> key using your model and return them in a list. <code>List[Model]</code> SnsSqsEnvelope 1. Parses data using <code>SqsModel</code>.  2. Parses SNS records in <code>body</code> key using <code>SnsNotificationModel</code>.  3. Parses data in <code>Message</code> key using your model and return them in a list. <code>List[Model]</code> ApiGatewayEnvelope 1. Parses data using <code>APIGatewayProxyEventModel</code>.  2. Parses <code>body</code> key using your model and returns it. <code>Model</code> ApiGatewayV2Envelope 1. Parses data using <code>APIGatewayProxyEventV2Model</code>.  2. Parses <code>body</code> key using your model and returns it. <code>Model</code> LambdaFunctionUrlEnvelope 1. Parses data using <code>LambdaFunctionUrlModel</code>.  2. Parses <code>body</code> key using your model and returns it. <code>Model</code> KafkaEnvelope 1. Parses data using <code>KafkaRecordModel</code>.  2. Parses <code>value</code> key using your model and returns it. <code>Model</code> VpcLatticeEnvelope 1. Parses data using <code>VpcLatticeModel</code>.  2. Parses <code>value</code> key using your model and returns it. <code>Model</code>"},{"location":"utilities/parser/#bringing-your-own-envelope","title":"Bringing your own envelope","text":"<p>You can create your own Envelope model and logic by inheriting from <code>BaseEnvelope</code>, and implementing the <code>parse</code> method.</p> <p>Here's a snippet of how the EventBridge envelope we demonstrated previously is implemented.</p> EventBridge ModelEventBridge Envelope <pre><code>from datetime import datetime\nfrom typing import Any, Dict, List\n\nfrom aws_lambda_powertools.utilities.parser import BaseModel, Field\n\n\nclass EventBridgeModel(BaseModel):\n    version: str\n    id: str  # noqa: A003,VNE003\n    source: str\n    account: str\n    time: datetime\n    region: str\n    resources: List[str]\n    detail_type: str = Field(None, alias=\"detail-type\")\n    detail: Dict[str, Any]\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.parser import BaseEnvelope, models\nfrom aws_lambda_powertools.utilities.parser.models import EventBridgeModel\n\nfrom typing import Any, Dict, Optional, TypeVar\n\nModel = TypeVar(\"Model\", bound=BaseModel)\n\nclass EventBridgeEnvelope(BaseEnvelope):\ndef parse(self, data: Optional[Union[Dict[str, Any], Any]], model: Model) -&gt; Optional[Model]:\n\"\"\"Parses data found with model provided\n\n        Parameters\n        ----------\n        data : Dict\n            Lambda event to be parsed\n        model : Model\n            Data model provided to parse after extracting data using envelope\n\n        Returns\n        -------\n        Any\n            Parsed detail payload with model provided\n        \"\"\"\nparsed_envelope = EventBridgeModel.parse_obj(data)\nreturn self._parse(data=parsed_envelope.detail, model=model)\n</code></pre> <p>What's going on here, you might ask:</p> <ol> <li>We defined an envelope named <code>EventBridgeEnvelope</code> inheriting from <code>BaseEnvelope</code></li> <li>Implemented the <code>parse</code> abstract method taking <code>data</code> and <code>model</code> as parameters</li> <li>Then, we parsed the incoming data with our envelope to confirm it matches EventBridge's structure defined in <code>EventBridgeModel</code></li> <li>Lastly, we call <code>_parse</code> from <code>BaseEnvelope</code> to parse the data in our envelope (.detail) using the customer model</li> </ol>"},{"location":"utilities/parser/#data-model-validation","title":"Data model validation","text":"Warning <p>This is radically different from the Validator utility which validates events against JSON Schema.</p> <p>You can use parser's validator for deep inspection of object values and complex relationships.</p> <p>There are two types of class method decorators you can use:</p> <ul> <li><code>validator</code> - Useful to quickly validate an individual field and its value</li> <li><code>root_validator</code> - Useful to validate the entire model's data</li> </ul> <p>Keep the following in mind regardless of which decorator you end up using it:</p> <ul> <li>You must raise either <code>ValueError</code>, <code>TypeError</code>, or <code>AssertionError</code> when value is not compliant</li> <li>You must return the value(s) itself if compliant</li> </ul>"},{"location":"utilities/parser/#validating-fields","title":"validating fields","text":"<p>Quick validation to verify whether the field <code>message</code> has the value of <code>hello world</code>.</p> Data field validation with validator<pre><code>from aws_lambda_powertools.utilities.parser import parse, BaseModel, validator\n\nclass HelloWorldModel(BaseModel):\n    message: str\n\n@validator('message')\ndef is_hello_world(cls, v):\n        if v != \"hello world\":\n            raise ValueError(\"Message must be hello world!\")\n        return v\n\nparse(model=HelloWorldModel, event={\"message\": \"hello universe\"})\n</code></pre> <p>If you run as-is, you should expect the following error with the message we provided in our exception:</p> Sample validation error message<pre><code>message\n  Message must be hello world! (type=value_error)\n</code></pre> <p>Alternatively, you can pass <code>'*'</code> as an argument for the decorator so that you can validate every value available.</p> Validating all data fields with custom logic<pre><code>from aws_lambda_powertools.utilities.parser import parse, BaseModel, validator\n\nclass HelloWorldModel(BaseModel):\n    message: str\n    sender: str\n\n@validator('*')\ndef has_whitespace(cls, v):\n        if ' ' not in v:\n            raise ValueError(\"Must have whitespace...\")\n\n        return v\n\nparse(model=HelloWorldModel, event={\"message\": \"hello universe\", \"sender\": \"universe\"})\n</code></pre>"},{"location":"utilities/parser/#validating-entire-model","title":"validating entire model","text":"<p><code>root_validator</code> can help when you have a complex validation mechanism. For example finding whether data has been omitted, comparing field values, etc.</p> Comparing and validating multiple fields at once with root_validator<pre><code>from aws_lambda_powertools.utilities.parser import parse, BaseModel, root_validator\n\nclass UserModel(BaseModel):\n    username: str\n    password1: str\n    password2: str\n\n    @root_validator\n    def check_passwords_match(cls, values):\n        pw1, pw2 = values.get('password1'), values.get('password2')\n        if pw1 is not None and pw2 is not None and pw1 != pw2:\n            raise ValueError('passwords do not match')\n        return values\n\npayload = {\n    \"username\": \"universe\",\n    \"password1\": \"myp@ssword\",\n    \"password2\": \"repeat password\"\n}\n\nparse(model=UserModel, event=payload)\n</code></pre> Info <p>You can read more about validating list items, reusing validators, validating raw inputs, and a lot more in Pydantic's documentation.</p>"},{"location":"utilities/parser/#advanced-use-cases","title":"Advanced use cases","text":"Tip: Looking to auto-generate models from JSON, YAML, JSON Schemas, OpenApi, etc? <p>Use Koudai Aono's data model code generation tool for Pydantic</p> <p>There are number of advanced use cases well documented in Pydantic's doc such as creating immutable models, declaring fields with dynamic values.</p> Pydantic helper functions <p>Pydantic also offers functions to parse models from files, dicts, string, etc.</p> <p>Two possible unknown use cases are Models and exception' serialization. Models have methods to export them as <code>dict</code>, <code>JSON</code>, <code>JSON Schema</code>, and Validation exceptions can be exported as JSON.</p> Converting data models in various formats<pre><code>from aws_lambda_powertools.utilities import Logger\nfrom aws_lambda_powertools.utilities.parser import parse, BaseModel, ValidationError, validator\n\nlogger = Logger(service=\"user\")\n\nclass UserModel(BaseModel):\n    username: str\n    password1: str\n    password2: str\n\npayload = {\n    \"username\": \"universe\",\n    \"password1\": \"myp@ssword\",\n    \"password2\": \"repeat password\"\n}\n\ndef my_function():\n    try:\n        return parse(model=UserModel, event=payload)\n    except ValidationError as e:\nlogger.exception(e.json())\nreturn {\n            \"status_code\": 400,\n            \"message\": \"Invalid username\"\n        }\n\nUser: UserModel = my_function()\nuser_dict = User.dict()\nuser_json = User.json()\nuser_json_schema_as_dict = User.schema()\nuser_json_schema_as_json = User.schema_json(indent=2)\n</code></pre> <p>These can be quite useful when manipulating models that later need to be serialized as inputs for services like DynamoDB, EventBridge, etc.</p>"},{"location":"utilities/parser/#faq","title":"FAQ","text":"<p>When should I use parser vs data_classes utility?</p> <p>Use data classes utility when you're after autocomplete, self-documented attributes and helpers to extract data from common event sources.</p> <p>Parser is best suited for those looking for a trade-off between defining their models for deep validation, parsing and autocomplete for an additional dependency to be brought in.</p> <p>How do I import X from Pydantic?</p> <p>We export most common classes, exceptions, and utilities from Pydantic as part of parser e.g. <code>from aws_lambda_powertools.utilities.parser import BaseModel</code>.</p> <p>If what you're trying to use isn't available as part of the high level import system, use the following escape hatch mechanism:</p> Pydantic import escape hatch<pre><code>from aws_lambda_powertools.utilities.parser.pydantic import &lt;what you'd like to import'&gt;\n</code></pre>"},{"location":"utilities/streaming/","title":"Streaming","text":"<p>The streaming utility handles datasets larger than the available memory as streaming data.</p>"},{"location":"utilities/streaming/#key-features","title":"Key features","text":"<ul> <li>Stream Amazon S3 objects with a file-like interface with minimal memory consumption</li> <li>Built-in popular data transformations to decompress and deserialize (gzip, CSV, and ZIP)</li> <li>Build your own data transformation and add it to the pipeline</li> </ul>"},{"location":"utilities/streaming/#background","title":"Background","text":"<p>Within Lambda, processing S3 objects larger than the allocated amount of memory can lead to out of memory or timeout situations. For cost efficiency, your S3 objects may be encoded and compressed in various formats (gzip, CSV, zip files, etc), increasing the  amount of non-business logic and reliability risks.</p> <p>Streaming utility makes this process easier by fetching parts of your data as you consume it, and transparently applying data transformations to the data stream. This allows you to process one, a few, or all rows of your large dataset while consuming a few MBs only.</p>"},{"location":"utilities/streaming/#getting-started","title":"Getting started","text":""},{"location":"utilities/streaming/#streaming-from-a-s3-object","title":"Streaming from a S3 object","text":"<p>With <code>S3Object</code>, you'll need the bucket, object key, and optionally a version ID to stream its content.</p> <p>We will fetch parts of your data from S3 as you process each line, consuming only the absolute minimal amount of memory.</p> Non-versioned bucketVersioned bucket <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\ns3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\nfor line in s3:\nprint(line)\n</code></pre> <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\ns3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"], version_id=event[\"version_id\"])\nfor line in s3:\nprint(line)\n</code></pre>"},{"location":"utilities/streaming/#data-transformations","title":"Data transformations","text":"<p>Think of data transformations like a data processing pipeline - apply one or more in order.</p> <p>As data is streamed, you can apply transformations to your data like decompressing gzip content and deserializing a CSV into a dictionary.</p> <p>For popular data transformations like CSV or Gzip, you can quickly enable it at the constructor level:</p> Decompressing and deserializing CSV <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\ns3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"], is_gzip=True, is_csv=True)\nfor line in s3:\n        print(line)\n</code></pre> <p>Alternatively, you can apply transformations later via the <code>transform</code> method. By default, it will return the transformed stream you can use to read its contents. If you prefer in-place modifications, use <code>in_place=True</code>.</p> When is this useful? <p>In scenarios where you might have a reusable logic to apply common transformations. This might be a function or a class that receives an instance of <code>S3Object</code>.</p> Returning a new objectTransform in-place <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import (\n    CsvTransform,\n    GzipTransform,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\ndata = s3.transform([GzipTransform(), CsvTransform()])\nfor line in data:\n        print(line)  # returns a dict\n</code></pre> <p>Note that when using <code>in_place=True</code>, there is no return (<code>None</code>).</p> <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import (\n    CsvTransform,\n    GzipTransform,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\ns3.transform([GzipTransform(), CsvTransform()], in_place=True)\nfor line in s3:\n        print(line)  # returns a dict\n</code></pre>"},{"location":"utilities/streaming/#handling-zip-files","title":"Handling ZIP files","text":"<p><code>ZipTransform</code> doesn't support combining other transformations.</p> <p>This is because a Zip file contains multiple files while transformations apply to a single stream.</p> <p>That said, you can still open a specific file as a stream, reading only the necessary bytes to extract it:</p> Reading an individual file in the zip as a stream<pre><code>from aws_lambda_powertools.utilities.streaming import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import ZipTransform\n\ns3object = S3Object(bucket=\"bucket\", key=\"key\")\nzip_reader = s3object.transform(ZipTransform())\nwith zip_reader.open(\"filename.txt\") as f:\nfor line in f:\n        print(line)\n</code></pre>"},{"location":"utilities/streaming/#built-in-data-transformations","title":"Built-in data transformations","text":"<p>We provide popular built-in transformations that you can apply against your streaming data.</p> Name Description Class name Gzip Gunzips the stream of data using the gzip library GzipTransform Zip Exposes the stream as a ZipFile object ZipTransform CSV Parses each CSV line as a CSV object, returning dictionary objects CsvTransform"},{"location":"utilities/streaming/#advanced","title":"Advanced","text":""},{"location":"utilities/streaming/#skipping-or-reading-backwards","title":"Skipping or reading backwards","text":"<p><code>S3Object</code> implements Python I/O interface. This means you can use <code>seek</code> to start reading contents of your file from any particular position, saving you processing time.</p>"},{"location":"utilities/streaming/#reading-backwards","title":"Reading backwards","text":"<p>For example, let's imagine you have a large CSV file, each row has a non-uniform size (bytes), and you want to read and process the last row only.</p> non_uniform_sample.csv<pre><code>id,name,location\n1,Ruben Fonseca, Denmark\n2,Heitor Lessa, Netherlands\n3,Leandro Damascena, Portugal\n</code></pre> <p>You found out the last row has exactly 30 bytes. We can use <code>seek()</code> to skip to the end of the file, read 30 bytes, then transform to CSV.</p> Reading only the last CSV row<pre><code>import io\nfrom typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nLAST_ROW_SIZE = 30\nCSV_HEADERS = [\"id\", \"name\", \"location\"]\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    sample_csv = S3Object(bucket=event[\"bucket\"], key=\"sample.csv\")\n\n    # From the end of the file, jump exactly 30 bytes backwards\nsample_csv.seek(-LAST_ROW_SIZE, io.SEEK_END)\n# Transform portion of data into CSV with our headers\nsample_csv.transform(CsvTransform(fieldnames=CSV_HEADERS), in_place=True)\n# We will only read the last portion of the file from S3\n    # as we're only interested in the last 'location' from our dataset\n    for last_row in sample_csv:\n        print(last_row[\"location\"])\n</code></pre>"},{"location":"utilities/streaming/#skipping","title":"Skipping","text":"<p>What if we want to jump the first N rows?</p> <p>You can also solve with <code>seek</code>, but let's take a large uniform CSV file to make this easier to grasp.</p> uniform_sample.csv<pre><code>reading,position,type\n21.3,5,+\n23.4,4,+\n21.3,0,-\n</code></pre> <p>You found out that each row has 8 bytes, the header line has 21 bytes, and every new line has 1 byte. You want to skip the first 100 lines.</p> Skipping the first 100 rows<pre><code>import io\nfrom typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\"\"\"\nAssuming the CSV files contains rows after the header always has 8 bytes + 1 byte newline:\n\nreading,position,type\n21.3,5,+\n23.4,4,+\n21.3,0,-\n...\n\"\"\"\n\nCSV_HEADERS = [\"reading\", \"position\", \"type\"]\nROW_SIZE = 8 + 1  # 1 byte newline\nHEADER_SIZE = 21 + 1  # 1 byte newline\nLINES_TO_JUMP = 100\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    sample_csv = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n\n    # Skip the header line\nsample_csv.seek(HEADER_SIZE, io.SEEK_SET)\n# Jump 100 lines of 9 bytes each (8 bytes of data + 1 byte newline)\nsample_csv.seek(LINES_TO_JUMP * ROW_SIZE, io.SEEK_CUR)\nsample_csv.transform(CsvTransform(), in_place=True)\n    for row in sample_csv:\n        print(row[\"reading\"])\n</code></pre>"},{"location":"utilities/streaming/#custom-options-for-data-transformations","title":"Custom options for data transformations","text":"<p>We will propagate additional options to the underlying implementation for each transform class.</p> Name Available options GzipTransform GzipFile constructor ZipTransform ZipFile constructor CsvTransform DictReader constructor <p>For instance, take <code>ZipTransform</code>. You can use the <code>compression</code> parameter if you want to unzip an S3 object compressed with <code>LZMA</code>.</p> Unzipping LZMA data <pre><code>import zipfile\nfrom typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import ZipTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n\nzf = s3.transform(ZipTransform(compression=zipfile.ZIP_LZMA))\nprint(zf.nameslist())\n    zf.extract(zf.namelist()[0], \"/tmp\")\n</code></pre> <p>Or, if you want to load a tab-separated file (TSV), you can use the <code>delimiter</code> parameter in the <code>CsvTransform</code>:</p> Deserializing tab-separated data values <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n\ntsv_stream = s3.transform(CsvTransform(delimiter=\"\\t\"))\nfor obj in tsv_stream:\n        print(obj)\n</code></pre>"},{"location":"utilities/streaming/#building-your-own-data-transformation","title":"Building your own data transformation","text":"<p>You can build your own custom data transformation by extending the <code>BaseTransform</code> class. The <code>transform</code> method receives an <code>IO[bytes]</code> object, and you are responsible for returning an <code>IO[bytes]</code> object.</p> Custom JSON transform <pre><code>import io\nfrom typing import IO, Optional\n\nimport ijson\n\nfrom aws_lambda_powertools.utilities.streaming.transformations import BaseTransform\n\n\n# Using io.RawIOBase gets us default implementations of many of the common IO methods\nclass JsonDeserializer(io.RawIOBase):\ndef __init__(self, input_stream: IO[bytes]):\nself.input = ijson.items(input_stream, \"\", multiple_values=True)\ndef read(self, size: int = -1) -&gt; Optional[bytes]:\n        raise NotImplementedError(f\"{__name__} does not implement read\")\n\n    def readline(self, size: Optional[int] = None) -&gt; bytes:\n        raise NotImplementedError(f\"{__name__} does not implement readline\")\n\n    def read_object(self) -&gt; dict:\n        return self.input.__next__()\n\n    def __next__(self):\n        return self.read_object()\n\n\nclass JsonTransform(BaseTransform):\ndef transform(self, input_stream: IO[bytes]) -&gt; JsonDeserializer:\nreturn JsonDeserializer(input_stream=input_stream)\n</code></pre>"},{"location":"utilities/streaming/#testing-your-code","title":"Testing your code","text":""},{"location":"utilities/streaming/#asserting-data-transformations","title":"Asserting data transformations","text":"<p>Create an input payload using <code>io.BytesIO</code> and assert the response of the transformation:</p> assert_transformation.pyassert_transformation_module.py <pre><code>import io\n\nimport boto3\nfrom assert_transformation_module import UpperTransform\nfrom botocore import stub\n\nfrom aws_lambda_powertools.utilities.streaming import S3Object\nfrom aws_lambda_powertools.utilities.streaming.compat import PowertoolsStreamingBody\n\n\ndef test_upper_transform():\n    # GIVEN\ndata_stream = io.BytesIO(b\"hello world\")\n# WHEN\ndata_stream = UpperTransform().transform(data_stream)\n# THEN\n    assert data_stream.read() == b\"HELLO WORLD\"\n\n\ndef test_s3_object_with_upper_transform():\n    # GIVEN\n    payload = b\"hello world\"\ns3_client = boto3.client(\"s3\")\ns3_stub = stub.Stubber(s3_client)\ns3_stub.add_response(\n\"get_object\",\n{\"Body\": PowertoolsStreamingBody(raw_stream=io.BytesIO(payload), content_length=len(payload))},\n)\ns3_stub.activate()\n\n# WHEN\ndata_stream = S3Object(bucket=\"bucket\", key=\"key\", boto3_client=s3_client)\ndata_stream.transform(UpperTransform(), in_place=True)\n\n    # THEN\n    assert data_stream.read() == b\"HELLO WORLD\"\n</code></pre> <pre><code>import io\nfrom typing import IO, Optional\n\nfrom aws_lambda_powertools.utilities.streaming.transformations import BaseTransform\n\n\nclass UpperIO(io.RawIOBase):\n    def __init__(self, input_stream: IO[bytes], encoding: str):\n        self.encoding = encoding\n        self.input_stream = io.TextIOWrapper(input_stream, encoding=encoding)\n\n    def read(self, size: int = -1) -&gt; Optional[bytes]:\n        data = self.input_stream.read(size)\n        return data.upper().encode(self.encoding)\n\nclass UpperTransform(BaseTransform):\n    def transform(self, input_stream: IO[bytes]) -&gt; UpperIO:\n        return UpperIO(input_stream=input_stream, encoding=\"utf-8\")\n</code></pre>"},{"location":"utilities/streaming/#known-limitations","title":"Known limitations","text":""},{"location":"utilities/streaming/#aws-x-ray-segment-size-limit","title":"AWS X-Ray segment size limit","text":"<p>We make multiple API calls to S3 as you read chunks from your S3 object. If your function is decorated with Tracer, you can easily hit AWS X-Ray 64K segment size when processing large files.</p> <p>Use tracer decorators in parts where you don't read your <code>S3Object</code> instead.</p>"},{"location":"utilities/typing/","title":"Typing","text":"<p>This typing utility provides static typing classes that can be used to ease the development by providing the IDE type hints.</p>"},{"location":"utilities/typing/#key-features","title":"Key features","text":"<ul> <li>Add static typing classes</li> <li>Ease the development by leveraging your IDE's type hints</li> <li>Avoid common typing mistakes in Python</li> </ul>"},{"location":"utilities/typing/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>We provide static typing for any context methods or properties implemented by Lambda context object.</p>"},{"location":"utilities/typing/#lambdacontext","title":"LambdaContext","text":"<p>The <code>LambdaContext</code> typing is typically used in the handler method for the Lambda function.</p> getting_started_validator_decorator_function.py <pre><code>from aws_lambda_powertools.utilities.typing import LambdaContext\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\n# Insert business logic\n    return event\n</code></pre>"},{"location":"utilities/typing/#working-with-context-methods-and-properties","title":"Working with context methods and properties","text":"<p>Using <code>LambdaContext</code> typing makes it possible to access information and hints of all properties and methods implemented by Lambda context object.</p> working_with_context_function.py <pre><code>from time import sleep\n\nimport requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nlogger = Logger()\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    limit_execution: int = 1000  # milliseconds\n\n    # scrape website and exit before lambda timeout\n    while context.get_remaining_time_in_millis() &gt; limit_execution:\ncomments: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/comments\")\n# add logic here and save the results of the request to an S3 bucket, for example.\n\n        logger.info(\n            {\n                \"operation\": \"scrape_website\",\n                \"request_id\": context.aws_request_id,\n                \"remaining_time\": context.get_remaining_time_in_millis(),\n                \"comments\": comments.json()[:2],\n},\n)\nsleep(1)\n\n    return {\"message\": \"Success\"}\n</code></pre> <p> </p>"},{"location":"utilities/validation/","title":"Validation","text":"<p>This utility provides JSON Schema validation for events and responses, including JMESPath support to unwrap events before validation.</p>"},{"location":"utilities/validation/#key-features","title":"Key features","text":"<ul> <li>Validate incoming event and response</li> <li>JMESPath support to unwrap events before validation applies</li> <li>Built-in envelopes to unwrap popular event sources payloads</li> </ul>"},{"location":"utilities/validation/#getting-started","title":"Getting started","text":"Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>You can validate inbound and outbound events using <code>validator</code> decorator.</p> <p>You can also use the standalone <code>validate</code> function, if you want more control over the validation process such as handling a validation error.</p> Tip: Using JSON Schemas for the first time? <p>Check this step-by-step tour in the official JSON Schema website.</p> <p>We support any JSONSchema draft supported by fastjsonschema library.</p> Warning <p>Both <code>validator</code> decorator and <code>validate</code> standalone function expects your JSON Schema to be a dictionary, not a filename.</p>"},{"location":"utilities/validation/#install","title":"Install","text":"<p>This is not necessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR</p> <p>Add <code>aws-lambda-powertools[validation]</code> as a dependency in your preferred tool: e.g., requirements.txt, pyproject.toml. This will ensure you have the required dependencies before using Validation.</p>"},{"location":"utilities/validation/#validator-decorator","title":"Validator decorator","text":"<p>Validator decorator is typically used to validate either inbound or functions' response.</p> <p>It will fail fast with <code>SchemaValidationError</code> exception if event or response doesn't conform with given JSON Schema.</p> getting_started_validator_decorator_function.pygetting_started_validator_decorator_schema.pygetting_started_validator_decorator_payload.json <pre><code>from dataclasses import dataclass, field\nfrom uuid import uuid4\n\nimport getting_started_validator_decorator_schema as schemas\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import validator\n# we can get list of allowed IPs from AWS Parameter Store using Parameters Utility\n# See: https://docs.powertools.aws.dev/lambda/python/latest/utilities/parameters/\nALLOWED_IPS = parameters.get_parameter(\"/lambda-powertools/allowed_ips\")\n\n\nclass UserPermissionsError(Exception):\n    ...\n\n\n@dataclass\nclass User:\n    ip: str\n    permissions: list\n    user_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n    name: str = \"Project Lambda Powertools\"\n\n\n# using a decorator to validate input and output data\n@validator(inbound_schema=schemas.INPUT, outbound_schema=schemas.OUTPUT)\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        user_details: dict = {}\n\n        # get permissions by user_id and project\n        if (\n            event.get(\"user_id\") == \"0d44b083-8206-4a3a-aa95-5d392a99be4a\"\n            and event.get(\"project\") == \"powertools\"\n            and event.get(\"ip\") in ALLOWED_IPS\n        ):\n            user_details = User(ip=event.get(\"ip\"), permissions=[\"read\", \"write\"]).__dict__\n\n        # the body must be an object because must match OUTPUT schema, otherwise it fails\nreturn {\"body\": user_details or None, \"statusCode\": 200 if user_details else 204}\nexcept Exception as e:\n        raise UserPermissionsError(str(e))\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [{\"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\", \"project\": \"powertools\", \"ip\": \"192.168.0.1\"}],\n    \"required\": [\"user_id\", \"project\", \"ip\"],\n    \"properties\": {\n\"user_id\": {\n\"$id\": \"#/properties/user_id\",\n\"type\": \"string\",\n\"title\": \"The user_id\",\n            \"examples\": [\"0d44b083-8206-4a3a-aa95-5d392a99be4a\"],\n            \"maxLength\": 50,\n        },\n\"project\": {\n\"$id\": \"#/properties/project\",\n\"type\": \"string\",\n\"title\": \"The project\",\n            \"examples\": [\"powertools\"],\n            \"maxLength\": 30,\n        },\n\"ip\": {\n\"$id\": \"#/properties/ip\",\n\"type\": \"string\",\n\"title\": \"The ip\",\n\"format\": \"ipv4\",\n\"examples\": [\"192.168.0.1\"],\n            \"maxLength\": 30,\n        },\n    },\n}\n\nOUTPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample outgoing schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [{\"statusCode\": 200, \"body\": {}}],\n    \"required\": [\"statusCode\", \"body\"],\n    \"properties\": {\n\"statusCode\": {\n\"$id\": \"#/properties/statusCode\",\n\"type\": \"integer\",\n\"title\": \"The statusCode\",\n            \"examples\": [200],\n            \"maxLength\": 3,\n        },\n\"body\": {\n\"$id\": \"#/properties/body\",\n\"type\": \"object\",\n\"title\": \"The body\",\n            \"examples\": [\n                '{\"ip\": \"192.168.0.1\", \"permissions\": [\"read\", \"write\"], \"user_id\": \"7576b683-295e-4f69-b558-70e789de1b18\", \"name\": \"Project Lambda Powertools\"}'  # noqa E501\n            ],\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\",\n\"project\": \"powertools\",\n\"ip\": \"192.168.0.1\"\n}\n</code></pre> Note <p>It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both.</p>"},{"location":"utilities/validation/#validate-function","title":"Validate function","text":"<p>Validate standalone function is typically used within the Lambda handler, or any other methods that perform data validation.</p> <p>You can also gracefully handle schema validation errors by catching <code>SchemaValidationError</code> exception.</p> getting_started_validator_standalone_function.pygetting_started_validator_standalone_schema.pygetting_started_validator_standalone_payload.json <pre><code>import getting_started_validator_standalone_schema as schemas\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n# we can get list of allowed IPs from AWS Parameter Store using Parameters Utility\n# See: https://docs.powertools.aws.dev/lambda/python/latest/utilities/parameters/\nALLOWED_IPS = parameters.get_parameter(\"/lambda-powertools/allowed_ips\")\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        user_authenticated: str = \"\"\n\n# using standalone function to validate input data only\nvalidate(event=event, schema=schemas.INPUT)\nif (\n            event.get(\"user_id\") == \"0d44b083-8206-4a3a-aa95-5d392a99be4a\"\n            and event.get(\"project\") == \"powertools\"\n            and event.get(\"ip\") in ALLOWED_IPS\n        ):\n            user_authenticated = \"Allowed\"\n\n# in this example the body can be of any type because we are not validating the OUTPUT\nreturn {\"body\": user_authenticated, \"statusCode\": 200 if user_authenticated else 204}\n    except SchemaValidationError as exception:\n        # SchemaValidationError indicates where a data mismatch is\n        return {\"body\": str(exception), \"statusCode\": 400}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n\"examples\": [{\"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\", \"powertools\": \"lessa\", \"ip\": \"192.168.0.1\"}],\n\"required\": [\"user_id\", \"project\", \"ip\"],\n\"properties\": {\n\"user_id\": {\n\"$id\": \"#/properties/user_id\",\n\"type\": \"string\",\n\"title\": \"The user_id\",\n            \"examples\": [\"0d44b083-8206-4a3a-aa95-5d392a99be4a\"],\n            \"maxLength\": 50,\n        },\n\"project\": {\n\"$id\": \"#/properties/project\",\n\"type\": \"string\",\n\"title\": \"The project\",\n            \"examples\": [\"powertools\"],\n            \"maxLength\": 30,\n        },\n\"ip\": {\n\"$id\": \"#/properties/ip\",\n\"type\": \"string\",\n\"title\": \"The ip\",\n\"format\": \"ipv4\",\n\"examples\": [\"192.168.0.1\"],\n            \"maxLength\": 30,\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\",\n\"project\": \"powertools\",\n\"ip\": \"192.168.0.1\"\n}\n</code></pre>"},{"location":"utilities/validation/#unwrapping-events-prior-to-validation","title":"Unwrapping events prior to validation","text":"<p>You might want to validate only a portion of your event - This is what the <code>envelope</code> parameter is for.</p> <p>Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation.</p> <p>Here is a sample custom EventBridge event, where we only validate what's inside the <code>detail</code> key:</p> getting_started_validator_unwrapping_function.pygetting_started_validator_unwrapping_schema.pygetting_started_validator_unwrapping_payload.json <pre><code>import boto3\nimport getting_started_validator_unwrapping_schema as schemas\nfrom aws_lambda_powertools.utilities.data_classes.event_bridge_event import (\n    EventBridgeEvent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import validator\ns3_client = boto3.resource(\"s3\")\n\n\n# we use the 'envelope' parameter to extract the payload inside the 'detail' key before validating\n@validator(inbound_schema=schemas.INPUT, envelope=\"detail\")\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    my_event = EventBridgeEvent(event)\n    data = my_event.detail.get(\"data\", {})\n    s3_bucket, s3_key = data.get(\"s3_bucket\"), data.get(\"s3_key\")\n\n    try:\n        s3_object = s3_client.Object(bucket_name=s3_bucket, key=s3_key)\n        payload = s3_object.get()[\"Body\"]\n        content = payload.read().decode(\"utf-8\")\n\n        return {\"message\": process_data_object(content), \"success\": True}\n    except s3_client.meta.client.exceptions.NoSuchBucket as exception:\n        return return_error_message(str(exception))\n    except s3_client.meta.client.exceptions.NoSuchKey as exception:\n        return return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"message\": message, \"success\": False}\n\n\ndef process_data_object(content: str) -&gt; str:\n    # insert logic here\n    return \"Data OK\"\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1660222326.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [\n        {\n\"data\": {\n\"s3_bucket\": \"aws-lambda-powertools\",\n\"s3_key\": \"event.txt\",\n\"file_size\": 200,\n\"file_type\": \"text/plain\",\n},\n},\n    ],\n    \"required\": [\"data\"],\n    \"properties\": {\n        \"data\": {\n            \"$id\": \"#root/data\",\n            \"title\": \"Root\",\n            \"type\": \"object\",\n\"required\": [\"s3_bucket\", \"s3_key\", \"file_size\", \"file_type\"],\n\"properties\": {\n\"s3_bucket\": {\n\"$id\": \"#root/data/s3_bucket\",\n                    \"title\": \"The S3 Bucker\",\n\"type\": \"string\",\n\"default\": \"\",\n                    \"examples\": [\"aws-lambda-powertools\"],\n                    \"pattern\": \"^.*$\",\n                },\n\"s3_key\": {\n\"$id\": \"#root/data/s3_key\",\n                    \"title\": \"The S3 Key\",\n\"type\": \"string\",\n\"default\": \"\",\n                    \"examples\": [\"folder/event.txt\"],\n                    \"pattern\": \"^.*$\",\n                },\n\"file_size\": {\n\"$id\": \"#root/data/file_size\",\n                    \"title\": \"The file size\",\n\"type\": \"integer\",\n\"examples\": [200],\n                    \"default\": 0,\n                },\n\"file_type\": {\n\"$id\": \"#root/data/file_type\",\n                    \"title\": \"The file type\",\n\"type\": \"string\",\n\"default\": \"\",\n                    \"examples\": [\"text/plain\"],\n                    \"pattern\": \"^.*$\",\n                },\n            },\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"id\": \"cdc73f9d-aea9-11e3-9d5a-835b769c0d9c\",\n\"detail-type\": \"CustomEvent\",\n\"source\": \"mycompany.service\",\n\"account\": \"123456789012\",\n\"time\": \"1970-01-01T00:00:00Z\",\n\"region\": \"us-east-1\",\n\"resources\": [],\n\"detail\": {\n\"data\": {\n\"s3_bucket\": \"aws-lambda-powertools\",\n\"s3_key\": \"folder/event.txt\",\n\"file_size\": 200,\n\"file_type\": \"text/plain\"\n}\n}\n}\n</code></pre> <p>This is quite powerful because you can use JMESPath Query language to extract records from arrays, combine pipe and function expressions.</p> <p>When combined, these features allow you to extract what you need before validating the actual payload.</p>"},{"location":"utilities/validation/#built-in-envelopes","title":"Built-in envelopes","text":"<p>We provide built-in envelopes to easily extract the payload from popular event sources.</p> unwrapping_popular_event_source_function.pyunwrapping_popular_event_source_schema.pyunwrapping_popular_event_source_payload.json <pre><code>import boto3\nimport unwrapping_popular_event_source_schema as schemas\nfrom botocore.exceptions import ClientError\n\nfrom aws_lambda_powertools.utilities.data_classes.event_bridge_event import (\n    EventBridgeEvent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import envelopes, validator\n# extracting detail from EventBridge custom event\n# see: https://docs.powertools.aws.dev/lambda/python/latest/utilities/jmespath_functions/#built-in-envelopes\n@validator(inbound_schema=schemas.INPUT, envelope=envelopes.EVENTBRIDGE)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    my_event = EventBridgeEvent(event)\n    ec2_client = boto3.resource(\"ec2\", region_name=my_event.region)\n\n    try:\n        instance_id = my_event.detail.get(\"instance_id\")\n        instance = ec2_client.Instance(instance_id)\n        instance.stop()\n\n        return {\"message\": f\"Successfully stopped {instance_id}\", \"success\": True}\n    except ClientError as exception:\n        return {\"message\": str(exception), \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"definitions\": {},\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1660233148.json\",\n    \"title\": \"Root\",\n    \"type\": \"object\",\n\"required\": [\"instance_id\", \"region\"],\n\"properties\": {\n\"instance_id\": {\n\"$id\": \"#root/instance_id\",\n            \"title\": \"Instance_id\",\n\"type\": \"string\",\n\"default\": \"\",\n            \"examples\": [\"i-042dd005362091826\"],\n            \"pattern\": \"^.*$\",\n        },\n\"region\": {\n\"$id\": \"#root/region\",\n            \"title\": \"Region\",\n\"type\": \"string\",\n\"default\": \"\",\n            \"examples\": [\"us-east-1\"],\n            \"pattern\": \"^.*$\",\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"id\": \"cdc73f9d-aea9-11e3-9d5a-835b769c0d9c\",\n\"detail-type\": \"Scheduled Event\",\n\"source\": \"aws.events\",\n\"account\": \"123456789012\",\n\"time\": \"1970-01-01T00:00:00Z\",\n\"region\": \"us-east-1\",\n\"resources\": [\n\"arn:aws:events:us-east-1:123456789012:rule/ExampleRule\"\n],\n\"detail\": {\n\"instance_id\": \"i-042dd005362091826\",\n\"region\": \"us-east-2\"\n}\n}\n</code></pre> <p>Here is a handy table with built-in envelopes along with their JMESPath expressions in case you want to build your own.</p> Envelope JMESPath expression <code>API_GATEWAY_HTTP</code> <code>powertools_json(body)</code> <code>API_GATEWAY_REST</code> <code>powertools_json(body)</code> <code>CLOUDWATCH_EVENTS_SCHEDULED</code> <code>detail</code> <code>CLOUDWATCH_LOGS</code> <code>awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*]</code> <code>EVENTBRIDGE</code> <code>detail</code> <code>KINESIS_DATA_STREAM</code> <code>Records[*].kinesis.powertools_json(powertools_base64(data))</code> <code>SNS</code> <code>Records[0].Sns.Message | powertools_json(@)</code> <code>SQS</code> <code>Records[*].powertools_json(body)</code>"},{"location":"utilities/validation/#advanced","title":"Advanced","text":""},{"location":"utilities/validation/#validating-custom-formats","title":"Validating custom formats","text":"Note <p>JSON Schema DRAFT 7 has many new built-in formats such as date, time, and specifically a regex format which might be a better replacement for a custom format, if you do have control over the schema.</p> <p>JSON Schemas with custom formats like <code>awsaccountid</code> will fail validation. If you have these, you can pass them using <code>formats</code> parameter:</p> custom_json_schema_type_format.json<pre><code>{\n\"accountid\": {\n\"format\": \"awsaccountid\",\n\"type\": \"string\"\n}\n}\n</code></pre> <p>For each format defined in a dictionary key, you must use a regex, or a function that returns a boolean to instruct the validator on how to proceed when encountering that type.</p> custom_format_function.pycustom_format_schema.pycustom_format_payload.json <pre><code>import json\nimport re\n\nimport boto3\nimport custom_format_schema as schemas\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n# awsaccountid must have 12 digits\ncustom_format = {\"awsaccountid\": lambda value: re.match(r\"^(\\d{12})$\", value)}\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        # validate input using custom json format\nvalidate(event=event, schema=schemas.INPUT, formats=custom_format)\nclient_organization = boto3.client(\"organizations\", region_name=event.get(\"region\"))\n        account_data = client_organization.describe_account(AccountId=event.get(\"accountid\"))\n\n        return {\n            \"account\": json.dumps(account_data.get(\"Account\"), default=str),\n            \"message\": \"Success\",\n            \"statusCode\": 200,\n        }\nexcept SchemaValidationError as exception:\nreturn return_error_message(str(exception))\n    except Exception as exception:\n        return return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"account\": None, \"message\": message, \"statusCode\": 400}\n</code></pre> <pre><code>INPUT = {\n    \"definitions\": {},\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1660245931.json\",\n    \"title\": \"Root\",\n    \"type\": \"object\",\n\"required\": [\"accountid\", \"region\"],\n\"properties\": {\n\"accountid\": {\n\"$id\": \"#root/accountid\",\n            \"title\": \"The accountid\",\n\"type\": \"string\",\n\"format\": \"awsaccountid\",\n\"default\": \"\",\n            \"examples\": [\"123456789012\"],\n        },\n\"region\": {\n\"$id\": \"#root/region\",\n            \"title\": \"The region\",\n\"type\": \"string\",\n\"default\": \"\",\n            \"examples\": [\"us-east-1\"],\n            \"pattern\": \"^.*$\",\n        },\n    },\n}\n</code></pre> <pre><code>{\n\"accountid\": \"200984112386\",\n\"region\": \"us-east-1\"\n}\n</code></pre>"},{"location":"utilities/validation/#built-in-jmespath-functions","title":"Built-in JMESPath functions","text":"<p>You might have events or responses that contain non-encoded JSON, where you need to decode before validating them.</p> <p>You can use our built-in JMESPath functions within your expressions to do exactly that to deserialize JSON Strings, decode base64, and decompress gzip data.</p> Info <p>We use these for built-in envelopes to easily to decode and unwrap events from sources like Kinesis, CloudWatch Logs, etc.</p>"}]}