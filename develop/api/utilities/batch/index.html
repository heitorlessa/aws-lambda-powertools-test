<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>aws_lambda_powertools.utilities.batch API documentation</title>
<meta name="description" content="Batch processing utility" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>aws_lambda_powertools.utilities.batch</code></h1>
</header>
<section id="section-intro">
<p>Batch processing utility</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-

&#34;&#34;&#34;
Batch processing utility
&#34;&#34;&#34;

from aws_lambda_powertools.utilities.batch.base import (
    AsyncBatchProcessor,
    BasePartialBatchProcessor,
    BasePartialProcessor,
    BatchProcessor,
    EventType,
    FailureResponse,
    SuccessResponse,
)
from aws_lambda_powertools.utilities.batch.decorators import (
    async_batch_processor,
    async_process_partial_response,
    batch_processor,
    process_partial_response,
)
from aws_lambda_powertools.utilities.batch.exceptions import ExceptionInfo
from aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor import (
    SqsFifoPartialProcessor,
)
from aws_lambda_powertools.utilities.batch.types import BatchTypeModels

__all__ = (
    &#34;async_batch_processor&#34;,
    &#34;async_process_partial_response&#34;,
    &#34;batch_processor&#34;,
    &#34;process_partial_response&#34;,
    &#34;BatchProcessor&#34;,
    &#34;AsyncBatchProcessor&#34;,
    &#34;BasePartialProcessor&#34;,
    &#34;BasePartialBatchProcessor&#34;,
    &#34;BatchTypeModels&#34;,
    &#34;ExceptionInfo&#34;,
    &#34;EventType&#34;,
    &#34;FailureResponse&#34;,
    &#34;SuccessResponse&#34;,
    &#34;SqsFifoPartialProcessor&#34;,
)</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="aws_lambda_powertools.utilities.batch.base" href="base.html">aws_lambda_powertools.utilities.batch.base</a></code></dt>
<dd>
<div class="desc"><p>Batch processing utilities</p></div>
</dd>
<dt><code class="name"><a title="aws_lambda_powertools.utilities.batch.decorators" href="decorators.html">aws_lambda_powertools.utilities.batch.decorators</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="aws_lambda_powertools.utilities.batch.exceptions" href="exceptions.html">aws_lambda_powertools.utilities.batch.exceptions</a></code></dt>
<dd>
<div class="desc"><p>Batch processing exceptions</p></div>
</dd>
<dt><code class="name"><a title="aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor" href="sqs_fifo_partial_processor.html">aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="aws_lambda_powertools.utilities.batch.types" href="types.html">aws_lambda_powertools.utilities.batch.types</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.async_batch_processor"><code class="name flex">
<span>def <span class="ident">async_batch_processor</span></span>(<span>handler: Callable, event: Dict, context: LambdaContext, record_handler: Callable[..., Awaitable[Any]], processor: <a title="aws_lambda_powertools.utilities.batch.AsyncBatchProcessor" href="#aws_lambda_powertools.utilities.batch.AsyncBatchProcessor">AsyncBatchProcessor</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Middleware to handle batch event processing</p>
<h2 id="notes">Notes</h2>
<p>Consider using async_process_partial_response function for an easier experience.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>handler</code></strong> :&ensp;<code>Callable</code></dt>
<dd>Lambda's handler</dd>
<dt><strong><code>event</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Lambda's Event</dd>
<dt><strong><code>context</code></strong> :&ensp;<code>LambdaContext</code></dt>
<dd>Lambda's Context</dd>
<dt><strong><code>record_handler</code></strong> :&ensp;<code>Callable[&hellip;, Awaitable[Any]]</code></dt>
<dd>Callable to process each record from the batch</dd>
<dt><strong><code>processor</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.AsyncBatchProcessor" href="#aws_lambda_powertools.utilities.batch.AsyncBatchProcessor">AsyncBatchProcessor</a></code></dt>
<dd>Batch Processor to handle partial failure cases</dd>
</dl>
<h2 id="examples">Examples</h2>
<p><strong>Processes Lambda's event with a BasePartialProcessor</strong>
&gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import async_batch_processor, AsyncBatchProcessor
&gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
&gt;&gt;&gt;
&gt;&gt;&gt; processor = AsyncBatchProcessor(event_type=EventType.SQS)
&gt;&gt;&gt;
&gt;&gt;&gt; async def async_record_handler(record: SQSRecord):
&gt;&gt;&gt;
payload: str = record.body
&gt;&gt;&gt;
return payload
&gt;&gt;&gt;
&gt;&gt;&gt; @async_batch_processor(record_handler=async_record_handler, processor=processor)
&gt;&gt;&gt; def lambda_handler(event, context):
&gt;&gt;&gt;
return processor.response()</p>
<h2 id="limitations">Limitations</h2>
<ul>
<li>Sync batch processors. Use <code><a title="aws_lambda_powertools.utilities.batch.batch_processor" href="#aws_lambda_powertools.utilities.batch.batch_processor">batch_processor()</a></code> instead.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@lambda_handler_decorator
def async_batch_processor(
    handler: Callable,
    event: Dict,
    context: LambdaContext,
    record_handler: Callable[..., Awaitable[Any]],
    processor: AsyncBatchProcessor,
):
    &#34;&#34;&#34;
    Middleware to handle batch event processing

    Notes
    -----
    Consider using async_process_partial_response function for an easier experience.

    Parameters
    ----------
    handler: Callable
        Lambda&#39;s handler
    event: Dict
        Lambda&#39;s Event
    context: LambdaContext
        Lambda&#39;s Context
    record_handler: Callable[..., Awaitable[Any]]
        Callable to process each record from the batch
    processor: AsyncBatchProcessor
        Batch Processor to handle partial failure cases

    Examples
    --------
    **Processes Lambda&#39;s event with a BasePartialProcessor**
        &gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import async_batch_processor, AsyncBatchProcessor
        &gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
        &gt;&gt;&gt;
        &gt;&gt;&gt; processor = AsyncBatchProcessor(event_type=EventType.SQS)
        &gt;&gt;&gt;
        &gt;&gt;&gt; async def async_record_handler(record: SQSRecord):
        &gt;&gt;&gt;     payload: str = record.body
        &gt;&gt;&gt;     return payload
        &gt;&gt;&gt;
        &gt;&gt;&gt; @async_batch_processor(record_handler=async_record_handler, processor=processor)
        &gt;&gt;&gt; def lambda_handler(event, context):
        &gt;&gt;&gt;     return processor.response()

    Limitations
    -----------
    * Sync batch processors. Use `batch_processor` instead.
    &#34;&#34;&#34;
    records = event[&#34;Records&#34;]

    with processor(records, record_handler, lambda_context=context):
        processor.async_process()

    return handler(event, context)</code></pre>
</details>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.async_process_partial_response"><code class="name flex">
<span>def <span class="ident">async_process_partial_response</span></span>(<span>event: Dict, record_handler: Callable, processor: <a title="aws_lambda_powertools.utilities.batch.AsyncBatchProcessor" href="#aws_lambda_powertools.utilities.batch.AsyncBatchProcessor">AsyncBatchProcessor</a>, context: LambdaContext | None = None) ‑> <a title="aws_lambda_powertools.utilities.batch.types.PartialItemFailureResponse" href="types.html#aws_lambda_powertools.utilities.batch.types.PartialItemFailureResponse">PartialItemFailureResponse</a></span>
</code></dt>
<dd>
<div class="desc"><p>Higher level function to handle batch event processing asynchronously.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>event</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Lambda's original event</dd>
<dt><strong><code>record_handler</code></strong> :&ensp;<code>Callable</code></dt>
<dd>Callable to process each record from the batch</dd>
<dt><strong><code>processor</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.AsyncBatchProcessor" href="#aws_lambda_powertools.utilities.batch.AsyncBatchProcessor">AsyncBatchProcessor</a></code></dt>
<dd>Batch Processor to handle partial failure cases</dd>
<dt><strong><code>context</code></strong> :&ensp;<code>LambdaContext</code></dt>
<dd>Lambda's context, used to optionally inject in record handler</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>PartialItemFailureResponse</code></dt>
<dd>Lambda Partial Batch Response</dd>
</dl>
<h2 id="examples">Examples</h2>
<p><strong>Processes Lambda's SQS event</strong></p>
<pre><code class="language-python">from aws_lambda_powertools.utilities.batch import AsyncBatchProcessor, EventType, process_partial_response
from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord

processor = BatchProcessor(EventType.SQS)

async def record_handler(record: SQSRecord):
    return record.body

def handler(event, context):
    return async_process_partial_response(
        event=event, record_handler=record_handler, processor=processor, context=context
    )
</code></pre>
<h2 id="limitations">Limitations</h2>
<ul>
<li>Sync batch processors. Use <code><a title="aws_lambda_powertools.utilities.batch.process_partial_response" href="#aws_lambda_powertools.utilities.batch.process_partial_response">process_partial_response()</a></code> instead.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def async_process_partial_response(
    event: Dict,
    record_handler: Callable,
    processor: AsyncBatchProcessor,
    context: LambdaContext | None = None,
) -&gt; PartialItemFailureResponse:
    &#34;&#34;&#34;
    Higher level function to handle batch event processing asynchronously.

    Parameters
    ----------
    event: Dict
        Lambda&#39;s original event
    record_handler: Callable
        Callable to process each record from the batch
    processor: AsyncBatchProcessor
        Batch Processor to handle partial failure cases
    context: LambdaContext
        Lambda&#39;s context, used to optionally inject in record handler

    Returns
    -------
    result: PartialItemFailureResponse
        Lambda Partial Batch Response

    Examples
    --------
    **Processes Lambda&#39;s SQS event**

    ```python
    from aws_lambda_powertools.utilities.batch import AsyncBatchProcessor, EventType, process_partial_response
    from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord

    processor = BatchProcessor(EventType.SQS)

    async def record_handler(record: SQSRecord):
        return record.body

    def handler(event, context):
        return async_process_partial_response(
            event=event, record_handler=record_handler, processor=processor, context=context
        )
    ```

    Limitations
    -----------
    * Sync batch processors. Use `process_partial_response` instead.
    &#34;&#34;&#34;
    try:
        records: List[Dict] = event.get(&#34;Records&#34;, [])
    except AttributeError:
        event_types = &#34;, &#34;.join(list(EventType.__members__))
        docs = &#34;https://awslabs.github.io/aws-lambda-powertools-python/latest/utilities/batch/#processing-messages-from-sqs&#34;  # noqa: E501 # long-line
        raise ValueError(
            f&#34;Invalid event format. Please ensure batch event is a valid {processor.event_type.value} event. \n&#34;
            f&#34;See sample events in our documentation for either {event_types}: \n {docs}&#34;
        )

    with processor(records, record_handler, context):
        processor.async_process()

    return processor.response()</code></pre>
</details>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.batch_processor"><code class="name flex">
<span>def <span class="ident">batch_processor</span></span>(<span>handler: Callable, event: Dict, context: LambdaContext, record_handler: Callable, processor: <a title="aws_lambda_powertools.utilities.batch.BatchProcessor" href="#aws_lambda_powertools.utilities.batch.BatchProcessor">BatchProcessor</a>)</span>
</code></dt>
<dd>
<div class="desc"><p>Middleware to handle batch event processing</p>
<h2 id="notes">Notes</h2>
<p>Consider using process_partial_response function for an easier experience.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>handler</code></strong> :&ensp;<code>Callable</code></dt>
<dd>Lambda's handler</dd>
<dt><strong><code>event</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Lambda's Event</dd>
<dt><strong><code>context</code></strong> :&ensp;<code>LambdaContext</code></dt>
<dd>Lambda's Context</dd>
<dt><strong><code>record_handler</code></strong> :&ensp;<code>Callable</code></dt>
<dd>Callable or corutine to process each record from the batch</dd>
<dt><strong><code>processor</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.BatchProcessor" href="#aws_lambda_powertools.utilities.batch.BatchProcessor">BatchProcessor</a></code></dt>
<dd>Batch Processor to handle partial failure cases</dd>
</dl>
<h2 id="examples">Examples</h2>
<p><strong>Processes Lambda's event with a BatchProcessor</strong></p>
<pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import batch_processor, BatchProcessor, EventType
&gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
&gt;&gt;&gt;
&gt;&gt;&gt; processor = BatchProcessor(EventType.SQS)
&gt;&gt;&gt;
&gt;&gt;&gt; def record_handler(record):
&gt;&gt;&gt;     return record["body"]
&gt;&gt;&gt;
&gt;&gt;&gt; @batch_processor(record_handler=record_handler, processor=BatchProcessor())
&gt;&gt;&gt; def handler(event, context):
&gt;&gt;&gt;     return processor.response()
</code></pre>
<h2 id="limitations">Limitations</h2>
<ul>
<li>Async batch processors. Use <code><a title="aws_lambda_powertools.utilities.batch.async_batch_processor" href="#aws_lambda_powertools.utilities.batch.async_batch_processor">async_batch_processor()</a></code> instead.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@lambda_handler_decorator
def batch_processor(
    handler: Callable, event: Dict, context: LambdaContext, record_handler: Callable, processor: BatchProcessor
):
    &#34;&#34;&#34;
    Middleware to handle batch event processing

    Notes
    -----
    Consider using process_partial_response function for an easier experience.

    Parameters
    ----------
    handler: Callable
        Lambda&#39;s handler
    event: Dict
        Lambda&#39;s Event
    context: LambdaContext
        Lambda&#39;s Context
    record_handler: Callable
        Callable or corutine to process each record from the batch
    processor: BatchProcessor
        Batch Processor to handle partial failure cases

    Examples
    --------
    **Processes Lambda&#39;s event with a BatchProcessor**

        &gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import batch_processor, BatchProcessor, EventType
        &gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
        &gt;&gt;&gt;
        &gt;&gt;&gt; processor = BatchProcessor(EventType.SQS)
        &gt;&gt;&gt;
        &gt;&gt;&gt; def record_handler(record):
        &gt;&gt;&gt;     return record[&#34;body&#34;]
        &gt;&gt;&gt;
        &gt;&gt;&gt; @batch_processor(record_handler=record_handler, processor=BatchProcessor())
        &gt;&gt;&gt; def handler(event, context):
        &gt;&gt;&gt;     return processor.response()

    Limitations
    -----------
    * Async batch processors. Use `async_batch_processor` instead.
    &#34;&#34;&#34;
    records = event[&#34;Records&#34;]

    with processor(records, record_handler, lambda_context=context):
        processor.process()

    return handler(event, context)</code></pre>
</details>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.process_partial_response"><code class="name flex">
<span>def <span class="ident">process_partial_response</span></span>(<span>event: Dict, record_handler: Callable, processor: <a title="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor" href="#aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor">BasePartialBatchProcessor</a>, context: LambdaContext | None = None) ‑> <a title="aws_lambda_powertools.utilities.batch.types.PartialItemFailureResponse" href="types.html#aws_lambda_powertools.utilities.batch.types.PartialItemFailureResponse">PartialItemFailureResponse</a></span>
</code></dt>
<dd>
<div class="desc"><p>Higher level function to handle batch event processing.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>event</code></strong> :&ensp;<code>Dict</code></dt>
<dd>Lambda's original event</dd>
<dt><strong><code>record_handler</code></strong> :&ensp;<code>Callable</code></dt>
<dd>Callable to process each record from the batch</dd>
<dt><strong><code>processor</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor" href="#aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor">BasePartialBatchProcessor</a></code></dt>
<dd>Batch Processor to handle partial failure cases</dd>
<dt><strong><code>context</code></strong> :&ensp;<code>LambdaContext</code></dt>
<dd>Lambda's context, used to optionally inject in record handler</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result</code></strong> :&ensp;<code>PartialItemFailureResponse</code></dt>
<dd>Lambda Partial Batch Response</dd>
</dl>
<h2 id="examples">Examples</h2>
<p><strong>Processes Lambda's SQS event</strong></p>
<pre><code class="language-python">from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, process_partial_response
from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord

processor = BatchProcessor(EventType.SQS)

def record_handler(record: SQSRecord):
    return record.body

def handler(event, context):
    return process_partial_response(
        event=event, record_handler=record_handler, processor=processor, context=context
    )
</code></pre>
<h2 id="limitations">Limitations</h2>
<ul>
<li>Async batch processors. Use <code><a title="aws_lambda_powertools.utilities.batch.async_process_partial_response" href="#aws_lambda_powertools.utilities.batch.async_process_partial_response">async_process_partial_response()</a></code> instead.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_partial_response(
    event: Dict,
    record_handler: Callable,
    processor: BasePartialBatchProcessor,
    context: LambdaContext | None = None,
) -&gt; PartialItemFailureResponse:
    &#34;&#34;&#34;
    Higher level function to handle batch event processing.

    Parameters
    ----------
    event: Dict
        Lambda&#39;s original event
    record_handler: Callable
        Callable to process each record from the batch
    processor: BasePartialBatchProcessor
        Batch Processor to handle partial failure cases
    context: LambdaContext
        Lambda&#39;s context, used to optionally inject in record handler

    Returns
    -------
    result: PartialItemFailureResponse
        Lambda Partial Batch Response

    Examples
    --------
    **Processes Lambda&#39;s SQS event**

    ```python
    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, process_partial_response
    from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord

    processor = BatchProcessor(EventType.SQS)

    def record_handler(record: SQSRecord):
        return record.body

    def handler(event, context):
        return process_partial_response(
            event=event, record_handler=record_handler, processor=processor, context=context
        )
    ```

    Limitations
    -----------
    * Async batch processors. Use `async_process_partial_response` instead.
    &#34;&#34;&#34;
    try:
        records: List[Dict] = event.get(&#34;Records&#34;, [])
    except AttributeError:
        event_types = &#34;, &#34;.join(list(EventType.__members__))
        docs = &#34;https://awslabs.github.io/aws-lambda-powertools-python/latest/utilities/batch/#processing-messages-from-sqs&#34;  # noqa: E501 # long-line
        raise ValueError(
            f&#34;Invalid event format. Please ensure batch event is a valid {processor.event_type.value} event. \n&#34;
            f&#34;See sample events in our documentation for either {event_types}: \n {docs}&#34;
        )

    with processor(records, record_handler, context):
        processor.process()

    return processor.response()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.AsyncBatchProcessor"><code class="flex name class">
<span>class <span class="ident">AsyncBatchProcessor</span></span>
<span>(</span><span>event_type: <a title="aws_lambda_powertools.utilities.batch.base.EventType" href="base.html#aws_lambda_powertools.utilities.batch.base.EventType">EventType</a>, model: Optional[ForwardRef('BatchTypeModels')] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB asynchronously.</p>
<h2 id="example">Example</h2>
<h2 id="process-batch-triggered-by-sqs">Process batch triggered by SQS</h2>
<pre><code class="language-python">import json

from aws_lambda_powertools import Logger, Tracer
from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
from aws_lambda_powertools.utilities.typing import LambdaContext


processor = BatchProcessor(event_type=EventType.SQS)
tracer = Tracer()
logger = Logger()


@tracer.capture_method
async def record_handler(record: SQSRecord):
    payload: str = record.body
    if payload:
        item: dict = json.loads(payload)
    ...

@logger.inject_lambda_context
@tracer.capture_lambda_handler
@batch_processor(record_handler=record_handler, processor=processor)
def lambda_handler(event, context: LambdaContext):
    return processor.response()
</code></pre>
<h2 id="process-batch-triggered-by-kinesis-data-streams">Process batch triggered by Kinesis Data Streams</h2>
<pre><code class="language-python">import json

from aws_lambda_powertools import Logger, Tracer
from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
from aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import KinesisStreamRecord
from aws_lambda_powertools.utilities.typing import LambdaContext


processor = BatchProcessor(event_type=EventType.KinesisDataStreams)
tracer = Tracer()
logger = Logger()


@tracer.capture_method
async def record_handler(record: KinesisStreamRecord):
    logger.info(record.kinesis.data_as_text)
    payload: dict = record.kinesis.data_as_json()
    ...

@logger.inject_lambda_context
@tracer.capture_lambda_handler
@batch_processor(record_handler=record_handler, processor=processor)
def lambda_handler(event, context: LambdaContext):
    return processor.response()
</code></pre>
<h2 id="process-batch-triggered-by-dynamodb-data-streams">Process batch triggered by DynamoDB Data Streams</h2>
<pre><code class="language-python">import json

from aws_lambda_powertools import Logger, Tracer
from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import DynamoDBRecord
from aws_lambda_powertools.utilities.typing import LambdaContext


processor = BatchProcessor(event_type=EventType.DynamoDBStreams)
tracer = Tracer()
logger = Logger()


@tracer.capture_method
async def record_handler(record: DynamoDBRecord):
    logger.info(record.dynamodb.new_image)
    payload: dict = json.loads(record.dynamodb.new_image.get(&quot;item&quot;))
    # alternatively:
    # changes: Dict[str, Any] = record.dynamodb.new_image  # noqa: E800
    # payload = change.get(&quot;Message&quot;) -&gt; &quot;&lt;payload&gt;&quot;
    ...

@logger.inject_lambda_context
@tracer.capture_lambda_handler
def lambda_handler(event, context: LambdaContext):
    batch = event[&quot;Records&quot;]
    with processor(records=batch, processor=processor):
        processed_messages = processor.process() # kick off processing, return list[tuple]

    return processor.response()
</code></pre>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>BatchProcessingError</code></dt>
<dd>When all batch records fail processing</dd>
</dl>
<h2 id="limitations">Limitations</h2>
<ul>
<li>Sync record handler not supported, use BatchProcessor instead.</li>
</ul>
<p>Process batch and partially report failed items</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>event_type</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.EventType" href="#aws_lambda_powertools.utilities.batch.EventType">EventType</a></code></dt>
<dd>Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>Optional["BatchTypeModels"]</code></dt>
<dd>Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord</dd>
</dl>
<h2 id="exceptions">Exceptions</h2>
<p>BatchProcessingError
Raised when the entire batch has failed processing</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AsyncBatchProcessor(BasePartialBatchProcessor):
    &#34;&#34;&#34;Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB asynchronously.

    Example
    -------

    ## Process batch triggered by SQS

    ```python
    import json

    from aws_lambda_powertools import Logger, Tracer
    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
    from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
    from aws_lambda_powertools.utilities.typing import LambdaContext


    processor = BatchProcessor(event_type=EventType.SQS)
    tracer = Tracer()
    logger = Logger()


    @tracer.capture_method
    async def record_handler(record: SQSRecord):
        payload: str = record.body
        if payload:
            item: dict = json.loads(payload)
        ...

    @logger.inject_lambda_context
    @tracer.capture_lambda_handler
    @batch_processor(record_handler=record_handler, processor=processor)
    def lambda_handler(event, context: LambdaContext):
        return processor.response()
    ```

    ## Process batch triggered by Kinesis Data Streams

    ```python
    import json

    from aws_lambda_powertools import Logger, Tracer
    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
    from aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import KinesisStreamRecord
    from aws_lambda_powertools.utilities.typing import LambdaContext


    processor = BatchProcessor(event_type=EventType.KinesisDataStreams)
    tracer = Tracer()
    logger = Logger()


    @tracer.capture_method
    async def record_handler(record: KinesisStreamRecord):
        logger.info(record.kinesis.data_as_text)
        payload: dict = record.kinesis.data_as_json()
        ...

    @logger.inject_lambda_context
    @tracer.capture_lambda_handler
    @batch_processor(record_handler=record_handler, processor=processor)
    def lambda_handler(event, context: LambdaContext):
        return processor.response()
    ```

    ## Process batch triggered by DynamoDB Data Streams

    ```python
    import json

    from aws_lambda_powertools import Logger, Tracer
    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
    from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import DynamoDBRecord
    from aws_lambda_powertools.utilities.typing import LambdaContext


    processor = BatchProcessor(event_type=EventType.DynamoDBStreams)
    tracer = Tracer()
    logger = Logger()


    @tracer.capture_method
    async def record_handler(record: DynamoDBRecord):
        logger.info(record.dynamodb.new_image)
        payload: dict = json.loads(record.dynamodb.new_image.get(&#34;item&#34;))
        # alternatively:
        # changes: Dict[str, Any] = record.dynamodb.new_image  # noqa: E800
        # payload = change.get(&#34;Message&#34;) -&gt; &#34;&lt;payload&gt;&#34;
        ...

    @logger.inject_lambda_context
    @tracer.capture_lambda_handler
    def lambda_handler(event, context: LambdaContext):
        batch = event[&#34;Records&#34;]
        with processor(records=batch, processor=processor):
            processed_messages = processor.process() # kick off processing, return list[tuple]

        return processor.response()
    ```


    Raises
    ------
    BatchProcessingError
        When all batch records fail processing

    Limitations
    -----------
    * Sync record handler not supported, use BatchProcessor instead.
    &#34;&#34;&#34;

    def _process_record(self, record: dict):
        raise NotImplementedError()

    async def _async_process_record(self, record: dict) -&gt; Union[SuccessResponse, FailureResponse]:
        &#34;&#34;&#34;
        Process a record with instance&#39;s handler

        Parameters
        ----------
        record: dict
            A batch record to be processed.
        &#34;&#34;&#34;
        data: Optional[&#34;BatchTypeModels&#34;] = None
        try:
            data = self._to_batch_type(record=record, event_type=self.event_type, model=self.model)
            if self._handler_accepts_lambda_context:
                result = await self.handler(record=data, lambda_context=self.lambda_context)
            else:
                result = await self.handler(record=data)

            return self.success_handler(record=record, result=result)
        except Exception as exc:
            # NOTE: Pydantic is an optional dependency, but when used and a poison pill scenario happens
            # we need to handle that exception differently.
            # We check for a public attr in validation errors coming from Pydantic exceptions (subclass or not)
            # and we compare if it&#39;s coming from the same model that trigger the exception in the first place
            model = getattr(exc, &#34;model&#34;, None)
            if model == self.model:
                return self._register_model_validation_error_record(record)

            return self.failure_handler(record=data, exception=sys.exc_info())</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor">BasePartialBatchProcessor</a></li>
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor">BasePartialProcessor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor">BasePartialBatchProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.async_process" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.async_process">async_process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.failure_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.failure_handler">failure_handler</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.process" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.process">process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.response" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.response">response</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.success_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.success_handler">success_handler</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor"><code class="flex name class">
<span>class <span class="ident">BasePartialBatchProcessor</span></span>
<span>(</span><span>event_type: <a title="aws_lambda_powertools.utilities.batch.base.EventType" href="base.html#aws_lambda_powertools.utilities.batch.base.EventType">EventType</a>, model: Optional[ForwardRef('BatchTypeModels')] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract class for batch processors.</p>
<p>Process batch and partially report failed items</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>event_type</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.EventType" href="#aws_lambda_powertools.utilities.batch.EventType">EventType</a></code></dt>
<dd>Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>Optional["BatchTypeModels"]</code></dt>
<dd>Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord</dd>
</dl>
<h2 id="exceptions">Exceptions</h2>
<p>BatchProcessingError
Raised when the entire batch has failed processing</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BasePartialBatchProcessor(BasePartialProcessor):  # noqa
    DEFAULT_RESPONSE: Dict[str, List[Optional[dict]]] = {&#34;batchItemFailures&#34;: []}

    def __init__(self, event_type: EventType, model: Optional[&#34;BatchTypeModels&#34;] = None):
        &#34;&#34;&#34;Process batch and partially report failed items

        Parameters
        ----------
        event_type: EventType
            Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event
        model: Optional[&#34;BatchTypeModels&#34;]
            Parser&#39;s data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord

        Exceptions
        ----------
        BatchProcessingError
            Raised when the entire batch has failed processing
        &#34;&#34;&#34;
        self.event_type = event_type
        self.model = model
        self.batch_response = copy.deepcopy(self.DEFAULT_RESPONSE)
        self._COLLECTOR_MAPPING = {
            EventType.SQS: self._collect_sqs_failures,
            EventType.KinesisDataStreams: self._collect_kinesis_failures,
            EventType.DynamoDBStreams: self._collect_dynamodb_failures,
        }
        self._DATA_CLASS_MAPPING = {
            EventType.SQS: SQSRecord,
            EventType.KinesisDataStreams: KinesisStreamRecord,
            EventType.DynamoDBStreams: DynamoDBRecord,
        }

        super().__init__()

    def response(self):
        &#34;&#34;&#34;Batch items that failed processing, if any&#34;&#34;&#34;
        return self.batch_response

    def _prepare(self):
        &#34;&#34;&#34;
        Remove results from previous execution.
        &#34;&#34;&#34;
        self.success_messages.clear()
        self.fail_messages.clear()
        self.exceptions.clear()
        self.batch_response = copy.deepcopy(self.DEFAULT_RESPONSE)

    def _clean(self):
        &#34;&#34;&#34;
        Report messages to be deleted in case of partial failure.
        &#34;&#34;&#34;

        if not self._has_messages_to_report():
            return

        if self._entire_batch_failed():
            raise BatchProcessingError(
                msg=f&#34;All records failed processing. {len(self.exceptions)} individual errors logged &#34;
                f&#34;separately below.&#34;,
                child_exceptions=self.exceptions,
            )

        messages = self._get_messages_to_report()
        self.batch_response = {&#34;batchItemFailures&#34;: messages}

    def _has_messages_to_report(self) -&gt; bool:
        if self.fail_messages:
            return True

        logger.debug(f&#34;All {len(self.success_messages)} records successfully processed&#34;)
        return False

    def _entire_batch_failed(self) -&gt; bool:
        return len(self.exceptions) == len(self.records)

    def _get_messages_to_report(self) -&gt; List[Dict[str, str]]:
        &#34;&#34;&#34;
        Format messages to use in batch deletion
        &#34;&#34;&#34;
        return self._COLLECTOR_MAPPING[self.event_type]()

    # Event Source Data Classes follow python idioms for fields
    # while Parser/Pydantic follows the event field names to the latter
    def _collect_sqs_failures(self):
        failures = []
        for msg in self.fail_messages:
            # If a message failed due to model validation (e.g., poison pill)
            # we convert to an event source data class...but self.model is still true
            # therefore, we do an additional check on whether the failed message is still a model
            # see https://github.com/awslabs/aws-lambda-powertools-python/issues/2091
            if self.model and getattr(msg, &#34;parse_obj&#34;, None):
                msg_id = msg.messageId
            else:
                msg_id = msg.message_id
            failures.append({&#34;itemIdentifier&#34;: msg_id})
        return failures

    def _collect_kinesis_failures(self):
        failures = []
        for msg in self.fail_messages:
            # # see https://github.com/awslabs/aws-lambda-powertools-python/issues/2091
            if self.model and getattr(msg, &#34;parse_obj&#34;, None):
                msg_id = msg.kinesis.sequenceNumber
            else:
                msg_id = msg.kinesis.sequence_number
            failures.append({&#34;itemIdentifier&#34;: msg_id})
        return failures

    def _collect_dynamodb_failures(self):
        failures = []
        for msg in self.fail_messages:
            # see https://github.com/awslabs/aws-lambda-powertools-python/issues/2091
            if self.model and getattr(msg, &#34;parse_obj&#34;, None):
                msg_id = msg.dynamodb.SequenceNumber
            else:
                msg_id = msg.dynamodb.sequence_number
            failures.append({&#34;itemIdentifier&#34;: msg_id})
        return failures

    @overload
    def _to_batch_type(self, record: dict, event_type: EventType, model: &#34;BatchTypeModels&#34;) -&gt; &#34;BatchTypeModels&#34;:
        ...  # pragma: no cover

    @overload
    def _to_batch_type(self, record: dict, event_type: EventType) -&gt; EventSourceDataClassTypes:
        ...  # pragma: no cover

    def _to_batch_type(self, record: dict, event_type: EventType, model: Optional[&#34;BatchTypeModels&#34;] = None):
        if model is not None:
            return model.parse_obj(record)
        return self._DATA_CLASS_MAPPING[event_type](record)

    def _register_model_validation_error_record(self, record: dict):
        &#34;&#34;&#34;Convert and register failure due to poison pills where model failed validation early&#34;&#34;&#34;
        # Parser will fail validation if record is a poison pill (malformed input)
        # this means we can&#39;t collect the message id if we try transforming again
        # so we convert into to the equivalent batch type model (e.g., SQS, Kinesis, DynamoDB Stream)
        # and downstream we can correctly collect the correct message id identifier and make the failed record available
        # see https://github.com/awslabs/aws-lambda-powertools-python/issues/2091
        logger.debug(&#34;Record cannot be converted to customer&#39;s model; converting without model&#34;)
        failed_record: &#34;EventSourceDataClassTypes&#34; = self._to_batch_type(record=record, event_type=self.event_type)
        return self.failure_handler(record=failed_record, exception=sys.exc_info())</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor">BasePartialProcessor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="aws_lambda_powertools.utilities.batch.base.AsyncBatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.AsyncBatchProcessor">AsyncBatchProcessor</a></li>
<li><a title="aws_lambda_powertools.utilities.batch.base.BatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BatchProcessor">BatchProcessor</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor.DEFAULT_RESPONSE"><code class="name">var <span class="ident">DEFAULT_RESPONSE</span> : Dict[str, List[Optional[dict]]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor.response"><code class="name flex">
<span>def <span class="ident">response</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Batch items that failed processing, if any</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def response(self):
    &#34;&#34;&#34;Batch items that failed processing, if any&#34;&#34;&#34;
    return self.batch_response</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor">BasePartialProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.async_process" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.async_process">async_process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.failure_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.failure_handler">failure_handler</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.process" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.process">process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.success_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.success_handler">success_handler</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialProcessor"><code class="flex name class">
<span>class <span class="ident">BasePartialProcessor</span></span>
</code></dt>
<dd>
<div class="desc"><p>Abstract class for batch processors.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BasePartialProcessor(ABC):
    &#34;&#34;&#34;
    Abstract class for batch processors.
    &#34;&#34;&#34;

    lambda_context: LambdaContext

    def __init__(self):
        self.success_messages: List[BatchEventTypes] = []
        self.fail_messages: List[BatchEventTypes] = []
        self.exceptions: List[ExceptionInfo] = []

    @abstractmethod
    def _prepare(self):
        &#34;&#34;&#34;
        Prepare context manager.
        &#34;&#34;&#34;
        raise NotImplementedError()

    @abstractmethod
    def _clean(self):
        &#34;&#34;&#34;
        Clear context manager.
        &#34;&#34;&#34;
        raise NotImplementedError()

    @abstractmethod
    def _process_record(self, record: dict):
        &#34;&#34;&#34;
        Process record with handler.
        &#34;&#34;&#34;
        raise NotImplementedError()

    def process(self) -&gt; List[Tuple]:
        &#34;&#34;&#34;
        Call instance&#39;s handler for each record.
        &#34;&#34;&#34;
        return [self._process_record(record) for record in self.records]

    @abstractmethod
    async def _async_process_record(self, record: dict):
        &#34;&#34;&#34;
        Async process record with handler.
        &#34;&#34;&#34;
        raise NotImplementedError()

    def async_process(self) -&gt; List[Tuple]:
        &#34;&#34;&#34;
        Async call instance&#39;s handler for each record.

        Note
        ----

        We keep the outer function synchronous to prevent making Lambda handler async, so to not impact
        customers&#39; existing middlewares. Instead, we create an async closure to handle asynchrony.

        We also handle edge cases like Lambda container thaw by getting an existing or creating an event loop.

        See: https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html#runtimes-lifecycle-shutdown
        &#34;&#34;&#34;

        async def async_process_closure():
            return list(await asyncio.gather(*[self._async_process_record(record) for record in self.records]))

        # WARNING
        # Do not use &#34;asyncio.run(async_process())&#34; due to Lambda container thaws/freeze, otherwise we might get &#34;Event Loop is closed&#34; # noqa: E501
        # Instead, get_event_loop() can also create one if a previous was erroneously closed
        # Mangum library does this as well. It&#39;s battle tested with other popular async-only frameworks like FastAPI
        # https://github.com/jordaneremieff/mangum/discussions/256#discussioncomment-2638946
        # https://github.com/jordaneremieff/mangum/blob/b85cd4a97f8ddd56094ccc540ca7156c76081745/mangum/protocols/http.py#L44

        # Let&#39;s prime the coroutine and decide
        # whether we create an event loop (Lambda) or schedule it as usual (non-Lambda)
        coro = async_process_closure()
        if os.getenv(constants.LAMBDA_TASK_ROOT_ENV):
            loop = asyncio.get_event_loop()  # NOTE: this might return an error starting in Python 3.12 in a few years
            task_instance = loop.create_task(coro)
            return loop.run_until_complete(task_instance)

        # Non-Lambda environment, run coroutine as usual
        return asyncio.run(coro)

    def __enter__(self):
        self._prepare()
        return self

    def __exit__(self, exception_type, exception_value, traceback):
        self._clean()

    def __call__(self, records: List[dict], handler: Callable, lambda_context: Optional[LambdaContext] = None):
        &#34;&#34;&#34;
        Set instance attributes before execution

        Parameters
        ----------
        records: List[dict]
            List with objects to be processed.
        handler: Callable
            Callable to process &#34;records&#34; entries.
        &#34;&#34;&#34;
        self.records = records
        self.handler = handler

        # NOTE: If a record handler has `lambda_context` parameter in its function signature, we inject it.
        # This is the earliest we can inspect for signature to prevent impacting performance.
        #
        #   Mechanism:
        #
        #   1. When using the `@batch_processor` decorator, this happens automatically.
        #   2. When using the context manager, customers have to include `lambda_context` param.
        #
        #   Scenario: Injects Lambda context
        #
        #   def record_handler(record, lambda_context): ... # noqa: E800
        #   with processor(records=batch, handler=record_handler, lambda_context=context): ... # noqa: E800
        #
        #   Scenario: Does NOT inject Lambda context (default)
        #
        #   def record_handler(record): pass # noqa: E800
        #   with processor(records=batch, handler=record_handler): ... # noqa: E800
        #
        if lambda_context is None:
            self._handler_accepts_lambda_context = False
        else:
            self.lambda_context = lambda_context
            self._handler_accepts_lambda_context = &#34;lambda_context&#34; in inspect.signature(self.handler).parameters

        return self

    def success_handler(self, record, result: Any) -&gt; SuccessResponse:
        &#34;&#34;&#34;
        Keeps track of batch records that were processed successfully

        Parameters
        ----------
        record: Any
            record that succeeded processing
        result: Any
            result from record handler

        Returns
        -------
        SuccessResponse
            &#34;success&#34;, result, original record
        &#34;&#34;&#34;
        entry = (&#34;success&#34;, result, record)
        self.success_messages.append(record)
        return entry

    def failure_handler(self, record, exception: ExceptionInfo) -&gt; FailureResponse:
        &#34;&#34;&#34;
        Keeps track of batch records that failed processing

        Parameters
        ----------
        record: Any
            record that failed processing
        exception: ExceptionInfo
            Exception information containing type, value, and traceback (sys.exc_info())

        Returns
        -------
        FailureResponse
            &#34;fail&#34;, exceptions args, original record
        &#34;&#34;&#34;
        exception_string = f&#34;{exception[0]}:{exception[1]}&#34;
        entry = (&#34;fail&#34;, exception_string, record)
        logger.debug(f&#34;Record processing exception: {exception_string}&#34;)
        self.exceptions.append(exception)
        self.fail_messages.append(record)
        return entry</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor">BasePartialBatchProcessor</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialProcessor.lambda_context"><code class="name">var <span class="ident">lambda_context</span> : <a title="aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext" href="../typing/lambda_context.html#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext">LambdaContext</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialProcessor.async_process"><code class="name flex">
<span>def <span class="ident">async_process</span></span>(<span>self) ‑> List[Tuple]</span>
</code></dt>
<dd>
<div class="desc"><p>Async call instance's handler for each record.</p>
<h2 id="note">Note</h2>
<p>We keep the outer function synchronous to prevent making Lambda handler async, so to not impact
customers' existing middlewares. Instead, we create an async closure to handle asynchrony.</p>
<p>We also handle edge cases like Lambda container thaw by getting an existing or creating an event loop.</p>
<p>See: <a href="https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html#runtimes-lifecycle-shutdown">https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html#runtimes-lifecycle-shutdown</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def async_process(self) -&gt; List[Tuple]:
    &#34;&#34;&#34;
    Async call instance&#39;s handler for each record.

    Note
    ----

    We keep the outer function synchronous to prevent making Lambda handler async, so to not impact
    customers&#39; existing middlewares. Instead, we create an async closure to handle asynchrony.

    We also handle edge cases like Lambda container thaw by getting an existing or creating an event loop.

    See: https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html#runtimes-lifecycle-shutdown
    &#34;&#34;&#34;

    async def async_process_closure():
        return list(await asyncio.gather(*[self._async_process_record(record) for record in self.records]))

    # WARNING
    # Do not use &#34;asyncio.run(async_process())&#34; due to Lambda container thaws/freeze, otherwise we might get &#34;Event Loop is closed&#34; # noqa: E501
    # Instead, get_event_loop() can also create one if a previous was erroneously closed
    # Mangum library does this as well. It&#39;s battle tested with other popular async-only frameworks like FastAPI
    # https://github.com/jordaneremieff/mangum/discussions/256#discussioncomment-2638946
    # https://github.com/jordaneremieff/mangum/blob/b85cd4a97f8ddd56094ccc540ca7156c76081745/mangum/protocols/http.py#L44

    # Let&#39;s prime the coroutine and decide
    # whether we create an event loop (Lambda) or schedule it as usual (non-Lambda)
    coro = async_process_closure()
    if os.getenv(constants.LAMBDA_TASK_ROOT_ENV):
        loop = asyncio.get_event_loop()  # NOTE: this might return an error starting in Python 3.12 in a few years
        task_instance = loop.create_task(coro)
        return loop.run_until_complete(task_instance)

    # Non-Lambda environment, run coroutine as usual
    return asyncio.run(coro)</code></pre>
</details>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialProcessor.failure_handler"><code class="name flex">
<span>def <span class="ident">failure_handler</span></span>(<span>self, record, exception: Tuple[Optional[Type[BaseException]], Optional[BaseException], Optional[traceback]]) ‑> Tuple[str, str, Union[<a title="aws_lambda_powertools.utilities.data_classes.sqs_event.SQSRecord" href="../data_classes/sqs_event.html#aws_lambda_powertools.utilities.data_classes.sqs_event.SQSRecord">SQSRecord</a>, <a title="aws_lambda_powertools.utilities.data_classes.kinesis_stream_event.KinesisStreamRecord" href="../data_classes/kinesis_stream_event.html#aws_lambda_powertools.utilities.data_classes.kinesis_stream_event.KinesisStreamRecord">KinesisStreamRecord</a>, <a title="aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event.DynamoDBRecord" href="../data_classes/dynamo_db_stream_event.html#aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event.DynamoDBRecord">DynamoDBRecord</a>, Type[<a title="aws_lambda_powertools.utilities.parser.models.sqs.SqsRecordModel" href="../parser/models/sqs.html#aws_lambda_powertools.utilities.parser.models.sqs.SqsRecordModel">SqsRecordModel</a>], Type[<a title="aws_lambda_powertools.utilities.parser.models.dynamodb.DynamoDBStreamRecordModel" href="../parser/models/dynamodb.html#aws_lambda_powertools.utilities.parser.models.dynamodb.DynamoDBStreamRecordModel">DynamoDBStreamRecordModel</a>], Type[<a title="aws_lambda_powertools.utilities.parser.models.kinesis.KinesisDataStreamRecord" href="../parser/models/kinesis.html#aws_lambda_powertools.utilities.parser.models.kinesis.KinesisDataStreamRecord">KinesisDataStreamRecord</a>], ForwardRef(None)]]</span>
</code></dt>
<dd>
<div class="desc"><p>Keeps track of batch records that failed processing</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>record</code></strong> :&ensp;<code>Any</code></dt>
<dd>record that failed processing</dd>
<dt><strong><code>exception</code></strong> :&ensp;<code>ExceptionInfo</code></dt>
<dd>Exception information containing type, value, and traceback (sys.exc_info())</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>FailureResponse</code></dt>
<dd>"fail", exceptions args, original record</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def failure_handler(self, record, exception: ExceptionInfo) -&gt; FailureResponse:
    &#34;&#34;&#34;
    Keeps track of batch records that failed processing

    Parameters
    ----------
    record: Any
        record that failed processing
    exception: ExceptionInfo
        Exception information containing type, value, and traceback (sys.exc_info())

    Returns
    -------
    FailureResponse
        &#34;fail&#34;, exceptions args, original record
    &#34;&#34;&#34;
    exception_string = f&#34;{exception[0]}:{exception[1]}&#34;
    entry = (&#34;fail&#34;, exception_string, record)
    logger.debug(f&#34;Record processing exception: {exception_string}&#34;)
    self.exceptions.append(exception)
    self.fail_messages.append(record)
    return entry</code></pre>
</details>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialProcessor.process"><code class="name flex">
<span>def <span class="ident">process</span></span>(<span>self) ‑> List[Tuple]</span>
</code></dt>
<dd>
<div class="desc"><p>Call instance's handler for each record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process(self) -&gt; List[Tuple]:
    &#34;&#34;&#34;
    Call instance&#39;s handler for each record.
    &#34;&#34;&#34;
    return [self._process_record(record) for record in self.records]</code></pre>
</details>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.BasePartialProcessor.success_handler"><code class="name flex">
<span>def <span class="ident">success_handler</span></span>(<span>self, record, result: Any) ‑> Tuple[str, Any, Union[<a title="aws_lambda_powertools.utilities.data_classes.sqs_event.SQSRecord" href="../data_classes/sqs_event.html#aws_lambda_powertools.utilities.data_classes.sqs_event.SQSRecord">SQSRecord</a>, <a title="aws_lambda_powertools.utilities.data_classes.kinesis_stream_event.KinesisStreamRecord" href="../data_classes/kinesis_stream_event.html#aws_lambda_powertools.utilities.data_classes.kinesis_stream_event.KinesisStreamRecord">KinesisStreamRecord</a>, <a title="aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event.DynamoDBRecord" href="../data_classes/dynamo_db_stream_event.html#aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event.DynamoDBRecord">DynamoDBRecord</a>, Type[<a title="aws_lambda_powertools.utilities.parser.models.sqs.SqsRecordModel" href="../parser/models/sqs.html#aws_lambda_powertools.utilities.parser.models.sqs.SqsRecordModel">SqsRecordModel</a>], Type[<a title="aws_lambda_powertools.utilities.parser.models.dynamodb.DynamoDBStreamRecordModel" href="../parser/models/dynamodb.html#aws_lambda_powertools.utilities.parser.models.dynamodb.DynamoDBStreamRecordModel">DynamoDBStreamRecordModel</a>], Type[<a title="aws_lambda_powertools.utilities.parser.models.kinesis.KinesisDataStreamRecord" href="../parser/models/kinesis.html#aws_lambda_powertools.utilities.parser.models.kinesis.KinesisDataStreamRecord">KinesisDataStreamRecord</a>], ForwardRef(None)]]</span>
</code></dt>
<dd>
<div class="desc"><p>Keeps track of batch records that were processed successfully</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>record</code></strong> :&ensp;<code>Any</code></dt>
<dd>record that succeeded processing</dd>
<dt><strong><code>result</code></strong> :&ensp;<code>Any</code></dt>
<dd>result from record handler</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>SuccessResponse</code></dt>
<dd>"success", result, original record</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def success_handler(self, record, result: Any) -&gt; SuccessResponse:
    &#34;&#34;&#34;
    Keeps track of batch records that were processed successfully

    Parameters
    ----------
    record: Any
        record that succeeded processing
    result: Any
        result from record handler

    Returns
    -------
    SuccessResponse
        &#34;success&#34;, result, original record
    &#34;&#34;&#34;
    entry = (&#34;success&#34;, result, record)
    self.success_messages.append(record)
    return entry</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.BatchProcessor"><code class="flex name class">
<span>class <span class="ident">BatchProcessor</span></span>
<span>(</span><span>event_type: <a title="aws_lambda_powertools.utilities.batch.base.EventType" href="base.html#aws_lambda_powertools.utilities.batch.base.EventType">EventType</a>, model: Optional[ForwardRef('BatchTypeModels')] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB.</p>
<h2 id="example">Example</h2>
<h2 id="process-batch-triggered-by-sqs">Process batch triggered by SQS</h2>
<pre><code class="language-python">import json

from aws_lambda_powertools import Logger, Tracer
from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
from aws_lambda_powertools.utilities.typing import LambdaContext


processor = BatchProcessor(event_type=EventType.SQS)
tracer = Tracer()
logger = Logger()


@tracer.capture_method
def record_handler(record: SQSRecord):
    payload: str = record.body
    if payload:
        item: dict = json.loads(payload)
    ...

@logger.inject_lambda_context
@tracer.capture_lambda_handler
@batch_processor(record_handler=record_handler, processor=processor)
def lambda_handler(event, context: LambdaContext):
    return processor.response()
</code></pre>
<h2 id="process-batch-triggered-by-kinesis-data-streams">Process batch triggered by Kinesis Data Streams</h2>
<pre><code class="language-python">import json

from aws_lambda_powertools import Logger, Tracer
from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
from aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import KinesisStreamRecord
from aws_lambda_powertools.utilities.typing import LambdaContext


processor = BatchProcessor(event_type=EventType.KinesisDataStreams)
tracer = Tracer()
logger = Logger()


@tracer.capture_method
def record_handler(record: KinesisStreamRecord):
    logger.info(record.kinesis.data_as_text)
    payload: dict = record.kinesis.data_as_json()
    ...

@logger.inject_lambda_context
@tracer.capture_lambda_handler
@batch_processor(record_handler=record_handler, processor=processor)
def lambda_handler(event, context: LambdaContext):
    return processor.response()
</code></pre>
<h2 id="process-batch-triggered-by-dynamodb-data-streams">Process batch triggered by DynamoDB Data Streams</h2>
<pre><code class="language-python">import json

from aws_lambda_powertools import Logger, Tracer
from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import DynamoDBRecord
from aws_lambda_powertools.utilities.typing import LambdaContext


processor = BatchProcessor(event_type=EventType.DynamoDBStreams)
tracer = Tracer()
logger = Logger()


@tracer.capture_method
def record_handler(record: DynamoDBRecord):
    logger.info(record.dynamodb.new_image)
    payload: dict = json.loads(record.dynamodb.new_image.get(&quot;item&quot;))
    # alternatively:
    # changes: Dict[str, Any] = record.dynamodb.new_image  # noqa: E800
    # payload = change.get(&quot;Message&quot;) -&gt; &quot;&lt;payload&gt;&quot;
    ...

@logger.inject_lambda_context
@tracer.capture_lambda_handler
def lambda_handler(event, context: LambdaContext):
    batch = event[&quot;Records&quot;]
    with processor(records=batch, processor=processor):
        processed_messages = processor.process() # kick off processing, return list[tuple]

    return processor.response()
</code></pre>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>BatchProcessingError</code></dt>
<dd>When all batch records fail processing</dd>
</dl>
<h2 id="limitations">Limitations</h2>
<ul>
<li>Async record handler not supported, use AsyncBatchProcessor instead.</li>
</ul>
<p>Process batch and partially report failed items</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>event_type</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.EventType" href="#aws_lambda_powertools.utilities.batch.EventType">EventType</a></code></dt>
<dd>Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>Optional["BatchTypeModels"]</code></dt>
<dd>Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord</dd>
</dl>
<h2 id="exceptions">Exceptions</h2>
<p>BatchProcessingError
Raised when the entire batch has failed processing</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BatchProcessor(BasePartialBatchProcessor):  # Keep old name for compatibility
    &#34;&#34;&#34;Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB.

    Example
    -------

    ## Process batch triggered by SQS

    ```python
    import json

    from aws_lambda_powertools import Logger, Tracer
    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
    from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
    from aws_lambda_powertools.utilities.typing import LambdaContext


    processor = BatchProcessor(event_type=EventType.SQS)
    tracer = Tracer()
    logger = Logger()


    @tracer.capture_method
    def record_handler(record: SQSRecord):
        payload: str = record.body
        if payload:
            item: dict = json.loads(payload)
        ...

    @logger.inject_lambda_context
    @tracer.capture_lambda_handler
    @batch_processor(record_handler=record_handler, processor=processor)
    def lambda_handler(event, context: LambdaContext):
        return processor.response()
    ```

    ## Process batch triggered by Kinesis Data Streams

    ```python
    import json

    from aws_lambda_powertools import Logger, Tracer
    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
    from aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import KinesisStreamRecord
    from aws_lambda_powertools.utilities.typing import LambdaContext


    processor = BatchProcessor(event_type=EventType.KinesisDataStreams)
    tracer = Tracer()
    logger = Logger()


    @tracer.capture_method
    def record_handler(record: KinesisStreamRecord):
        logger.info(record.kinesis.data_as_text)
        payload: dict = record.kinesis.data_as_json()
        ...

    @logger.inject_lambda_context
    @tracer.capture_lambda_handler
    @batch_processor(record_handler=record_handler, processor=processor)
    def lambda_handler(event, context: LambdaContext):
        return processor.response()
    ```

    ## Process batch triggered by DynamoDB Data Streams

    ```python
    import json

    from aws_lambda_powertools import Logger, Tracer
    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor
    from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import DynamoDBRecord
    from aws_lambda_powertools.utilities.typing import LambdaContext


    processor = BatchProcessor(event_type=EventType.DynamoDBStreams)
    tracer = Tracer()
    logger = Logger()


    @tracer.capture_method
    def record_handler(record: DynamoDBRecord):
        logger.info(record.dynamodb.new_image)
        payload: dict = json.loads(record.dynamodb.new_image.get(&#34;item&#34;))
        # alternatively:
        # changes: Dict[str, Any] = record.dynamodb.new_image  # noqa: E800
        # payload = change.get(&#34;Message&#34;) -&gt; &#34;&lt;payload&gt;&#34;
        ...

    @logger.inject_lambda_context
    @tracer.capture_lambda_handler
    def lambda_handler(event, context: LambdaContext):
        batch = event[&#34;Records&#34;]
        with processor(records=batch, processor=processor):
            processed_messages = processor.process() # kick off processing, return list[tuple]

        return processor.response()
    ```


    Raises
    ------
    BatchProcessingError
        When all batch records fail processing

    Limitations
    -----------
    * Async record handler not supported, use AsyncBatchProcessor instead.
    &#34;&#34;&#34;

    async def _async_process_record(self, record: dict):
        raise NotImplementedError()

    def _process_record(self, record: dict) -&gt; Union[SuccessResponse, FailureResponse]:
        &#34;&#34;&#34;
        Process a record with instance&#39;s handler

        Parameters
        ----------
        record: dict
            A batch record to be processed.
        &#34;&#34;&#34;
        data: Optional[&#34;BatchTypeModels&#34;] = None
        try:
            data = self._to_batch_type(record=record, event_type=self.event_type, model=self.model)
            if self._handler_accepts_lambda_context:
                result = self.handler(record=data, lambda_context=self.lambda_context)
            else:
                result = self.handler(record=data)

            return self.success_handler(record=record, result=result)
        except Exception as exc:
            # NOTE: Pydantic is an optional dependency, but when used and a poison pill scenario happens
            # we need to handle that exception differently.
            # We check for a public attr in validation errors coming from Pydantic exceptions (subclass or not)
            # and we compare if it&#39;s coming from the same model that trigger the exception in the first place
            model = getattr(exc, &#34;model&#34;, None)
            if model == self.model:
                return self._register_model_validation_error_record(record)

            return self.failure_handler(record=data, exception=sys.exc_info())</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor">BasePartialBatchProcessor</a></li>
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor">BasePartialProcessor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor.SqsFifoPartialProcessor" href="sqs_fifo_partial_processor.html#aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor.SqsFifoPartialProcessor">SqsFifoPartialProcessor</a></li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor">BasePartialBatchProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.async_process" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.async_process">async_process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.failure_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.failure_handler">failure_handler</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.process" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.process">process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.response" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.response">response</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.success_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.success_handler">success_handler</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.EventType"><code class="flex name class">
<span>class <span class="ident">EventType</span></span>
<span>(</span><span>value, names=None, *, module=None, qualname=None, type=None, start=1)</span>
</code></dt>
<dd>
<div class="desc"><p>An enumeration.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class EventType(Enum):
    SQS = &#34;SQS&#34;
    KinesisDataStreams = &#34;KinesisDataStreams&#34;
    DynamoDBStreams = &#34;DynamoDBStreams&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>enum.Enum</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.EventType.DynamoDBStreams"><code class="name">var <span class="ident">DynamoDBStreams</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.EventType.KinesisDataStreams"><code class="name">var <span class="ident">KinesisDataStreams</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.EventType.SQS"><code class="name">var <span class="ident">SQS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</dd>
<dt id="aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor"><code class="flex name class">
<span>class <span class="ident">SqsFifoPartialProcessor</span></span>
<span>(</span><span>model: Optional[ForwardRef('BatchSqsTypeModel')] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Process native partial responses from SQS FIFO queues.</p>
<p>Stops processing records when the first record fails. The remaining records are reported as failed items.</p>
<p>Example</p>
<hr>
<h2 id="process-batch-triggered-by-a-fifo-sqs">Process batch triggered by a FIFO SQS</h2>
<pre><code class="language-python">import json

from aws_lambda_powertools import Logger, Tracer
from aws_lambda_powertools.utilities.batch import SqsFifoPartialProcessor, EventType, batch_processor
from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
from aws_lambda_powertools.utilities.typing import LambdaContext


processor = SqsFifoPartialProcessor()
tracer = Tracer()
logger = Logger()


@tracer.capture_method
def record_handler(record: SQSRecord):
    payload: str = record.body
    if payload:
        item: dict = json.loads(payload)
    ...

@logger.inject_lambda_context
@tracer.capture_lambda_handler
@batch_processor(record_handler=record_handler, processor=processor)
def lambda_handler(event, context: LambdaContext):
    return processor.response()
</code></pre>
<p>Process batch and partially report failed items</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>event_type</code></strong> :&ensp;<code><a title="aws_lambda_powertools.utilities.batch.EventType" href="#aws_lambda_powertools.utilities.batch.EventType">EventType</a></code></dt>
<dd>Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>Optional["BatchTypeModels"]</code></dt>
<dd>Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord</dd>
</dl>
<h2 id="exceptions">Exceptions</h2>
<p>BatchProcessingError
Raised when the entire batch has failed processing</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SqsFifoPartialProcessor(BatchProcessor):
    &#34;&#34;&#34;Process native partial responses from SQS FIFO queues.

    Stops processing records when the first record fails. The remaining records are reported as failed items.

    Example
    _______

    ## Process batch triggered by a FIFO SQS

    ```python
    import json

    from aws_lambda_powertools import Logger, Tracer
    from aws_lambda_powertools.utilities.batch import SqsFifoPartialProcessor, EventType, batch_processor
    from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord
    from aws_lambda_powertools.utilities.typing import LambdaContext


    processor = SqsFifoPartialProcessor()
    tracer = Tracer()
    logger = Logger()


    @tracer.capture_method
    def record_handler(record: SQSRecord):
        payload: str = record.body
        if payload:
            item: dict = json.loads(payload)
        ...

    @logger.inject_lambda_context
    @tracer.capture_lambda_handler
    @batch_processor(record_handler=record_handler, processor=processor)
    def lambda_handler(event, context: LambdaContext):
        return processor.response()
    ```
    &#34;&#34;&#34;

    circuit_breaker_exc = (
        SQSFifoCircuitBreakerError,
        SQSFifoCircuitBreakerError(&#34;A previous record failed processing&#34;),
        None,
    )

    def __init__(self, model: Optional[&#34;BatchSqsTypeModel&#34;] = None):
        super().__init__(EventType.SQS, model)

    def process(self) -&gt; List[Tuple]:
        &#34;&#34;&#34;
        Call instance&#39;s handler for each record. When the first failed message is detected,
        the process is short-circuited, and the remaining messages are reported as failed items.
        &#34;&#34;&#34;
        result: List[Tuple] = []

        for i, record in enumerate(self.records):
            # If we have failed messages, it means that the last message failed.
            # We then short circuit the process, failing the remaining messages
            if self.fail_messages:
                return self._short_circuit_processing(i, result)

            # Otherwise, process the message normally
            result.append(self._process_record(record))

        return result

    def _short_circuit_processing(self, first_failure_index: int, result: List[Tuple]) -&gt; List[Tuple]:
        &#34;&#34;&#34;
        Starting from the first failure index, fail all the remaining messages, and append them to the result list.
        &#34;&#34;&#34;
        remaining_records = self.records[first_failure_index:]
        for remaining_record in remaining_records:
            data = self._to_batch_type(record=remaining_record, event_type=self.event_type, model=self.model)
            result.append(self.failure_handler(record=data, exception=self.circuit_breaker_exc))
        return result

    async def _async_process_record(self, record: dict):
        raise NotImplementedError()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="aws_lambda_powertools.utilities.batch.base.BatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BatchProcessor">BatchProcessor</a></li>
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor">BasePartialBatchProcessor</a></li>
<li><a title="aws_lambda_powertools.utilities.batch.base.BasePartialProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor">BasePartialProcessor</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor.circuit_breaker_exc"><code class="name">var <span class="ident">circuit_breaker_exc</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor.process"><code class="name flex">
<span>def <span class="ident">process</span></span>(<span>self) ‑> List[Tuple]</span>
</code></dt>
<dd>
<div class="desc"><p>Call instance's handler for each record. When the first failed message is detected,
the process is short-circuited, and the remaining messages are reported as failed items.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process(self) -&gt; List[Tuple]:
    &#34;&#34;&#34;
    Call instance&#39;s handler for each record. When the first failed message is detected,
    the process is short-circuited, and the remaining messages are reported as failed items.
    &#34;&#34;&#34;
    result: List[Tuple] = []

    for i, record in enumerate(self.records):
        # If we have failed messages, it means that the last message failed.
        # We then short circuit the process, failing the remaining messages
        if self.fail_messages:
            return self._short_circuit_processing(i, result)

        # Otherwise, process the message normally
        result.append(self._process_record(record))

    return result</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="aws_lambda_powertools.utilities.batch.base.BatchProcessor" href="base.html#aws_lambda_powertools.utilities.batch.base.BatchProcessor">BatchProcessor</a></b></code>:
<ul class="hlist">
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BatchProcessor.async_process" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.async_process">async_process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BatchProcessor.failure_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.failure_handler">failure_handler</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BatchProcessor.response" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.response">response</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.base.BatchProcessor.success_handler" href="base.html#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.success_handler">success_handler</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="aws_lambda_powertools.utilities" href="../index.html">aws_lambda_powertools.utilities</a></code></li>
</ul>
</li>
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="aws_lambda_powertools.utilities.batch.base" href="base.html">aws_lambda_powertools.utilities.batch.base</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.decorators" href="decorators.html">aws_lambda_powertools.utilities.batch.decorators</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.exceptions" href="exceptions.html">aws_lambda_powertools.utilities.batch.exceptions</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor" href="sqs_fifo_partial_processor.html">aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.types" href="types.html">aws_lambda_powertools.utilities.batch.types</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="aws_lambda_powertools.utilities.batch.async_batch_processor" href="#aws_lambda_powertools.utilities.batch.async_batch_processor">async_batch_processor</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.async_process_partial_response" href="#aws_lambda_powertools.utilities.batch.async_process_partial_response">async_process_partial_response</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.batch_processor" href="#aws_lambda_powertools.utilities.batch.batch_processor">batch_processor</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.process_partial_response" href="#aws_lambda_powertools.utilities.batch.process_partial_response">process_partial_response</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="aws_lambda_powertools.utilities.batch.AsyncBatchProcessor" href="#aws_lambda_powertools.utilities.batch.AsyncBatchProcessor">AsyncBatchProcessor</a></code></h4>
</li>
<li>
<h4><code><a title="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor" href="#aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor">BasePartialBatchProcessor</a></code></h4>
<ul class="">
<li><code><a title="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor.DEFAULT_RESPONSE" href="#aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor.DEFAULT_RESPONSE">DEFAULT_RESPONSE</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor.response" href="#aws_lambda_powertools.utilities.batch.BasePartialBatchProcessor.response">response</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="aws_lambda_powertools.utilities.batch.BasePartialProcessor" href="#aws_lambda_powertools.utilities.batch.BasePartialProcessor">BasePartialProcessor</a></code></h4>
<ul class="">
<li><code><a title="aws_lambda_powertools.utilities.batch.BasePartialProcessor.async_process" href="#aws_lambda_powertools.utilities.batch.BasePartialProcessor.async_process">async_process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.BasePartialProcessor.failure_handler" href="#aws_lambda_powertools.utilities.batch.BasePartialProcessor.failure_handler">failure_handler</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.BasePartialProcessor.lambda_context" href="#aws_lambda_powertools.utilities.batch.BasePartialProcessor.lambda_context">lambda_context</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.BasePartialProcessor.process" href="#aws_lambda_powertools.utilities.batch.BasePartialProcessor.process">process</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.BasePartialProcessor.success_handler" href="#aws_lambda_powertools.utilities.batch.BasePartialProcessor.success_handler">success_handler</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="aws_lambda_powertools.utilities.batch.BatchProcessor" href="#aws_lambda_powertools.utilities.batch.BatchProcessor">BatchProcessor</a></code></h4>
</li>
<li>
<h4><code><a title="aws_lambda_powertools.utilities.batch.EventType" href="#aws_lambda_powertools.utilities.batch.EventType">EventType</a></code></h4>
<ul class="">
<li><code><a title="aws_lambda_powertools.utilities.batch.EventType.DynamoDBStreams" href="#aws_lambda_powertools.utilities.batch.EventType.DynamoDBStreams">DynamoDBStreams</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.EventType.KinesisDataStreams" href="#aws_lambda_powertools.utilities.batch.EventType.KinesisDataStreams">KinesisDataStreams</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.EventType.SQS" href="#aws_lambda_powertools.utilities.batch.EventType.SQS">SQS</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor" href="#aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor">SqsFifoPartialProcessor</a></code></h4>
<ul class="">
<li><code><a title="aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor.circuit_breaker_exc" href="#aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor.circuit_breaker_exc">circuit_breaker_exc</a></code></li>
<li><code><a title="aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor.process" href="#aws_lambda_powertools.utilities.batch.SqsFifoPartialProcessor.process">process</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>